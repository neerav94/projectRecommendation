Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

re-write the same, which is in contrast to that in the Map-
Reduce framework.

In this paper, we consider the class of applications which
can be treated for data parallel black-box-style execution,
where the input data can be partitioned into arbitrary smaller
subsets and multiple instances of the same application can
be executed, in parallel, on every data subsets. We as-
sume the existence of a combiner application which can then
gather the results from the execution instances and combine
them into a uniﬁed result. A cloud computing platform in
the IoT context is expected to contain heterogeneous ma-
chines, like sensor gateways, personal computers at home,
or mobile communication devices, etc., connected via links
with heterogeneous characteristics. These devices are not
dedicated computing resources and are usually connected via
unreliable communication links. The availability of both the
computing resources and communication links are bursty,
and even the computation elements may not be available
with their full power. In such a platform the performance of
analysis of a data-set will depend on the appropriate parti-
tioning and distribution of the data-set considering the avail-
ability pattern of the resources. In this paper we attempt
to address the problem of data partitioning for black-box
kind of data analysis applications in the IoT context with
the objective to minimize the overall execution time of an
analytical application.

This paper is organized as follows. Section 2 presents
some related background on data distribution and partition
in distributed computing domain, along with the complex-
ity of the problem. A formalism of the problem is shown in
Section 3. A heuristic to obtain a partition of data based on
capacity of the participant nodes is presented in Section 4.
Simulation results are presented in Section 5. Finally Sec-
tion 6 concludes this paper with directions to future work.

2. BACKGROUND

One of the potential factor of improving the performance
of a distributed platform is the eﬀect of movement of data for
computation. Bent et al analyzed the problem of schedul-
ing when data movement is considered along with compu-
tation [4]. Kosar et al propose a batch processing system
which is aware of data volume [12].

Google’s Map-Reduce framework [6] eﬀectively exploits
the power of distributed system for many data intensive
problems. The platform was later adopted as the Hadoop
open source project [1] by Yahoo. Researchers are working
on the techniques of improving the performance of Hadoop-
like Map-Reduce frameworks. Authors in [20] investigate the
eﬀect of data locality for Map-Reduce jobs in Hadoop sys-
tem and propose a data-locality aware scheduler for Hadoop.
The Quincy scheduler balances the priority of the task with
locality of data [11]. In a Map-Reduce framework skewness
of data distribution hinders system throughput, when some
reduce-servers are loaded with more data to process. Au-
thors in [9] present a data partition scheme to balance the
data processing load on reduce-servers. Their approach is
a greedy one where the least loaded server gets the largest
partition.

A computing system can be viewed as a producer-consumer
system, where application and data are producers of com-
puting demand and the computing elements are consumers
of such demands. The rate of consumption of computing
demand by a computing resource can deﬁned as the capac-

ity of the resource. Capacity of computing elements in a
system plays an important role in the problem of data par-
titioning. Capacity models are not easy to deﬁne since there
are interdependencies among diﬀerent elements of computa-
tion. Some detailed models of computing capacity can be
found in [7, 15, 16]. Authors in [2] use a simple model of
capacity computation, which is a linear combination CPU
clock speed, memory size, bandwidth, etc, and they parti-
tion a data set according to the capacity ratio of the nodes.
Then they show that this simple method of partitioning can
improve the performance of some simple Map-Reduce pro-
grams.

In this paper we propose a model of data partitioner such
that the overall computation span of a job is minimized. The
next section discusses the complexity of the problem we are
addressing.

2.1 Complexity of the Problem

In this paper we consider an application A which processes
a data-set and generates a result. Mathematically, we con-
sider the application as a function, deﬁned as A : P(D) →
R, where the range R deﬁnes the set from which the return
value of the algorithm A is drawn. The domain of the appli-
cation is a set of data drawn from D, denoted as the power
set of D, P(D).

Let D be a member of P(D) acting as an input set. Let
D = {d1, d2, d3, . . . , dm}. We partition D into n segments
D1, D2, D3, . . . , Dn such that Sn
i=1 Di = D and Di ∩ Dj =
∅ : 1 ≤ i, j ≤ n, i 6= j and typically n ≤ m. In a distributed
computing platform, n instances of A can be initiated with
diﬀerent partitions of the input set, i.e. , we have a set of
tasks J = {A(D1), A(D2), . . . , A(Dn)}. We assume that
the existence of a combiner/reducer which takes care of the
return values of these instances, but is outside the scope of
this paper.

Completion time of each task A(Di) will depend on vari-
ous system and application parameters. We want to achieve
an eﬀective partition such that the make-span of J , which
in the ﬁeld of research in scheduling refers to the latest com-
pletion time of the tasks, is minimized.

The problem of data partitioning can be reduced into a
more generic and well researched ﬁeld of scheduling. Instead
of creating n partitions of D, one can create m partitions,
each containing exactly one, atomic data element. Execu-
tion of these m partitions with m instances of A gives us a
job of m tasks J ′ = {A(d1), A(d2), . . . , A(dm)}, which now
need to be scheduled on n resources.

However, in the context of IoT framework, nodes and com-
munication links may not always be available. Scheduling
under such availability constraint in multi-processor system
has been studied [17,19]. The version of the scheduling prob-
lem we address in this paper falls in the class Q|pmtn, rs|Cmax,
implying that jobs can be preempted and resumed later, and
processes are unavailable in multiple time-durations during
the whole scheduling time-span, where the objective is to
minimize the make-span of the jobs. The problem without
any availability constraint (P ||Cmax) is known to be NP-
hard, the problem with availability constraints (P |rs|Cmax),
where jobs can be resumed, is also hard [14]. Therefore, the
non-uniform processing version of the problem Q|rs|Cmax
is also hard. In our present work we address the problem
of scheduling when the machines are of diﬀerent speeds and
the tasks are independent.

Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

re-write the same, which is in contrast to that in the Map-
Reduce framework.

In this paper, we consider the class of applications which
can be treated for data parallel black-box-style execution,
where the input data can be partitioned into arbitrary smaller
subsets and multiple instances of the same application can
be executed, in parallel, on every data subsets. We as-
sume the existence of a combiner application which can then
gather the results from the execution instances and combine
them into a uniﬁed result. A cloud computing platform in
the IoT context is expected to contain heterogeneous ma-
chines, like sensor gateways, personal computers at home,
or mobile communication devices, etc., connected via links
with heterogeneous characteristics. These devices are not
dedicated computing resources and are usually connected via
unreliable communication links. The availability of both the
computing resources and communication links are bursty,
and even the computation elements may not be available
with their full power. In such a platform the performance of
analysis of a data-set will depend on the appropriate parti-
tioning and distribution of the data-set considering the avail-
ability pattern of the resources. In this paper we attempt
to address the problem of data partitioning for black-box
kind of data analysis applications in the IoT context with
the objective to minimize the overall execution time of an
analytical application.

This paper is organized as follows. Section 2 presents
some related background on data distribution and partition
in distributed computing domain, along with the complex-
ity of the problem. A formalism of the problem is shown in
Section 3. A heuristic to obtain a partition of data based on
capacity of the participant nodes is presented in Section 4.
Simulation results are presented in Section 5. Finally Sec-
tion 6 concludes this paper with directions to future work.

2. BACKGROUND

One of the potential factor of improving the performance
of a distributed platform is the eﬀect of movement of data for
computation. Bent et al analyzed the problem of schedul-
ing when data movement is considered along with compu-
tation [4]. Kosar et al propose a batch processing system
which is aware of data volume [12].

Google’s Map-Reduce framework [6] eﬀectively exploits
the power of distributed system for many data intensive
problems. The platform was later adopted as the Hadoop
open source project [1] by Yahoo. Researchers are working
on the techniques of improving the performance of Hadoop-
like Map-Reduce frameworks. Authors in [20] investigate the
eﬀect of data locality for Map-Reduce jobs in Hadoop sys-
tem and propose a data-locality aware scheduler for Hadoop.
The Quincy scheduler balances the priority of the task with
locality of data [11]. In a Map-Reduce framework skewness
of data distribution hinders system throughput, when some
reduce-servers are loaded with more data to process. Au-
thors in [9] present a data partition scheme to balance the
data processing load on reduce-servers. Their approach is
a greedy one where the least loaded server gets the largest
partition.

A computing system can be viewed as a producer-consumer
system, where application and data are producers of com-
puting demand and the computing elements are consumers
of such demands. The rate of consumption of computing
demand by a computing resource can deﬁned as the capac-

ity of the resource. Capacity of computing elements in a
system plays an important role in the problem of data par-
titioning. Capacity models are not easy to deﬁne since there
are interdependencies among diﬀerent elements of computa-
tion. Some detailed models of computing capacity can be
found in [7, 15, 16]. Authors in [2] use a simple model of
capacity computation, which is a linear combination CPU
clock speed, memory size, bandwidth, etc, and they parti-
tion a data set according to the capacity ratio of the nodes.
Then they show that this simple method of partitioning can
improve the performance of some simple Map-Reduce pro-
grams.

In this paper we propose a model of data partitioner such
that the overall computation span of a job is minimized. The
next section discusses the complexity of the problem we are
addressing.

2.1 Complexity of the Problem

In this paper we consider an application A which processes
a data-set and generates a result. Mathematically, we con-
sider the application as a function, deﬁned as A : P(D) →
R, where the range R deﬁnes the set from which the return
value of the algorithm A is drawn. The domain of the appli-
cation is a set of data drawn from D, denoted as the power
set of D, P(D).

Let D be a member of P(D) acting as an input set. Let
D = {d1, d2, d3, . . . , dm}. We partition D into n segments
D1, D2, D3, . . . , Dn such that Sn
i=1 Di = D and Di ∩ Dj =
∅ : 1 ≤ i, j ≤ n, i 6= j and typically n ≤ m. In a distributed
computing platform, n instances of A can be initiated with
diﬀerent partitions of the input set, i.e. , we have a set of
tasks J = {A(D1), A(D2), . . . , A(Dn)}. We assume that
the existence of a combiner/reducer which takes care of the
return values of these instances, but is outside the scope of
this paper.

Completion time of each task A(Di) will depend on vari-
ous system and application parameters. We want to achieve
an eﬀective partition such that the make-span of J , which
in the ﬁeld of research in scheduling refers to the latest com-
pletion time of the tasks, is minimized.

The problem of data partitioning can be reduced into a
more generic and well researched ﬁeld of scheduling. Instead
of creating n partitions of D, one can create m partitions,
each containing exactly one, atomic data element. Execu-
tion of these m partitions with m instances of A gives us a
job of m tasks J ′ = {A(d1), A(d2), . . . , A(dm)}, which now
need to be scheduled on n resources.

However, in the context of IoT framework, nodes and com-
munication links may not always be available. Scheduling
under such availability constraint in multi-processor system
has been studied [17,19]. The version of the scheduling prob-
lem we address in this paper falls in the class Q|pmtn, rs|Cmax,
implying that jobs can be preempted and resumed later, and
processes are unavailable in multiple time-durations during
the whole scheduling time-span, where the objective is to
minimize the make-span of the jobs. The problem without
any availability constraint (P ||Cmax) is known to be NP-
hard, the problem with availability constraints (P |rs|Cmax),
where jobs can be resumed, is also hard [14]. Therefore, the
non-uniform processing version of the problem Q|rs|Cmax
is also hard. In our present work we address the problem
of scheduling when the machines are of diﬀerent speeds and
the tasks are independent.

The problem of scheduling under availability-constraint is
well studied. This section provides some relevant results for
the class of scheduling problems we are addressing in this
paper. Schmidt studied the problem Pm|pmtn, rs|Cmax and
gave conditions under which a feasible preemptive sched-
ule exists [18]. He shows that such a feasible solution can
be constructed in O(n + m × log m), where m is number
of machines and n is the number of jobs. He also showed
that number of scheduler induced preemption is proportional
to the number of processing intervals. Lawler and Mar-
tel proposed a pseudo-polynomial time algorithm for the
scheduling problem involving two machines with preemptive
jobs under total weighted tardiness minimization criterion,
i.e. Q2|pmtn, rs|P wjUj [13]. For more than two machines
under the criterion of minimization of maximum lateness of
jobs (Q|rj, pmtn|Lmax), a polynomial time algorithm was
proposed by B˜la˙zewicz et al [3]. Gharbi et al present heuris-
tics for problems in P, N Cinc||Cmax and P |rj, qj|Cmax and
showed that their algorithm can work for large instances of
the problems [8]. Hashemian in his masters dissertation [10]
presents ILP formulations for some scheduling problem un-
der availability constraints.

In this paper, we assume unavailability are advertised by
the nodes or links and are, therefore, known in advance. We
consider developing a static schedule and partition of data
elements which takes into account the advertised availabili-
ties. In the next section we present a heuristic to determine
a schedule to reduce make-span of the job.

3. PROBLEM DEFINITION

We assume a distributed computing environment where
one central node, acting as data partitioner (DP), is con-
nected to n computing nodes, P = {P1, P2, . . . , Pn}, in a
star topology. The edges are associated with a weight, li,
depicting link speed. A node is characterized by a tuple
{si, vi}, where si denote the CPU speed (clock speed) and
vi is the advertised non-availability of the node.

The data partitioner has in its possession the data D =
{d1, d2, . . . dm}. We assume the non-availability of the nodes
and links are advertised. Under these constraints the prob-
lem is to achieve a partition of the data D into n partitions
D1, D2, . . . , Dn and each partition Di is assigned to process
Pi, such that the make-span of the job is minimized. We say
a partition of D is consistent iﬀ,

n

[

i=1

Di = D

Di ∩ Dj = ∅ . . . 1 ≤ i, j ≤ n,

i 6= j

(1)

(2)

The model of the problem assumes the tasks to be homo-
geneous and independent, and therefore independent. This
essentially implies that the data partition problem can be
transformed into partition problem of the number of data
elements.

4. HEURISTIC FOR MAKE-SPAN

MINIMIZATION

In this section we present a heuristic to partition a data
set D to assign to a set of n processes. The heuristic is based
on the ratio-based data partition model, but it continuously
reﬁnes the partitions considering advertised non-availability

of the processes. The outline of the algorithm is presented
as Algorithm 1.

The algorithm starts with a partition obtained by apply-
ing ratio-based partition from the capacity of the processes.
This partition method considers that processes are always
available. The make-span obtained from this partition is a
base make-span, mse which does not consider intermittent
unavailability and hence signiﬁes a lower limit of the make-
span for the given data set. Due to intermittent unavailabil-
ity of a process, the completion time of processing the data
partition assigned to it will be pushed away from its base
completion time. This may eﬀectively cause an elongation
of the make-span of processing D. The algorithm, then,
tries to reﬁne the partition to reduce the eﬀective make-
span by re-assigning some data element to other processes
in the following manner. We deﬁne slack time as the dura-
tion [mse, ms]. It estimates total number of data elements
processed during the slack time period and these are then
redistributed using the ratio model. This iteration contin-
ues until there is no substantial improvement in the eﬀective
make-span in subsequent passes.

In the presentation of this heuristic, we assume the follow-
ing model of capacity of a computing element, which consists
of the communication link with the DP and the computing
element itself. We deﬁne capacity as a linear composition of
the cost of transfer of one data element form DP and pro-
cessing cost of the element at the node. The communication
cost is the estimated latency of transferring one data element
from the DP to the node and can be expressed as a func-
tion of the link speed. The computation cost is the estimated
time to process one data element in the node. The computa-
tion cost model is subject of independent research. Here we
assume that some estimate of the cost can be obtained from
some model involving the algorithmic complexity of prob-
lem, CPU speed, memory capacity at all levels, disk speed,
etc [2]. In the heuristic presented in Algorithm 1, has to its
disposal the tuple < N , P > as the system model, where

• N : N → R : deﬁnes the network latency to transfer
one data element from DP. N (i) = tn implies that tn
time unit is required to transfer one data element from
DP to Pi.

• P : N → R : deﬁnes processing speed of one data
element. P(i) = tp implies Pi requires tp time units to
process one data element.

Similarly the availability of each of the ith resource elements
can be described as < Vi >, where,

• Vi : N → {0, 1} is a binary function which denotes
whether link or computation node of a resource ele-
ment is available at certain time unit and is deﬁned
as,

Vi(t) =




true . . .

f alse . . .

Pi and link between DP and
Piare available at the
tth time-unit
otherwise

We deﬁne the following vector of functions to charac-
terize availability of computation elements in the sys-
tem.

~V =< V1, V2, . . . Vn >

Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

re-write the same, which is in contrast to that in the Map-
Reduce framework.

In this paper, we consider the class of applications which
can be treated for data parallel black-box-style execution,
where the input data can be partitioned into arbitrary smaller
subsets and multiple instances of the same application can
be executed, in parallel, on every data subsets. We as-
sume the existence of a combiner application which can then
gather the results from the execution instances and combine
them into a uniﬁed result. A cloud computing platform in
the IoT context is expected to contain heterogeneous ma-
chines, like sensor gateways, personal computers at home,
or mobile communication devices, etc., connected via links
with heterogeneous characteristics. These devices are not
dedicated computing resources and are usually connected via
unreliable communication links. The availability of both the
computing resources and communication links are bursty,
and even the computation elements may not be available
with their full power. In such a platform the performance of
analysis of a data-set will depend on the appropriate parti-
tioning and distribution of the data-set considering the avail-
ability pattern of the resources. In this paper we attempt
to address the problem of data partitioning for black-box
kind of data analysis applications in the IoT context with
the objective to minimize the overall execution time of an
analytical application.

This paper is organized as follows. Section 2 presents
some related background on data distribution and partition
in distributed computing domain, along with the complex-
ity of the problem. A formalism of the problem is shown in
Section 3. A heuristic to obtain a partition of data based on
capacity of the participant nodes is presented in Section 4.
Simulation results are presented in Section 5. Finally Sec-
tion 6 concludes this paper with directions to future work.

2. BACKGROUND

One of the potential factor of improving the performance
of a distributed platform is the eﬀect of movement of data for
computation. Bent et al analyzed the problem of schedul-
ing when data movement is considered along with compu-
tation [4]. Kosar et al propose a batch processing system
which is aware of data volume [12].

Google’s Map-Reduce framework [6] eﬀectively exploits
the power of distributed system for many data intensive
problems. The platform was later adopted as the Hadoop
open source project [1] by Yahoo. Researchers are working
on the techniques of improving the performance of Hadoop-
like Map-Reduce frameworks. Authors in [20] investigate the
eﬀect of data locality for Map-Reduce jobs in Hadoop sys-
tem and propose a data-locality aware scheduler for Hadoop.
The Quincy scheduler balances the priority of the task with
locality of data [11]. In a Map-Reduce framework skewness
of data distribution hinders system throughput, when some
reduce-servers are loaded with more data to process. Au-
thors in [9] present a data partition scheme to balance the
data processing load on reduce-servers. Their approach is
a greedy one where the least loaded server gets the largest
partition.

A computing system can be viewed as a producer-consumer
system, where application and data are producers of com-
puting demand and the computing elements are consumers
of such demands. The rate of consumption of computing
demand by a computing resource can deﬁned as the capac-

ity of the resource. Capacity of computing elements in a
system plays an important role in the problem of data par-
titioning. Capacity models are not easy to deﬁne since there
are interdependencies among diﬀerent elements of computa-
tion. Some detailed models of computing capacity can be
found in [7, 15, 16]. Authors in [2] use a simple model of
capacity computation, which is a linear combination CPU
clock speed, memory size, bandwidth, etc, and they parti-
tion a data set according to the capacity ratio of the nodes.
Then they show that this simple method of partitioning can
improve the performance of some simple Map-Reduce pro-
grams.

In this paper we propose a model of data partitioner such
that the overall computation span of a job is minimized. The
next section discusses the complexity of the problem we are
addressing.

2.1 Complexity of the Problem

In this paper we consider an application A which processes
a data-set and generates a result. Mathematically, we con-
sider the application as a function, deﬁned as A : P(D) →
R, where the range R deﬁnes the set from which the return
value of the algorithm A is drawn. The domain of the appli-
cation is a set of data drawn from D, denoted as the power
set of D, P(D).

Let D be a member of P(D) acting as an input set. Let
D = {d1, d2, d3, . . . , dm}. We partition D into n segments
D1, D2, D3, . . . , Dn such that Sn
i=1 Di = D and Di ∩ Dj =
∅ : 1 ≤ i, j ≤ n, i 6= j and typically n ≤ m. In a distributed
computing platform, n instances of A can be initiated with
diﬀerent partitions of the input set, i.e. , we have a set of
tasks J = {A(D1), A(D2), . . . , A(Dn)}. We assume that
the existence of a combiner/reducer which takes care of the
return values of these instances, but is outside the scope of
this paper.

Completion time of each task A(Di) will depend on vari-
ous system and application parameters. We want to achieve
an eﬀective partition such that the make-span of J , which
in the ﬁeld of research in scheduling refers to the latest com-
pletion time of the tasks, is minimized.

The problem of data partitioning can be reduced into a
more generic and well researched ﬁeld of scheduling. Instead
of creating n partitions of D, one can create m partitions,
each containing exactly one, atomic data element. Execu-
tion of these m partitions with m instances of A gives us a
job of m tasks J ′ = {A(d1), A(d2), . . . , A(dm)}, which now
need to be scheduled on n resources.

However, in the context of IoT framework, nodes and com-
munication links may not always be available. Scheduling
under such availability constraint in multi-processor system
has been studied [17,19]. The version of the scheduling prob-
lem we address in this paper falls in the class Q|pmtn, rs|Cmax,
implying that jobs can be preempted and resumed later, and
processes are unavailable in multiple time-durations during
the whole scheduling time-span, where the objective is to
minimize the make-span of the jobs. The problem without
any availability constraint (P ||Cmax) is known to be NP-
hard, the problem with availability constraints (P |rs|Cmax),
where jobs can be resumed, is also hard [14]. Therefore, the
non-uniform processing version of the problem Q|rs|Cmax
is also hard. In our present work we address the problem
of scheduling when the machines are of diﬀerent speeds and
the tasks are independent.

The problem of scheduling under availability-constraint is
well studied. This section provides some relevant results for
the class of scheduling problems we are addressing in this
paper. Schmidt studied the problem Pm|pmtn, rs|Cmax and
gave conditions under which a feasible preemptive sched-
ule exists [18]. He shows that such a feasible solution can
be constructed in O(n + m × log m), where m is number
of machines and n is the number of jobs. He also showed
that number of scheduler induced preemption is proportional
to the number of processing intervals. Lawler and Mar-
tel proposed a pseudo-polynomial time algorithm for the
scheduling problem involving two machines with preemptive
jobs under total weighted tardiness minimization criterion,
i.e. Q2|pmtn, rs|P wjUj [13]. For more than two machines
under the criterion of minimization of maximum lateness of
jobs (Q|rj, pmtn|Lmax), a polynomial time algorithm was
proposed by B˜la˙zewicz et al [3]. Gharbi et al present heuris-
tics for problems in P, N Cinc||Cmax and P |rj, qj|Cmax and
showed that their algorithm can work for large instances of
the problems [8]. Hashemian in his masters dissertation [10]
presents ILP formulations for some scheduling problem un-
der availability constraints.

In this paper, we assume unavailability are advertised by
the nodes or links and are, therefore, known in advance. We
consider developing a static schedule and partition of data
elements which takes into account the advertised availabili-
ties. In the next section we present a heuristic to determine
a schedule to reduce make-span of the job.

3. PROBLEM DEFINITION

We assume a distributed computing environment where
one central node, acting as data partitioner (DP), is con-
nected to n computing nodes, P = {P1, P2, . . . , Pn}, in a
star topology. The edges are associated with a weight, li,
depicting link speed. A node is characterized by a tuple
{si, vi}, where si denote the CPU speed (clock speed) and
vi is the advertised non-availability of the node.

The data partitioner has in its possession the data D =
{d1, d2, . . . dm}. We assume the non-availability of the nodes
and links are advertised. Under these constraints the prob-
lem is to achieve a partition of the data D into n partitions
D1, D2, . . . , Dn and each partition Di is assigned to process
Pi, such that the make-span of the job is minimized. We say
a partition of D is consistent iﬀ,

n

[

i=1

Di = D

Di ∩ Dj = ∅ . . . 1 ≤ i, j ≤ n,

i 6= j

(1)

(2)

The model of the problem assumes the tasks to be homo-
geneous and independent, and therefore independent. This
essentially implies that the data partition problem can be
transformed into partition problem of the number of data
elements.

4. HEURISTIC FOR MAKE-SPAN

MINIMIZATION

In this section we present a heuristic to partition a data
set D to assign to a set of n processes. The heuristic is based
on the ratio-based data partition model, but it continuously
reﬁnes the partitions considering advertised non-availability

of the processes. The outline of the algorithm is presented
as Algorithm 1.

The algorithm starts with a partition obtained by apply-
ing ratio-based partition from the capacity of the processes.
This partition method considers that processes are always
available. The make-span obtained from this partition is a
base make-span, mse which does not consider intermittent
unavailability and hence signiﬁes a lower limit of the make-
span for the given data set. Due to intermittent unavailabil-
ity of a process, the completion time of processing the data
partition assigned to it will be pushed away from its base
completion time. This may eﬀectively cause an elongation
of the make-span of processing D. The algorithm, then,
tries to reﬁne the partition to reduce the eﬀective make-
span by re-assigning some data element to other processes
in the following manner. We deﬁne slack time as the dura-
tion [mse, ms]. It estimates total number of data elements
processed during the slack time period and these are then
redistributed using the ratio model. This iteration contin-
ues until there is no substantial improvement in the eﬀective
make-span in subsequent passes.

In the presentation of this heuristic, we assume the follow-
ing model of capacity of a computing element, which consists
of the communication link with the DP and the computing
element itself. We deﬁne capacity as a linear composition of
the cost of transfer of one data element form DP and pro-
cessing cost of the element at the node. The communication
cost is the estimated latency of transferring one data element
from the DP to the node and can be expressed as a func-
tion of the link speed. The computation cost is the estimated
time to process one data element in the node. The computa-
tion cost model is subject of independent research. Here we
assume that some estimate of the cost can be obtained from
some model involving the algorithmic complexity of prob-
lem, CPU speed, memory capacity at all levels, disk speed,
etc [2]. In the heuristic presented in Algorithm 1, has to its
disposal the tuple < N , P > as the system model, where

• N : N → R : deﬁnes the network latency to transfer
one data element from DP. N (i) = tn implies that tn
time unit is required to transfer one data element from
DP to Pi.

• P : N → R : deﬁnes processing speed of one data
element. P(i) = tp implies Pi requires tp time units to
process one data element.

Similarly the availability of each of the ith resource elements
can be described as < Vi >, where,

• Vi : N → {0, 1} is a binary function which denotes
whether link or computation node of a resource ele-
ment is available at certain time unit and is deﬁned
as,

Vi(t) =




true . . .

f alse . . .

Pi and link between DP and
Piare available at the
tth time-unit
otherwise

We deﬁne the following vector of functions to charac-
terize availability of computation elements in the sys-
tem.

~V =< V1, V2, . . . Vn >

We assume time units to be discrete, i.e. if time unit is in
seconds, then Vi(t) = 0 implies the ith resource element is
unavailable for the full tth second.

4.1 Proof of Correctness

The proof of correctness of the heuristic involves proving

• Consistency of the partition. The data partition ob-
tained from the heuristic is consistent, i.e. it satisﬁes
the conditions of Equations 1 and 2.

• Termination. The heuristic terminates in ﬁnite time.

Our heuristic is based on the ratio-based partition and we
assume that the ratio-based partition satisﬁes all the above
correctness criterion. Based on this we prove the followings.

Proof. Consistency of Partition: The proof of the con-
sistency rests on the ratio-partition algorithm, which serves
as the basis of our heuristic. We assume that the partition
of D obtained from ratio-model at the line 1 of Algorithm 1
i=1 Di = D is

is consistent. So at this line the invariant Pn

satisﬁed.

The for-loop starting at line 1 calculates the aggregate
number of data elements, ∆D, which will be processed in the
slack time, i.e. beyond the ideal make-span time-line (ideal
make-span is computed without considering unavailability
of the processes). At line ?? the algorithm determines the
count of data elements processes in the slack time for ith
process as ∆d. The ∆d is cumulated in ∆D at line 1 before
being subtracted from the Di at line 1. Therefore at the end
i=1 Di(cid:1) + ∆D = D
The ratio-based partition at line 1 partitions only ∆D
and by the consistency guarantee of the algorithm the in-
i=1 ∆Di = ∆D holds. Therefore, the invariant

of the for-loop at line 1 the invariant (cid:0)Pn

variant Pn
i=1 Di(cid:1) + (cid:0)Pn
(cid:0)Pn
Finally the values of ∆Di’s are added with the D′

i=1 ∆Di(cid:1) = D also holds.

holds.

is in the
for-loop at line 1. So, at the end of the for-loop, invariant
i=1 Di = D holds. Therefore at the end of the algorithm
i=1 Di = D holds and Di’s can be used to

Pn
the condition Pn

obtain a consistent partition of D. Hence proved.

Now we prove the termination property of the algorithm.

Proof. Termination: First we show that the Algorithm 2
terminates. To show this we need to show that condition at
line 2 is satisﬁed. The initial value of lastτ is the comple-
tion time of analysis of D data elements.
In the repeat-
until loop of the algorithm, the value of τ monotonically
increases. Therefore, the value of cτ also monotonically in-
creases. Since the the value of cτ is the count of unavailable
slots in τ duration and there are ﬁnite number of unavailable
slots, increment of cτ is also ﬁnite. Therefore, the condition
at line 2 will be satisﬁed in ﬁnite time.

Now we show that the unconditional loop encompassing
lines 1 - 1 of algorithm 1 is terminated by execution of break
at line 1 in ﬁnite time. We need to show that the if-condition
checking at the line 1 is successful in ﬁnite execution time.
The if-condition at line 1 checks the diﬀerence between the
make-span of the previous run of the loop with the make-
span corresponding to the reﬁned partition of D. In each
iteration of the loop the make-span value computed in ms
should steadily decrease, otherwise the if-condition is satis-
ﬁed and the algorithm terminates.

Algorithm 1: Makespan-Reﬁnement
input : D, N , P, ~V
output: A partition of the data
begin

Partition D as (D1, D2, D3, . . . Dn) using
ratio-based model ;
for 1 ≤ i ≤ n do

/* Compute completion time of each
partitions without availability
information

Ci = CompletionT ime (Di, N (i), P(i), ∅);

/* Compute make-span without considering

unavailability of the processes

*/

*/

mse ← max {Ci : 1 ≤ i ≤ n};
lastms ← mse;
repeat

for 1 ≤ i ≤ n do

/* Compute completion time of each

partitions using availability
information

*/

Ci ←
CompletionT ime(cid:16)Di, N (i), P(i), ~V ↑i(cid:17);

/* Compute make-span with unavailability

information

ms ← max {Ci : 1 ≤ i ≤ n};
if lastms ≤ ms then

/* No more refinement of partitions

possible

break from loop

∆D ← 0 ;
for 1 ≤ i ≤ n do

*/

*/

/* Slack time :

computation effort of

Pi on Di data elements in the
interval [mse, ms]

*/

∆d ← ⌊ mse −ms
if ∆d > 0 then

N (i)+P(i) ⌋;

/* Calculate the number of data

elements processed in the slack
time

*/

Di ← Di − ∆d ;
∆D ← ∆D + ∆d ;

Partition ∆D as (∆D1, ∆D2, . . . ∆Dn) using
ratio-based model. ;
for 1 ≤ i ≤ n do Di ← Di + ∆Di ;
lastms ← ms ;

until;
Return partition (D1, D2, . . . Dn) ;

Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

re-write the same, which is in contrast to that in the Map-
Reduce framework.

In this paper, we consider the class of applications which
can be treated for data parallel black-box-style execution,
where the input data can be partitioned into arbitrary smaller
subsets and multiple instances of the same application can
be executed, in parallel, on every data subsets. We as-
sume the existence of a combiner application which can then
gather the results from the execution instances and combine
them into a uniﬁed result. A cloud computing platform in
the IoT context is expected to contain heterogeneous ma-
chines, like sensor gateways, personal computers at home,
or mobile communication devices, etc., connected via links
with heterogeneous characteristics. These devices are not
dedicated computing resources and are usually connected via
unreliable communication links. The availability of both the
computing resources and communication links are bursty,
and even the computation elements may not be available
with their full power. In such a platform the performance of
analysis of a data-set will depend on the appropriate parti-
tioning and distribution of the data-set considering the avail-
ability pattern of the resources. In this paper we attempt
to address the problem of data partitioning for black-box
kind of data analysis applications in the IoT context with
the objective to minimize the overall execution time of an
analytical application.

This paper is organized as follows. Section 2 presents
some related background on data distribution and partition
in distributed computing domain, along with the complex-
ity of the problem. A formalism of the problem is shown in
Section 3. A heuristic to obtain a partition of data based on
capacity of the participant nodes is presented in Section 4.
Simulation results are presented in Section 5. Finally Sec-
tion 6 concludes this paper with directions to future work.

2. BACKGROUND

One of the potential factor of improving the performance
of a distributed platform is the eﬀect of movement of data for
computation. Bent et al analyzed the problem of schedul-
ing when data movement is considered along with compu-
tation [4]. Kosar et al propose a batch processing system
which is aware of data volume [12].

Google’s Map-Reduce framework [6] eﬀectively exploits
the power of distributed system for many data intensive
problems. The platform was later adopted as the Hadoop
open source project [1] by Yahoo. Researchers are working
on the techniques of improving the performance of Hadoop-
like Map-Reduce frameworks. Authors in [20] investigate the
eﬀect of data locality for Map-Reduce jobs in Hadoop sys-
tem and propose a data-locality aware scheduler for Hadoop.
The Quincy scheduler balances the priority of the task with
locality of data [11]. In a Map-Reduce framework skewness
of data distribution hinders system throughput, when some
reduce-servers are loaded with more data to process. Au-
thors in [9] present a data partition scheme to balance the
data processing load on reduce-servers. Their approach is
a greedy one where the least loaded server gets the largest
partition.

A computing system can be viewed as a producer-consumer
system, where application and data are producers of com-
puting demand and the computing elements are consumers
of such demands. The rate of consumption of computing
demand by a computing resource can deﬁned as the capac-

ity of the resource. Capacity of computing elements in a
system plays an important role in the problem of data par-
titioning. Capacity models are not easy to deﬁne since there
are interdependencies among diﬀerent elements of computa-
tion. Some detailed models of computing capacity can be
found in [7, 15, 16]. Authors in [2] use a simple model of
capacity computation, which is a linear combination CPU
clock speed, memory size, bandwidth, etc, and they parti-
tion a data set according to the capacity ratio of the nodes.
Then they show that this simple method of partitioning can
improve the performance of some simple Map-Reduce pro-
grams.

In this paper we propose a model of data partitioner such
that the overall computation span of a job is minimized. The
next section discusses the complexity of the problem we are
addressing.

2.1 Complexity of the Problem

In this paper we consider an application A which processes
a data-set and generates a result. Mathematically, we con-
sider the application as a function, deﬁned as A : P(D) →
R, where the range R deﬁnes the set from which the return
value of the algorithm A is drawn. The domain of the appli-
cation is a set of data drawn from D, denoted as the power
set of D, P(D).

Let D be a member of P(D) acting as an input set. Let
D = {d1, d2, d3, . . . , dm}. We partition D into n segments
D1, D2, D3, . . . , Dn such that Sn
i=1 Di = D and Di ∩ Dj =
∅ : 1 ≤ i, j ≤ n, i 6= j and typically n ≤ m. In a distributed
computing platform, n instances of A can be initiated with
diﬀerent partitions of the input set, i.e. , we have a set of
tasks J = {A(D1), A(D2), . . . , A(Dn)}. We assume that
the existence of a combiner/reducer which takes care of the
return values of these instances, but is outside the scope of
this paper.

Completion time of each task A(Di) will depend on vari-
ous system and application parameters. We want to achieve
an eﬀective partition such that the make-span of J , which
in the ﬁeld of research in scheduling refers to the latest com-
pletion time of the tasks, is minimized.

The problem of data partitioning can be reduced into a
more generic and well researched ﬁeld of scheduling. Instead
of creating n partitions of D, one can create m partitions,
each containing exactly one, atomic data element. Execu-
tion of these m partitions with m instances of A gives us a
job of m tasks J ′ = {A(d1), A(d2), . . . , A(dm)}, which now
need to be scheduled on n resources.

However, in the context of IoT framework, nodes and com-
munication links may not always be available. Scheduling
under such availability constraint in multi-processor system
has been studied [17,19]. The version of the scheduling prob-
lem we address in this paper falls in the class Q|pmtn, rs|Cmax,
implying that jobs can be preempted and resumed later, and
processes are unavailable in multiple time-durations during
the whole scheduling time-span, where the objective is to
minimize the make-span of the jobs. The problem without
any availability constraint (P ||Cmax) is known to be NP-
hard, the problem with availability constraints (P |rs|Cmax),
where jobs can be resumed, is also hard [14]. Therefore, the
non-uniform processing version of the problem Q|rs|Cmax
is also hard. In our present work we address the problem
of scheduling when the machines are of diﬀerent speeds and
the tasks are independent.

The problem of scheduling under availability-constraint is
well studied. This section provides some relevant results for
the class of scheduling problems we are addressing in this
paper. Schmidt studied the problem Pm|pmtn, rs|Cmax and
gave conditions under which a feasible preemptive sched-
ule exists [18]. He shows that such a feasible solution can
be constructed in O(n + m × log m), where m is number
of machines and n is the number of jobs. He also showed
that number of scheduler induced preemption is proportional
to the number of processing intervals. Lawler and Mar-
tel proposed a pseudo-polynomial time algorithm for the
scheduling problem involving two machines with preemptive
jobs under total weighted tardiness minimization criterion,
i.e. Q2|pmtn, rs|P wjUj [13]. For more than two machines
under the criterion of minimization of maximum lateness of
jobs (Q|rj, pmtn|Lmax), a polynomial time algorithm was
proposed by B˜la˙zewicz et al [3]. Gharbi et al present heuris-
tics for problems in P, N Cinc||Cmax and P |rj, qj|Cmax and
showed that their algorithm can work for large instances of
the problems [8]. Hashemian in his masters dissertation [10]
presents ILP formulations for some scheduling problem un-
der availability constraints.

In this paper, we assume unavailability are advertised by
the nodes or links and are, therefore, known in advance. We
consider developing a static schedule and partition of data
elements which takes into account the advertised availabili-
ties. In the next section we present a heuristic to determine
a schedule to reduce make-span of the job.

3. PROBLEM DEFINITION

We assume a distributed computing environment where
one central node, acting as data partitioner (DP), is con-
nected to n computing nodes, P = {P1, P2, . . . , Pn}, in a
star topology. The edges are associated with a weight, li,
depicting link speed. A node is characterized by a tuple
{si, vi}, where si denote the CPU speed (clock speed) and
vi is the advertised non-availability of the node.

The data partitioner has in its possession the data D =
{d1, d2, . . . dm}. We assume the non-availability of the nodes
and links are advertised. Under these constraints the prob-
lem is to achieve a partition of the data D into n partitions
D1, D2, . . . , Dn and each partition Di is assigned to process
Pi, such that the make-span of the job is minimized. We say
a partition of D is consistent iﬀ,

n

[

i=1

Di = D

Di ∩ Dj = ∅ . . . 1 ≤ i, j ≤ n,

i 6= j

(1)

(2)

The model of the problem assumes the tasks to be homo-
geneous and independent, and therefore independent. This
essentially implies that the data partition problem can be
transformed into partition problem of the number of data
elements.

4. HEURISTIC FOR MAKE-SPAN

MINIMIZATION

In this section we present a heuristic to partition a data
set D to assign to a set of n processes. The heuristic is based
on the ratio-based data partition model, but it continuously
reﬁnes the partitions considering advertised non-availability

of the processes. The outline of the algorithm is presented
as Algorithm 1.

The algorithm starts with a partition obtained by apply-
ing ratio-based partition from the capacity of the processes.
This partition method considers that processes are always
available. The make-span obtained from this partition is a
base make-span, mse which does not consider intermittent
unavailability and hence signiﬁes a lower limit of the make-
span for the given data set. Due to intermittent unavailabil-
ity of a process, the completion time of processing the data
partition assigned to it will be pushed away from its base
completion time. This may eﬀectively cause an elongation
of the make-span of processing D. The algorithm, then,
tries to reﬁne the partition to reduce the eﬀective make-
span by re-assigning some data element to other processes
in the following manner. We deﬁne slack time as the dura-
tion [mse, ms]. It estimates total number of data elements
processed during the slack time period and these are then
redistributed using the ratio model. This iteration contin-
ues until there is no substantial improvement in the eﬀective
make-span in subsequent passes.

In the presentation of this heuristic, we assume the follow-
ing model of capacity of a computing element, which consists
of the communication link with the DP and the computing
element itself. We deﬁne capacity as a linear composition of
the cost of transfer of one data element form DP and pro-
cessing cost of the element at the node. The communication
cost is the estimated latency of transferring one data element
from the DP to the node and can be expressed as a func-
tion of the link speed. The computation cost is the estimated
time to process one data element in the node. The computa-
tion cost model is subject of independent research. Here we
assume that some estimate of the cost can be obtained from
some model involving the algorithmic complexity of prob-
lem, CPU speed, memory capacity at all levels, disk speed,
etc [2]. In the heuristic presented in Algorithm 1, has to its
disposal the tuple < N , P > as the system model, where

• N : N → R : deﬁnes the network latency to transfer
one data element from DP. N (i) = tn implies that tn
time unit is required to transfer one data element from
DP to Pi.

• P : N → R : deﬁnes processing speed of one data
element. P(i) = tp implies Pi requires tp time units to
process one data element.

Similarly the availability of each of the ith resource elements
can be described as < Vi >, where,

• Vi : N → {0, 1} is a binary function which denotes
whether link or computation node of a resource ele-
ment is available at certain time unit and is deﬁned
as,

Vi(t) =




true . . .

f alse . . .

Pi and link between DP and
Piare available at the
tth time-unit
otherwise

We deﬁne the following vector of functions to charac-
terize availability of computation elements in the sys-
tem.

~V =< V1, V2, . . . Vn >

We assume time units to be discrete, i.e. if time unit is in
seconds, then Vi(t) = 0 implies the ith resource element is
unavailable for the full tth second.

4.1 Proof of Correctness

The proof of correctness of the heuristic involves proving

• Consistency of the partition. The data partition ob-
tained from the heuristic is consistent, i.e. it satisﬁes
the conditions of Equations 1 and 2.

• Termination. The heuristic terminates in ﬁnite time.

Our heuristic is based on the ratio-based partition and we
assume that the ratio-based partition satisﬁes all the above
correctness criterion. Based on this we prove the followings.

Proof. Consistency of Partition: The proof of the con-
sistency rests on the ratio-partition algorithm, which serves
as the basis of our heuristic. We assume that the partition
of D obtained from ratio-model at the line 1 of Algorithm 1
i=1 Di = D is

is consistent. So at this line the invariant Pn

satisﬁed.

The for-loop starting at line 1 calculates the aggregate
number of data elements, ∆D, which will be processed in the
slack time, i.e. beyond the ideal make-span time-line (ideal
make-span is computed without considering unavailability
of the processes). At line ?? the algorithm determines the
count of data elements processes in the slack time for ith
process as ∆d. The ∆d is cumulated in ∆D at line 1 before
being subtracted from the Di at line 1. Therefore at the end
i=1 Di(cid:1) + ∆D = D
The ratio-based partition at line 1 partitions only ∆D
and by the consistency guarantee of the algorithm the in-
i=1 ∆Di = ∆D holds. Therefore, the invariant

of the for-loop at line 1 the invariant (cid:0)Pn

variant Pn
i=1 Di(cid:1) + (cid:0)Pn
(cid:0)Pn
Finally the values of ∆Di’s are added with the D′

i=1 ∆Di(cid:1) = D also holds.

holds.

is in the
for-loop at line 1. So, at the end of the for-loop, invariant
i=1 Di = D holds. Therefore at the end of the algorithm
i=1 Di = D holds and Di’s can be used to

Pn
the condition Pn

obtain a consistent partition of D. Hence proved.

Now we prove the termination property of the algorithm.

Proof. Termination: First we show that the Algorithm 2
terminates. To show this we need to show that condition at
line 2 is satisﬁed. The initial value of lastτ is the comple-
tion time of analysis of D data elements.
In the repeat-
until loop of the algorithm, the value of τ monotonically
increases. Therefore, the value of cτ also monotonically in-
creases. Since the the value of cτ is the count of unavailable
slots in τ duration and there are ﬁnite number of unavailable
slots, increment of cτ is also ﬁnite. Therefore, the condition
at line 2 will be satisﬁed in ﬁnite time.

Now we show that the unconditional loop encompassing
lines 1 - 1 of algorithm 1 is terminated by execution of break
at line 1 in ﬁnite time. We need to show that the if-condition
checking at the line 1 is successful in ﬁnite execution time.
The if-condition at line 1 checks the diﬀerence between the
make-span of the previous run of the loop with the make-
span corresponding to the reﬁned partition of D. In each
iteration of the loop the make-span value computed in ms
should steadily decrease, otherwise the if-condition is satis-
ﬁed and the algorithm terminates.

Algorithm 1: Makespan-Reﬁnement
input : D, N , P, ~V
output: A partition of the data
begin

Partition D as (D1, D2, D3, . . . Dn) using
ratio-based model ;
for 1 ≤ i ≤ n do

/* Compute completion time of each
partitions without availability
information

Ci = CompletionT ime (Di, N (i), P(i), ∅);

/* Compute make-span without considering

unavailability of the processes

*/

*/

mse ← max {Ci : 1 ≤ i ≤ n};
lastms ← mse;
repeat

for 1 ≤ i ≤ n do

/* Compute completion time of each

partitions using availability
information

*/

Ci ←
CompletionT ime(cid:16)Di, N (i), P(i), ~V ↑i(cid:17);

/* Compute make-span with unavailability

information

ms ← max {Ci : 1 ≤ i ≤ n};
if lastms ≤ ms then

/* No more refinement of partitions

possible

break from loop

∆D ← 0 ;
for 1 ≤ i ≤ n do

*/

*/

/* Slack time :

computation effort of

Pi on Di data elements in the
interval [mse, ms]

*/

∆d ← ⌊ mse −ms
if ∆d > 0 then

N (i)+P(i) ⌋;

/* Calculate the number of data

elements processed in the slack
time

*/

Di ← Di − ∆d ;
∆D ← ∆D + ∆d ;

Partition ∆D as (∆D1, ∆D2, . . . ∆Dn) using
ratio-based model. ;
for 1 ≤ i ≤ n do Di ← Di + ∆Di ;
lastms ← ms ;

until;
Return partition (D1, D2, . . . Dn) ;

Algorithm 2: CompletionTime
input : D, l, c, V
output: Completion Time
begin

[Compute completion time for D data elements on a
resource element with communication cost as l and
computation cost as c, where the availability
information (per time unit) for the computing
elements is described by functions V’s]
lastτ ← τ ← T ← (|D| × (l + c)) ;
repeat

cτ ← 0 ;
for 1 ≤ t ≤ τ do

if V(t) = f alse then

/* tth time is unavailable
cτ ← cτ + 1;

*/

τ ← T + cτ ;
if lastτ = τ then break from loop;
lastτ ← τ ;

until;
return τ ;

According to the algorithm, the value of mse signiﬁes the
make-span for processing the data-set D with n processes,
without considering the unavailable time periods.
It sig-
niﬁes an ideal case and there is no possible partition with
make-span less than mse. However, due to intermittent un-
availability of processes, completion time for individual pro-
cess increases (refer Algo 2), and as a result the eﬀective
make-span (ms) may be more than mse, i.e. ms ≥ mse.
The diﬀerence ms − mse is upper bounded by TA, the max-
imum of the unavailable periods for all processes in the in-
terval [0, ms]. Since ms ≥ mse, lastms ≥ mse. Therefore,
(lastms − ms) < TA.

Since ms must monotonically decrease with each itera-
tion of the loop, i.e. after each iteration lastms > ms and
(lastms − ms) < TA, where TA is ﬁnite, the loop must ter-
minate after ﬁnite number of iterations.

5. EXPERIMENTS AND RESULTS

The experiments were conducted on a simulation frame-
work and the make-spans of the tasks were recorded. The
framework creates static partition of a given number of data.
We used ratio-based partitioning to compare against the
partition created by our heuristic. Our experiment set-up
includes 10 nodes and simulated under 3 diﬀerent scenarios
depicted below.

• Scenario #1: A set of homogeneous nodes (i.e. with
almost same computation power) are connected to the
data partitioner (DP). The link between the DP and
the nodes are homogeneous (i.e. with almost same link
speed).

• Scenario #2: We simulate two clusters of nodes, C1
and C2. The nodes in individual clusters are homo-
geneous. Nodes in cluster C1 are of high computation
speed and those in cluster C2 are of lower computation
speed. The link speed between the DP and nodes in C1
are of higher than that between the data partitioner
and nodes in C2.

Ratio Model
Part-Ref Model

n
a
p
s
-
e
k
a
m

 670

 660

 650

 640

 630

 620

 0

 50  100  150  200  250  300  350  400  450  500

# of unavailable slots

(a) For increasing unavailability (Sce-
nario#3)

n
a
p
s
-
e
k
a
m

 520

 510

 500

 490

 480

 470

 460

Ratio Model
Part-Ref Model

 0

 50  100  150  200  250  300  350  400  450  500

# of data elements

(b) For diﬀerent data volumes
nario#2)

(Sce-

Figure 1: Comparison of Make-Spans

• Scenario #3: This scenario is similar to the scenario#2,
except that the link speed between the DP and nodes
in C1 are of lower than that between the DP and nodes
in C2.

5.1 Variability of Unavailable Slots

The number of unavailable slots were varied with random
assignment of unavailable slots to processes and the make-
span of the schedule is observed. Figure 1(a) shows com-
parison of make-spans for scenario #3, where high-speed
machines are 4 times faster than the low-speed machines,
high-speed links are twice as fast as the low-speed links, and
high-speed machines are connected on high-speed links and
low-speed machines are connected by low-speed links. The
horizontal axis shows total number of unavailable slots which
are randomly distributed among processes.

The result shows that with the increase of number of un-
available slots the make-span obtained from ratio-based par-
tition increases. This is expected since the ratio-based par-
tition does not consider unavailable slots. Our algorithm
tries to redistribute work to obtain a balance of work loads
based on the capacity of the elements with the objective
to reduce make-span. As the number of unavailable slots
increases, there is more scope to perform reﬁnement and
improve make-span.
In this case, the factor by which a
computation is done by high speed machines is higher than
the factor by which a high-speed link transfers data. In this
condition, when a low-speed machine is unavailable for a du-
ration, the job can be transferred to a high-speed machine
with eﬀective reduction in make-span. Our method gener-
ates data partition and distribution such that the make-span
is better in most of the cases for all the scenarios.

Make-span Improvement with

Data Partitioning for IoT Frameworks

Himadri Sekhar Paul

TATA Innovation Labs

Arijit Mukherjee

TATA Innovation Labs

Swarnava Dey

TATA Innovation Labs

TATA Consultancy Services

TATA Consultancy Services

TATA Consultancy Services

Ltd

Kolkata, India

Ltd

Kolkata, India

Ltd

Kolkata, India

HimadriSekhar.Paul@tcs.com

Mukherjee.Arijit@tcs.com

Swarnava.Dey@tcs.com

ABSTRACT
With the current emphasis on intelligent infrastructures,
sensor based ubiquitous intelligent systems, commonly known
as ‘Cyber-Physical Systems’, have become important. Data
acquisition, management, and analysis for knowledge ex-
traction will give rise to a new generation of infrastructure
and services encompassing every aspects of our daily lives.
Such analysis are performed by well-known algorithms, hav-
ing various constraints, including soft-real time constraints.
This will create the need for a computing infrastructure
where data parallel applications can be run. Data distri-
bution for such applications assumes an important role for
the performance of the system. In this paper, we address
the problem of data partitioning as part of data distribu-
tion, such that parallel analysis of the partitions can mini-
mize the overall run-time of the analysis. We investigate the
problem under the scenarios where the communication links
and computation nodes are unreliable and intermittently un-
available. We assume all such non-availabilities are known
to the partitioner and propose an algorithm which gener-
ates a static partition of the data based on the capacity and
availability of the elements in the system.

Keywords
Availability-constraint, Scheduling, Distributed system

1.

INTRODUCTION

The next generation cyber-physical systems will be com-
posed of networked infrastructures of smart objects. In such
an infrastructure, objects will be able to sense the physical
environment in which they belong through the sensory de-
vices attached to it. Applications running on the such in-
frastructures will be able to extract sensory data, analyze
them and generate control signals on which objects will re-
spond. Such an infrastructure will transform the Internet
into Internet of Things (IoT) where ‘things’ will interact

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ComNet-IoT’14 January 4-7, Coimbatore, India
Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.

over the communication framework provided by the Inter-
net. Cyber-physical systems will bring opportunity to oﬀer
applications and services in multitude of domains including
e-Governance, health-care, transport system, water services,
energy utilization, waste management, and many more. Ef-
fective functioning of the services will depend on the precise
analysis of the data accrued through the ubiquitous sensor
devices. As an example, in the health-care domain, data-
mining techniques can be used to create clusters or groups
of persons with similar physiological conditions, which will
oﬀer the health-care professionals the opportunity to diag-
nose the condition based on knowledge gained from cluster-
ing. Real-time analysis of streaming data in a medical emer-
gency unit may lead to early detection of impending medical
conditions and alert the caregivers. Analysis of daily energy
usage per appliance within home or oﬃce may form the basis
of a predictive system for energy & utility systems.

An IoT platform is expected to manage analytical applica-
tions with diverse characteristics, such applications with pe-
riodic tasks, applications handling large data, applications
having soft real-time constraints, etc. Distributed system
is advocated to meet the diverse requirements of such ap-
plications. The computation infrastructure of an IoT plat-
form is essentially a distributed system containing high end
servers. Recently, it has been suggested that edge devices
may also be included in the platform [5]. The sheer number
of edge devices which is projected to come into use in the
near future, makes such devices a lucrative source of compu-
tation power. In eﬀect, tomorrow’s IoT infrastructure will
be geared to exploit power of a wide range of computing re-
sources. However, applications (legacy or otherwise) which
are not inherently distributed will not be able to eﬀectively
utilize the computing infrastructure. In many cases it is not
practical to re-write the application to harness a distributed
computing platform because the source code may not be
available, or libraries used in such applications do not allow
them to transform to the required platform, or simply the
eﬀort required for the transformation is not feasible. Such
applications are treated as ‘black boxes’ and are executed
without modiﬁcation. In this class of black box applications,
some may be data parallel applications, where the applica-
tion can be executed in parallel on subsets of input data and
the individual results can be combined to the desired result
with comparative ease. This pertains to the class of prob-
lems addressed by the Map-Reduce technique [6]. However,
this black-box execution proposition has a distinct advan-
tage of treating the application as it is, without having to

re-write the same, which is in contrast to that in the Map-
Reduce framework.

In this paper, we consider the class of applications which
can be treated for data parallel black-box-style execution,
where the input data can be partitioned into arbitrary smaller
subsets and multiple instances of the same application can
be executed, in parallel, on every data subsets. We as-
sume the existence of a combiner application which can then
gather the results from the execution instances and combine
them into a uniﬁed result. A cloud computing platform in
the IoT context is expected to contain heterogeneous ma-
chines, like sensor gateways, personal computers at home,
or mobile communication devices, etc., connected via links
with heterogeneous characteristics. These devices are not
dedicated computing resources and are usually connected via
unreliable communication links. The availability of both the
computing resources and communication links are bursty,
and even the computation elements may not be available
with their full power. In such a platform the performance of
analysis of a data-set will depend on the appropriate parti-
tioning and distribution of the data-set considering the avail-
ability pattern of the resources. In this paper we attempt
to address the problem of data partitioning for black-box
kind of data analysis applications in the IoT context with
the objective to minimize the overall execution time of an
analytical application.

This paper is organized as follows. Section 2 presents
some related background on data distribution and partition
in distributed computing domain, along with the complex-
ity of the problem. A formalism of the problem is shown in
Section 3. A heuristic to obtain a partition of data based on
capacity of the participant nodes is presented in Section 4.
Simulation results are presented in Section 5. Finally Sec-
tion 6 concludes this paper with directions to future work.

2. BACKGROUND

One of the potential factor of improving the performance
of a distributed platform is the eﬀect of movement of data for
computation. Bent et al analyzed the problem of schedul-
ing when data movement is considered along with compu-
tation [4]. Kosar et al propose a batch processing system
which is aware of data volume [12].

Google’s Map-Reduce framework [6] eﬀectively exploits
the power of distributed system for many data intensive
problems. The platform was later adopted as the Hadoop
open source project [1] by Yahoo. Researchers are working
on the techniques of improving the performance of Hadoop-
like Map-Reduce frameworks. Authors in [20] investigate the
eﬀect of data locality for Map-Reduce jobs in Hadoop sys-
tem and propose a data-locality aware scheduler for Hadoop.
The Quincy scheduler balances the priority of the task with
locality of data [11]. In a Map-Reduce framework skewness
of data distribution hinders system throughput, when some
reduce-servers are loaded with more data to process. Au-
thors in [9] present a data partition scheme to balance the
data processing load on reduce-servers. Their approach is
a greedy one where the least loaded server gets the largest
partition.

A computing system can be viewed as a producer-consumer
system, where application and data are producers of com-
puting demand and the computing elements are consumers
of such demands. The rate of consumption of computing
demand by a computing resource can deﬁned as the capac-

ity of the resource. Capacity of computing elements in a
system plays an important role in the problem of data par-
titioning. Capacity models are not easy to deﬁne since there
are interdependencies among diﬀerent elements of computa-
tion. Some detailed models of computing capacity can be
found in [7, 15, 16]. Authors in [2] use a simple model of
capacity computation, which is a linear combination CPU
clock speed, memory size, bandwidth, etc, and they parti-
tion a data set according to the capacity ratio of the nodes.
Then they show that this simple method of partitioning can
improve the performance of some simple Map-Reduce pro-
grams.

In this paper we propose a model of data partitioner such
that the overall computation span of a job is minimized. The
next section discusses the complexity of the problem we are
addressing.

2.1 Complexity of the Problem

In this paper we consider an application A which processes
a data-set and generates a result. Mathematically, we con-
sider the application as a function, deﬁned as A : P(D) →
R, where the range R deﬁnes the set from which the return
value of the algorithm A is drawn. The domain of the appli-
cation is a set of data drawn from D, denoted as the power
set of D, P(D).

Let D be a member of P(D) acting as an input set. Let
D = {d1, d2, d3, . . . , dm}. We partition D into n segments
D1, D2, D3, . . . , Dn such that Sn
i=1 Di = D and Di ∩ Dj =
∅ : 1 ≤ i, j ≤ n, i 6= j and typically n ≤ m. In a distributed
computing platform, n instances of A can be initiated with
diﬀerent partitions of the input set, i.e. , we have a set of
tasks J = {A(D1), A(D2), . . . , A(Dn)}. We assume that
the existence of a combiner/reducer which takes care of the
return values of these instances, but is outside the scope of
this paper.

Completion time of each task A(Di) will depend on vari-
ous system and application parameters. We want to achieve
an eﬀective partition such that the make-span of J , which
in the ﬁeld of research in scheduling refers to the latest com-
pletion time of the tasks, is minimized.

The problem of data partitioning can be reduced into a
more generic and well researched ﬁeld of scheduling. Instead
of creating n partitions of D, one can create m partitions,
each containing exactly one, atomic data element. Execu-
tion of these m partitions with m instances of A gives us a
job of m tasks J ′ = {A(d1), A(d2), . . . , A(dm)}, which now
need to be scheduled on n resources.

However, in the context of IoT framework, nodes and com-
munication links may not always be available. Scheduling
under such availability constraint in multi-processor system
has been studied [17,19]. The version of the scheduling prob-
lem we address in this paper falls in the class Q|pmtn, rs|Cmax,
implying that jobs can be preempted and resumed later, and
processes are unavailable in multiple time-durations during
the whole scheduling time-span, where the objective is to
minimize the make-span of the jobs. The problem without
any availability constraint (P ||Cmax) is known to be NP-
hard, the problem with availability constraints (P |rs|Cmax),
where jobs can be resumed, is also hard [14]. Therefore, the
non-uniform processing version of the problem Q|rs|Cmax
is also hard. In our present work we address the problem
of scheduling when the machines are of diﬀerent speeds and
the tasks are independent.

The problem of scheduling under availability-constraint is
well studied. This section provides some relevant results for
the class of scheduling problems we are addressing in this
paper. Schmidt studied the problem Pm|pmtn, rs|Cmax and
gave conditions under which a feasible preemptive sched-
ule exists [18]. He shows that such a feasible solution can
be constructed in O(n + m × log m), where m is number
of machines and n is the number of jobs. He also showed
that number of scheduler induced preemption is proportional
to the number of processing intervals. Lawler and Mar-
tel proposed a pseudo-polynomial time algorithm for the
scheduling problem involving two machines with preemptive
jobs under total weighted tardiness minimization criterion,
i.e. Q2|pmtn, rs|P wjUj [13]. For more than two machines
under the criterion of minimization of maximum lateness of
jobs (Q|rj, pmtn|Lmax), a polynomial time algorithm was
proposed by B˜la˙zewicz et al [3]. Gharbi et al present heuris-
tics for problems in P, N Cinc||Cmax and P |rj, qj|Cmax and
showed that their algorithm can work for large instances of
the problems [8]. Hashemian in his masters dissertation [10]
presents ILP formulations for some scheduling problem un-
der availability constraints.

In this paper, we assume unavailability are advertised by
the nodes or links and are, therefore, known in advance. We
consider developing a static schedule and partition of data
elements which takes into account the advertised availabili-
ties. In the next section we present a heuristic to determine
a schedule to reduce make-span of the job.

3. PROBLEM DEFINITION

We assume a distributed computing environment where
one central node, acting as data partitioner (DP), is con-
nected to n computing nodes, P = {P1, P2, . . . , Pn}, in a
star topology. The edges are associated with a weight, li,
depicting link speed. A node is characterized by a tuple
{si, vi}, where si denote the CPU speed (clock speed) and
vi is the advertised non-availability of the node.

The data partitioner has in its possession the data D =
{d1, d2, . . . dm}. We assume the non-availability of the nodes
and links are advertised. Under these constraints the prob-
lem is to achieve a partition of the data D into n partitions
D1, D2, . . . , Dn and each partition Di is assigned to process
Pi, such that the make-span of the job is minimized. We say
a partition of D is consistent iﬀ,

n

[

i=1

Di = D

Di ∩ Dj = ∅ . . . 1 ≤ i, j ≤ n,

i 6= j

(1)

(2)

The model of the problem assumes the tasks to be homo-
geneous and independent, and therefore independent. This
essentially implies that the data partition problem can be
transformed into partition problem of the number of data
elements.

4. HEURISTIC FOR MAKE-SPAN

MINIMIZATION

In this section we present a heuristic to partition a data
set D to assign to a set of n processes. The heuristic is based
on the ratio-based data partition model, but it continuously
reﬁnes the partitions considering advertised non-availability

of the processes. The outline of the algorithm is presented
as Algorithm 1.

The algorithm starts with a partition obtained by apply-
ing ratio-based partition from the capacity of the processes.
This partition method considers that processes are always
available. The make-span obtained from this partition is a
base make-span, mse which does not consider intermittent
unavailability and hence signiﬁes a lower limit of the make-
span for the given data set. Due to intermittent unavailabil-
ity of a process, the completion time of processing the data
partition assigned to it will be pushed away from its base
completion time. This may eﬀectively cause an elongation
of the make-span of processing D. The algorithm, then,
tries to reﬁne the partition to reduce the eﬀective make-
span by re-assigning some data element to other processes
in the following manner. We deﬁne slack time as the dura-
tion [mse, ms]. It estimates total number of data elements
processed during the slack time period and these are then
redistributed using the ratio model. This iteration contin-
ues until there is no substantial improvement in the eﬀective
make-span in subsequent passes.

In the presentation of this heuristic, we assume the follow-
ing model of capacity of a computing element, which consists
of the communication link with the DP and the computing
element itself. We deﬁne capacity as a linear composition of
the cost of transfer of one data element form DP and pro-
cessing cost of the element at the node. The communication
cost is the estimated latency of transferring one data element
from the DP to the node and can be expressed as a func-
tion of the link speed. The computation cost is the estimated
time to process one data element in the node. The computa-
tion cost model is subject of independent research. Here we
assume that some estimate of the cost can be obtained from
some model involving the algorithmic complexity of prob-
lem, CPU speed, memory capacity at all levels, disk speed,
etc [2]. In the heuristic presented in Algorithm 1, has to its
disposal the tuple < N , P > as the system model, where

• N : N → R : deﬁnes the network latency to transfer
one data element from DP. N (i) = tn implies that tn
time unit is required to transfer one data element from
DP to Pi.

• P : N → R : deﬁnes processing speed of one data
element. P(i) = tp implies Pi requires tp time units to
process one data element.

Similarly the availability of each of the ith resource elements
can be described as < Vi >, where,

• Vi : N → {0, 1} is a binary function which denotes
whether link or computation node of a resource ele-
ment is available at certain time unit and is deﬁned
as,

Vi(t) =




true . . .

f alse . . .

Pi and link between DP and
Piare available at the
tth time-unit
otherwise

We deﬁne the following vector of functions to charac-
terize availability of computation elements in the sys-
tem.

~V =< V1, V2, . . . Vn >

We assume time units to be discrete, i.e. if time unit is in
seconds, then Vi(t) = 0 implies the ith resource element is
unavailable for the full tth second.

4.1 Proof of Correctness

The proof of correctness of the heuristic involves proving

• Consistency of the partition. The data partition ob-
tained from the heuristic is consistent, i.e. it satisﬁes
the conditions of Equations 1 and 2.

• Termination. The heuristic terminates in ﬁnite time.

Our heuristic is based on the ratio-based partition and we
assume that the ratio-based partition satisﬁes all the above
correctness criterion. Based on this we prove the followings.

Proof. Consistency of Partition: The proof of the con-
sistency rests on the ratio-partition algorithm, which serves
as the basis of our heuristic. We assume that the partition
of D obtained from ratio-model at the line 1 of Algorithm 1
i=1 Di = D is

is consistent. So at this line the invariant Pn

satisﬁed.

The for-loop starting at line 1 calculates the aggregate
number of data elements, ∆D, which will be processed in the
slack time, i.e. beyond the ideal make-span time-line (ideal
make-span is computed without considering unavailability
of the processes). At line ?? the algorithm determines the
count of data elements processes in the slack time for ith
process as ∆d. The ∆d is cumulated in ∆D at line 1 before
being subtracted from the Di at line 1. Therefore at the end
i=1 Di(cid:1) + ∆D = D
The ratio-based partition at line 1 partitions only ∆D
and by the consistency guarantee of the algorithm the in-
i=1 ∆Di = ∆D holds. Therefore, the invariant

of the for-loop at line 1 the invariant (cid:0)Pn

variant Pn
i=1 Di(cid:1) + (cid:0)Pn
(cid:0)Pn
Finally the values of ∆Di’s are added with the D′

i=1 ∆Di(cid:1) = D also holds.

holds.

is in the
for-loop at line 1. So, at the end of the for-loop, invariant
i=1 Di = D holds. Therefore at the end of the algorithm
i=1 Di = D holds and Di’s can be used to

Pn
the condition Pn

obtain a consistent partition of D. Hence proved.

Now we prove the termination property of the algorithm.

Proof. Termination: First we show that the Algorithm 2
terminates. To show this we need to show that condition at
line 2 is satisﬁed. The initial value of lastτ is the comple-
tion time of analysis of D data elements.
In the repeat-
until loop of the algorithm, the value of τ monotonically
increases. Therefore, the value of cτ also monotonically in-
creases. Since the the value of cτ is the count of unavailable
slots in τ duration and there are ﬁnite number of unavailable
slots, increment of cτ is also ﬁnite. Therefore, the condition
at line 2 will be satisﬁed in ﬁnite time.

Now we show that the unconditional loop encompassing
lines 1 - 1 of algorithm 1 is terminated by execution of break
at line 1 in ﬁnite time. We need to show that the if-condition
checking at the line 1 is successful in ﬁnite execution time.
The if-condition at line 1 checks the diﬀerence between the
make-span of the previous run of the loop with the make-
span corresponding to the reﬁned partition of D. In each
iteration of the loop the make-span value computed in ms
should steadily decrease, otherwise the if-condition is satis-
ﬁed and the algorithm terminates.

Algorithm 1: Makespan-Reﬁnement
input : D, N , P, ~V
output: A partition of the data
begin

Partition D as (D1, D2, D3, . . . Dn) using
ratio-based model ;
for 1 ≤ i ≤ n do

/* Compute completion time of each
partitions without availability
information

Ci = CompletionT ime (Di, N (i), P(i), ∅);

/* Compute make-span without considering

unavailability of the processes

*/

*/

mse ← max {Ci : 1 ≤ i ≤ n};
lastms ← mse;
repeat

for 1 ≤ i ≤ n do

/* Compute completion time of each

partitions using availability
information

*/

Ci ←
CompletionT ime(cid:16)Di, N (i), P(i), ~V ↑i(cid:17);

/* Compute make-span with unavailability

information

ms ← max {Ci : 1 ≤ i ≤ n};
if lastms ≤ ms then

/* No more refinement of partitions

possible

break from loop

∆D ← 0 ;
for 1 ≤ i ≤ n do

*/

*/

/* Slack time :

computation effort of

Pi on Di data elements in the
interval [mse, ms]

*/

∆d ← ⌊ mse −ms
if ∆d > 0 then

N (i)+P(i) ⌋;

/* Calculate the number of data

elements processed in the slack
time

*/

Di ← Di − ∆d ;
∆D ← ∆D + ∆d ;

Partition ∆D as (∆D1, ∆D2, . . . ∆Dn) using
ratio-based model. ;
for 1 ≤ i ≤ n do Di ← Di + ∆Di ;
lastms ← ms ;

until;
Return partition (D1, D2, . . . Dn) ;

Algorithm 2: CompletionTime
input : D, l, c, V
output: Completion Time
begin

[Compute completion time for D data elements on a
resource element with communication cost as l and
computation cost as c, where the availability
information (per time unit) for the computing
elements is described by functions V’s]
lastτ ← τ ← T ← (|D| × (l + c)) ;
repeat

cτ ← 0 ;
for 1 ≤ t ≤ τ do

if V(t) = f alse then

/* tth time is unavailable
cτ ← cτ + 1;

*/

τ ← T + cτ ;
if lastτ = τ then break from loop;
lastτ ← τ ;

until;
return τ ;

According to the algorithm, the value of mse signiﬁes the
make-span for processing the data-set D with n processes,
without considering the unavailable time periods.
It sig-
niﬁes an ideal case and there is no possible partition with
make-span less than mse. However, due to intermittent un-
availability of processes, completion time for individual pro-
cess increases (refer Algo 2), and as a result the eﬀective
make-span (ms) may be more than mse, i.e. ms ≥ mse.
The diﬀerence ms − mse is upper bounded by TA, the max-
imum of the unavailable periods for all processes in the in-
terval [0, ms]. Since ms ≥ mse, lastms ≥ mse. Therefore,
(lastms − ms) < TA.

Since ms must monotonically decrease with each itera-
tion of the loop, i.e. after each iteration lastms > ms and
(lastms − ms) < TA, where TA is ﬁnite, the loop must ter-
minate after ﬁnite number of iterations.

5. EXPERIMENTS AND RESULTS

The experiments were conducted on a simulation frame-
work and the make-spans of the tasks were recorded. The
framework creates static partition of a given number of data.
We used ratio-based partitioning to compare against the
partition created by our heuristic. Our experiment set-up
includes 10 nodes and simulated under 3 diﬀerent scenarios
depicted below.

• Scenario #1: A set of homogeneous nodes (i.e. with
almost same computation power) are connected to the
data partitioner (DP). The link between the DP and
the nodes are homogeneous (i.e. with almost same link
speed).

• Scenario #2: We simulate two clusters of nodes, C1
and C2. The nodes in individual clusters are homo-
geneous. Nodes in cluster C1 are of high computation
speed and those in cluster C2 are of lower computation
speed. The link speed between the DP and nodes in C1
are of higher than that between the data partitioner
and nodes in C2.

Ratio Model
Part-Ref Model

n
a
p
s
-
e
k
a
m

 670

 660

 650

 640

 630

 620

 0

 50  100  150  200  250  300  350  400  450  500

# of unavailable slots

(a) For increasing unavailability (Sce-
nario#3)

n
a
p
s
-
e
k
a
m

 520

 510

 500

 490

 480

 470

 460

Ratio Model
Part-Ref Model

 0

 50  100  150  200  250  300  350  400  450  500

# of data elements

(b) For diﬀerent data volumes
nario#2)

(Sce-

Figure 1: Comparison of Make-Spans

• Scenario #3: This scenario is similar to the scenario#2,
except that the link speed between the DP and nodes
in C1 are of lower than that between the DP and nodes
in C2.

5.1 Variability of Unavailable Slots

The number of unavailable slots were varied with random
assignment of unavailable slots to processes and the make-
span of the schedule is observed. Figure 1(a) shows com-
parison of make-spans for scenario #3, where high-speed
machines are 4 times faster than the low-speed machines,
high-speed links are twice as fast as the low-speed links, and
high-speed machines are connected on high-speed links and
low-speed machines are connected by low-speed links. The
horizontal axis shows total number of unavailable slots which
are randomly distributed among processes.

The result shows that with the increase of number of un-
available slots the make-span obtained from ratio-based par-
tition increases. This is expected since the ratio-based par-
tition does not consider unavailable slots. Our algorithm
tries to redistribute work to obtain a balance of work loads
based on the capacity of the elements with the objective
to reduce make-span. As the number of unavailable slots
increases, there is more scope to perform reﬁnement and
improve make-span.
In this case, the factor by which a
computation is done by high speed machines is higher than
the factor by which a high-speed link transfers data. In this
condition, when a low-speed machine is unavailable for a du-
ration, the job can be transferred to a high-speed machine
with eﬀective reduction in make-span. Our method gener-
ates data partition and distribution such that the make-span
is better in most of the cases for all the scenarios.

[9] B. Guﬂer, N. Augsten, A. Reiser, and A. Kemper.
Handling data skew in MapReduce. In CLOSER,
pages 574 – 583, 2011.

[10] N. Hashemian. Makespan minimization for parallel

machines scheduling with availability constraints.
Master’s thesis, Dept. of Industrial Engg., Dalhousie
University, Halifax, Nova Scotia, 2010.

[11] M. Isard, V. Prabhakaran, J. Currey, U. Wieder,

K. Talwar, and A. Goldberg. Quincy : Fair scheduling
for distributed computing clusters. In ACM SIGOPS
22nd Symp. on Operating Systems Principles,
SOSP’09, pages 261 – 276. ACM, 2009.

[12] T. Kosar and M. Balman. A new paradigm:

Data-aware scheduling in grid computing. Future
Generation Computer Systems, 25(4):406 – 413, 2009.
[13] E. L. Lawler and C. U. Martel. Preemptive scheduling

of two uniform machines to minimize the number of
late jobs. Operations Research, 37:314–318, 1989.

[14] C. Y. Lee. Machine scheduling with an availability

constraint. Journal of Global Optimization, 9:395–416,
1996.

[15] A. Rakitskiy, B. Ryabko, and A. Fionov. Evaluation of
computer capacity for P5 Intel processors. In Problems
of Redundancy in Information and Control Systems
(RED), XIII International Symposium on, pages 70
–73, sept. 2012.

[16] B. Ryabko. Using information theory to study

eﬃciency and capacity of computers and similar
devices. Information, 1(1):3–12, 2010.

[17] H. R. D. Saidy and M. T. Taghavi-Fard. Study of

scheduling problems with machine availability
constraint. Journal of Industrial and Systems
Engineering, 1(4):360–383, 2008.

[18] G. Schmidt. Scheduling on semi-identical processors.
Zeitschrift f ˜Aijr Operations Research, A28:153–162,
1984.

[19] G. Schmidt. Scheduling with limited machine
availability. European Journal of Operational
Research, 121:1–15, 2000.

[20] J. Xie, S. Yin, X. Ruan, Z. Ding, Y. Tian, J. Majors,

A. Manzanares, and X. Qin. Improving MapReduce
performance through data placement in heterogeneous
hadoop clusters. In Parallel Distributed Processing,
Workshops and Phd Forum (IPDPSW), 2010 IEEE
International Symposium on, pages 1–9, 2010.

5.2 Variability of Data Volume

We varied the number of data elements and compared the
make-span of the job, given that a total of 500 time units
are unavailable across all processors. Figure 1(b) shows the
comparison the make span for the scenario#2, where the
high speed machines are 4-times as fast as the low-speed ma-
chines, link speed of a high-speed connection is 2-times faster
than a low-speed connections, and high-speed machines are
connected to low-speed links and low-speed machines are
connected to high-speed links. The results of other cases are
similar and not presented here. In these cases our heuris-
tic could exploit the unavailable information and produce a
make-span which is at-least comparable to ratio-based model
and out performs in many cases.

6. CONCLUSION AND FUTURE WORK

An IoT framework is a conglomeration of heterogeneous
resources connected by heterogeneous communication. In-
corporating these resources in a framework, where their com-
putation powers can be eﬀectively harnessed, poses several
challenges. In this paper we address the problem of data par-
titioning for data parallel applications, under the scenario
where nodes may be unavailable spuriously in a day. We
present a formulation of the problem and present a heuristic
for the problem.

The model we present in this paper assumes the availabil-
ity of the nodes are advertised and we exploit this knowledge
to generate a static schedule. However, in practical scenarios
all unavailability may not be advertised. Statistical model
of availability can be incorporated in the model to address
non-advertised unavailability, like transient faults.

7. REFERENCES
[1] Hadoop. http://hadoop.apache.org.
[2] R. Arasanal and D. Rumani. Improving MapReduce

performance through complexity and performance
based data placement in heterogeneous hadoop
clusters. In Intl. Conf. on Distributed Computing and
Internet Technology (ICDCIT), feb 2013.

[3] J. B˜la˙zewicz, M. Drozdowski, P. Formanowicz,

W. Kubiak, and G. Schmidt. Scheduling preemptable
tasks on parallel processors with limited availability.
Parallel Computing, 26(9):1195 – 1211, 2000.

[4] J. Bent, D. Rotem, A. Romosan, and A. Shoshani.
Coordination of data movement with computation
scheduling on a cluster. In Challenges of Large
Applications in Distributed Environments, 2005.
CLADE 2005. Proceedings, pages 25–34, 2005.

[5] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli. Fog

computing and its role in the internet of things. In
Proc. of the 1st Mobile Cloud Computing, MCC-2012,
pages 13–16. ACM, 2012.

[6] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed
data processing on large clusters. Commun. ACM,
51(1):107–113, Jan. 2008.

[7] A. Fionov, Y. Polyakov, and B. Ryabko. Application

of computer capacity to evaluation of Intel x86
processors. In F. L. G. et al, editor, Proc of the 2nd
Intl Congress CACS, IASC, pages 99–104, 2012.

[8] A. Gharbia and M. Haouari. Optimal parallel

machines scheduling with availability constraints.
Discrete Applied Mathematics, 148:63–87, 2005.

