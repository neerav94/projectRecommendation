Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

using	 Â  Googleâ€™s	 Â  dataset	 Â  [1].	 Â  The	 Â  algorithm	 Â  performed	 Â  well	 Â  on	 Â  smaller	 Â  subsets	 Â  of	 Â  our	 Â  data	 Â  but	 Â  when	 Â 
training	 Â on	 Â a	 Â large	 Â vocabulary	 Â (>1	 Â M),	 Â the	 Â training	 Â time	 Â became	 Â excessively	 Â large,	 Â so	 Â we	 Â used	 Â pre-Â­â€trained	 Â 
word	 Â vectors	 Â [1].	 Â 
Named	 Â Entity	 Â Recognition	 Â 
NER	 Â  is	 Â  a	 Â  classification	 Â  problem,	 Â  where	 Â  each	 Â  input	 Â  word	 Â  is	 Â  classified	 Â  as	 Â  being	 Â  a	 Â  Location,	 Â  Person,	 Â 
Organization,	 Â  Miscellaneous	 Â  and	 Â  Other	 Â  (not	 Â  any	 Â  named	 Â  entity).	 Â  The	 Â  algorithm	 Â  uses	 Â  tokenized	 Â  text	 Â  to	 Â 
train	 Â  a	 Â  neural	 Â  network	 Â  model	 Â  for	 Â  named	 Â  entity	 Â  recognition	 Â  with	 Â  multiple	 Â  classes.	 Â  The	 Â  detailed	 Â 
annotation	 Â  structure	 Â  for	 Â  the	 Â  dataset	 Â  is	 Â  given	 Â  at	 Â  [13].	 Â  The	 Â  training	 Â  and	 Â  the	 Â  testing	 Â  data	 Â  for	 Â  the	 Â  NER	 Â 
algorithm	 Â  is	 Â  taken	 Â  from	 Â  CoNLL03	 Â  corpus.	 Â  The	 Â  data	 Â  consists	 Â  of	 Â  sentences	 Â  with	 Â  one	 Â  token	 Â  per	 Â  line	 Â  and	 Â 
each	 Â  token	 Â  is	 Â  associated	 Â  with	 Â  5	 Â  possible	 Â  labels:	 Â  {O,	 Â  LOC,	 Â  MISC,	 Â  ORG,	 Â  PER}	 Â  representing	 Â  the	 Â  classes	 Â 
defined	 Â  above.	 Â  The	 Â  word	 Â  vectors	 Â  learned	 Â  using	 Â  the	 Â  CBOW	 Â  model	 Â  were	 Â  used	 Â  to	 Â  construct	 Â  context	 Â 
windows	 Â that	 Â serve	 Â as	 Â input	 Â features	 Â to	 Â the	 Â neural	 Â network.	 Â 

The	 Â  model	 Â  is	 Â  implemented	 Â  as	 Â  single	 Â  layer	 Â  neural	 Â  network	 Â  with	 Â  word	 Â  embedding	 Â  as	 Â  the	 Â  input	 Â  layer	 Â 
feeding	 Â to	 Â feedforward	 Â algorithm.	 Â The	 Â predicted	 Â class	 Â vector	 Â is	 Â then	 Â compared	 Â to	 Â the	 Â actual	 Â class	 Â and	 Â 
the	 Â delta	 Â error	 Â propagates	 Â back	 Â updating	 Â the	 Â model.	 Â As	 Â the	 Â algorithm	 Â iterates	 Â through	 Â the	 Â dataset	 Â it	 Â 
learns	 Â both	 Â the	 Â classifier	 Â and	 Â the	 Â word	 Â representations.	 Â 	 Â 

The	 Â feedforward	 Â operation	 Â is	 Â given	 Â by	 Â the	 Â following	 Â set	 Â of	 Â equations	 Â 

ğ‘§=ğ‘Š ğ‘¥!!!ğ‘¥!ğ‘¥!!! +ğ‘(!)	 Â 
â„=ğ‘¡ğ‘ğ‘›â„(ğ‘§)	 Â 
ğ‘=ğ‘”(ğ‘ˆâ„+ğ‘!)	 Â 
ğ‘¦!!ğ‘™ğ‘œğ‘”ğ‘!,!(ğ‘¥(!))

Where	 Â ((ğ‘¥!!!,ğ‘¥!,ğ‘¥!!!)	 Â is	 Â the	 Â context	 Â window,	 Â W	 Â and	 Â U	 Â are	 Â the	 Â model	 Â parameters	 Â and	 Â g	 Â is	 Â the	 Â softmax	 Â 

function.	 Â The	 Â cost	 Â function	 Â to	 Â minimize	 Â is	 Â given	 Â by	 Â the	 Â following	 Â equation	 Â 

ğ½ğœƒ = Â 

!
!!!

!
!!!

ğ´+ ğœ†2ğ‘š(ğ‘Š !+ ğ‘ˆ !) Â 

	 Â 

Where	 Â m	 Â is	 Â the	 Â number	 Â of	 Â data	 Â samples,	 Â K	 Â is	 Â the	 Â number	 Â of	 Â entity	 Â classes	 Â and	 Â Î»	 Â is	 Â the	 Â regularization	 Â 
parameter.	 Â  The	 Â  parameters	 Â  are	 Â  learned	 Â  using	 Â  stochastic	 Â  gradient	 Â  descent	 Â  algorithm	 Â  and	 Â  gradient	 Â 
checking	 Â is	 Â used	 Â for	 Â bug-Â­â€free	 Â implementation.	 Â 

The	 Â  evaluation	 Â  of	 Â  the	 Â  implemented	 Â  algorithm	 Â  was	 Â  done	 Â  using	 Â  the	 Â  CoNLL03	 Â  conlleval	 Â  Perl	 Â  script.	 Â  The	 Â 
script	 Â evaluates	 Â the	 Â NER	 Â systemâ€™s	 Â capability	 Â of	 Â identifying	 Â named	 Â entities.	 Â It	 Â gives	 Â a	 Â clear	 Â presentation	 Â of	 Â 
the	 Â  performance	 Â  of	 Â  the	 Â  system	 Â  on	 Â  various	 Â  entity	 Â  categories	 Â  (person,	 Â 
location,	 Â  organization,	 Â 
miscellaneous	 Â and	 Â other)	 Â based	 Â on	 Â the	 Â precision,	 Â recall	 Â and	 Â F1	 Â measures.	 Â 
Results	 Â 

Tuning	 Â Parameters	 Â 

The	 Â parameters	 Â of	 Â the	 Â system	 Â that	 Â were	 Â tuned	 Â for	 Â higher	 Â accuracy	 Â were:	 Â 

Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

using	 Â  Googleâ€™s	 Â  dataset	 Â  [1].	 Â  The	 Â  algorithm	 Â  performed	 Â  well	 Â  on	 Â  smaller	 Â  subsets	 Â  of	 Â  our	 Â  data	 Â  but	 Â  when	 Â 
training	 Â on	 Â a	 Â large	 Â vocabulary	 Â (>1	 Â M),	 Â the	 Â training	 Â time	 Â became	 Â excessively	 Â large,	 Â so	 Â we	 Â used	 Â pre-Â­â€trained	 Â 
word	 Â vectors	 Â [1].	 Â 
Named	 Â Entity	 Â Recognition	 Â 
NER	 Â  is	 Â  a	 Â  classification	 Â  problem,	 Â  where	 Â  each	 Â  input	 Â  word	 Â  is	 Â  classified	 Â  as	 Â  being	 Â  a	 Â  Location,	 Â  Person,	 Â 
Organization,	 Â  Miscellaneous	 Â  and	 Â  Other	 Â  (not	 Â  any	 Â  named	 Â  entity).	 Â  The	 Â  algorithm	 Â  uses	 Â  tokenized	 Â  text	 Â  to	 Â 
train	 Â  a	 Â  neural	 Â  network	 Â  model	 Â  for	 Â  named	 Â  entity	 Â  recognition	 Â  with	 Â  multiple	 Â  classes.	 Â  The	 Â  detailed	 Â 
annotation	 Â  structure	 Â  for	 Â  the	 Â  dataset	 Â  is	 Â  given	 Â  at	 Â  [13].	 Â  The	 Â  training	 Â  and	 Â  the	 Â  testing	 Â  data	 Â  for	 Â  the	 Â  NER	 Â 
algorithm	 Â  is	 Â  taken	 Â  from	 Â  CoNLL03	 Â  corpus.	 Â  The	 Â  data	 Â  consists	 Â  of	 Â  sentences	 Â  with	 Â  one	 Â  token	 Â  per	 Â  line	 Â  and	 Â 
each	 Â  token	 Â  is	 Â  associated	 Â  with	 Â  5	 Â  possible	 Â  labels:	 Â  {O,	 Â  LOC,	 Â  MISC,	 Â  ORG,	 Â  PER}	 Â  representing	 Â  the	 Â  classes	 Â 
defined	 Â  above.	 Â  The	 Â  word	 Â  vectors	 Â  learned	 Â  using	 Â  the	 Â  CBOW	 Â  model	 Â  were	 Â  used	 Â  to	 Â  construct	 Â  context	 Â 
windows	 Â that	 Â serve	 Â as	 Â input	 Â features	 Â to	 Â the	 Â neural	 Â network.	 Â 

The	 Â  model	 Â  is	 Â  implemented	 Â  as	 Â  single	 Â  layer	 Â  neural	 Â  network	 Â  with	 Â  word	 Â  embedding	 Â  as	 Â  the	 Â  input	 Â  layer	 Â 
feeding	 Â to	 Â feedforward	 Â algorithm.	 Â The	 Â predicted	 Â class	 Â vector	 Â is	 Â then	 Â compared	 Â to	 Â the	 Â actual	 Â class	 Â and	 Â 
the	 Â delta	 Â error	 Â propagates	 Â back	 Â updating	 Â the	 Â model.	 Â As	 Â the	 Â algorithm	 Â iterates	 Â through	 Â the	 Â dataset	 Â it	 Â 
learns	 Â both	 Â the	 Â classifier	 Â and	 Â the	 Â word	 Â representations.	 Â 	 Â 

The	 Â feedforward	 Â operation	 Â is	 Â given	 Â by	 Â the	 Â following	 Â set	 Â of	 Â equations	 Â 

ğ‘§=ğ‘Š ğ‘¥!!!ğ‘¥!ğ‘¥!!! +ğ‘(!)	 Â 
â„=ğ‘¡ğ‘ğ‘›â„(ğ‘§)	 Â 
ğ‘=ğ‘”(ğ‘ˆâ„+ğ‘!)	 Â 
ğ‘¦!!ğ‘™ğ‘œğ‘”ğ‘!,!(ğ‘¥(!))

Where	 Â ((ğ‘¥!!!,ğ‘¥!,ğ‘¥!!!)	 Â is	 Â the	 Â context	 Â window,	 Â W	 Â and	 Â U	 Â are	 Â the	 Â model	 Â parameters	 Â and	 Â g	 Â is	 Â the	 Â softmax	 Â 

function.	 Â The	 Â cost	 Â function	 Â to	 Â minimize	 Â is	 Â given	 Â by	 Â the	 Â following	 Â equation	 Â 

ğ½ğœƒ = Â 

!
!!!

!
!!!

ğ´+ ğœ†2ğ‘š(ğ‘Š !+ ğ‘ˆ !) Â 

	 Â 

Where	 Â m	 Â is	 Â the	 Â number	 Â of	 Â data	 Â samples,	 Â K	 Â is	 Â the	 Â number	 Â of	 Â entity	 Â classes	 Â and	 Â Î»	 Â is	 Â the	 Â regularization	 Â 
parameter.	 Â  The	 Â  parameters	 Â  are	 Â  learned	 Â  using	 Â  stochastic	 Â  gradient	 Â  descent	 Â  algorithm	 Â  and	 Â  gradient	 Â 
checking	 Â is	 Â used	 Â for	 Â bug-Â­â€free	 Â implementation.	 Â 

The	 Â  evaluation	 Â  of	 Â  the	 Â  implemented	 Â  algorithm	 Â  was	 Â  done	 Â  using	 Â  the	 Â  CoNLL03	 Â  conlleval	 Â  Perl	 Â  script.	 Â  The	 Â 
script	 Â evaluates	 Â the	 Â NER	 Â systemâ€™s	 Â capability	 Â of	 Â identifying	 Â named	 Â entities.	 Â It	 Â gives	 Â a	 Â clear	 Â presentation	 Â of	 Â 
the	 Â  performance	 Â  of	 Â  the	 Â  system	 Â  on	 Â  various	 Â  entity	 Â  categories	 Â  (person,	 Â 
location,	 Â  organization,	 Â 
miscellaneous	 Â and	 Â other)	 Â based	 Â on	 Â the	 Â precision,	 Â recall	 Â and	 Â F1	 Â measures.	 Â 
Results	 Â 

Tuning	 Â Parameters	 Â 

The	 Â parameters	 Â of	 Â the	 Â system	 Â that	 Â were	 Â tuned	 Â for	 Â higher	 Â accuracy	 Â were:	 Â 

â€¢  The	 Â regularization	 Â constant	 Â (Î»)	 Â 
â€¢  The	 Â learning	 Â rate	 Â (Î±)	 Â 
â€¢  The	 Â context	 Â window	 Â size	 Â (C)	 Â 
â€¢  The	 Â number	 Â of	 Â iterations	 Â (epochs)	 Â 

We	 Â used	 Â context	 Â window	 Â size	 Â of	 Â 3	 Â and	 Â 5	 Â for	 Â the	 Â model;	 Â better	 Â results	 Â were	 Â achieved	 Â with	 Â size	 Â 5.	 Â It	 Â was	 Â 
observed	 Â  that	 Â  increasing	 Â  number	 Â  of	 Â  iterations	 Â  does	 Â  not	 Â  necessarily	 Â  increase	 Â  the	 Â  performance.	 Â  The	 Â 
improvement	 Â  stagnated	 Â  after	 Â  40	 Â  iterations.	 Â  For	 Â  regularization	 Â  parameter	 Â  (Î»	 Â  =0.02)	 Â  gave	 Â  the	 Â  best	 Â 
performance.	 Â  The	 Â  performance	 Â  was	 Â  decreasing	 Â  for	 Â  higher	 Â  values	 Â  of	 Â  Î».	 Â  The	 Â  learning	 Â  rate	 Â  (Î±)	 Â  was	 Â 
optimized	 Â at	 Â 0.075.	 Â Lower	 Â learning	 Â rate	 Â gives	 Â inferior	 Â results.	 Â 	 Â 	 Â The	 Â optimal	 Â values	 Â found	 Â for	 Â the	 Â tuning	 Â 
parameters	 Â are	 Â given	 Â in	 Â Table	 Â 1.	 Â 

	 Â 

	 Â 

Parameters	 Â 

Epoch	 Â 

Learning	 Â Rate	 Â (Î±)	 Â 
Regularization	 Â (Î»)	 Â 

Context	 Â Window	 Â Size	 Â (C)	 Â 

Optimal	 Â Value	 Â 

40	 Â 

0.075	 Â 
0.02	 Â 

5	 Â 

Table	 Â 1:	 Â Optimal	 Â Parameter	 Â Values	 Â for	 Â NER	 Â 

	 Â 

LOC	 Â 
MISC	 Â 
ORG	 Â 
PER	 Â 

System	 Â 

Recall	 Â 
85.20%	 Â 
74.53%	 Â 
64.58%	 Â 
76.53%	 Â 
75.44%	 Â 

Precision	 Â 
92.10%	 Â 
91.39%	 Â 
84.54%	 Â 
96.17%	 Â 
91.73%	 Â 

F1	 Â 

88.52%	 Â 
82.10%	 Â 
73.22%	 Â 
85.23%	 Â 
82.79%	 Â 

Table	 Â 2:	 Â NER	 Â Evaluation	 Â Results	 Â 

Recall	 Â 

Precision	 Â 

F1	 Â 

LOC	 Â 

PER	 Â 

System	 Â 

120.00%	 Â 

100.00%	 Â 

80.00%	 Â 

60.00%	 Â 

40.00%	 Â 

20.00%	 Â 

0.00%	 Â 

MISC	 Â 

ORG	 Â 

	 Â 	 Â 	 Â 

	 Â 	 Â 	 Â 
	 Â 	 Â Figure	 Â 1:	 Â NER	 Â Evaluation	 Â results	 Â 
Question	 Â Answering	 Â 
Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â used	 Â in	 Â a	 Â lot	 Â of	 Â NLP	 Â tasks.	 Â In	 Â particular,	 Â they	 Â play	 Â a	 Â prominent	 Â 
role	 Â in	 Â Question-Â­â€Answering.	 Â Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â typically	 Â used	 Â in	 Â question	 Â answering	 Â 
systems	 Â like	 Â AFNER	 Â to	 Â narrow	 Â down	 Â the	 Â candidate	 Â answers	 Â which	 Â match	 Â the	 Â semantic	 Â category	 Â of	 Â the	 Â 
selected	 Â answer.	 Â 	 Â For	 Â example,	 Â the	 Â answer	 Â to	 Â the	 Â question	 Â â€œWhich	 Â is	 Â the	 Â Capital	 Â of	 Â Franceâ€,	 Â the	 Â system	 Â 
identifies	 Â  the	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer	 Â  to	 Â  be	 Â  a	 Â  Location	 Â  (LOC).	 Â  Thus,	 Â  the	 Â  system	 Â  will	 Â  only	 Â 

Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

using	 Â  Googleâ€™s	 Â  dataset	 Â  [1].	 Â  The	 Â  algorithm	 Â  performed	 Â  well	 Â  on	 Â  smaller	 Â  subsets	 Â  of	 Â  our	 Â  data	 Â  but	 Â  when	 Â 
training	 Â on	 Â a	 Â large	 Â vocabulary	 Â (>1	 Â M),	 Â the	 Â training	 Â time	 Â became	 Â excessively	 Â large,	 Â so	 Â we	 Â used	 Â pre-Â­â€trained	 Â 
word	 Â vectors	 Â [1].	 Â 
Named	 Â Entity	 Â Recognition	 Â 
NER	 Â  is	 Â  a	 Â  classification	 Â  problem,	 Â  where	 Â  each	 Â  input	 Â  word	 Â  is	 Â  classified	 Â  as	 Â  being	 Â  a	 Â  Location,	 Â  Person,	 Â 
Organization,	 Â  Miscellaneous	 Â  and	 Â  Other	 Â  (not	 Â  any	 Â  named	 Â  entity).	 Â  The	 Â  algorithm	 Â  uses	 Â  tokenized	 Â  text	 Â  to	 Â 
train	 Â  a	 Â  neural	 Â  network	 Â  model	 Â  for	 Â  named	 Â  entity	 Â  recognition	 Â  with	 Â  multiple	 Â  classes.	 Â  The	 Â  detailed	 Â 
annotation	 Â  structure	 Â  for	 Â  the	 Â  dataset	 Â  is	 Â  given	 Â  at	 Â  [13].	 Â  The	 Â  training	 Â  and	 Â  the	 Â  testing	 Â  data	 Â  for	 Â  the	 Â  NER	 Â 
algorithm	 Â  is	 Â  taken	 Â  from	 Â  CoNLL03	 Â  corpus.	 Â  The	 Â  data	 Â  consists	 Â  of	 Â  sentences	 Â  with	 Â  one	 Â  token	 Â  per	 Â  line	 Â  and	 Â 
each	 Â  token	 Â  is	 Â  associated	 Â  with	 Â  5	 Â  possible	 Â  labels:	 Â  {O,	 Â  LOC,	 Â  MISC,	 Â  ORG,	 Â  PER}	 Â  representing	 Â  the	 Â  classes	 Â 
defined	 Â  above.	 Â  The	 Â  word	 Â  vectors	 Â  learned	 Â  using	 Â  the	 Â  CBOW	 Â  model	 Â  were	 Â  used	 Â  to	 Â  construct	 Â  context	 Â 
windows	 Â that	 Â serve	 Â as	 Â input	 Â features	 Â to	 Â the	 Â neural	 Â network.	 Â 

The	 Â  model	 Â  is	 Â  implemented	 Â  as	 Â  single	 Â  layer	 Â  neural	 Â  network	 Â  with	 Â  word	 Â  embedding	 Â  as	 Â  the	 Â  input	 Â  layer	 Â 
feeding	 Â to	 Â feedforward	 Â algorithm.	 Â The	 Â predicted	 Â class	 Â vector	 Â is	 Â then	 Â compared	 Â to	 Â the	 Â actual	 Â class	 Â and	 Â 
the	 Â delta	 Â error	 Â propagates	 Â back	 Â updating	 Â the	 Â model.	 Â As	 Â the	 Â algorithm	 Â iterates	 Â through	 Â the	 Â dataset	 Â it	 Â 
learns	 Â both	 Â the	 Â classifier	 Â and	 Â the	 Â word	 Â representations.	 Â 	 Â 

The	 Â feedforward	 Â operation	 Â is	 Â given	 Â by	 Â the	 Â following	 Â set	 Â of	 Â equations	 Â 

ğ‘§=ğ‘Š ğ‘¥!!!ğ‘¥!ğ‘¥!!! +ğ‘(!)	 Â 
â„=ğ‘¡ğ‘ğ‘›â„(ğ‘§)	 Â 
ğ‘=ğ‘”(ğ‘ˆâ„+ğ‘!)	 Â 
ğ‘¦!!ğ‘™ğ‘œğ‘”ğ‘!,!(ğ‘¥(!))

Where	 Â ((ğ‘¥!!!,ğ‘¥!,ğ‘¥!!!)	 Â is	 Â the	 Â context	 Â window,	 Â W	 Â and	 Â U	 Â are	 Â the	 Â model	 Â parameters	 Â and	 Â g	 Â is	 Â the	 Â softmax	 Â 

function.	 Â The	 Â cost	 Â function	 Â to	 Â minimize	 Â is	 Â given	 Â by	 Â the	 Â following	 Â equation	 Â 

ğ½ğœƒ = Â 

!
!!!

!
!!!

ğ´+ ğœ†2ğ‘š(ğ‘Š !+ ğ‘ˆ !) Â 

	 Â 

Where	 Â m	 Â is	 Â the	 Â number	 Â of	 Â data	 Â samples,	 Â K	 Â is	 Â the	 Â number	 Â of	 Â entity	 Â classes	 Â and	 Â Î»	 Â is	 Â the	 Â regularization	 Â 
parameter.	 Â  The	 Â  parameters	 Â  are	 Â  learned	 Â  using	 Â  stochastic	 Â  gradient	 Â  descent	 Â  algorithm	 Â  and	 Â  gradient	 Â 
checking	 Â is	 Â used	 Â for	 Â bug-Â­â€free	 Â implementation.	 Â 

The	 Â  evaluation	 Â  of	 Â  the	 Â  implemented	 Â  algorithm	 Â  was	 Â  done	 Â  using	 Â  the	 Â  CoNLL03	 Â  conlleval	 Â  Perl	 Â  script.	 Â  The	 Â 
script	 Â evaluates	 Â the	 Â NER	 Â systemâ€™s	 Â capability	 Â of	 Â identifying	 Â named	 Â entities.	 Â It	 Â gives	 Â a	 Â clear	 Â presentation	 Â of	 Â 
the	 Â  performance	 Â  of	 Â  the	 Â  system	 Â  on	 Â  various	 Â  entity	 Â  categories	 Â  (person,	 Â 
location,	 Â  organization,	 Â 
miscellaneous	 Â and	 Â other)	 Â based	 Â on	 Â the	 Â precision,	 Â recall	 Â and	 Â F1	 Â measures.	 Â 
Results	 Â 

Tuning	 Â Parameters	 Â 

The	 Â parameters	 Â of	 Â the	 Â system	 Â that	 Â were	 Â tuned	 Â for	 Â higher	 Â accuracy	 Â were:	 Â 

â€¢  The	 Â regularization	 Â constant	 Â (Î»)	 Â 
â€¢  The	 Â learning	 Â rate	 Â (Î±)	 Â 
â€¢  The	 Â context	 Â window	 Â size	 Â (C)	 Â 
â€¢  The	 Â number	 Â of	 Â iterations	 Â (epochs)	 Â 

We	 Â used	 Â context	 Â window	 Â size	 Â of	 Â 3	 Â and	 Â 5	 Â for	 Â the	 Â model;	 Â better	 Â results	 Â were	 Â achieved	 Â with	 Â size	 Â 5.	 Â It	 Â was	 Â 
observed	 Â  that	 Â  increasing	 Â  number	 Â  of	 Â  iterations	 Â  does	 Â  not	 Â  necessarily	 Â  increase	 Â  the	 Â  performance.	 Â  The	 Â 
improvement	 Â  stagnated	 Â  after	 Â  40	 Â  iterations.	 Â  For	 Â  regularization	 Â  parameter	 Â  (Î»	 Â  =0.02)	 Â  gave	 Â  the	 Â  best	 Â 
performance.	 Â  The	 Â  performance	 Â  was	 Â  decreasing	 Â  for	 Â  higher	 Â  values	 Â  of	 Â  Î».	 Â  The	 Â  learning	 Â  rate	 Â  (Î±)	 Â  was	 Â 
optimized	 Â at	 Â 0.075.	 Â Lower	 Â learning	 Â rate	 Â gives	 Â inferior	 Â results.	 Â 	 Â 	 Â The	 Â optimal	 Â values	 Â found	 Â for	 Â the	 Â tuning	 Â 
parameters	 Â are	 Â given	 Â in	 Â Table	 Â 1.	 Â 

	 Â 

	 Â 

Parameters	 Â 

Epoch	 Â 

Learning	 Â Rate	 Â (Î±)	 Â 
Regularization	 Â (Î»)	 Â 

Context	 Â Window	 Â Size	 Â (C)	 Â 

Optimal	 Â Value	 Â 

40	 Â 

0.075	 Â 
0.02	 Â 

5	 Â 

Table	 Â 1:	 Â Optimal	 Â Parameter	 Â Values	 Â for	 Â NER	 Â 

	 Â 

LOC	 Â 
MISC	 Â 
ORG	 Â 
PER	 Â 

System	 Â 

Recall	 Â 
85.20%	 Â 
74.53%	 Â 
64.58%	 Â 
76.53%	 Â 
75.44%	 Â 

Precision	 Â 
92.10%	 Â 
91.39%	 Â 
84.54%	 Â 
96.17%	 Â 
91.73%	 Â 

F1	 Â 

88.52%	 Â 
82.10%	 Â 
73.22%	 Â 
85.23%	 Â 
82.79%	 Â 

Table	 Â 2:	 Â NER	 Â Evaluation	 Â Results	 Â 

Recall	 Â 

Precision	 Â 

F1	 Â 

LOC	 Â 

PER	 Â 

System	 Â 

120.00%	 Â 

100.00%	 Â 

80.00%	 Â 

60.00%	 Â 

40.00%	 Â 

20.00%	 Â 

0.00%	 Â 

MISC	 Â 

ORG	 Â 

	 Â 	 Â 	 Â 

	 Â 	 Â 	 Â 
	 Â 	 Â Figure	 Â 1:	 Â NER	 Â Evaluation	 Â results	 Â 
Question	 Â Answering	 Â 
Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â used	 Â in	 Â a	 Â lot	 Â of	 Â NLP	 Â tasks.	 Â In	 Â particular,	 Â they	 Â play	 Â a	 Â prominent	 Â 
role	 Â in	 Â Question-Â­â€Answering.	 Â Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â typically	 Â used	 Â in	 Â question	 Â answering	 Â 
systems	 Â like	 Â AFNER	 Â to	 Â narrow	 Â down	 Â the	 Â candidate	 Â answers	 Â which	 Â match	 Â the	 Â semantic	 Â category	 Â of	 Â the	 Â 
selected	 Â answer.	 Â 	 Â For	 Â example,	 Â the	 Â answer	 Â to	 Â the	 Â question	 Â â€œWhich	 Â is	 Â the	 Â Capital	 Â of	 Â Franceâ€,	 Â the	 Â system	 Â 
identifies	 Â  the	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer	 Â  to	 Â  be	 Â  a	 Â  Location	 Â  (LOC).	 Â  Thus,	 Â  the	 Â  system	 Â  will	 Â  only	 Â 

consider	 Â  the	 Â  named	 Â  entities	 Â  with	 Â  category	 Â  LOC	 Â  as	 Â  answers	 Â  thereby	 Â  affecting	 Â  both	 Â  the	 Â  precision	 Â  and	 Â 
performance	 Â of	 Â the	 Â overall	 Â system.	 Â 

In	 Â  this	 Â  paper	 Â  we	 Â  utilize	 Â  our	 Â  Neural	 Â  Network	 Â  based	 Â  NER	 Â  model	 Â  to	 Â  identify	 Â  and	 Â  classify	 Â  NEs	 Â  in	 Â  natural	 Â 
language	 Â  questions.	 Â  We	 Â  hypothesize	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  can	 Â  benefit	 Â  from	 Â  the	 Â  inclusion	 Â  of	 Â  the	 Â  pre-Â­â€
labelled	 Â  questions	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  training	 Â  and	 Â  testing	 Â  corpus	 Â  for	 Â  the	 Â  experiment	 Â  was	 Â 
downloaded	 Â from	 Â [14].	 Â The	 Â training	 Â data	 Â consists	 Â of	 Â 5500	 Â annotated	 Â questions	 Â with	 Â categories	 Â PER,	 Â LOC	 Â 
and	 Â ORG.	 Â Similarly	 Â the	 Â test	 Â data	 Â consists	 Â of	 Â 500	 Â pre-Â­â€annotated	 Â questions.	 Â 

The	 Â performance	 Â is	 Â baselined	 Â using	 Â the	 Â system	 Â trained	 Â on	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â tested	 Â on	 Â the	 Â 500	 Â 
test	 Â questions.	 Â The	 Â baseline	 Â results	 Â are	 Â given	 Â in	 Â the	 Â Table	 Â 3.	 Â Although	 Â the	 Â F-Â­â€measure	 Â for	 Â the	 Â free	 Â text	 Â 
test	 Â corpus	 Â was	 Â 82.79%,	 Â the	 Â systemâ€™s	 Â performance	 Â drops	 Â to	 Â 56.81%	 Â when	 Â tested	 Â on	 Â the	 Â 500	 Â annotated	 Â 
questions	 Â test	 Â corpus.	 Â Next,	 Â we	 Â trained	 Â the	 Â NER	 Â system	 Â on	 Â the	 Â training	 Â corpus	 Â of	 Â 5500	 Â pre-Â­â€annotated	 Â 
questions	 Â and	 Â tested	 Â the	 Â resulting	 Â model	 Â both	 Â on	 Â the	 Â CoNLL03	 Â test	 Â data	 Â and	 Â the	 Â 500	 Â test	 Â questions.	 Â The	 Â 
results	 Â  of	 Â  the	 Â  step	 Â  are	 Â  given	 Â  in	 Â  Table	 Â  4.	 Â  The	 Â  system	 Â  performed	 Â  well	 Â  on	 Â  the	 Â  annotated	 Â  questions	 Â  test	 Â 
corpus	 Â but	 Â failed	 Â miserably	 Â for	 Â the	 Â CoNLL03	 Â free	 Â text	 Â test	 Â corpus.	 Â Finally,	 Â the	 Â NER	 Â system	 Â was	 Â trained	 Â on	 Â 
using	 Â both	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â 5500	 Â pre-Â­â€annotated	 Â questions	 Â corpus.	 Â The	 Â performance	 Â on	 Â both	 Â the	 Â 
test	 Â datasets	 Â are	 Â given	 Â in	 Â Table	 Â 5.	 Â We	 Â achieved	 Â an	 Â F-Â­â€measure	 Â of	 Â 83.2%	 Â on	 Â the	 Â question	 Â test	 Â data	 Â when	 Â 
the	 Â training	 Â data	 Â contained	 Â both	 Â the	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â data.	 Â 

The	 Â  results	 Â  obtained	 Â  in	 Â  this	 Â  work	 Â  suggests	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  used	 Â  in	 Â  aiding	 Â  question	 Â  answering	 Â 
system	 Â benefits	 Â from	 Â including	 Â questions	 Â in	 Â the	 Â training	 Â corpus.	 Â To	 Â build	 Â a	 Â NER	 Â model	 Â which	 Â provides	 Â an	 Â 
F-Â­â€measure	 Â >	 Â 80%	 Â we	 Â should	 Â build	 Â a	 Â training	 Â corpus	 Â which	 Â is	 Â a	 Â suitable	 Â mix	 Â of	 Â free	 Â text	 Â and	 Â annotated	 Â 
questions.	 Â As	 Â shown	 Â in	 Â Table	 Â 5,	 Â the	 Â inclusion	 Â of	 Â free	 Â text	 Â in	 Â the	 Â training	 Â data	 Â is	 Â not	 Â relevant	 Â if	 Â we	 Â have	 Â 
sufficient	 Â questions	 Â to	 Â train	 Â the	 Â NER	 Â system	 Â and	 Â the	 Â system	 Â is	 Â used	 Â only	 Â for	 Â Question	 Â Answering.	 Â But	 Â to	 Â 
build	 Â a	 Â general-Â­â€purpose	 Â model	 Â the	 Â system	 Â will	 Â benefit	 Â from	 Â combination	 Â of	 Â training	 Â data.	 Â 

	 Â 

Train	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â 
Table	 Â 3:	 Â Baseline	 Â NER	 Â Results	 Â 

14987	 Â 

Tokens	 Â 
219554	 Â 

Eval	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
51.37	 Â 
51.37	 Â 

Precision	 Â 

(%)	 Â 
91.73	 Â 
63.53	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.79	 Â 
56.81	 Â 

Type	 Â 

Train	 Â 

Recall	 Â 
(%)	 Â 
18.18	 Â 
Questions	 Â 
72.95	 Â 
Table	 Â 4:	 Â Trained	 Â on	 Â 5500	 Â Pre-Â­â€annotated	 Â questions	 Â only	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Tokens	 Â 
61074	 Â 

Sentences	 Â 

5452	 Â 

Eval	 Â 

Precision	 Â 

(%)	 Â 
43.17	 Â 
89.22	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
25.58	 Â 
80.07	 Â 

Train	 Â 

Eval	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â +	 Â Questions	 Â 
Table	 Â 5:	 Â Trained	 Â on	 Â both	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â questions	 Â 

20439	 Â 

Tokens	 Â 
280628	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
76.16	 Â 
79.03	 Â 

Precision	 Â 

(%)	 Â 
90.76	 Â 
87.84	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.82	 Â 
83.20	 Â 

	 Â 

Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

using	 Â  Googleâ€™s	 Â  dataset	 Â  [1].	 Â  The	 Â  algorithm	 Â  performed	 Â  well	 Â  on	 Â  smaller	 Â  subsets	 Â  of	 Â  our	 Â  data	 Â  but	 Â  when	 Â 
training	 Â on	 Â a	 Â large	 Â vocabulary	 Â (>1	 Â M),	 Â the	 Â training	 Â time	 Â became	 Â excessively	 Â large,	 Â so	 Â we	 Â used	 Â pre-Â­â€trained	 Â 
word	 Â vectors	 Â [1].	 Â 
Named	 Â Entity	 Â Recognition	 Â 
NER	 Â  is	 Â  a	 Â  classification	 Â  problem,	 Â  where	 Â  each	 Â  input	 Â  word	 Â  is	 Â  classified	 Â  as	 Â  being	 Â  a	 Â  Location,	 Â  Person,	 Â 
Organization,	 Â  Miscellaneous	 Â  and	 Â  Other	 Â  (not	 Â  any	 Â  named	 Â  entity).	 Â  The	 Â  algorithm	 Â  uses	 Â  tokenized	 Â  text	 Â  to	 Â 
train	 Â  a	 Â  neural	 Â  network	 Â  model	 Â  for	 Â  named	 Â  entity	 Â  recognition	 Â  with	 Â  multiple	 Â  classes.	 Â  The	 Â  detailed	 Â 
annotation	 Â  structure	 Â  for	 Â  the	 Â  dataset	 Â  is	 Â  given	 Â  at	 Â  [13].	 Â  The	 Â  training	 Â  and	 Â  the	 Â  testing	 Â  data	 Â  for	 Â  the	 Â  NER	 Â 
algorithm	 Â  is	 Â  taken	 Â  from	 Â  CoNLL03	 Â  corpus.	 Â  The	 Â  data	 Â  consists	 Â  of	 Â  sentences	 Â  with	 Â  one	 Â  token	 Â  per	 Â  line	 Â  and	 Â 
each	 Â  token	 Â  is	 Â  associated	 Â  with	 Â  5	 Â  possible	 Â  labels:	 Â  {O,	 Â  LOC,	 Â  MISC,	 Â  ORG,	 Â  PER}	 Â  representing	 Â  the	 Â  classes	 Â 
defined	 Â  above.	 Â  The	 Â  word	 Â  vectors	 Â  learned	 Â  using	 Â  the	 Â  CBOW	 Â  model	 Â  were	 Â  used	 Â  to	 Â  construct	 Â  context	 Â 
windows	 Â that	 Â serve	 Â as	 Â input	 Â features	 Â to	 Â the	 Â neural	 Â network.	 Â 

The	 Â  model	 Â  is	 Â  implemented	 Â  as	 Â  single	 Â  layer	 Â  neural	 Â  network	 Â  with	 Â  word	 Â  embedding	 Â  as	 Â  the	 Â  input	 Â  layer	 Â 
feeding	 Â to	 Â feedforward	 Â algorithm.	 Â The	 Â predicted	 Â class	 Â vector	 Â is	 Â then	 Â compared	 Â to	 Â the	 Â actual	 Â class	 Â and	 Â 
the	 Â delta	 Â error	 Â propagates	 Â back	 Â updating	 Â the	 Â model.	 Â As	 Â the	 Â algorithm	 Â iterates	 Â through	 Â the	 Â dataset	 Â it	 Â 
learns	 Â both	 Â the	 Â classifier	 Â and	 Â the	 Â word	 Â representations.	 Â 	 Â 

The	 Â feedforward	 Â operation	 Â is	 Â given	 Â by	 Â the	 Â following	 Â set	 Â of	 Â equations	 Â 

ğ‘§=ğ‘Š ğ‘¥!!!ğ‘¥!ğ‘¥!!! +ğ‘(!)	 Â 
â„=ğ‘¡ğ‘ğ‘›â„(ğ‘§)	 Â 
ğ‘=ğ‘”(ğ‘ˆâ„+ğ‘!)	 Â 
ğ‘¦!!ğ‘™ğ‘œğ‘”ğ‘!,!(ğ‘¥(!))

Where	 Â ((ğ‘¥!!!,ğ‘¥!,ğ‘¥!!!)	 Â is	 Â the	 Â context	 Â window,	 Â W	 Â and	 Â U	 Â are	 Â the	 Â model	 Â parameters	 Â and	 Â g	 Â is	 Â the	 Â softmax	 Â 

function.	 Â The	 Â cost	 Â function	 Â to	 Â minimize	 Â is	 Â given	 Â by	 Â the	 Â following	 Â equation	 Â 

ğ½ğœƒ = Â 

!
!!!

!
!!!

ğ´+ ğœ†2ğ‘š(ğ‘Š !+ ğ‘ˆ !) Â 

	 Â 

Where	 Â m	 Â is	 Â the	 Â number	 Â of	 Â data	 Â samples,	 Â K	 Â is	 Â the	 Â number	 Â of	 Â entity	 Â classes	 Â and	 Â Î»	 Â is	 Â the	 Â regularization	 Â 
parameter.	 Â  The	 Â  parameters	 Â  are	 Â  learned	 Â  using	 Â  stochastic	 Â  gradient	 Â  descent	 Â  algorithm	 Â  and	 Â  gradient	 Â 
checking	 Â is	 Â used	 Â for	 Â bug-Â­â€free	 Â implementation.	 Â 

The	 Â  evaluation	 Â  of	 Â  the	 Â  implemented	 Â  algorithm	 Â  was	 Â  done	 Â  using	 Â  the	 Â  CoNLL03	 Â  conlleval	 Â  Perl	 Â  script.	 Â  The	 Â 
script	 Â evaluates	 Â the	 Â NER	 Â systemâ€™s	 Â capability	 Â of	 Â identifying	 Â named	 Â entities.	 Â It	 Â gives	 Â a	 Â clear	 Â presentation	 Â of	 Â 
the	 Â  performance	 Â  of	 Â  the	 Â  system	 Â  on	 Â  various	 Â  entity	 Â  categories	 Â  (person,	 Â 
location,	 Â  organization,	 Â 
miscellaneous	 Â and	 Â other)	 Â based	 Â on	 Â the	 Â precision,	 Â recall	 Â and	 Â F1	 Â measures.	 Â 
Results	 Â 

Tuning	 Â Parameters	 Â 

The	 Â parameters	 Â of	 Â the	 Â system	 Â that	 Â were	 Â tuned	 Â for	 Â higher	 Â accuracy	 Â were:	 Â 

â€¢  The	 Â regularization	 Â constant	 Â (Î»)	 Â 
â€¢  The	 Â learning	 Â rate	 Â (Î±)	 Â 
â€¢  The	 Â context	 Â window	 Â size	 Â (C)	 Â 
â€¢  The	 Â number	 Â of	 Â iterations	 Â (epochs)	 Â 

We	 Â used	 Â context	 Â window	 Â size	 Â of	 Â 3	 Â and	 Â 5	 Â for	 Â the	 Â model;	 Â better	 Â results	 Â were	 Â achieved	 Â with	 Â size	 Â 5.	 Â It	 Â was	 Â 
observed	 Â  that	 Â  increasing	 Â  number	 Â  of	 Â  iterations	 Â  does	 Â  not	 Â  necessarily	 Â  increase	 Â  the	 Â  performance.	 Â  The	 Â 
improvement	 Â  stagnated	 Â  after	 Â  40	 Â  iterations.	 Â  For	 Â  regularization	 Â  parameter	 Â  (Î»	 Â  =0.02)	 Â  gave	 Â  the	 Â  best	 Â 
performance.	 Â  The	 Â  performance	 Â  was	 Â  decreasing	 Â  for	 Â  higher	 Â  values	 Â  of	 Â  Î».	 Â  The	 Â  learning	 Â  rate	 Â  (Î±)	 Â  was	 Â 
optimized	 Â at	 Â 0.075.	 Â Lower	 Â learning	 Â rate	 Â gives	 Â inferior	 Â results.	 Â 	 Â 	 Â The	 Â optimal	 Â values	 Â found	 Â for	 Â the	 Â tuning	 Â 
parameters	 Â are	 Â given	 Â in	 Â Table	 Â 1.	 Â 

	 Â 

	 Â 

Parameters	 Â 

Epoch	 Â 

Learning	 Â Rate	 Â (Î±)	 Â 
Regularization	 Â (Î»)	 Â 

Context	 Â Window	 Â Size	 Â (C)	 Â 

Optimal	 Â Value	 Â 

40	 Â 

0.075	 Â 
0.02	 Â 

5	 Â 

Table	 Â 1:	 Â Optimal	 Â Parameter	 Â Values	 Â for	 Â NER	 Â 

	 Â 

LOC	 Â 
MISC	 Â 
ORG	 Â 
PER	 Â 

System	 Â 

Recall	 Â 
85.20%	 Â 
74.53%	 Â 
64.58%	 Â 
76.53%	 Â 
75.44%	 Â 

Precision	 Â 
92.10%	 Â 
91.39%	 Â 
84.54%	 Â 
96.17%	 Â 
91.73%	 Â 

F1	 Â 

88.52%	 Â 
82.10%	 Â 
73.22%	 Â 
85.23%	 Â 
82.79%	 Â 

Table	 Â 2:	 Â NER	 Â Evaluation	 Â Results	 Â 

Recall	 Â 

Precision	 Â 

F1	 Â 

LOC	 Â 

PER	 Â 

System	 Â 

120.00%	 Â 

100.00%	 Â 

80.00%	 Â 

60.00%	 Â 

40.00%	 Â 

20.00%	 Â 

0.00%	 Â 

MISC	 Â 

ORG	 Â 

	 Â 	 Â 	 Â 

	 Â 	 Â 	 Â 
	 Â 	 Â Figure	 Â 1:	 Â NER	 Â Evaluation	 Â results	 Â 
Question	 Â Answering	 Â 
Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â used	 Â in	 Â a	 Â lot	 Â of	 Â NLP	 Â tasks.	 Â In	 Â particular,	 Â they	 Â play	 Â a	 Â prominent	 Â 
role	 Â in	 Â Question-Â­â€Answering.	 Â Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â typically	 Â used	 Â in	 Â question	 Â answering	 Â 
systems	 Â like	 Â AFNER	 Â to	 Â narrow	 Â down	 Â the	 Â candidate	 Â answers	 Â which	 Â match	 Â the	 Â semantic	 Â category	 Â of	 Â the	 Â 
selected	 Â answer.	 Â 	 Â For	 Â example,	 Â the	 Â answer	 Â to	 Â the	 Â question	 Â â€œWhich	 Â is	 Â the	 Â Capital	 Â of	 Â Franceâ€,	 Â the	 Â system	 Â 
identifies	 Â  the	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer	 Â  to	 Â  be	 Â  a	 Â  Location	 Â  (LOC).	 Â  Thus,	 Â  the	 Â  system	 Â  will	 Â  only	 Â 

consider	 Â  the	 Â  named	 Â  entities	 Â  with	 Â  category	 Â  LOC	 Â  as	 Â  answers	 Â  thereby	 Â  affecting	 Â  both	 Â  the	 Â  precision	 Â  and	 Â 
performance	 Â of	 Â the	 Â overall	 Â system.	 Â 

In	 Â  this	 Â  paper	 Â  we	 Â  utilize	 Â  our	 Â  Neural	 Â  Network	 Â  based	 Â  NER	 Â  model	 Â  to	 Â  identify	 Â  and	 Â  classify	 Â  NEs	 Â  in	 Â  natural	 Â 
language	 Â  questions.	 Â  We	 Â  hypothesize	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  can	 Â  benefit	 Â  from	 Â  the	 Â  inclusion	 Â  of	 Â  the	 Â  pre-Â­â€
labelled	 Â  questions	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  training	 Â  and	 Â  testing	 Â  corpus	 Â  for	 Â  the	 Â  experiment	 Â  was	 Â 
downloaded	 Â from	 Â [14].	 Â The	 Â training	 Â data	 Â consists	 Â of	 Â 5500	 Â annotated	 Â questions	 Â with	 Â categories	 Â PER,	 Â LOC	 Â 
and	 Â ORG.	 Â Similarly	 Â the	 Â test	 Â data	 Â consists	 Â of	 Â 500	 Â pre-Â­â€annotated	 Â questions.	 Â 

The	 Â performance	 Â is	 Â baselined	 Â using	 Â the	 Â system	 Â trained	 Â on	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â tested	 Â on	 Â the	 Â 500	 Â 
test	 Â questions.	 Â The	 Â baseline	 Â results	 Â are	 Â given	 Â in	 Â the	 Â Table	 Â 3.	 Â Although	 Â the	 Â F-Â­â€measure	 Â for	 Â the	 Â free	 Â text	 Â 
test	 Â corpus	 Â was	 Â 82.79%,	 Â the	 Â systemâ€™s	 Â performance	 Â drops	 Â to	 Â 56.81%	 Â when	 Â tested	 Â on	 Â the	 Â 500	 Â annotated	 Â 
questions	 Â test	 Â corpus.	 Â Next,	 Â we	 Â trained	 Â the	 Â NER	 Â system	 Â on	 Â the	 Â training	 Â corpus	 Â of	 Â 5500	 Â pre-Â­â€annotated	 Â 
questions	 Â and	 Â tested	 Â the	 Â resulting	 Â model	 Â both	 Â on	 Â the	 Â CoNLL03	 Â test	 Â data	 Â and	 Â the	 Â 500	 Â test	 Â questions.	 Â The	 Â 
results	 Â  of	 Â  the	 Â  step	 Â  are	 Â  given	 Â  in	 Â  Table	 Â  4.	 Â  The	 Â  system	 Â  performed	 Â  well	 Â  on	 Â  the	 Â  annotated	 Â  questions	 Â  test	 Â 
corpus	 Â but	 Â failed	 Â miserably	 Â for	 Â the	 Â CoNLL03	 Â free	 Â text	 Â test	 Â corpus.	 Â Finally,	 Â the	 Â NER	 Â system	 Â was	 Â trained	 Â on	 Â 
using	 Â both	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â 5500	 Â pre-Â­â€annotated	 Â questions	 Â corpus.	 Â The	 Â performance	 Â on	 Â both	 Â the	 Â 
test	 Â datasets	 Â are	 Â given	 Â in	 Â Table	 Â 5.	 Â We	 Â achieved	 Â an	 Â F-Â­â€measure	 Â of	 Â 83.2%	 Â on	 Â the	 Â question	 Â test	 Â data	 Â when	 Â 
the	 Â training	 Â data	 Â contained	 Â both	 Â the	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â data.	 Â 

The	 Â  results	 Â  obtained	 Â  in	 Â  this	 Â  work	 Â  suggests	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  used	 Â  in	 Â  aiding	 Â  question	 Â  answering	 Â 
system	 Â benefits	 Â from	 Â including	 Â questions	 Â in	 Â the	 Â training	 Â corpus.	 Â To	 Â build	 Â a	 Â NER	 Â model	 Â which	 Â provides	 Â an	 Â 
F-Â­â€measure	 Â >	 Â 80%	 Â we	 Â should	 Â build	 Â a	 Â training	 Â corpus	 Â which	 Â is	 Â a	 Â suitable	 Â mix	 Â of	 Â free	 Â text	 Â and	 Â annotated	 Â 
questions.	 Â As	 Â shown	 Â in	 Â Table	 Â 5,	 Â the	 Â inclusion	 Â of	 Â free	 Â text	 Â in	 Â the	 Â training	 Â data	 Â is	 Â not	 Â relevant	 Â if	 Â we	 Â have	 Â 
sufficient	 Â questions	 Â to	 Â train	 Â the	 Â NER	 Â system	 Â and	 Â the	 Â system	 Â is	 Â used	 Â only	 Â for	 Â Question	 Â Answering.	 Â But	 Â to	 Â 
build	 Â a	 Â general-Â­â€purpose	 Â model	 Â the	 Â system	 Â will	 Â benefit	 Â from	 Â combination	 Â of	 Â training	 Â data.	 Â 

	 Â 

Train	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â 
Table	 Â 3:	 Â Baseline	 Â NER	 Â Results	 Â 

14987	 Â 

Tokens	 Â 
219554	 Â 

Eval	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
51.37	 Â 
51.37	 Â 

Precision	 Â 

(%)	 Â 
91.73	 Â 
63.53	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.79	 Â 
56.81	 Â 

Type	 Â 

Train	 Â 

Recall	 Â 
(%)	 Â 
18.18	 Â 
Questions	 Â 
72.95	 Â 
Table	 Â 4:	 Â Trained	 Â on	 Â 5500	 Â Pre-Â­â€annotated	 Â questions	 Â only	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Tokens	 Â 
61074	 Â 

Sentences	 Â 

5452	 Â 

Eval	 Â 

Precision	 Â 

(%)	 Â 
43.17	 Â 
89.22	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
25.58	 Â 
80.07	 Â 

Train	 Â 

Eval	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â +	 Â Questions	 Â 
Table	 Â 5:	 Â Trained	 Â on	 Â both	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â questions	 Â 

20439	 Â 

Tokens	 Â 
280628	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
76.16	 Â 
79.03	 Â 

Precision	 Â 

(%)	 Â 
90.76	 Â 
87.84	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.82	 Â 
83.20	 Â 

	 Â 

Clustering	 Â word	 Â vectors	 Â for	 Â training	 Â NER	 Â 
The	 Â clustering	 Â was	 Â done	 Â using	 Â K-Â­â€means	 Â algorithm	 Â on	 Â the	 Â 200	 Â dimensional	 Â word	 Â vectors	 Â generated	 Â by	 Â 
Word2Vec	 Â model.	 Â We	 Â constructed	 Â clusters	 Â of	 Â multiple	 Â granularities,	 Â through	 Â hierarchical	 Â clustering.	 Â The	 Â 
primary	 Â  intuition	 Â  being	 Â  that	 Â  clustering	 Â  would	 Â  give	 Â  us	 Â  a	 Â  unsupervised	 Â  automated	 Â  way	 Â  to	 Â  increase	 Â  our	 Â 
training	 Â  data,	 Â  similar	 Â  to	 Â  construction	 Â  a	 Â  NER	 Â  gazetteer.	 Â  We	 Â  found	 Â  that	 Â  unigram	 Â  clusters	 Â  capture	 Â  broad	 Â 
categories	 Â of	 Â entities	 Â (countries	 Â and	 Â states	 Â in	 Â a	 Â single	 Â cluster,	 Â names)	 Â and	 Â would	 Â be	 Â useful	 Â in	 Â NER	 Â if	 Â there	 Â 
are	 Â more	 Â number	 Â of	 Â labels.	 Â Also	 Â increasing	 Â the	 Â number	 Â of	 Â clusters	 Â gave	 Â us	 Â better	 Â separation	 Â of	 Â entities.	 Â 
The	 Â  clusters	 Â  generated	 Â  were	 Â  used	 Â  to	 Â  train	 Â  the	 Â  NER	 Â  model.	 Â  The	 Â  results	 Â  are	 Â  given	 Â  in	 Â  Table	 Â  6.	 Â  	 Â  An	 Â 
important	 Â  realization	 Â  was	 Â  that,	 Â  the	 Â  single	 Â  word	 Â  clusters	 Â  do	 Â  not	 Â  capture	 Â  context,	 Â  so	 Â  training	 Â  n-Â­â€gram	 Â 
clusters	 Â (setting	 Â n	 Â to	 Â be	 Â the	 Â size	 Â of	 Â the	 Â context	 Â window)	 Â could	 Â be	 Â more	 Â useful	 Â approach	 Â in	 Â clustering	 Â [5].	 Â 	 Â 

25.10	 Â 
83.40	 Â 
28.34	 Â 
83.56	 Â 

Cluster	 Â Granularity	 Â  F-Â­â€Measure	 Â (%)	 Â 
Training	 Â Corpus	 Â 
Clusters	 Â 
800	 Â 
CoNLL03	 Â +	 Â Clusters	 Â  800	 Â 
Clusters	 Â 
2000	 Â 
CoNLL03	 Â +	 Â Clusters	 Â  2000	 Â 	 Â 
Table	 Â 6:	 Â Testing	 Â Cluster	 Â Granularity	 Â 
Further	 Â Study	 Â 
Combining	 Â neural	 Â networks	 Â with	 Â word	 Â vector	 Â models	 Â for	 Â Named	 Â Entity	 Â recognition	 Â is	 Â an	 Â active	 Â field	 Â of	 Â 
study.	 Â Named	 Â Entity	 Â Recognition	 Â using	 Â recurrent	 Â neural	 Â networks	 Â (RNN)	 Â and	 Â Long	 Â Short	 Â Term	 Â Memory	 Â 
(LSTM)	 Â is	 Â also	 Â a	 Â promising	 Â future	 Â direction	 Â and	 Â better	 Â results	 Â have	 Â been	 Â achieved	 Â by	 Â it.	 Â Future	 Â directions	 Â 
of	 Â study	 Â for	 Â question	 Â answering	 Â would	 Â focus	 Â attention	 Â on	 Â dynamic	 Â memory	 Â networks	 Â that	 Â make	 Â the	 Â use	 Â 
of	 Â word	 Â vectors	 Â by	 Â combining	 Â a	 Â knowledge	 Â base	 Â (or	 Â facts)	 Â to	 Â achieve	 Â state	 Â of	 Â the	 Â art-Â­â€results	 Â [6].	 Â 
Acknowledgments:	 Â 
We	 Â would	 Â like	 Â to	 Â thank	 Â Prof.	 Â Andrew	 Â Ng	 Â and	 Â our	 Â project	 Â mentor,	 Â Youssef	 Â Ahres,	 Â for	 Â their	 Â guidance	 Â and	 Â 
support	 Â during	 Â the	 Â project.	 Â 	 Â 

Figure	 Â 2:	 Â PCA	 Â representation	 Â of	 Â Word	 Â Vectors	 Â 

	 Â 

	 Â 

Named	 Â Entity	 Â Recognition	 Â and	 Â Question	 Â Answering	 Â 	 Â 

Using	 Â Word	 Â Vectors	 Â and	 Â Clustering	 Â 

Zia	 Â Ahmed	 Â 

zahmed@stanford.edu	 Â 

	 Â 

Rajkiran	 Â Veluri	 Â 	 Â 

rveluri@stanford.edu	 Â 	 Â 

CS229:	 Â Machine	 Â Learning	 Â Project	 Â 

Computer	 Â Science	 Â Department,	 Â Stanford	 Â University	 Â 

	 Â 

Problem	 Â Statement	 Â 
In	 Â this	 Â paper	 Â we	 Â investigate	 Â the	 Â word2Vec	 Â model	 Â as	 Â proposed	 Â by	 Â Tomas	 Â Mikilov	 Â for	 Â determining	 Â word	 Â 
relationships	 Â  and	 Â  use	 Â  the	 Â  word	 Â  vectors	 Â  to	 Â  implement	 Â  a	 Â  Named	 Â  Entity	 Â  Recognition	 Â  (NER)	 Â  System.	 Â  NER	 Â 
plays	 Â a	 Â key	 Â role	 Â in	 Â many	 Â Natural	 Â Processing	 Â tasks	 Â like	 Â Question	 Â Answering	 Â (QA).	 Â This	 Â is	 Â due	 Â to	 Â the	 Â fact	 Â 
that	 Â  answers	 Â  to	 Â  many	 Â  questions	 Â  are	 Â  named	 Â  entities	 Â  that	 Â  depend	 Â  on	 Â  the	 Â  semantic	 Â  category	 Â  of	 Â  the	 Â 
expected	 Â  answer.	 Â  In	 Â  this	 Â  context,	 Â  we	 Â  examine	 Â  the	 Â  effectiveness	 Â  of	 Â  our	 Â  NER	 Â  algorithm	 Â  to	 Â  identify	 Â  the	 Â 
entity	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer.	 Â  In	 Â  particular	 Â  we	 Â  study	 Â  the	 Â  methodology	 Â  of	 Â  boosting	 Â  the	 Â 
performance	 Â of	 Â the	 Â NER	 Â system	 Â by	 Â training	 Â on	 Â pre-Â­â€annotated	 Â natural	 Â language	 Â questions	 Â combined	 Â with	 Â 
the	 Â annotated	 Â free	 Â text	 Â data.	 Â We	 Â hypothesize	 Â that	 Â the	 Â NER	 Â system	 Â can	 Â benefit	 Â from	 Â the	 Â inclusion	 Â of	 Â the	 Â 
pre-Â­â€labelled	 Â  questions.	 Â  Further	 Â  we	 Â  explore	 Â  clustering	 Â  mechanism	 Â  to	 Â  classify	 Â  Word	 Â  vectors	 Â  into	 Â  entity	 Â 
classes	 Â and	 Â discuss	 Â how	 Â clustering	 Â can	 Â be	 Â used	 Â to	 Â improve	 Â the	 Â performance	 Â of	 Â the	 Â NER	 Â system.	 Â 	 Â 
Introduction	 Â 
The	 Â Word2Vec	 Â model,	 Â proposed	 Â by	 Â Tomas	 Â Mikolov	 Â at	 Â Google,	 Â used	 Â Skip	 Â Gram	 Â and	 Â Continuous	 Â Bag	 Â of	 Â 
Words	 Â (CBOW)	 Â model	 Â to	 Â create	 Â word	 Â embeddings	 Â [8].	 Â An	 Â extension	 Â of	 Â Word2Vec	 Â is	 Â the	 Â Glove	 Â model	 Â 
proposed	 Â by	 Â Penninglon,	 Â which	 Â is	 Â easier	 Â to	 Â parallelize	 Â [9].	 Â These	 Â models	 Â have	 Â enabled	 Â natural	 Â language	 Â 
processing	 Â tasks	 Â like	 Â NER,	 Â POS	 Â tagging	 Â to	 Â avoid	 Â manual	 Â designing	 Â of	 Â features,	 Â by	 Â using	 Â word	 Â vectors	 Â that	 Â 
capture	 Â  the	 Â  syntactic	 Â  and	 Â  semantic	 Â  information	 Â  through	 Â  latent	 Â  dimensional	 Â  features.	 Â  	 Â  	 Â  Still,	 Â  the	 Â  finer	 Â 
nuances	 Â  of	 Â  word	 Â  embeddings	 Â  in	 Â  vectors	 Â  space	 Â  have	 Â  not	 Â  been	 Â  understood	 Â  fully.	 Â  For	 Â  Named	 Â  Entity	 Â 
Recognition(NER),	 Â we	 Â decided	 Â to	 Â use	 Â word	 Â vectors	 Â but	 Â a	 Â comparable	 Â performance	 Â has	 Â been	 Â reported	 Â 
using	 Â Brown	 Â Clusters	 Â which	 Â is	 Â a	 Â hierarchical	 Â agglomerative	 Â clustering	 Â algorithm	 Â relying	 Â on	 Â maximizing	 Â 
the	 Â mutual	 Â information	 Â of	 Â bigrams	 Â [11].	 Â An	 Â advantage	 Â of	 Â Brown	 Â Clusters	 Â is	 Â that	 Â it	 Â works	 Â better	 Â on	 Â rare	 Â 
words.	 Â  Another	 Â  scalable	 Â  algorithm	 Â  using	 Â  deep	 Â  learning	 Â  for	 Â  NER	 Â  was	 Â  proposed	 Â  by	 Â  Collobert	 Â  and	 Â 
Weston[12].	 Â Ratinov	 Â and	 Â Roth	 Â discuss	 Â issues	 Â in	 Â designing	 Â NER	 Â systems	 Â in	 Â [10].	 Â 	 Â In	 Â this	 Â paper	 Â we	 Â use	 Â the	 Â 
vector	 Â  representations	 Â  of	 Â  words	 Â  to	 Â  implement	 Â  a	 Â  neural	 Â  network	 Â  based	 Â  NER	 Â  system,	 Â  which	 Â  is	 Â  then	 Â 
utilized	 Â to	 Â aid	 Â in	 Â Question	 Â answering	 Â by	 Â reducing	 Â the	 Â answer	 Â candidates.	 Â 
Word	 Â Vectors	 Â 
The	 Â method	 Â used	 Â to	 Â generate	 Â word	 Â vectors	 Â is	 Â the	 Â continuous	 Â bag-Â­â€of-Â­â€word	 Â model	 Â (CBOW)	 Â by	 Â Mikolov	 Â et	 Â 
al.	 Â (2013).	 Â CBOW	 Â is	 Â a	 Â neural	 Â network	 Â model	 Â which	 Â tends	 Â to	 Â predict	 Â the	 Â target	 Â word	 Â based	 Â on	 Â the	 Â input	 Â 
window	 Â  of	 Â  context	 Â  words	 Â  surrounding	 Â  the	 Â  target	 Â  word.	 Â  The	 Â  training	 Â  process	 Â  creates	 Â  low-Â­â€dimensional	 Â 
word	 Â  vectors	 Â  (each	 Â  word	 Â  is	 Â  200	 Â  dimensional)	 Â  for	 Â  each	 Â  word	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  word	 Â  vectors	 Â 
which	 Â  are	 Â  contextually,	 Â  syntactically	 Â  and	 Â  semantically	 Â  similar	 Â  tend	 Â  to	 Â  lie	 Â  near	 Â  each	 Â  other	 Â  in	 Â  this	 Â  low	 Â 
dimensional	 Â  space,	 Â  as	 Â  shown	 Â  in	 Â  the	 Â  PCA	 Â  analysis	 Â  of	 Â  the	 Â  few	 Â  handpicked	 Â  words	 Â  from	 Â  the	 Â  vocabulary.	 Â 
Refer	 Â  Figure	 Â  2	 Â  for	 Â  2D	 Â  PCA	 Â  representation	 Â  of	 Â  word	 Â  vectors.	 Â  We	 Â  use	 Â  these	 Â  word	 Â  representations	 Â  as	 Â 
features	 Â to	 Â build	 Â the	 Â NER	 Â system	 Â which	 Â is	 Â described	 Â below.	 Â We	 Â implemented	 Â CBOW	 Â model	 Â and	 Â trained	 Â 

using	 Â  Googleâ€™s	 Â  dataset	 Â  [1].	 Â  The	 Â  algorithm	 Â  performed	 Â  well	 Â  on	 Â  smaller	 Â  subsets	 Â  of	 Â  our	 Â  data	 Â  but	 Â  when	 Â 
training	 Â on	 Â a	 Â large	 Â vocabulary	 Â (>1	 Â M),	 Â the	 Â training	 Â time	 Â became	 Â excessively	 Â large,	 Â so	 Â we	 Â used	 Â pre-Â­â€trained	 Â 
word	 Â vectors	 Â [1].	 Â 
Named	 Â Entity	 Â Recognition	 Â 
NER	 Â  is	 Â  a	 Â  classification	 Â  problem,	 Â  where	 Â  each	 Â  input	 Â  word	 Â  is	 Â  classified	 Â  as	 Â  being	 Â  a	 Â  Location,	 Â  Person,	 Â 
Organization,	 Â  Miscellaneous	 Â  and	 Â  Other	 Â  (not	 Â  any	 Â  named	 Â  entity).	 Â  The	 Â  algorithm	 Â  uses	 Â  tokenized	 Â  text	 Â  to	 Â 
train	 Â  a	 Â  neural	 Â  network	 Â  model	 Â  for	 Â  named	 Â  entity	 Â  recognition	 Â  with	 Â  multiple	 Â  classes.	 Â  The	 Â  detailed	 Â 
annotation	 Â  structure	 Â  for	 Â  the	 Â  dataset	 Â  is	 Â  given	 Â  at	 Â  [13].	 Â  The	 Â  training	 Â  and	 Â  the	 Â  testing	 Â  data	 Â  for	 Â  the	 Â  NER	 Â 
algorithm	 Â  is	 Â  taken	 Â  from	 Â  CoNLL03	 Â  corpus.	 Â  The	 Â  data	 Â  consists	 Â  of	 Â  sentences	 Â  with	 Â  one	 Â  token	 Â  per	 Â  line	 Â  and	 Â 
each	 Â  token	 Â  is	 Â  associated	 Â  with	 Â  5	 Â  possible	 Â  labels:	 Â  {O,	 Â  LOC,	 Â  MISC,	 Â  ORG,	 Â  PER}	 Â  representing	 Â  the	 Â  classes	 Â 
defined	 Â  above.	 Â  The	 Â  word	 Â  vectors	 Â  learned	 Â  using	 Â  the	 Â  CBOW	 Â  model	 Â  were	 Â  used	 Â  to	 Â  construct	 Â  context	 Â 
windows	 Â that	 Â serve	 Â as	 Â input	 Â features	 Â to	 Â the	 Â neural	 Â network.	 Â 

The	 Â  model	 Â  is	 Â  implemented	 Â  as	 Â  single	 Â  layer	 Â  neural	 Â  network	 Â  with	 Â  word	 Â  embedding	 Â  as	 Â  the	 Â  input	 Â  layer	 Â 
feeding	 Â to	 Â feedforward	 Â algorithm.	 Â The	 Â predicted	 Â class	 Â vector	 Â is	 Â then	 Â compared	 Â to	 Â the	 Â actual	 Â class	 Â and	 Â 
the	 Â delta	 Â error	 Â propagates	 Â back	 Â updating	 Â the	 Â model.	 Â As	 Â the	 Â algorithm	 Â iterates	 Â through	 Â the	 Â dataset	 Â it	 Â 
learns	 Â both	 Â the	 Â classifier	 Â and	 Â the	 Â word	 Â representations.	 Â 	 Â 

The	 Â feedforward	 Â operation	 Â is	 Â given	 Â by	 Â the	 Â following	 Â set	 Â of	 Â equations	 Â 

ğ‘§=ğ‘Š ğ‘¥!!!ğ‘¥!ğ‘¥!!! +ğ‘(!)	 Â 
â„=ğ‘¡ğ‘ğ‘›â„(ğ‘§)	 Â 
ğ‘=ğ‘”(ğ‘ˆâ„+ğ‘!)	 Â 
ğ‘¦!!ğ‘™ğ‘œğ‘”ğ‘!,!(ğ‘¥(!))

Where	 Â ((ğ‘¥!!!,ğ‘¥!,ğ‘¥!!!)	 Â is	 Â the	 Â context	 Â window,	 Â W	 Â and	 Â U	 Â are	 Â the	 Â model	 Â parameters	 Â and	 Â g	 Â is	 Â the	 Â softmax	 Â 

function.	 Â The	 Â cost	 Â function	 Â to	 Â minimize	 Â is	 Â given	 Â by	 Â the	 Â following	 Â equation	 Â 

ğ½ğœƒ = Â 

!
!!!

!
!!!

ğ´+ ğœ†2ğ‘š(ğ‘Š !+ ğ‘ˆ !) Â 

	 Â 

Where	 Â m	 Â is	 Â the	 Â number	 Â of	 Â data	 Â samples,	 Â K	 Â is	 Â the	 Â number	 Â of	 Â entity	 Â classes	 Â and	 Â Î»	 Â is	 Â the	 Â regularization	 Â 
parameter.	 Â  The	 Â  parameters	 Â  are	 Â  learned	 Â  using	 Â  stochastic	 Â  gradient	 Â  descent	 Â  algorithm	 Â  and	 Â  gradient	 Â 
checking	 Â is	 Â used	 Â for	 Â bug-Â­â€free	 Â implementation.	 Â 

The	 Â  evaluation	 Â  of	 Â  the	 Â  implemented	 Â  algorithm	 Â  was	 Â  done	 Â  using	 Â  the	 Â  CoNLL03	 Â  conlleval	 Â  Perl	 Â  script.	 Â  The	 Â 
script	 Â evaluates	 Â the	 Â NER	 Â systemâ€™s	 Â capability	 Â of	 Â identifying	 Â named	 Â entities.	 Â It	 Â gives	 Â a	 Â clear	 Â presentation	 Â of	 Â 
the	 Â  performance	 Â  of	 Â  the	 Â  system	 Â  on	 Â  various	 Â  entity	 Â  categories	 Â  (person,	 Â 
location,	 Â  organization,	 Â 
miscellaneous	 Â and	 Â other)	 Â based	 Â on	 Â the	 Â precision,	 Â recall	 Â and	 Â F1	 Â measures.	 Â 
Results	 Â 

Tuning	 Â Parameters	 Â 

The	 Â parameters	 Â of	 Â the	 Â system	 Â that	 Â were	 Â tuned	 Â for	 Â higher	 Â accuracy	 Â were:	 Â 

â€¢  The	 Â regularization	 Â constant	 Â (Î»)	 Â 
â€¢  The	 Â learning	 Â rate	 Â (Î±)	 Â 
â€¢  The	 Â context	 Â window	 Â size	 Â (C)	 Â 
â€¢  The	 Â number	 Â of	 Â iterations	 Â (epochs)	 Â 

We	 Â used	 Â context	 Â window	 Â size	 Â of	 Â 3	 Â and	 Â 5	 Â for	 Â the	 Â model;	 Â better	 Â results	 Â were	 Â achieved	 Â with	 Â size	 Â 5.	 Â It	 Â was	 Â 
observed	 Â  that	 Â  increasing	 Â  number	 Â  of	 Â  iterations	 Â  does	 Â  not	 Â  necessarily	 Â  increase	 Â  the	 Â  performance.	 Â  The	 Â 
improvement	 Â  stagnated	 Â  after	 Â  40	 Â  iterations.	 Â  For	 Â  regularization	 Â  parameter	 Â  (Î»	 Â  =0.02)	 Â  gave	 Â  the	 Â  best	 Â 
performance.	 Â  The	 Â  performance	 Â  was	 Â  decreasing	 Â  for	 Â  higher	 Â  values	 Â  of	 Â  Î».	 Â  The	 Â  learning	 Â  rate	 Â  (Î±)	 Â  was	 Â 
optimized	 Â at	 Â 0.075.	 Â Lower	 Â learning	 Â rate	 Â gives	 Â inferior	 Â results.	 Â 	 Â 	 Â The	 Â optimal	 Â values	 Â found	 Â for	 Â the	 Â tuning	 Â 
parameters	 Â are	 Â given	 Â in	 Â Table	 Â 1.	 Â 

	 Â 

	 Â 

Parameters	 Â 

Epoch	 Â 

Learning	 Â Rate	 Â (Î±)	 Â 
Regularization	 Â (Î»)	 Â 

Context	 Â Window	 Â Size	 Â (C)	 Â 

Optimal	 Â Value	 Â 

40	 Â 

0.075	 Â 
0.02	 Â 

5	 Â 

Table	 Â 1:	 Â Optimal	 Â Parameter	 Â Values	 Â for	 Â NER	 Â 

	 Â 

LOC	 Â 
MISC	 Â 
ORG	 Â 
PER	 Â 

System	 Â 

Recall	 Â 
85.20%	 Â 
74.53%	 Â 
64.58%	 Â 
76.53%	 Â 
75.44%	 Â 

Precision	 Â 
92.10%	 Â 
91.39%	 Â 
84.54%	 Â 
96.17%	 Â 
91.73%	 Â 

F1	 Â 

88.52%	 Â 
82.10%	 Â 
73.22%	 Â 
85.23%	 Â 
82.79%	 Â 

Table	 Â 2:	 Â NER	 Â Evaluation	 Â Results	 Â 

Recall	 Â 

Precision	 Â 

F1	 Â 

LOC	 Â 

PER	 Â 

System	 Â 

120.00%	 Â 

100.00%	 Â 

80.00%	 Â 

60.00%	 Â 

40.00%	 Â 

20.00%	 Â 

0.00%	 Â 

MISC	 Â 

ORG	 Â 

	 Â 	 Â 	 Â 

	 Â 	 Â 	 Â 
	 Â 	 Â Figure	 Â 1:	 Â NER	 Â Evaluation	 Â results	 Â 
Question	 Â Answering	 Â 
Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â used	 Â in	 Â a	 Â lot	 Â of	 Â NLP	 Â tasks.	 Â In	 Â particular,	 Â they	 Â play	 Â a	 Â prominent	 Â 
role	 Â in	 Â Question-Â­â€Answering.	 Â Named	 Â Entity	 Â Recognition	 Â systems	 Â are	 Â typically	 Â used	 Â in	 Â question	 Â answering	 Â 
systems	 Â like	 Â AFNER	 Â to	 Â narrow	 Â down	 Â the	 Â candidate	 Â answers	 Â which	 Â match	 Â the	 Â semantic	 Â category	 Â of	 Â the	 Â 
selected	 Â answer.	 Â 	 Â For	 Â example,	 Â the	 Â answer	 Â to	 Â the	 Â question	 Â â€œWhich	 Â is	 Â the	 Â Capital	 Â of	 Â Franceâ€,	 Â the	 Â system	 Â 
identifies	 Â  the	 Â  category	 Â  of	 Â  the	 Â  expected	 Â  answer	 Â  to	 Â  be	 Â  a	 Â  Location	 Â  (LOC).	 Â  Thus,	 Â  the	 Â  system	 Â  will	 Â  only	 Â 

consider	 Â  the	 Â  named	 Â  entities	 Â  with	 Â  category	 Â  LOC	 Â  as	 Â  answers	 Â  thereby	 Â  affecting	 Â  both	 Â  the	 Â  precision	 Â  and	 Â 
performance	 Â of	 Â the	 Â overall	 Â system.	 Â 

In	 Â  this	 Â  paper	 Â  we	 Â  utilize	 Â  our	 Â  Neural	 Â  Network	 Â  based	 Â  NER	 Â  model	 Â  to	 Â  identify	 Â  and	 Â  classify	 Â  NEs	 Â  in	 Â  natural	 Â 
language	 Â  questions.	 Â  We	 Â  hypothesize	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  can	 Â  benefit	 Â  from	 Â  the	 Â  inclusion	 Â  of	 Â  the	 Â  pre-Â­â€
labelled	 Â  questions	 Â  in	 Â  the	 Â  training	 Â  corpus.	 Â  The	 Â  training	 Â  and	 Â  testing	 Â  corpus	 Â  for	 Â  the	 Â  experiment	 Â  was	 Â 
downloaded	 Â from	 Â [14].	 Â The	 Â training	 Â data	 Â consists	 Â of	 Â 5500	 Â annotated	 Â questions	 Â with	 Â categories	 Â PER,	 Â LOC	 Â 
and	 Â ORG.	 Â Similarly	 Â the	 Â test	 Â data	 Â consists	 Â of	 Â 500	 Â pre-Â­â€annotated	 Â questions.	 Â 

The	 Â performance	 Â is	 Â baselined	 Â using	 Â the	 Â system	 Â trained	 Â on	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â tested	 Â on	 Â the	 Â 500	 Â 
test	 Â questions.	 Â The	 Â baseline	 Â results	 Â are	 Â given	 Â in	 Â the	 Â Table	 Â 3.	 Â Although	 Â the	 Â F-Â­â€measure	 Â for	 Â the	 Â free	 Â text	 Â 
test	 Â corpus	 Â was	 Â 82.79%,	 Â the	 Â systemâ€™s	 Â performance	 Â drops	 Â to	 Â 56.81%	 Â when	 Â tested	 Â on	 Â the	 Â 500	 Â annotated	 Â 
questions	 Â test	 Â corpus.	 Â Next,	 Â we	 Â trained	 Â the	 Â NER	 Â system	 Â on	 Â the	 Â training	 Â corpus	 Â of	 Â 5500	 Â pre-Â­â€annotated	 Â 
questions	 Â and	 Â tested	 Â the	 Â resulting	 Â model	 Â both	 Â on	 Â the	 Â CoNLL03	 Â test	 Â data	 Â and	 Â the	 Â 500	 Â test	 Â questions.	 Â The	 Â 
results	 Â  of	 Â  the	 Â  step	 Â  are	 Â  given	 Â  in	 Â  Table	 Â  4.	 Â  The	 Â  system	 Â  performed	 Â  well	 Â  on	 Â  the	 Â  annotated	 Â  questions	 Â  test	 Â 
corpus	 Â but	 Â failed	 Â miserably	 Â for	 Â the	 Â CoNLL03	 Â free	 Â text	 Â test	 Â corpus.	 Â Finally,	 Â the	 Â NER	 Â system	 Â was	 Â trained	 Â on	 Â 
using	 Â both	 Â the	 Â CoNLL03	 Â corpus	 Â and	 Â 5500	 Â pre-Â­â€annotated	 Â questions	 Â corpus.	 Â The	 Â performance	 Â on	 Â both	 Â the	 Â 
test	 Â datasets	 Â are	 Â given	 Â in	 Â Table	 Â 5.	 Â We	 Â achieved	 Â an	 Â F-Â­â€measure	 Â of	 Â 83.2%	 Â on	 Â the	 Â question	 Â test	 Â data	 Â when	 Â 
the	 Â training	 Â data	 Â contained	 Â both	 Â the	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â data.	 Â 

The	 Â  results	 Â  obtained	 Â  in	 Â  this	 Â  work	 Â  suggests	 Â  that	 Â  the	 Â  NER	 Â  system	 Â  used	 Â  in	 Â  aiding	 Â  question	 Â  answering	 Â 
system	 Â benefits	 Â from	 Â including	 Â questions	 Â in	 Â the	 Â training	 Â corpus.	 Â To	 Â build	 Â a	 Â NER	 Â model	 Â which	 Â provides	 Â an	 Â 
F-Â­â€measure	 Â >	 Â 80%	 Â we	 Â should	 Â build	 Â a	 Â training	 Â corpus	 Â which	 Â is	 Â a	 Â suitable	 Â mix	 Â of	 Â free	 Â text	 Â and	 Â annotated	 Â 
questions.	 Â As	 Â shown	 Â in	 Â Table	 Â 5,	 Â the	 Â inclusion	 Â of	 Â free	 Â text	 Â in	 Â the	 Â training	 Â data	 Â is	 Â not	 Â relevant	 Â if	 Â we	 Â have	 Â 
sufficient	 Â questions	 Â to	 Â train	 Â the	 Â NER	 Â system	 Â and	 Â the	 Â system	 Â is	 Â used	 Â only	 Â for	 Â Question	 Â Answering.	 Â But	 Â to	 Â 
build	 Â a	 Â general-Â­â€purpose	 Â model	 Â the	 Â system	 Â will	 Â benefit	 Â from	 Â combination	 Â of	 Â training	 Â data.	 Â 

	 Â 

Train	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â 
Table	 Â 3:	 Â Baseline	 Â NER	 Â Results	 Â 

14987	 Â 

Tokens	 Â 
219554	 Â 

Eval	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
51.37	 Â 
51.37	 Â 

Precision	 Â 

(%)	 Â 
91.73	 Â 
63.53	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.79	 Â 
56.81	 Â 

Type	 Â 

Train	 Â 

Recall	 Â 
(%)	 Â 
18.18	 Â 
Questions	 Â 
72.95	 Â 
Table	 Â 4:	 Â Trained	 Â on	 Â 5500	 Â Pre-Â­â€annotated	 Â questions	 Â only	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Tokens	 Â 
61074	 Â 

Sentences	 Â 

5452	 Â 

Eval	 Â 

Precision	 Â 

(%)	 Â 
43.17	 Â 
89.22	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
25.58	 Â 
80.07	 Â 

Train	 Â 

Eval	 Â 

Type	 Â 

Sentences	 Â 

Free	 Â text	 Â +	 Â Questions	 Â 
Table	 Â 5:	 Â Trained	 Â on	 Â both	 Â free	 Â text	 Â and	 Â pre-Â­â€annotated	 Â questions	 Â 

20439	 Â 

Tokens	 Â 
280628	 Â 

Free	 Â Text	 Â 
Questions	 Â 

Recall	 Â 
(%)	 Â 
76.16	 Â 
79.03	 Â 

Precision	 Â 

(%)	 Â 
90.76	 Â 
87.84	 Â 

F-Â­â€Measure	 Â 

(%)	 Â 
82.82	 Â 
83.20	 Â 

	 Â 

Clustering	 Â word	 Â vectors	 Â for	 Â training	 Â NER	 Â 
The	 Â clustering	 Â was	 Â done	 Â using	 Â K-Â­â€means	 Â algorithm	 Â on	 Â the	 Â 200	 Â dimensional	 Â word	 Â vectors	 Â generated	 Â by	 Â 
Word2Vec	 Â model.	 Â We	 Â constructed	 Â clusters	 Â of	 Â multiple	 Â granularities,	 Â through	 Â hierarchical	 Â clustering.	 Â The	 Â 
primary	 Â  intuition	 Â  being	 Â  that	 Â  clustering	 Â  would	 Â  give	 Â  us	 Â  a	 Â  unsupervised	 Â  automated	 Â  way	 Â  to	 Â  increase	 Â  our	 Â 
training	 Â  data,	 Â  similar	 Â  to	 Â  construction	 Â  a	 Â  NER	 Â  gazetteer.	 Â  We	 Â  found	 Â  that	 Â  unigram	 Â  clusters	 Â  capture	 Â  broad	 Â 
categories	 Â of	 Â entities	 Â (countries	 Â and	 Â states	 Â in	 Â a	 Â single	 Â cluster,	 Â names)	 Â and	 Â would	 Â be	 Â useful	 Â in	 Â NER	 Â if	 Â there	 Â 
are	 Â more	 Â number	 Â of	 Â labels.	 Â Also	 Â increasing	 Â the	 Â number	 Â of	 Â clusters	 Â gave	 Â us	 Â better	 Â separation	 Â of	 Â entities.	 Â 
The	 Â  clusters	 Â  generated	 Â  were	 Â  used	 Â  to	 Â  train	 Â  the	 Â  NER	 Â  model.	 Â  The	 Â  results	 Â  are	 Â  given	 Â  in	 Â  Table	 Â  6.	 Â  	 Â  An	 Â 
important	 Â  realization	 Â  was	 Â  that,	 Â  the	 Â  single	 Â  word	 Â  clusters	 Â  do	 Â  not	 Â  capture	 Â  context,	 Â  so	 Â  training	 Â  n-Â­â€gram	 Â 
clusters	 Â (setting	 Â n	 Â to	 Â be	 Â the	 Â size	 Â of	 Â the	 Â context	 Â window)	 Â could	 Â be	 Â more	 Â useful	 Â approach	 Â in	 Â clustering	 Â [5].	 Â 	 Â 

25.10	 Â 
83.40	 Â 
28.34	 Â 
83.56	 Â 

Cluster	 Â Granularity	 Â  F-Â­â€Measure	 Â (%)	 Â 
Training	 Â Corpus	 Â 
Clusters	 Â 
800	 Â 
CoNLL03	 Â +	 Â Clusters	 Â  800	 Â 
Clusters	 Â 
2000	 Â 
CoNLL03	 Â +	 Â Clusters	 Â  2000	 Â 	 Â 
Table	 Â 6:	 Â Testing	 Â Cluster	 Â Granularity	 Â 
Further	 Â Study	 Â 
Combining	 Â neural	 Â networks	 Â with	 Â word	 Â vector	 Â models	 Â for	 Â Named	 Â Entity	 Â recognition	 Â is	 Â an	 Â active	 Â field	 Â of	 Â 
study.	 Â Named	 Â Entity	 Â Recognition	 Â using	 Â recurrent	 Â neural	 Â networks	 Â (RNN)	 Â and	 Â Long	 Â Short	 Â Term	 Â Memory	 Â 
(LSTM)	 Â is	 Â also	 Â a	 Â promising	 Â future	 Â direction	 Â and	 Â better	 Â results	 Â have	 Â been	 Â achieved	 Â by	 Â it.	 Â Future	 Â directions	 Â 
of	 Â study	 Â for	 Â question	 Â answering	 Â would	 Â focus	 Â attention	 Â on	 Â dynamic	 Â memory	 Â networks	 Â that	 Â make	 Â the	 Â use	 Â 
of	 Â word	 Â vectors	 Â by	 Â combining	 Â a	 Â knowledge	 Â base	 Â (or	 Â facts)	 Â to	 Â achieve	 Â state	 Â of	 Â the	 Â art-Â­â€results	 Â [6].	 Â 
Acknowledgments:	 Â 
We	 Â would	 Â like	 Â to	 Â thank	 Â Prof.	 Â Andrew	 Â Ng	 Â and	 Â our	 Â project	 Â mentor,	 Â Youssef	 Â Ahres,	 Â for	 Â their	 Â guidance	 Â and	 Â 
support	 Â during	 Â the	 Â project.	 Â 	 Â 

Figure	 Â 2:	 Â PCA	 Â representation	 Â of	 Â Word	 Â Vectors	 Â 

	 Â 

	 Â 

References:	 Â 
	 Â 

[1]	 Â  https://code.google.com/p/word2vec/.	 Â 	 Â 

[2]	 Â  Miller,	 Â S.,	 Â Guinness,	 Â J.,	 Â &	 Â Zamanian,	 Â A.	 Â (2004,	 Â May).	 Â Name	 Â Tagging	 Â with	 Â Word	 Â Clusters	 Â and	 Â Discriminative	 Â 

Training.	 Â In	 Â HLT-Â­â€NAACL	 Â (Vol.	 Â 4,	 Â pp.	 Â 337-Â­â€342).	 Â 	 Â 

[3]	 Â  Siencnik,	 Â S.	 Â K.	 Â (2015,	 Â May).	 Â Adapting	 Â word2vec	 Â to	 Â Named	 Â Entity	 Â Recognition.	 Â In	 Â Nordic	 Â Conference	 Â of	 Â 

Computational	 Â Linguistics	 Â NODALIDA	 Â 2015	 Â (p.	 Â 239).	 Â 

[4]	 Â  Mendes,	 Â A.	 Â C.,	 Â Coheur,	 Â L.,	 Â &	 Â Lobo,	 Â P.	 Â V.	 Â (2010,	 Â May).	 Â Named	 Â Entity	 Â Recognition	 Â in	 Â Questions:	 Â Towards	 Â a	 Â 

Golden	 Â Collection.	 Â In	 Â LREC.	 Â 

[5]	 Â 	 Â  Lin,	 Â D.,	 Â &	 Â Wu,	 Â X.	 Â (2009,	 Â August).	 Â Phrase	 Â clustering	 Â for	 Â discriminative	 Â learning.	 Â In	 Â Proceedings	 Â of	 Â the	 Â Joint	 Â 
Conference	 Â of	 Â the	 Â 47th	 Â Annual	 Â Meeting	 Â of	 Â the	 Â ACL	 Â and	 Â the	 Â 4th	 Â International	 Â Joint	 Â Conference	 Â on	 Â Natural	 Â 
Language	 Â Processing	 Â of	 Â the	 Â AFNLP:	 Â Volume	 Â 2-Â­â€Volume	 Â 2	 Â (pp.	 Â 1030-Â­â€1038).	 Â Association	 Â for	 Â Computational	 Â 
Linguistics.	 Â 

[6]	 Â 

	 Â Kumar,	 Â A.,	 Â Irsoy,	 Â O.,	 Â Su,	 Â J.,	 Â Bradbury,	 Â J.,	 Â English,	 Â R.,	 Â Pierce,	 Â B.,	 Â ...	 Â &	 Â Socher,	 Â R.	 Â (2015).	 Â Ask	 Â me	 Â anything:	 Â 
Dynamic	 Â memory	 Â networks	 Â for	 Â natural	 Â language	 Â processing.	 Â arXiv	 Â preprint	 Â arXiv:1506.07285.	 Â 

[7]	 Â  Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of 

words and phrases and their compositionality. In Advances in neural information processing systems (pp. 
3111-3119). 

[8]	 Â 	 Â  Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in 

vector space. arXiv preprint arXiv:1301.3781. 

[9]	 Â 	 Â  Pennington, J., Socher, R., & Manning, C. D. (2014). Glove: Global vectors for word representation. 

Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12, 1532-1543. 
	 Â Ratinov, L., & Roth, D. (2009, June). Design challenges and misconceptions in named entity recognition. 
In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (pp. 147-
155). Association for Computational Linguistics. 

[10]	 Â 

[11]	 Â 	 Â Brown, P. F., Desouza, P. V., Mercer, R. L., Pietra, V. J. D., & Lai, J. C. (1992). Class-based n-gram 

models of natural language. Computational linguistics, 18(4), 467-479. 

[12]	 Â 	 Â Collobert, R., & Weston, J. (2008, July). A unified architecture for natural language processing: Deep 

neural networks with multitask learning. In Proceedings of the 25th international conference on Machine 
learning (pp. 160-167). ACM. 

Data	 Â 

[13]	 Â  http://www.cnts.ua.ac.be/conll2003/ner/annotation.txt	 Â 	 Â 

	 Â 	 Â 	 Â 	 Â 	 Â 	 Â 	 Â 	 Â [14]	 Â 	 Â  https://qa.l2f.inesc-Â­â€id.pt/wiki/index.php/Resources	 Â 

[15]	 Â  http://mattmahoney.net/dc/text8.zip	 Â 

	 Â 

