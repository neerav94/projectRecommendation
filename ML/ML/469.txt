Predicting the Treatment Status

Nikolay Doudchenko

1

Introduction

Many studies in social sciences deal with treatment eﬀect models.1 Usually there is a
treatment variable which determines whether a particular individual (or more generally
a unit of observation) was aﬀected by some impact (the binary case) or the intensity of
this impact. A researcher is interested in evaluating the eﬀect of the treatment measured
as some function of the joint distribution of y(i)
1 , the potential outcome for individual
i conditional on being treated, and y(i)
0 , the potential outcome conditional on not being
treated. There are many papers devoted to studying this setup due to a very fundamental
problem that for each individual i either y(i)
is observed in the data, but never
both.

1 or y(i)

0

In my project I consider a somewhat diﬀerent problem. What if we don’t know who
has got the treatment and who has not? For example, suppose that we organize a lottery
in which every participant draws a lottery ticket from a big jar. Some of the tickets
are the winning ones (the individual is treated) while some aren’t (the individual is not
treated). We cannot observe whether a particular person has won, but we can observe
some outcome potentially aﬀected by the realization of the lottery. Can we infer anything
about the treatment?2 To be precise, I ask two questions: (i) Can we guess the treatment
status? (ii) Is it possible to measure the treatment eﬀect even though we don’t observe
the treatment dummy?

I approach this problem as an unsupervised learning problem. Although the treat-
ment status is observed in the data that I use, I assume that in practice it won’t be and
there will be no way to train the model. The main tool in my analysis is what I call the
“Hidden Variable Model” (HVM). Essentially, this is a hidden Markov model with the
main diﬀerence being that there is no Markov structure and instead of observing a num-
ber of consecutive realizations for one individual we observe a number of “independent”
individuals. The hidden state is exactly the treatment status which we don’t observe. We
may also know some additional details of the assignment process or how the treatment
aﬀects the outcome. For example, we may know that the treatment status was determined

1Another prominent example would be medical studies. It does not matter for the theoretical deriva-
tions. Neither does it for the simulations. The “real world data” that I use comes from economics so I
stick to the social sciences context and terminology.

2Another interesting formulation is the following. What if there is an additional step required to
complete the treatment? We know the individuals that were supposed to be treated, but we don’t know
who actually undertook that step. What can we do in this case?

1

Predicting the Treatment Status

Nikolay Doudchenko

1

Introduction

Many studies in social sciences deal with treatment eﬀect models.1 Usually there is a
treatment variable which determines whether a particular individual (or more generally
a unit of observation) was aﬀected by some impact (the binary case) or the intensity of
this impact. A researcher is interested in evaluating the eﬀect of the treatment measured
as some function of the joint distribution of y(i)
1 , the potential outcome for individual
i conditional on being treated, and y(i)
0 , the potential outcome conditional on not being
treated. There are many papers devoted to studying this setup due to a very fundamental
problem that for each individual i either y(i)
is observed in the data, but never
both.

1 or y(i)

0

In my project I consider a somewhat diﬀerent problem. What if we don’t know who
has got the treatment and who has not? For example, suppose that we organize a lottery
in which every participant draws a lottery ticket from a big jar. Some of the tickets
are the winning ones (the individual is treated) while some aren’t (the individual is not
treated). We cannot observe whether a particular person has won, but we can observe
some outcome potentially aﬀected by the realization of the lottery. Can we infer anything
about the treatment?2 To be precise, I ask two questions: (i) Can we guess the treatment
status? (ii) Is it possible to measure the treatment eﬀect even though we don’t observe
the treatment dummy?

I approach this problem as an unsupervised learning problem. Although the treat-
ment status is observed in the data that I use, I assume that in practice it won’t be and
there will be no way to train the model. The main tool in my analysis is what I call the
“Hidden Variable Model” (HVM). Essentially, this is a hidden Markov model with the
main diﬀerence being that there is no Markov structure and instead of observing a num-
ber of consecutive realizations for one individual we observe a number of “independent”
individuals. The hidden state is exactly the treatment status which we don’t observe. We
may also know some additional details of the assignment process or how the treatment
aﬀects the outcome. For example, we may know that the treatment status was determined

1Another prominent example would be medical studies. It does not matter for the theoretical deriva-
tions. Neither does it for the simulations. The “real world data” that I use comes from economics so I
stick to the social sciences context and terminology.

2Another interesting formulation is the following. What if there is an additional step required to
complete the treatment? We know the individuals that were supposed to be treated, but we don’t know
who actually undertook that step. What can we do in this case?

1

based on a subset of features or that only some of the features aﬀect the distribution of
the outcome.

In this project I consider both simulated data and a “real” publicly available dataset

that comes from a study by Angrist, Bettinger, Bloom, and King (2002).

The results suggest that as both the treatment and the outcome are stochastic the
treatment status is hard to retrieve. Not surprisingly, the stronger is the treatment eﬀect
the easier it becomes to guess the treatment variable. Intuitively, if the treatment eﬀect is
positive and large, a large value of the outcome suggests that the individual was treated.
The estimates of the treatment eﬀect are more precisely estimated. As obtaining these
estimates is usually the main goal of the researcher, there is some hope that this project
wasn’t completely useless.

The rest of the text is organized as follows. Section 2 describes the statistical model
referred to as the “Hidden Variable Model.” Section 3 reports the results obtained using
simulated data. Section 4 discusses the “real” dataset that I use in Section 5. Section 6
concludes.

2 Model

1 , . . . , x(i)

Suppose that for each observation i = 1, . . . , m there are n feature (or covariates) x(i) =
n )T which determine the probability, p(d = 1|x(i)), of being assigned to the
(x(i)
treatment group. The treatment status, d(i), and the covariates jointly determine the
distribution of the outcome variable, p(y|d(i), x(i)). The graphical representation of the
model is given in Figure 1.

Figure 1: Graphical Representation of the Model

Here the word “Rand” means that the covariates, the treatment status and the outcome
are stochastic.

I assume that only x(i) and y(i) are observed and d(i) is hidden. The likelihood of

(cid:88)

d=0,1

2

(y(i), x(i)) is given by

p(y(i), x(i)) =

p(y(i), d|x(i))p(x(i)).

Covariates (x)RandTreatment Status (d)Output (y)RandRandPredicting the Treatment Status

Nikolay Doudchenko

1

Introduction

Many studies in social sciences deal with treatment eﬀect models.1 Usually there is a
treatment variable which determines whether a particular individual (or more generally
a unit of observation) was aﬀected by some impact (the binary case) or the intensity of
this impact. A researcher is interested in evaluating the eﬀect of the treatment measured
as some function of the joint distribution of y(i)
1 , the potential outcome for individual
i conditional on being treated, and y(i)
0 , the potential outcome conditional on not being
treated. There are many papers devoted to studying this setup due to a very fundamental
problem that for each individual i either y(i)
is observed in the data, but never
both.

1 or y(i)

0

In my project I consider a somewhat diﬀerent problem. What if we don’t know who
has got the treatment and who has not? For example, suppose that we organize a lottery
in which every participant draws a lottery ticket from a big jar. Some of the tickets
are the winning ones (the individual is treated) while some aren’t (the individual is not
treated). We cannot observe whether a particular person has won, but we can observe
some outcome potentially aﬀected by the realization of the lottery. Can we infer anything
about the treatment?2 To be precise, I ask two questions: (i) Can we guess the treatment
status? (ii) Is it possible to measure the treatment eﬀect even though we don’t observe
the treatment dummy?

I approach this problem as an unsupervised learning problem. Although the treat-
ment status is observed in the data that I use, I assume that in practice it won’t be and
there will be no way to train the model. The main tool in my analysis is what I call the
“Hidden Variable Model” (HVM). Essentially, this is a hidden Markov model with the
main diﬀerence being that there is no Markov structure and instead of observing a num-
ber of consecutive realizations for one individual we observe a number of “independent”
individuals. The hidden state is exactly the treatment status which we don’t observe. We
may also know some additional details of the assignment process or how the treatment
aﬀects the outcome. For example, we may know that the treatment status was determined

1Another prominent example would be medical studies. It does not matter for the theoretical deriva-
tions. Neither does it for the simulations. The “real world data” that I use comes from economics so I
stick to the social sciences context and terminology.

2Another interesting formulation is the following. What if there is an additional step required to
complete the treatment? We know the individuals that were supposed to be treated, but we don’t know
who actually undertook that step. What can we do in this case?

1

based on a subset of features or that only some of the features aﬀect the distribution of
the outcome.

In this project I consider both simulated data and a “real” publicly available dataset

that comes from a study by Angrist, Bettinger, Bloom, and King (2002).

The results suggest that as both the treatment and the outcome are stochastic the
treatment status is hard to retrieve. Not surprisingly, the stronger is the treatment eﬀect
the easier it becomes to guess the treatment variable. Intuitively, if the treatment eﬀect is
positive and large, a large value of the outcome suggests that the individual was treated.
The estimates of the treatment eﬀect are more precisely estimated. As obtaining these
estimates is usually the main goal of the researcher, there is some hope that this project
wasn’t completely useless.

The rest of the text is organized as follows. Section 2 describes the statistical model
referred to as the “Hidden Variable Model.” Section 3 reports the results obtained using
simulated data. Section 4 discusses the “real” dataset that I use in Section 5. Section 6
concludes.

2 Model

1 , . . . , x(i)

Suppose that for each observation i = 1, . . . , m there are n feature (or covariates) x(i) =
n )T which determine the probability, p(d = 1|x(i)), of being assigned to the
(x(i)
treatment group. The treatment status, d(i), and the covariates jointly determine the
distribution of the outcome variable, p(y|d(i), x(i)). The graphical representation of the
model is given in Figure 1.

Figure 1: Graphical Representation of the Model

Here the word “Rand” means that the covariates, the treatment status and the outcome
are stochastic.

I assume that only x(i) and y(i) are observed and d(i) is hidden. The likelihood of

(cid:88)

d=0,1

2

(y(i), x(i)) is given by

p(y(i), x(i)) =

p(y(i), d|x(i))p(x(i)).

Covariates (x)RandTreatment Status (d)Output (y)RandRandThe log-likelihood is

log p(y(i), x(i)) = log

Qi(d)

+ log p(x(i))

(cid:32)(cid:88)
≥ (cid:88)
(cid:88)

d=0,1

d=0,1

(cid:33)

p(y(i), d|x(i))

Qi(d)
p(y(i), d|x(i))

Qi(d)

Qi(d) log

+ log p(x(i))

=

Qi(d) log

d=0,1

p(y(i)|d, x(i))p(d|x(i))

Qi(d)

+ log p(x(i)),

where Qi(d) is a p.m.f. of some distribution over d ∈ {0, 1}. The inequality above follows
from Jensen’s inequality.
If we assume that p(d|x(i)) and p(y|d, x(i)) have particular parametric forms, these

parameters can be estimated using the expectation-maximization (EM) algorithm.

There is one fundamental issue though. We can try to split the dataset into two parts,
but it is impossible to say which of these two parts is the treatment group and which
is the control group. In practice there is usually some additional knowledge that allows
us to make an assumption about the sign of the treatment eﬀect. Here I assume that
the treatment eﬀect is positive which allows us to predict that the group with the higher
average y(i) is the treatment group.

2.1 Expectation-maximization
I assume that p(d|x(i)) = pd and is known. In other words, the assignment to the treatment
and control groups is completely random (does not depend on the covariates) and the
researcher knows the fraction of people assigned to the treatment group.3

I also assume that y is binary (the case that corresponds to the real data that I use)

and that

p(y|d, x(i)) =(cid:0)g(θ0d + θT x(i))(cid:1)y(cid:0)1 − g(θ0d + θT x(i))(cid:1)1−y

,

where g(s) = 1/(1 + exp (−s)) is the sigmoid function and θ0, θ = (θ1, . . . , θn)T are the
parameters that we need to estimate.
During the E-step of the algorithm I compute Qi(d) ∝ p(y(i), d|x(i)). During the

M-step I use Newton’s method to maximize the lower bound for the log-likelihood.4

3 Simulations

The goal of this section is to assess the performance of the model when we know exactly
how the data is generated. Throughout this section n = 10, x(i)
1 = 1 for all i = 1, . . . , m,

3It is easy to modify the M-step for the case when pd is unknown.
4I tried to use gradient ascent too, but it leads to less accurate estimates of the average treatment

eﬀect. Moreover, the estimates become very sensitive to the initial values of θ0, θ.

3

Predicting the Treatment Status

Nikolay Doudchenko

1

Introduction

Many studies in social sciences deal with treatment eﬀect models.1 Usually there is a
treatment variable which determines whether a particular individual (or more generally
a unit of observation) was aﬀected by some impact (the binary case) or the intensity of
this impact. A researcher is interested in evaluating the eﬀect of the treatment measured
as some function of the joint distribution of y(i)
1 , the potential outcome for individual
i conditional on being treated, and y(i)
0 , the potential outcome conditional on not being
treated. There are many papers devoted to studying this setup due to a very fundamental
problem that for each individual i either y(i)
is observed in the data, but never
both.

1 or y(i)

0

In my project I consider a somewhat diﬀerent problem. What if we don’t know who
has got the treatment and who has not? For example, suppose that we organize a lottery
in which every participant draws a lottery ticket from a big jar. Some of the tickets
are the winning ones (the individual is treated) while some aren’t (the individual is not
treated). We cannot observe whether a particular person has won, but we can observe
some outcome potentially aﬀected by the realization of the lottery. Can we infer anything
about the treatment?2 To be precise, I ask two questions: (i) Can we guess the treatment
status? (ii) Is it possible to measure the treatment eﬀect even though we don’t observe
the treatment dummy?

I approach this problem as an unsupervised learning problem. Although the treat-
ment status is observed in the data that I use, I assume that in practice it won’t be and
there will be no way to train the model. The main tool in my analysis is what I call the
“Hidden Variable Model” (HVM). Essentially, this is a hidden Markov model with the
main diﬀerence being that there is no Markov structure and instead of observing a num-
ber of consecutive realizations for one individual we observe a number of “independent”
individuals. The hidden state is exactly the treatment status which we don’t observe. We
may also know some additional details of the assignment process or how the treatment
aﬀects the outcome. For example, we may know that the treatment status was determined

1Another prominent example would be medical studies. It does not matter for the theoretical deriva-
tions. Neither does it for the simulations. The “real world data” that I use comes from economics so I
stick to the social sciences context and terminology.

2Another interesting formulation is the following. What if there is an additional step required to
complete the treatment? We know the individuals that were supposed to be treated, but we don’t know
who actually undertook that step. What can we do in this case?

1

based on a subset of features or that only some of the features aﬀect the distribution of
the outcome.

In this project I consider both simulated data and a “real” publicly available dataset

that comes from a study by Angrist, Bettinger, Bloom, and King (2002).

The results suggest that as both the treatment and the outcome are stochastic the
treatment status is hard to retrieve. Not surprisingly, the stronger is the treatment eﬀect
the easier it becomes to guess the treatment variable. Intuitively, if the treatment eﬀect is
positive and large, a large value of the outcome suggests that the individual was treated.
The estimates of the treatment eﬀect are more precisely estimated. As obtaining these
estimates is usually the main goal of the researcher, there is some hope that this project
wasn’t completely useless.

The rest of the text is organized as follows. Section 2 describes the statistical model
referred to as the “Hidden Variable Model.” Section 3 reports the results obtained using
simulated data. Section 4 discusses the “real” dataset that I use in Section 5. Section 6
concludes.

2 Model

1 , . . . , x(i)

Suppose that for each observation i = 1, . . . , m there are n feature (or covariates) x(i) =
n )T which determine the probability, p(d = 1|x(i)), of being assigned to the
(x(i)
treatment group. The treatment status, d(i), and the covariates jointly determine the
distribution of the outcome variable, p(y|d(i), x(i)). The graphical representation of the
model is given in Figure 1.

Figure 1: Graphical Representation of the Model

Here the word “Rand” means that the covariates, the treatment status and the outcome
are stochastic.

I assume that only x(i) and y(i) are observed and d(i) is hidden. The likelihood of

(cid:88)

d=0,1

2

(y(i), x(i)) is given by

p(y(i), x(i)) =

p(y(i), d|x(i))p(x(i)).

Covariates (x)RandTreatment Status (d)Output (y)RandRandThe log-likelihood is

log p(y(i), x(i)) = log

Qi(d)

+ log p(x(i))

(cid:32)(cid:88)
≥ (cid:88)
(cid:88)

d=0,1

d=0,1

(cid:33)

p(y(i), d|x(i))

Qi(d)
p(y(i), d|x(i))

Qi(d)

Qi(d) log

+ log p(x(i))

=

Qi(d) log

d=0,1

p(y(i)|d, x(i))p(d|x(i))

Qi(d)

+ log p(x(i)),

where Qi(d) is a p.m.f. of some distribution over d ∈ {0, 1}. The inequality above follows
from Jensen’s inequality.
If we assume that p(d|x(i)) and p(y|d, x(i)) have particular parametric forms, these

parameters can be estimated using the expectation-maximization (EM) algorithm.

There is one fundamental issue though. We can try to split the dataset into two parts,
but it is impossible to say which of these two parts is the treatment group and which
is the control group. In practice there is usually some additional knowledge that allows
us to make an assumption about the sign of the treatment eﬀect. Here I assume that
the treatment eﬀect is positive which allows us to predict that the group with the higher
average y(i) is the treatment group.

2.1 Expectation-maximization
I assume that p(d|x(i)) = pd and is known. In other words, the assignment to the treatment
and control groups is completely random (does not depend on the covariates) and the
researcher knows the fraction of people assigned to the treatment group.3

I also assume that y is binary (the case that corresponds to the real data that I use)

and that

p(y|d, x(i)) =(cid:0)g(θ0d + θT x(i))(cid:1)y(cid:0)1 − g(θ0d + θT x(i))(cid:1)1−y

,

where g(s) = 1/(1 + exp (−s)) is the sigmoid function and θ0, θ = (θ1, . . . , θn)T are the
parameters that we need to estimate.
During the E-step of the algorithm I compute Qi(d) ∝ p(y(i), d|x(i)). During the

M-step I use Newton’s method to maximize the lower bound for the log-likelihood.4

3 Simulations

The goal of this section is to assess the performance of the model when we know exactly
how the data is generated. Throughout this section n = 10, x(i)
1 = 1 for all i = 1, . . . , m,

3It is easy to modify the M-step for the case when pd is unknown.
4I tried to use gradient ascent too, but it leads to less accurate estimates of the average treatment

eﬀect. Moreover, the estimates become very sensitive to the initial values of θ0, θ.

3

j ∼ N (0, 1) and independent across i = 1, . . . , m and j = 2 . . . , n. I set p0 = p1 = 1/2,
x(i)
θ1 = 0, θj = 1 for j = 2, . . . , 5 and θj = −1 for j = 6, . . . , 10. I assume that d(i) and y(i)
are generated according to the model described in Section 2.

The next two plots show how the misclassiﬁcation error5 and the estimate of the aver-
age treatment eﬀect6 behave when θ0 changes.7 These plots show that the algorithm fails

Figure 2: Misclassiﬁcation Error and Average Treatment Eﬀect vs. θ0

to accurately predict the treatment status. Although it becomes easier as the treatment
eﬀect increases, even when θ0 = 10 on average 25% of the observations are misclassiﬁed.
However, as both the treatment status and the outcome are stochastic, even the “oracle”
model predicts poorly and produces essentially the same misclassiﬁcation errors as the
main model.

The estimates of the average treatment eﬀect look much more promising. There are
considerable discrepancies when θ0 is small, but as it increases the estimate of the average
treatment eﬀect converge to that of an “oracle” model.

To economize the space I don’t report the behavior of the misclassiﬁcation error and
the estimate of the average treatment eﬀect as a function of the sample size.8 The sample
sizes above 1,000 seem to have essentially no eﬀect on the performance.

4 Data

The dataset that I use comes from Angrist, Bettinger, Bloom, and King (2002).9 I use
the data from a randomized trial in Colombia conducted in the 90s. The idea of the

5This is an unsupervised learning problem so the term “misclassiﬁcation error” might be confusing.
However, the d(i) are actually observed so it is possible to calculate how many times the model has
correctly guessed d(i).

6As in the statistical model that I consider the treatment status is independent of the potential out-
0 ] = E[y(i)|d(i) =

come (the randomization assumption), the “true” average treatment eﬀect is E[y(i)
1] − E[y(i)|d(i) = 0] and can be easily estimated.

1 − y(i)

7In the plots the word “oracle” refers to the case when we know the true parameters of the model,

but do not observe the d(i)’s. The word “true” refers to the case when d(i)’s are observed.

8I presented these results at the poster session.
9This section is based heavily on the description of the experiment in the paper.

4

024681000.050.10.150.20.250.30.350.40.450.5θ0Misclassification Error  Error (actual)Error (oracle)0246810−0.100.10.20.30.40.50.6θ0Average Treatment Effect  ATE (estimated)ATE (oracle)ATE (true)Predicting the Treatment Status

Nikolay Doudchenko

1

Introduction

Many studies in social sciences deal with treatment eﬀect models.1 Usually there is a
treatment variable which determines whether a particular individual (or more generally
a unit of observation) was aﬀected by some impact (the binary case) or the intensity of
this impact. A researcher is interested in evaluating the eﬀect of the treatment measured
as some function of the joint distribution of y(i)
1 , the potential outcome for individual
i conditional on being treated, and y(i)
0 , the potential outcome conditional on not being
treated. There are many papers devoted to studying this setup due to a very fundamental
problem that for each individual i either y(i)
is observed in the data, but never
both.

1 or y(i)

0

In my project I consider a somewhat diﬀerent problem. What if we don’t know who
has got the treatment and who has not? For example, suppose that we organize a lottery
in which every participant draws a lottery ticket from a big jar. Some of the tickets
are the winning ones (the individual is treated) while some aren’t (the individual is not
treated). We cannot observe whether a particular person has won, but we can observe
some outcome potentially aﬀected by the realization of the lottery. Can we infer anything
about the treatment?2 To be precise, I ask two questions: (i) Can we guess the treatment
status? (ii) Is it possible to measure the treatment eﬀect even though we don’t observe
the treatment dummy?

I approach this problem as an unsupervised learning problem. Although the treat-
ment status is observed in the data that I use, I assume that in practice it won’t be and
there will be no way to train the model. The main tool in my analysis is what I call the
“Hidden Variable Model” (HVM). Essentially, this is a hidden Markov model with the
main diﬀerence being that there is no Markov structure and instead of observing a num-
ber of consecutive realizations for one individual we observe a number of “independent”
individuals. The hidden state is exactly the treatment status which we don’t observe. We
may also know some additional details of the assignment process or how the treatment
aﬀects the outcome. For example, we may know that the treatment status was determined

1Another prominent example would be medical studies. It does not matter for the theoretical deriva-
tions. Neither does it for the simulations. The “real world data” that I use comes from economics so I
stick to the social sciences context and terminology.

2Another interesting formulation is the following. What if there is an additional step required to
complete the treatment? We know the individuals that were supposed to be treated, but we don’t know
who actually undertook that step. What can we do in this case?

1

based on a subset of features or that only some of the features aﬀect the distribution of
the outcome.

In this project I consider both simulated data and a “real” publicly available dataset

that comes from a study by Angrist, Bettinger, Bloom, and King (2002).

The results suggest that as both the treatment and the outcome are stochastic the
treatment status is hard to retrieve. Not surprisingly, the stronger is the treatment eﬀect
the easier it becomes to guess the treatment variable. Intuitively, if the treatment eﬀect is
positive and large, a large value of the outcome suggests that the individual was treated.
The estimates of the treatment eﬀect are more precisely estimated. As obtaining these
estimates is usually the main goal of the researcher, there is some hope that this project
wasn’t completely useless.

The rest of the text is organized as follows. Section 2 describes the statistical model
referred to as the “Hidden Variable Model.” Section 3 reports the results obtained using
simulated data. Section 4 discusses the “real” dataset that I use in Section 5. Section 6
concludes.

2 Model

1 , . . . , x(i)

Suppose that for each observation i = 1, . . . , m there are n feature (or covariates) x(i) =
n )T which determine the probability, p(d = 1|x(i)), of being assigned to the
(x(i)
treatment group. The treatment status, d(i), and the covariates jointly determine the
distribution of the outcome variable, p(y|d(i), x(i)). The graphical representation of the
model is given in Figure 1.

Figure 1: Graphical Representation of the Model

Here the word “Rand” means that the covariates, the treatment status and the outcome
are stochastic.

I assume that only x(i) and y(i) are observed and d(i) is hidden. The likelihood of

(cid:88)

d=0,1

2

(y(i), x(i)) is given by

p(y(i), x(i)) =

p(y(i), d|x(i))p(x(i)).

Covariates (x)RandTreatment Status (d)Output (y)RandRandThe log-likelihood is

log p(y(i), x(i)) = log

Qi(d)

+ log p(x(i))

(cid:32)(cid:88)
≥ (cid:88)
(cid:88)

d=0,1

d=0,1

(cid:33)

p(y(i), d|x(i))

Qi(d)
p(y(i), d|x(i))

Qi(d)

Qi(d) log

+ log p(x(i))

=

Qi(d) log

d=0,1

p(y(i)|d, x(i))p(d|x(i))

Qi(d)

+ log p(x(i)),

where Qi(d) is a p.m.f. of some distribution over d ∈ {0, 1}. The inequality above follows
from Jensen’s inequality.
If we assume that p(d|x(i)) and p(y|d, x(i)) have particular parametric forms, these

parameters can be estimated using the expectation-maximization (EM) algorithm.

There is one fundamental issue though. We can try to split the dataset into two parts,
but it is impossible to say which of these two parts is the treatment group and which
is the control group. In practice there is usually some additional knowledge that allows
us to make an assumption about the sign of the treatment eﬀect. Here I assume that
the treatment eﬀect is positive which allows us to predict that the group with the higher
average y(i) is the treatment group.

2.1 Expectation-maximization
I assume that p(d|x(i)) = pd and is known. In other words, the assignment to the treatment
and control groups is completely random (does not depend on the covariates) and the
researcher knows the fraction of people assigned to the treatment group.3

I also assume that y is binary (the case that corresponds to the real data that I use)

and that

p(y|d, x(i)) =(cid:0)g(θ0d + θT x(i))(cid:1)y(cid:0)1 − g(θ0d + θT x(i))(cid:1)1−y

,

where g(s) = 1/(1 + exp (−s)) is the sigmoid function and θ0, θ = (θ1, . . . , θn)T are the
parameters that we need to estimate.
During the E-step of the algorithm I compute Qi(d) ∝ p(y(i), d|x(i)). During the

M-step I use Newton’s method to maximize the lower bound for the log-likelihood.4

3 Simulations

The goal of this section is to assess the performance of the model when we know exactly
how the data is generated. Throughout this section n = 10, x(i)
1 = 1 for all i = 1, . . . , m,

3It is easy to modify the M-step for the case when pd is unknown.
4I tried to use gradient ascent too, but it leads to less accurate estimates of the average treatment

eﬀect. Moreover, the estimates become very sensitive to the initial values of θ0, θ.

3

j ∼ N (0, 1) and independent across i = 1, . . . , m and j = 2 . . . , n. I set p0 = p1 = 1/2,
x(i)
θ1 = 0, θj = 1 for j = 2, . . . , 5 and θj = −1 for j = 6, . . . , 10. I assume that d(i) and y(i)
are generated according to the model described in Section 2.

The next two plots show how the misclassiﬁcation error5 and the estimate of the aver-
age treatment eﬀect6 behave when θ0 changes.7 These plots show that the algorithm fails

Figure 2: Misclassiﬁcation Error and Average Treatment Eﬀect vs. θ0

to accurately predict the treatment status. Although it becomes easier as the treatment
eﬀect increases, even when θ0 = 10 on average 25% of the observations are misclassiﬁed.
However, as both the treatment status and the outcome are stochastic, even the “oracle”
model predicts poorly and produces essentially the same misclassiﬁcation errors as the
main model.

The estimates of the average treatment eﬀect look much more promising. There are
considerable discrepancies when θ0 is small, but as it increases the estimate of the average
treatment eﬀect converge to that of an “oracle” model.

To economize the space I don’t report the behavior of the misclassiﬁcation error and
the estimate of the average treatment eﬀect as a function of the sample size.8 The sample
sizes above 1,000 seem to have essentially no eﬀect on the performance.

4 Data

The dataset that I use comes from Angrist, Bettinger, Bloom, and King (2002).9 I use
the data from a randomized trial in Colombia conducted in the 90s. The idea of the

5This is an unsupervised learning problem so the term “misclassiﬁcation error” might be confusing.
However, the d(i) are actually observed so it is possible to calculate how many times the model has
correctly guessed d(i).

6As in the statistical model that I consider the treatment status is independent of the potential out-
0 ] = E[y(i)|d(i) =

come (the randomization assumption), the “true” average treatment eﬀect is E[y(i)
1] − E[y(i)|d(i) = 0] and can be easily estimated.

1 − y(i)

7In the plots the word “oracle” refers to the case when we know the true parameters of the model,

but do not observe the d(i)’s. The word “true” refers to the case when d(i)’s are observed.

8I presented these results at the poster session.
9This section is based heavily on the description of the experiment in the paper.

4

024681000.050.10.150.20.250.30.350.40.450.5θ0Misclassification Error  Error (actual)Error (oracle)0246810−0.100.10.20.30.40.50.6θ0Average Treatment Effect  ATE (estimated)ATE (oracle)ATE (true)experiment was to randomly assign vouchers to the low-income families with children
attending public primary schools. These vouchers could be used to pay the tuitions in
private secondary schools.

The data consist of 1,315 individual level observations. The features include student’s
gender and age, the city where he or she lives, the year of the lottery (1993, 1995, or 1997),
a dummy for whether the student’s household has a phone, age and years of schooling
of student’s parents. There is also a treatment status variable which I want to predict,
but I assume that it is not observed by the researcher. The outcome variable which the
treatment status is supposed to aﬀect is a dummy for whether the student had ﬁnished
the 8th grade by the time of the follow up survey.

5 Results

I compare
The table below reports the performance of the model on the “real” data.
the HVM with the k-means model on the full set of features with k = 2. The “true”
average treatment eﬀect (computed using the actual values of d(i)’s) is 0.068. Therefore,
the numbers below demonstrate that both the HVM and the k-means perform poorly. As
noted in the previous section, when the treatment eﬀect is low the HVM tends to produce
inaccurate estimates (which substantially depend on the initial values).

Model
k-means
Hidden variable

Misclassiﬁcation Error Average Treatment Eﬀect

0.499
0.465

0.353
0.002

6 Conclusion

The results suggest that the Hidden Variable Model allows us to estimate the average
treatment eﬀect and tends to perform somewhat better than a simple k-means model.
However, it fails to accurately predict the treatment status and the estimate of the average
treatment eﬀect depends on the initial values.
and consider alternative speciﬁcations of p(y|d, x(i)).

To improve the performance of the model I would like to add more (derived) features

References

Angrist, J., E. Bettinger, E. Bloom, and E. King (2002). Vouchers for private schooling in
colombia: Evidence from a randomized natural experiment. The American Economic
Review .

Kuroki, M. and J. Pearl (2014). Measurement bias and eﬀect restoration in causal infer-

ence. Biometrika 101 (2), 423–437.

5

