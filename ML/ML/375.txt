Recommendation based on user experiences

Hai Vu

December 13, 2014

Abstract

Latent factor model is one common technique to build rec-
ommendation systems. Standard latent factor model however
does not take into account the order in which each individual
user makes the ratings. Modeling the shift in user behaviour
over time will not only allow making better recommendations
to users, but also discover their hidden categories, “level of
experiences” or “progression stages”. In this project, we ap-
ply the standard latent factor technique to a movie review
data set and then apply the new technique to model user
experience on this data set.

We ﬁnd that the improvement in prediction depends on the
time span of the dataset. But more importantly, we can use
the model to draw interesting insight from the discovered
“user experiences” - guiding user to the next level of expe-
riences.

depedent. We ﬁrst discuss standard recommeder system that
discover time-depedent features in order to make suggestion
to users. We then discuss new model (introduced in [3]) to
deal with time-depedent feature that we named “user expe-
rience”. We experiment with a movie data set, evaluate the
improvment over standard recommender system, and discuss
other beneﬁts of discovering user experiences.

2. Modelling user’s time-indepedent latent
features

Rating is modelled as a sum of average score, item and users
biases, and the similarity of user and items in the latent fea-
ture space.

• brui=µ + bi + bu + qT

ipu

The Baseline algorithm

1. Introduction

Recommender systems follow 2 main strategies:
content-
based ﬁltering and collaborative ﬁltering. Collaborative is
often the preﬀered approach as it requires no domain knowl-
edge and no feature gathering eﬀort. The 2 primary methods
for collaborative ﬁltering are latent factor models and neigh-
borhood methods.

In user-user neighbourhood methods, similarity between users
is measured by transforming them into the item space. Simi-
lar logic applies to item-item similarity. In latent factor meth-
ods, both user and items are transfomed into a latent featuee
space. An item is recommended to a user if thu are simi-
lar, their vector representation in the latent feature spase is
relatively high.

In principle, the factorization method maps users and items
onto the feature space and the similarity on this space is mea-
sured by inner product. The higher the product of these 2
projected vectors the better the user rates the movie. Teh
hidden feature space has k dimensions.

The challenge is to ﬁnd the feature space, or in other word,
to decompose the user-item matrix into the product of 2 ma-
trices. The ﬁrst matric links users to the hidden features and
the second matric links products to the features. Given that
the user-product is sparse we don’t try to factorise the matrix
(using Singular Value Decomposition approach). Instead we
minimize the error on available ratings.

• min Pu,i (rui-(µ + bi + bu + qT
• where λ (||qi||2 +||pu||2) is regularization

ipu )2+λ(||qi ||2 +||pu||2)

We select latent factor model because it allows us to identify
the hidden feature of the users. These features are time in-

• µ is the mean rating, bi and buare bias for items and users

respectively. Hidden feature space has k dimensions.

1

Recommendation based on user experiences

Hai Vu

December 13, 2014

Abstract

Latent factor model is one common technique to build rec-
ommendation systems. Standard latent factor model however
does not take into account the order in which each individual
user makes the ratings. Modeling the shift in user behaviour
over time will not only allow making better recommendations
to users, but also discover their hidden categories, “level of
experiences” or “progression stages”. In this project, we ap-
ply the standard latent factor technique to a movie review
data set and then apply the new technique to model user
experience on this data set.

We ﬁnd that the improvement in prediction depends on the
time span of the dataset. But more importantly, we can use
the model to draw interesting insight from the discovered
“user experiences” - guiding user to the next level of expe-
riences.

depedent. We ﬁrst discuss standard recommeder system that
discover time-depedent features in order to make suggestion
to users. We then discuss new model (introduced in [3]) to
deal with time-depedent feature that we named “user expe-
rience”. We experiment with a movie data set, evaluate the
improvment over standard recommender system, and discuss
other beneﬁts of discovering user experiences.

2. Modelling user’s time-indepedent latent
features

Rating is modelled as a sum of average score, item and users
biases, and the similarity of user and items in the latent fea-
ture space.

• brui=µ + bi + bu + qT

ipu

The Baseline algorithm

1. Introduction

Recommender systems follow 2 main strategies:
content-
based ﬁltering and collaborative ﬁltering. Collaborative is
often the preﬀered approach as it requires no domain knowl-
edge and no feature gathering eﬀort. The 2 primary methods
for collaborative ﬁltering are latent factor models and neigh-
borhood methods.

In user-user neighbourhood methods, similarity between users
is measured by transforming them into the item space. Simi-
lar logic applies to item-item similarity. In latent factor meth-
ods, both user and items are transfomed into a latent featuee
space. An item is recommended to a user if thu are simi-
lar, their vector representation in the latent feature spase is
relatively high.

In principle, the factorization method maps users and items
onto the feature space and the similarity on this space is mea-
sured by inner product. The higher the product of these 2
projected vectors the better the user rates the movie. Teh
hidden feature space has k dimensions.

The challenge is to ﬁnd the feature space, or in other word,
to decompose the user-item matrix into the product of 2 ma-
trices. The ﬁrst matric links users to the hidden features and
the second matric links products to the features. Given that
the user-product is sparse we don’t try to factorise the matrix
(using Singular Value Decomposition approach). Instead we
minimize the error on available ratings.

• min Pu,i (rui-(µ + bi + bu + qT
• where λ (||qi||2 +||pu||2) is regularization

ipu )2+λ(||qi ||2 +||pu||2)

We select latent factor model because it allows us to identify
the hidden feature of the users. These features are time in-

• µ is the mean rating, bi and buare bias for items and users

respectively. Hidden feature space has k dimensions.

1

We will use Stochastic Gradient Descent to ﬁnd the optimal
solution. We chose it over Alternating Leaset Square due to
is easy implementation and fast running time. Taking deriva-
tion to each parameters we arrive at the following update at
each iteration:

• εiu= 2 (riu- (µ + b_itemi + b_useru +qi pu

T)

• qi <— qi + η (εiu pu- 2 λ qi )

• pu <— pu + η (ǫiu qi - 2 λ pu)

• b_itemi <— b_itemi + ηbias (εiu - 2λ b_itemi

• b_useru <— b_useru + ηbias (εiu- 2 λ b_useru )

• µ can be calculated from the dataset.

3. Modeling time-depedent user experiences

When a user rates a product, she stays at speciﬁc experience
level, denoted by an integer e where e = 1,..k (k is the highest
exprience level). We assume that

• users at the same exprience level will behave similarly

(apart from their hidden features)

• experience level never decreases over time

Our intuitive expectation of user experience is that its level
never decreases. We believe that monitonicity is natural as-
sumption and will not narrow too much the scope of applica-
tion. In addition, the monitonicity constraint will also help
to avoid overﬁtting because only a limited set of experience
sequence could be mapped to the sequence of ratings. Now
the new model consists of 2 set of parameters :

• set 1: µ, b_item, b_user, q, p for each user experience

level

• set 2: the assignment of each rating to an experience
level. For each user, the assignment is subjected to the
monotonicity constraint.

To train the model we need to ﬁnd the above set of param-
eters to minimize error expression as in previous section. As
objective function is not convex, we will ﬁnd the local opti-
mum by alternatively optimize one parameter set while keep-
ing the other set ﬁxed and repeate until the error becomes
small enough.

The algorithm

• Step 0 - Initialization: for each user, assign experience
level evenly so that each user at each level makes rating
appoximately equal number of times. (while statisfying
monitonicity constraint)

• Step 1 - Filter ratings according to exprience level and
Train model for each individual experience level
(training smaller experience levels ﬁrst). Collect all rat-
ings belonging a speciﬁc level and apply the standard
recommendation method to this dataset. In this step we
keep parameter set 2 ﬁxed while optimizing parameter
set 1.

• Step 2 - Reassign ratings to experience levels. For
each user, reassign rating times to exprience levels to
minimise the error. In this step we keep parameter set 1
ﬁxed while optimizing parameter set 2.

• Repeat steps 1,2 until convergence.

To avoid overﬁtting we introduce a smoothing component
into our error function so that parameters of experience level
k will not signiﬁcantly diﬀerent from those of experience level
k-1 . This change impacts the derivation of error and the
update rule as follows:

• qi <– qi +η (εiupu- 2λ(qi- q_otheri))

• pu <– pu+η(ǫiuqi - 2λ(pu- p_otheri))

• b_itemi <–

b_itemi +ηbias(εiu

-

2λ(b_itemi -

b_item_otheri))

• b_itemu <–

b_itemu +ηbias(εiu-

2λ(b_itemu -

b_item_otheru ))

While ﬁtting model for exprience k, we use q_other, p_other,
b_item_other, b_user_other parameters of the model k-1.

For Step 2, we use dynamic programming to reassign each
rating to new experience level.

4. Implementation details

Data set

Availabel at: http://grouplens.org/datasets/movielens/

2

Recommendation based on user experiences

Hai Vu

December 13, 2014

Abstract

Latent factor model is one common technique to build rec-
ommendation systems. Standard latent factor model however
does not take into account the order in which each individual
user makes the ratings. Modeling the shift in user behaviour
over time will not only allow making better recommendations
to users, but also discover their hidden categories, “level of
experiences” or “progression stages”. In this project, we ap-
ply the standard latent factor technique to a movie review
data set and then apply the new technique to model user
experience on this data set.

We ﬁnd that the improvement in prediction depends on the
time span of the dataset. But more importantly, we can use
the model to draw interesting insight from the discovered
“user experiences” - guiding user to the next level of expe-
riences.

depedent. We ﬁrst discuss standard recommeder system that
discover time-depedent features in order to make suggestion
to users. We then discuss new model (introduced in [3]) to
deal with time-depedent feature that we named “user expe-
rience”. We experiment with a movie data set, evaluate the
improvment over standard recommender system, and discuss
other beneﬁts of discovering user experiences.

2. Modelling user’s time-indepedent latent
features

Rating is modelled as a sum of average score, item and users
biases, and the similarity of user and items in the latent fea-
ture space.

• brui=µ + bi + bu + qT

ipu

The Baseline algorithm

1. Introduction

Recommender systems follow 2 main strategies:
content-
based ﬁltering and collaborative ﬁltering. Collaborative is
often the preﬀered approach as it requires no domain knowl-
edge and no feature gathering eﬀort. The 2 primary methods
for collaborative ﬁltering are latent factor models and neigh-
borhood methods.

In user-user neighbourhood methods, similarity between users
is measured by transforming them into the item space. Simi-
lar logic applies to item-item similarity. In latent factor meth-
ods, both user and items are transfomed into a latent featuee
space. An item is recommended to a user if thu are simi-
lar, their vector representation in the latent feature spase is
relatively high.

In principle, the factorization method maps users and items
onto the feature space and the similarity on this space is mea-
sured by inner product. The higher the product of these 2
projected vectors the better the user rates the movie. Teh
hidden feature space has k dimensions.

The challenge is to ﬁnd the feature space, or in other word,
to decompose the user-item matrix into the product of 2 ma-
trices. The ﬁrst matric links users to the hidden features and
the second matric links products to the features. Given that
the user-product is sparse we don’t try to factorise the matrix
(using Singular Value Decomposition approach). Instead we
minimize the error on available ratings.

• min Pu,i (rui-(µ + bi + bu + qT
• where λ (||qi||2 +||pu||2) is regularization

ipu )2+λ(||qi ||2 +||pu||2)

We select latent factor model because it allows us to identify
the hidden feature of the users. These features are time in-

• µ is the mean rating, bi and buare bias for items and users

respectively. Hidden feature space has k dimensions.

1

We will use Stochastic Gradient Descent to ﬁnd the optimal
solution. We chose it over Alternating Leaset Square due to
is easy implementation and fast running time. Taking deriva-
tion to each parameters we arrive at the following update at
each iteration:

• εiu= 2 (riu- (µ + b_itemi + b_useru +qi pu

T)

• qi <— qi + η (εiu pu- 2 λ qi )

• pu <— pu + η (ǫiu qi - 2 λ pu)

• b_itemi <— b_itemi + ηbias (εiu - 2λ b_itemi

• b_useru <— b_useru + ηbias (εiu- 2 λ b_useru )

• µ can be calculated from the dataset.

3. Modeling time-depedent user experiences

When a user rates a product, she stays at speciﬁc experience
level, denoted by an integer e where e = 1,..k (k is the highest
exprience level). We assume that

• users at the same exprience level will behave similarly

(apart from their hidden features)

• experience level never decreases over time

Our intuitive expectation of user experience is that its level
never decreases. We believe that monitonicity is natural as-
sumption and will not narrow too much the scope of applica-
tion. In addition, the monitonicity constraint will also help
to avoid overﬁtting because only a limited set of experience
sequence could be mapped to the sequence of ratings. Now
the new model consists of 2 set of parameters :

• set 1: µ, b_item, b_user, q, p for each user experience

level

• set 2: the assignment of each rating to an experience
level. For each user, the assignment is subjected to the
monotonicity constraint.

To train the model we need to ﬁnd the above set of param-
eters to minimize error expression as in previous section. As
objective function is not convex, we will ﬁnd the local opti-
mum by alternatively optimize one parameter set while keep-
ing the other set ﬁxed and repeate until the error becomes
small enough.

The algorithm

• Step 0 - Initialization: for each user, assign experience
level evenly so that each user at each level makes rating
appoximately equal number of times. (while statisfying
monitonicity constraint)

• Step 1 - Filter ratings according to exprience level and
Train model for each individual experience level
(training smaller experience levels ﬁrst). Collect all rat-
ings belonging a speciﬁc level and apply the standard
recommendation method to this dataset. In this step we
keep parameter set 2 ﬁxed while optimizing parameter
set 1.

• Step 2 - Reassign ratings to experience levels. For
each user, reassign rating times to exprience levels to
minimise the error. In this step we keep parameter set 1
ﬁxed while optimizing parameter set 2.

• Repeat steps 1,2 until convergence.

To avoid overﬁtting we introduce a smoothing component
into our error function so that parameters of experience level
k will not signiﬁcantly diﬀerent from those of experience level
k-1 . This change impacts the derivation of error and the
update rule as follows:

• qi <– qi +η (εiupu- 2λ(qi- q_otheri))

• pu <– pu+η(ǫiuqi - 2λ(pu- p_otheri))

• b_itemi <–

b_itemi +ηbias(εiu

-

2λ(b_itemi -

b_item_otheri))

• b_itemu <–

b_itemu +ηbias(εiu-

2λ(b_itemu -

b_item_otheru ))

While ﬁtting model for exprience k, we use q_other, p_other,
b_item_other, b_user_other parameters of the model k-1.

For Step 2, we use dynamic programming to reassign each
rating to new experience level.

4. Implementation details

Data set

Availabel at: http://grouplens.org/datasets/movielens/

2

Format of data ﬁles: each row includes user id , movie id,
rating, timestamp.

Avoid overﬁtting

Overﬁtting is avoided by

Dataset 100K: number of users = 943, number of movies =
1676, number of ratings = 100,000. Timespan = 214 days.
Rating = 1-5. Number of rating / user: at least 20

• using regularisation to make the model simple : param-
eter of the experiences level k should be similar to that
of level k-1. We arrive at λ = 2.

Dataset 1M: number of users = 6040, number of movies =
3900. number of ratings = 1,000,000. Timespan = 1038 days.
Rating = 1-5. Number of rating / user: at least 20

Filtering relevant users

We select only users whose have been at least 10 days (Latest
rating and earliest ratign are done at least 10 days apart) in
the system and make at least 20 ratings. Users who spend less
time in the system have not potentialy reveal her behaviour
and therefore will not be considered.

Learning rate and convergence

As we run standard latent factor model repeteadly at step 1 of
the Algorithm above, we want to use the same learning rate η
and ηbiasfor each iteration. We obtain these values by running
a baseline algorithm on the data set without considering the
user exprience at all. For this dataset, we get ηbias = 0.02, η
= 0.03. Note, we use diﬀerent learning rate η for p, q and for
bias parameters because the bias parameters are simpler to
learn.

Initialisation

At step 1 of the algorithm, The initial value of q and p are
randomly generated so that <q,p> is in comparable range of
the maximal rating value.

Cross validation, testing

• forcing simple asssignment : monotonicity constraint on

experience level for each user

Number of hidden features

Each user has k number of hidden features that are time in-
depedent and e number of experience levels. The maximal
value of k is 20 and e is 5. We don’t see RMSE improvement
with large k or e value.

Dynamic programming

For Step 2 , we use dynamic programming to reassign each
rating to new experience level. Dynamic programming is fea-
sible because the best assignment for ratings r1, r2, ...rn con-
tains the best assginment for ratings r1, r2, ...rn−1 as its sub-
set. (Here r1, r2, ...rn are ordered according to the time of
ratings)

5. Result, discussion

How much improvement does the new model bring ?

If we keep only users from dataset 100K, whose timespan is
more than 10 days, we achieve RMSE of 0.887 versus the
baseline RMSE 0.997 (the baseline model is the standard rec-
ommendation which does not consider user experience). We
argue that users who just spend very little time in the movie
system will not exhibit behaviour shift, instead they exhibit
a “noise behaviour”. Once they spend more time in the
system, their behaviour will be shaped and follow the mono-
tonicity trend. Therefore removing these noise behaviours
will help identify the key user experiences.

For validation, we split the data set so that we can make
10-fold cross validation. Regarding testing, for each tuple
(user, movie, timestamp) in the test dataset, we ﬁnd the user
experience level by looking up the level associated with the
closest timestamps in the traingning set. Giventhe level , the
parameters (µ, b_item, b_user, q, p) are then obtained and
Root Mean Square RMSE is calculated.

Dataset 100K: Baseline RMSE = 0.997. Keeping users who
spend at least 10 days in the system. User experience based
model: RMSE = 0.871.
Improvement over baseline: 12%.
Number of experience level :3. Regularisationλ = 2, number
of time indepedent latent features k = 20, learning rate for
bias parameter ηbias = 0.02,for other parameters η = 0.03.

3

Recommendation based on user experiences

Hai Vu

December 13, 2014

Abstract

Latent factor model is one common technique to build rec-
ommendation systems. Standard latent factor model however
does not take into account the order in which each individual
user makes the ratings. Modeling the shift in user behaviour
over time will not only allow making better recommendations
to users, but also discover their hidden categories, “level of
experiences” or “progression stages”. In this project, we ap-
ply the standard latent factor technique to a movie review
data set and then apply the new technique to model user
experience on this data set.

We ﬁnd that the improvement in prediction depends on the
time span of the dataset. But more importantly, we can use
the model to draw interesting insight from the discovered
“user experiences” - guiding user to the next level of expe-
riences.

depedent. We ﬁrst discuss standard recommeder system that
discover time-depedent features in order to make suggestion
to users. We then discuss new model (introduced in [3]) to
deal with time-depedent feature that we named “user expe-
rience”. We experiment with a movie data set, evaluate the
improvment over standard recommender system, and discuss
other beneﬁts of discovering user experiences.

2. Modelling user’s time-indepedent latent
features

Rating is modelled as a sum of average score, item and users
biases, and the similarity of user and items in the latent fea-
ture space.

• brui=µ + bi + bu + qT

ipu

The Baseline algorithm

1. Introduction

Recommender systems follow 2 main strategies:
content-
based ﬁltering and collaborative ﬁltering. Collaborative is
often the preﬀered approach as it requires no domain knowl-
edge and no feature gathering eﬀort. The 2 primary methods
for collaborative ﬁltering are latent factor models and neigh-
borhood methods.

In user-user neighbourhood methods, similarity between users
is measured by transforming them into the item space. Simi-
lar logic applies to item-item similarity. In latent factor meth-
ods, both user and items are transfomed into a latent featuee
space. An item is recommended to a user if thu are simi-
lar, their vector representation in the latent feature spase is
relatively high.

In principle, the factorization method maps users and items
onto the feature space and the similarity on this space is mea-
sured by inner product. The higher the product of these 2
projected vectors the better the user rates the movie. Teh
hidden feature space has k dimensions.

The challenge is to ﬁnd the feature space, or in other word,
to decompose the user-item matrix into the product of 2 ma-
trices. The ﬁrst matric links users to the hidden features and
the second matric links products to the features. Given that
the user-product is sparse we don’t try to factorise the matrix
(using Singular Value Decomposition approach). Instead we
minimize the error on available ratings.

• min Pu,i (rui-(µ + bi + bu + qT
• where λ (||qi||2 +||pu||2) is regularization

ipu )2+λ(||qi ||2 +||pu||2)

We select latent factor model because it allows us to identify
the hidden feature of the users. These features are time in-

• µ is the mean rating, bi and buare bias for items and users

respectively. Hidden feature space has k dimensions.

1

We will use Stochastic Gradient Descent to ﬁnd the optimal
solution. We chose it over Alternating Leaset Square due to
is easy implementation and fast running time. Taking deriva-
tion to each parameters we arrive at the following update at
each iteration:

• εiu= 2 (riu- (µ + b_itemi + b_useru +qi pu

T)

• qi <— qi + η (εiu pu- 2 λ qi )

• pu <— pu + η (ǫiu qi - 2 λ pu)

• b_itemi <— b_itemi + ηbias (εiu - 2λ b_itemi

• b_useru <— b_useru + ηbias (εiu- 2 λ b_useru )

• µ can be calculated from the dataset.

3. Modeling time-depedent user experiences

When a user rates a product, she stays at speciﬁc experience
level, denoted by an integer e where e = 1,..k (k is the highest
exprience level). We assume that

• users at the same exprience level will behave similarly

(apart from their hidden features)

• experience level never decreases over time

Our intuitive expectation of user experience is that its level
never decreases. We believe that monitonicity is natural as-
sumption and will not narrow too much the scope of applica-
tion. In addition, the monitonicity constraint will also help
to avoid overﬁtting because only a limited set of experience
sequence could be mapped to the sequence of ratings. Now
the new model consists of 2 set of parameters :

• set 1: µ, b_item, b_user, q, p for each user experience

level

• set 2: the assignment of each rating to an experience
level. For each user, the assignment is subjected to the
monotonicity constraint.

To train the model we need to ﬁnd the above set of param-
eters to minimize error expression as in previous section. As
objective function is not convex, we will ﬁnd the local opti-
mum by alternatively optimize one parameter set while keep-
ing the other set ﬁxed and repeate until the error becomes
small enough.

The algorithm

• Step 0 - Initialization: for each user, assign experience
level evenly so that each user at each level makes rating
appoximately equal number of times. (while statisfying
monitonicity constraint)

• Step 1 - Filter ratings according to exprience level and
Train model for each individual experience level
(training smaller experience levels ﬁrst). Collect all rat-
ings belonging a speciﬁc level and apply the standard
recommendation method to this dataset. In this step we
keep parameter set 2 ﬁxed while optimizing parameter
set 1.

• Step 2 - Reassign ratings to experience levels. For
each user, reassign rating times to exprience levels to
minimise the error. In this step we keep parameter set 1
ﬁxed while optimizing parameter set 2.

• Repeat steps 1,2 until convergence.

To avoid overﬁtting we introduce a smoothing component
into our error function so that parameters of experience level
k will not signiﬁcantly diﬀerent from those of experience level
k-1 . This change impacts the derivation of error and the
update rule as follows:

• qi <– qi +η (εiupu- 2λ(qi- q_otheri))

• pu <– pu+η(ǫiuqi - 2λ(pu- p_otheri))

• b_itemi <–

b_itemi +ηbias(εiu

-

2λ(b_itemi -

b_item_otheri))

• b_itemu <–

b_itemu +ηbias(εiu-

2λ(b_itemu -

b_item_otheru ))

While ﬁtting model for exprience k, we use q_other, p_other,
b_item_other, b_user_other parameters of the model k-1.

For Step 2, we use dynamic programming to reassign each
rating to new experience level.

4. Implementation details

Data set

Availabel at: http://grouplens.org/datasets/movielens/

2

Format of data ﬁles: each row includes user id , movie id,
rating, timestamp.

Avoid overﬁtting

Overﬁtting is avoided by

Dataset 100K: number of users = 943, number of movies =
1676, number of ratings = 100,000. Timespan = 214 days.
Rating = 1-5. Number of rating / user: at least 20

• using regularisation to make the model simple : param-
eter of the experiences level k should be similar to that
of level k-1. We arrive at λ = 2.

Dataset 1M: number of users = 6040, number of movies =
3900. number of ratings = 1,000,000. Timespan = 1038 days.
Rating = 1-5. Number of rating / user: at least 20

Filtering relevant users

We select only users whose have been at least 10 days (Latest
rating and earliest ratign are done at least 10 days apart) in
the system and make at least 20 ratings. Users who spend less
time in the system have not potentialy reveal her behaviour
and therefore will not be considered.

Learning rate and convergence

As we run standard latent factor model repeteadly at step 1 of
the Algorithm above, we want to use the same learning rate η
and ηbiasfor each iteration. We obtain these values by running
a baseline algorithm on the data set without considering the
user exprience at all. For this dataset, we get ηbias = 0.02, η
= 0.03. Note, we use diﬀerent learning rate η for p, q and for
bias parameters because the bias parameters are simpler to
learn.

Initialisation

At step 1 of the algorithm, The initial value of q and p are
randomly generated so that <q,p> is in comparable range of
the maximal rating value.

Cross validation, testing

• forcing simple asssignment : monotonicity constraint on

experience level for each user

Number of hidden features

Each user has k number of hidden features that are time in-
depedent and e number of experience levels. The maximal
value of k is 20 and e is 5. We don’t see RMSE improvement
with large k or e value.

Dynamic programming

For Step 2 , we use dynamic programming to reassign each
rating to new experience level. Dynamic programming is fea-
sible because the best assignment for ratings r1, r2, ...rn con-
tains the best assginment for ratings r1, r2, ...rn−1 as its sub-
set. (Here r1, r2, ...rn are ordered according to the time of
ratings)

5. Result, discussion

How much improvement does the new model bring ?

If we keep only users from dataset 100K, whose timespan is
more than 10 days, we achieve RMSE of 0.887 versus the
baseline RMSE 0.997 (the baseline model is the standard rec-
ommendation which does not consider user experience). We
argue that users who just spend very little time in the movie
system will not exhibit behaviour shift, instead they exhibit
a “noise behaviour”. Once they spend more time in the
system, their behaviour will be shaped and follow the mono-
tonicity trend. Therefore removing these noise behaviours
will help identify the key user experiences.

For validation, we split the data set so that we can make
10-fold cross validation. Regarding testing, for each tuple
(user, movie, timestamp) in the test dataset, we ﬁnd the user
experience level by looking up the level associated with the
closest timestamps in the traingning set. Giventhe level , the
parameters (µ, b_item, b_user, q, p) are then obtained and
Root Mean Square RMSE is calculated.

Dataset 100K: Baseline RMSE = 0.997. Keeping users who
spend at least 10 days in the system. User experience based
model: RMSE = 0.871.
Improvement over baseline: 12%.
Number of experience level :3. Regularisationλ = 2, number
of time indepedent latent features k = 20, learning rate for
bias parameter ηbias = 0.02,for other parameters η = 0.03.

3

Distinctive beneﬁt over traditional recommendation
system: guiding to the next level

While traditional system recommend the product the user
most probably like at the current state of their experience,
our user-exprience based system can do more: give them the
product so that they progress one level and also like it.

Here is the outline:

• Step 1) For a user u, ﬁnd his current exprience level, say
e. Find the averate time a user spend in exprience level
e.

• Step 2) If user user u has spent much longer than average
at this experience level, then use parameter set Θe+1to
make oﬀer ( instead of using Θe as normal recommedna-
tio system does)

6. Conclusion

We have experimented with user-exprience based recom-
mender system as suggested in [3]. We conﬁrm that the
improvement in term of RMSE over baseline recommender
system is in the range of 12-15%.
Our work reveals that:

• For the model to work eﬃcienlty and delivering improve-
ment over baseline recommenders, the dataset needs to
be cleaned upfront to remove users who spend too little
time in the system. We introduce the conjecture about
“noisy behaviour” that could reduce the performance im-
provement.

• We suggest to amek use of the learnt user experience to
make oﬀers to users so that they progress faster. The
steps are outlined in section 5.

• We discuss the model smoothing that is necessary to re-
duce overﬁtting. We observed that model smothing will
increase the performance about 2% in one of our dataset

As future work, the model could be extended to model diﬀer-
ent classes of progresstions (see [4]) .

Dataset
Baseline RMSE

User-exprience based model RMSE
Improvement over baseline

100K
0.997
0.871
12%

1M
1.002
0.847
15%

Does time depedent behaviour exist in the dataset?

This a fundamental question. Based on our experiements
we must remove “noisy behaviour” (see above), and consider
only users who have been engaged with the system for minum
period of time. This duration is application dependent and
could be measured in diﬀerent ways. For a movie system in
this project with timespan 200-1000 days (data set 100K and
1M) we observe that the threshold of 10 days is feasible.

Impact of model smoothing

When users jump from one experience level to the next, we
don’t expect too sudden change in their behaviour. Therefore
it is reasonalbe to smooth the model parameters:

• Θ=(µ + b_itemi + b_useru +qi ,pu) to keep the sum

Σe||Θe-Θe−1|| small .

This term is part of our error function describe in Section 3.
However, to see how much we have gained with smoothing we
also try to minimise

• Σe||Θe|| instead of Σe||Θe-Θe−1|| .

We observe that the smoothing gain in RMSE reduction is
2% (from 0.8871 down to 0.871 on Dataset 1) .

Beneﬁts of discovering user experiences

Instead of modelling user-experience and then using it to pre-
dict future user ratings, one can also just take the latest rat-
ings of each indivudual users and run a standard recommen-
dation on that ﬁltered data set. Which one has better pre-
diction power ? If all users have already reached the highest
experience level, then our user-experience model provide less
advantages. However, we expect that this is not the case in
typical systems.

Another beneﬁt is to identify a group of users who got stuck
in certain experience level for longer than average time. Do
they need special treatment ? Can they churn ? Or can
we help them to progress so othat they stay with us ? This
question leads to the next topic below.

4

Recommendation based on user experiences

Hai Vu

December 13, 2014

Abstract

Latent factor model is one common technique to build rec-
ommendation systems. Standard latent factor model however
does not take into account the order in which each individual
user makes the ratings. Modeling the shift in user behaviour
over time will not only allow making better recommendations
to users, but also discover their hidden categories, “level of
experiences” or “progression stages”. In this project, we ap-
ply the standard latent factor technique to a movie review
data set and then apply the new technique to model user
experience on this data set.

We ﬁnd that the improvement in prediction depends on the
time span of the dataset. But more importantly, we can use
the model to draw interesting insight from the discovered
“user experiences” - guiding user to the next level of expe-
riences.

depedent. We ﬁrst discuss standard recommeder system that
discover time-depedent features in order to make suggestion
to users. We then discuss new model (introduced in [3]) to
deal with time-depedent feature that we named “user expe-
rience”. We experiment with a movie data set, evaluate the
improvment over standard recommender system, and discuss
other beneﬁts of discovering user experiences.

2. Modelling user’s time-indepedent latent
features

Rating is modelled as a sum of average score, item and users
biases, and the similarity of user and items in the latent fea-
ture space.

• brui=µ + bi + bu + qT

ipu

The Baseline algorithm

1. Introduction

Recommender systems follow 2 main strategies:
content-
based ﬁltering and collaborative ﬁltering. Collaborative is
often the preﬀered approach as it requires no domain knowl-
edge and no feature gathering eﬀort. The 2 primary methods
for collaborative ﬁltering are latent factor models and neigh-
borhood methods.

In user-user neighbourhood methods, similarity between users
is measured by transforming them into the item space. Simi-
lar logic applies to item-item similarity. In latent factor meth-
ods, both user and items are transfomed into a latent featuee
space. An item is recommended to a user if thu are simi-
lar, their vector representation in the latent feature spase is
relatively high.

In principle, the factorization method maps users and items
onto the feature space and the similarity on this space is mea-
sured by inner product. The higher the product of these 2
projected vectors the better the user rates the movie. Teh
hidden feature space has k dimensions.

The challenge is to ﬁnd the feature space, or in other word,
to decompose the user-item matrix into the product of 2 ma-
trices. The ﬁrst matric links users to the hidden features and
the second matric links products to the features. Given that
the user-product is sparse we don’t try to factorise the matrix
(using Singular Value Decomposition approach). Instead we
minimize the error on available ratings.

• min Pu,i (rui-(µ + bi + bu + qT
• where λ (||qi||2 +||pu||2) is regularization

ipu )2+λ(||qi ||2 +||pu||2)

We select latent factor model because it allows us to identify
the hidden feature of the users. These features are time in-

• µ is the mean rating, bi and buare bias for items and users

respectively. Hidden feature space has k dimensions.

1

We will use Stochastic Gradient Descent to ﬁnd the optimal
solution. We chose it over Alternating Leaset Square due to
is easy implementation and fast running time. Taking deriva-
tion to each parameters we arrive at the following update at
each iteration:

• εiu= 2 (riu- (µ + b_itemi + b_useru +qi pu

T)

• qi <— qi + η (εiu pu- 2 λ qi )

• pu <— pu + η (ǫiu qi - 2 λ pu)

• b_itemi <— b_itemi + ηbias (εiu - 2λ b_itemi

• b_useru <— b_useru + ηbias (εiu- 2 λ b_useru )

• µ can be calculated from the dataset.

3. Modeling time-depedent user experiences

When a user rates a product, she stays at speciﬁc experience
level, denoted by an integer e where e = 1,..k (k is the highest
exprience level). We assume that

• users at the same exprience level will behave similarly

(apart from their hidden features)

• experience level never decreases over time

Our intuitive expectation of user experience is that its level
never decreases. We believe that monitonicity is natural as-
sumption and will not narrow too much the scope of applica-
tion. In addition, the monitonicity constraint will also help
to avoid overﬁtting because only a limited set of experience
sequence could be mapped to the sequence of ratings. Now
the new model consists of 2 set of parameters :

• set 1: µ, b_item, b_user, q, p for each user experience

level

• set 2: the assignment of each rating to an experience
level. For each user, the assignment is subjected to the
monotonicity constraint.

To train the model we need to ﬁnd the above set of param-
eters to minimize error expression as in previous section. As
objective function is not convex, we will ﬁnd the local opti-
mum by alternatively optimize one parameter set while keep-
ing the other set ﬁxed and repeate until the error becomes
small enough.

The algorithm

• Step 0 - Initialization: for each user, assign experience
level evenly so that each user at each level makes rating
appoximately equal number of times. (while statisfying
monitonicity constraint)

• Step 1 - Filter ratings according to exprience level and
Train model for each individual experience level
(training smaller experience levels ﬁrst). Collect all rat-
ings belonging a speciﬁc level and apply the standard
recommendation method to this dataset. In this step we
keep parameter set 2 ﬁxed while optimizing parameter
set 1.

• Step 2 - Reassign ratings to experience levels. For
each user, reassign rating times to exprience levels to
minimise the error. In this step we keep parameter set 1
ﬁxed while optimizing parameter set 2.

• Repeat steps 1,2 until convergence.

To avoid overﬁtting we introduce a smoothing component
into our error function so that parameters of experience level
k will not signiﬁcantly diﬀerent from those of experience level
k-1 . This change impacts the derivation of error and the
update rule as follows:

• qi <– qi +η (εiupu- 2λ(qi- q_otheri))

• pu <– pu+η(ǫiuqi - 2λ(pu- p_otheri))

• b_itemi <–

b_itemi +ηbias(εiu

-

2λ(b_itemi -

b_item_otheri))

• b_itemu <–

b_itemu +ηbias(εiu-

2λ(b_itemu -

b_item_otheru ))

While ﬁtting model for exprience k, we use q_other, p_other,
b_item_other, b_user_other parameters of the model k-1.

For Step 2, we use dynamic programming to reassign each
rating to new experience level.

4. Implementation details

Data set

Availabel at: http://grouplens.org/datasets/movielens/

2

Format of data ﬁles: each row includes user id , movie id,
rating, timestamp.

Avoid overﬁtting

Overﬁtting is avoided by

Dataset 100K: number of users = 943, number of movies =
1676, number of ratings = 100,000. Timespan = 214 days.
Rating = 1-5. Number of rating / user: at least 20

• using regularisation to make the model simple : param-
eter of the experiences level k should be similar to that
of level k-1. We arrive at λ = 2.

Dataset 1M: number of users = 6040, number of movies =
3900. number of ratings = 1,000,000. Timespan = 1038 days.
Rating = 1-5. Number of rating / user: at least 20

Filtering relevant users

We select only users whose have been at least 10 days (Latest
rating and earliest ratign are done at least 10 days apart) in
the system and make at least 20 ratings. Users who spend less
time in the system have not potentialy reveal her behaviour
and therefore will not be considered.

Learning rate and convergence

As we run standard latent factor model repeteadly at step 1 of
the Algorithm above, we want to use the same learning rate η
and ηbiasfor each iteration. We obtain these values by running
a baseline algorithm on the data set without considering the
user exprience at all. For this dataset, we get ηbias = 0.02, η
= 0.03. Note, we use diﬀerent learning rate η for p, q and for
bias parameters because the bias parameters are simpler to
learn.

Initialisation

At step 1 of the algorithm, The initial value of q and p are
randomly generated so that <q,p> is in comparable range of
the maximal rating value.

Cross validation, testing

• forcing simple asssignment : monotonicity constraint on

experience level for each user

Number of hidden features

Each user has k number of hidden features that are time in-
depedent and e number of experience levels. The maximal
value of k is 20 and e is 5. We don’t see RMSE improvement
with large k or e value.

Dynamic programming

For Step 2 , we use dynamic programming to reassign each
rating to new experience level. Dynamic programming is fea-
sible because the best assignment for ratings r1, r2, ...rn con-
tains the best assginment for ratings r1, r2, ...rn−1 as its sub-
set. (Here r1, r2, ...rn are ordered according to the time of
ratings)

5. Result, discussion

How much improvement does the new model bring ?

If we keep only users from dataset 100K, whose timespan is
more than 10 days, we achieve RMSE of 0.887 versus the
baseline RMSE 0.997 (the baseline model is the standard rec-
ommendation which does not consider user experience). We
argue that users who just spend very little time in the movie
system will not exhibit behaviour shift, instead they exhibit
a “noise behaviour”. Once they spend more time in the
system, their behaviour will be shaped and follow the mono-
tonicity trend. Therefore removing these noise behaviours
will help identify the key user experiences.

For validation, we split the data set so that we can make
10-fold cross validation. Regarding testing, for each tuple
(user, movie, timestamp) in the test dataset, we ﬁnd the user
experience level by looking up the level associated with the
closest timestamps in the traingning set. Giventhe level , the
parameters (µ, b_item, b_user, q, p) are then obtained and
Root Mean Square RMSE is calculated.

Dataset 100K: Baseline RMSE = 0.997. Keeping users who
spend at least 10 days in the system. User experience based
model: RMSE = 0.871.
Improvement over baseline: 12%.
Number of experience level :3. Regularisationλ = 2, number
of time indepedent latent features k = 20, learning rate for
bias parameter ηbias = 0.02,for other parameters η = 0.03.

3

Distinctive beneﬁt over traditional recommendation
system: guiding to the next level

While traditional system recommend the product the user
most probably like at the current state of their experience,
our user-exprience based system can do more: give them the
product so that they progress one level and also like it.

Here is the outline:

• Step 1) For a user u, ﬁnd his current exprience level, say
e. Find the averate time a user spend in exprience level
e.

• Step 2) If user user u has spent much longer than average
at this experience level, then use parameter set Θe+1to
make oﬀer ( instead of using Θe as normal recommedna-
tio system does)

6. Conclusion

We have experimented with user-exprience based recom-
mender system as suggested in [3]. We conﬁrm that the
improvement in term of RMSE over baseline recommender
system is in the range of 12-15%.
Our work reveals that:

• For the model to work eﬃcienlty and delivering improve-
ment over baseline recommenders, the dataset needs to
be cleaned upfront to remove users who spend too little
time in the system. We introduce the conjecture about
“noisy behaviour” that could reduce the performance im-
provement.

• We suggest to amek use of the learnt user experience to
make oﬀers to users so that they progress faster. The
steps are outlined in section 5.

• We discuss the model smoothing that is necessary to re-
duce overﬁtting. We observed that model smothing will
increase the performance about 2% in one of our dataset

As future work, the model could be extended to model diﬀer-
ent classes of progresstions (see [4]) .

Dataset
Baseline RMSE

User-exprience based model RMSE
Improvement over baseline

100K
0.997
0.871
12%

1M
1.002
0.847
15%

Does time depedent behaviour exist in the dataset?

This a fundamental question. Based on our experiements
we must remove “noisy behaviour” (see above), and consider
only users who have been engaged with the system for minum
period of time. This duration is application dependent and
could be measured in diﬀerent ways. For a movie system in
this project with timespan 200-1000 days (data set 100K and
1M) we observe that the threshold of 10 days is feasible.

Impact of model smoothing

When users jump from one experience level to the next, we
don’t expect too sudden change in their behaviour. Therefore
it is reasonalbe to smooth the model parameters:

• Θ=(µ + b_itemi + b_useru +qi ,pu) to keep the sum

Σe||Θe-Θe−1|| small .

This term is part of our error function describe in Section 3.
However, to see how much we have gained with smoothing we
also try to minimise

• Σe||Θe|| instead of Σe||Θe-Θe−1|| .

We observe that the smoothing gain in RMSE reduction is
2% (from 0.8871 down to 0.871 on Dataset 1) .

Beneﬁts of discovering user experiences

Instead of modelling user-experience and then using it to pre-
dict future user ratings, one can also just take the latest rat-
ings of each indivudual users and run a standard recommen-
dation on that ﬁltered data set. Which one has better pre-
diction power ? If all users have already reached the highest
experience level, then our user-experience model provide less
advantages. However, we expect that this is not the case in
typical systems.

Another beneﬁt is to identify a group of users who got stuck
in certain experience level for longer than average time. Do
they need special treatment ? Can they churn ? Or can
we help them to progress so othat they stay with us ? This
question leads to the next topic below.

4

References

[1] Y. Koren. Collaborative ﬁltering with temporal dynamics.
Commun. ACM , 2010

[2] Y. Koren and R. Bell. Advances in collaborative ﬁltering.
In Recommender Systems Handbook . Springer, 2011.

[3] From Amateurs to Connoisseurs: Modeling the Evolution
of User Expertise through Online Reviews by J. McAuley,
J. Leskovec. ACM International Conference on World Wide
Web (WWW), 2013.

[4] Finding Progression Stages in Time-evolving Event Se-
quences by J. Yang, J. McAuley, J. Leskovec, P. LePendu, N.
Shah. ACM International Conference on World Wide Web
(WWW), 2014.

5

