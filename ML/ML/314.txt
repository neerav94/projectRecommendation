P300-Speller Error Correction Using EEG Data

Felix Boyeaux

Nehan Chatoor

fboyeaux@stanford.edu

nchatoor@stanford.edu

Stanford University

Department of Computer Science

CS 229

1

Introduction

The P300-Speller is a non-intrusive BCI based on the con-

cept of electroencephalography (EEG), and consists of dis-

Brain-computer interfaces (BCI) seek to enable computers

playing 36 characters in a 6-by-6 matrix. When the subject

to predict what action a person wants to accomplish based

focuses on one of the characters in the grid, the electrodes

solely on his or her brain waves as he or she thinks about

placed of the patient’s scalp record the brain-wave patterns

the task at hand. If the computer can be trained to attain a

and recognizes which particular character the subject is try-

high degree of accuracy in such predictions, this technology

ing to choose.

can be applied to a variety of uses and will beneﬁt many, in-

cluding the disabled and speech-impaired by enabling them

to communicate without needing assistance. However, de-

riving information from brain wave data is quite challenging

due to the presence of considerable amount of noise, which

arises as the brain strives to support other functions of our

body in addition to thought. Thus, computers’ predictions

can be fairly erroneous in such interfaces. This paper seeks

to use machine learning algorithms to detect when a speciﬁc

BCI, the P300-Speller, erroneously predicts the next letter

in a word that the person is trying to spell. Being success-

ful in detecting erroneous predictions can in turn be used

to improve the performance of the speller by outputting the

second-best guess in case of error.

Figure 1: Sample EEG reading

1

Figure 2: P300 setup (courtesy of Brunner et al.)

2 Dataset

For the purposes of this paper, we drew inspiration and

obtained our dataset from the study conducted by Perrin et

al. (2012). Their study was comprised of 26 participants,

each of whom were asked to spell twelve ﬁve-letter words

in each of four sessions and twenty ﬁve-letter words in a

ﬁfth session. Each participant spelled a word by thinking

about a letter at a time while attached to scalp electrodes.

The electrical activity in the neurons generated by their

thoughts was captured by EEG, which were then analyzed

by the P300-Speller which then displayed a predicted letter

on the computer screen for 1.3 seconds.

P300-Speller Error Correction Using EEG Data

Felix Boyeaux

Nehan Chatoor

fboyeaux@stanford.edu

nchatoor@stanford.edu

Stanford University

Department of Computer Science

CS 229

1

Introduction

The P300-Speller is a non-intrusive BCI based on the con-

cept of electroencephalography (EEG), and consists of dis-

Brain-computer interfaces (BCI) seek to enable computers

playing 36 characters in a 6-by-6 matrix. When the subject

to predict what action a person wants to accomplish based

focuses on one of the characters in the grid, the electrodes

solely on his or her brain waves as he or she thinks about

placed of the patient’s scalp record the brain-wave patterns

the task at hand. If the computer can be trained to attain a

and recognizes which particular character the subject is try-

high degree of accuracy in such predictions, this technology

ing to choose.

can be applied to a variety of uses and will beneﬁt many, in-

cluding the disabled and speech-impaired by enabling them

to communicate without needing assistance. However, de-

riving information from brain wave data is quite challenging

due to the presence of considerable amount of noise, which

arises as the brain strives to support other functions of our

body in addition to thought. Thus, computers’ predictions

can be fairly erroneous in such interfaces. This paper seeks

to use machine learning algorithms to detect when a speciﬁc

BCI, the P300-Speller, erroneously predicts the next letter

in a word that the person is trying to spell. Being success-

ful in detecting erroneous predictions can in turn be used

to improve the performance of the speller by outputting the

second-best guess in case of error.

Figure 1: Sample EEG reading

1

Figure 2: P300 setup (courtesy of Brunner et al.)

2 Dataset

For the purposes of this paper, we drew inspiration and

obtained our dataset from the study conducted by Perrin et

al. (2012). Their study was comprised of 26 participants,

each of whom were asked to spell twelve ﬁve-letter words

in each of four sessions and twenty ﬁve-letter words in a

ﬁfth session. Each participant spelled a word by thinking

about a letter at a time while attached to scalp electrodes.

The electrical activity in the neurons generated by their

thoughts was captured by EEG, which were then analyzed

by the P300-Speller which then displayed a predicted letter

on the computer screen for 1.3 seconds.

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

Figure 3: Experimental setup

The data for each individual and each session originally

recorded the EEG data for each of the 57 electrodes at a

frequency of 600Hz. Additionally, the dataset included a

ﬂag for the beginning of each feedback event (displaying the

computer’s best guess). Finally, for each feedback event, the

dataset included an indicator variable of whether the com-

puter’s guess was correct or not. This allowed us to use the

tools of supervised earning when deriving our models.

soning behind this hypothesis is that the participant would

have a certain response to the accuracy or the inaccuracy of

the computer’s output, which will be reﬂected in the EEG

readings. At 200Hz, these 1.3 seconds resulted in 260 read-

ings per electrode, for each of the 57 electrodes, or 14,820

features for each of the 5440 feedback events in our training

set. Motivated by Onton and Makeig (2006), we preprocess

the data by running independent component analysis on the

EEG recordings in order to ﬁlter out blink and heartbeat

artifacts. Through ICA, we also hoped to isolated a few

sources that best predict errors of the speller. Moreover, to

reduce the dimensionality of the training set, we conducted

principal component analysis on both the data preprocessed

with ICA and the original data for comparison. We found

that in both cases, ﬁrst principal component explained up

to 90% of the total variance of the data.

Figure 5: Results of PCA for non-ICA data

For the sake of computational eﬃciency, we therefore based

our models on the the ﬁrst principal component of our data,

which allowed us to reduce the dimensionality of the features

Figure 4: EEG electrodes setup

from 14,820 to 260. Out of the 5540 observations, we with-

held 1632 (30% of observations) randomly selected training

examples for the purpose of hold-out cross-validation.

3 Features and Preprocessing

For the purposes of this paper, we used a dataset downsam-

4 Models

pled to 200Hz for computational tractability, and focused

In Perrin et al. (2012), the error detection function uses a

the analysis on the 1.3 seconds after the start of a feedback

Gaussian Discriminant Analysis (GDA) algorithm, which,

event, during which the P300 Speller displays its predic-

based on an area under the receiver operating character-

tion. We hypothesized that it is during this period that the

istic curve (AUROC) metric,

is not statistically signiﬁ-

relevant brain activity for error detection occurs. The rea-

cant from the trivial predictor which randomizes between

2 of 5

Comp.1Comp.3Comp.5Comp.7Comp.9pcaVariances010000002500000P300-Speller Error Correction Using EEG Data

Felix Boyeaux

Nehan Chatoor

fboyeaux@stanford.edu

nchatoor@stanford.edu

Stanford University

Department of Computer Science

CS 229

1

Introduction

The P300-Speller is a non-intrusive BCI based on the con-

cept of electroencephalography (EEG), and consists of dis-

Brain-computer interfaces (BCI) seek to enable computers

playing 36 characters in a 6-by-6 matrix. When the subject

to predict what action a person wants to accomplish based

focuses on one of the characters in the grid, the electrodes

solely on his or her brain waves as he or she thinks about

placed of the patient’s scalp record the brain-wave patterns

the task at hand. If the computer can be trained to attain a

and recognizes which particular character the subject is try-

high degree of accuracy in such predictions, this technology

ing to choose.

can be applied to a variety of uses and will beneﬁt many, in-

cluding the disabled and speech-impaired by enabling them

to communicate without needing assistance. However, de-

riving information from brain wave data is quite challenging

due to the presence of considerable amount of noise, which

arises as the brain strives to support other functions of our

body in addition to thought. Thus, computers’ predictions

can be fairly erroneous in such interfaces. This paper seeks

to use machine learning algorithms to detect when a speciﬁc

BCI, the P300-Speller, erroneously predicts the next letter

in a word that the person is trying to spell. Being success-

ful in detecting erroneous predictions can in turn be used

to improve the performance of the speller by outputting the

second-best guess in case of error.

Figure 1: Sample EEG reading

1

Figure 2: P300 setup (courtesy of Brunner et al.)

2 Dataset

For the purposes of this paper, we drew inspiration and

obtained our dataset from the study conducted by Perrin et

al. (2012). Their study was comprised of 26 participants,

each of whom were asked to spell twelve ﬁve-letter words

in each of four sessions and twenty ﬁve-letter words in a

ﬁfth session. Each participant spelled a word by thinking

about a letter at a time while attached to scalp electrodes.

The electrical activity in the neurons generated by their

thoughts was captured by EEG, which were then analyzed

by the P300-Speller which then displayed a predicted letter

on the computer screen for 1.3 seconds.

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

Figure 3: Experimental setup

The data for each individual and each session originally

recorded the EEG data for each of the 57 electrodes at a

frequency of 600Hz. Additionally, the dataset included a

ﬂag for the beginning of each feedback event (displaying the

computer’s best guess). Finally, for each feedback event, the

dataset included an indicator variable of whether the com-

puter’s guess was correct or not. This allowed us to use the

tools of supervised earning when deriving our models.

soning behind this hypothesis is that the participant would

have a certain response to the accuracy or the inaccuracy of

the computer’s output, which will be reﬂected in the EEG

readings. At 200Hz, these 1.3 seconds resulted in 260 read-

ings per electrode, for each of the 57 electrodes, or 14,820

features for each of the 5440 feedback events in our training

set. Motivated by Onton and Makeig (2006), we preprocess

the data by running independent component analysis on the

EEG recordings in order to ﬁlter out blink and heartbeat

artifacts. Through ICA, we also hoped to isolated a few

sources that best predict errors of the speller. Moreover, to

reduce the dimensionality of the training set, we conducted

principal component analysis on both the data preprocessed

with ICA and the original data for comparison. We found

that in both cases, ﬁrst principal component explained up

to 90% of the total variance of the data.

Figure 5: Results of PCA for non-ICA data

For the sake of computational eﬃciency, we therefore based

our models on the the ﬁrst principal component of our data,

which allowed us to reduce the dimensionality of the features

Figure 4: EEG electrodes setup

from 14,820 to 260. Out of the 5540 observations, we with-

held 1632 (30% of observations) randomly selected training

examples for the purpose of hold-out cross-validation.

3 Features and Preprocessing

For the purposes of this paper, we used a dataset downsam-

4 Models

pled to 200Hz for computational tractability, and focused

In Perrin et al. (2012), the error detection function uses a

the analysis on the 1.3 seconds after the start of a feedback

Gaussian Discriminant Analysis (GDA) algorithm, which,

event, during which the P300 Speller displays its predic-

based on an area under the receiver operating character-

tion. We hypothesized that it is during this period that the

istic curve (AUROC) metric,

is not statistically signiﬁ-

relevant brain activity for error detection occurs. The rea-

cant from the trivial predictor which randomizes between

2 of 5

Comp.1Comp.3Comp.5Comp.7Comp.9pcaVariances010000002500000Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

the two classes with probability 1/2. We similarly imple-

performance. In our algorithm, we use a cost C = 1, and a

ment GDA for the purpose of having a benchmark pre-

Gaussian kernel, which achieved consistently better perfor-

dictor with which to compare our algorithms. This clas-

mance than a linear kernel.

siﬁer predicts an error (y = 1) if the posterior probability
p(y = 1 | x) ≥ 0.5, where x is the training set, and assum-
ing the priors y ∼ Bernouilli(φ), x | y = 0 ∼ N (µ0, Σ) and
x | y = 1 ∼ N (µ1, Σ). We estimate the parameters φ, µ0, µ1
and Σ using Maximum Likelihood Estimation.

To improve on the GDA benchmark, we implement three

state-of-the-art machine learning classiﬁcation algorithms:

support vector machines (SVM), random forests (RF) and

gradient boosting machines (GBM). The latter two both

use a decision tree as the base learner and are examples of

4.2 Random forests

On a high level, random forests, as developed in Breiman

(2001), grow a multitude of classiﬁcation trees. To classify

a new object for a feature vector, each tree in the forest

classiﬁes the object, and the the classiﬁcation with most

votes is the classiﬁcation chosen by the forest.

Random forests are based on the concept of bootstrap

ensemble methods, which have shown considerable perfor-

aggregating (bagging). To predict the class of a new input,

mance in the classiﬁcation for EEG-based brain-computer

one selects B bootstrap samples from the training set, and

interfaces, since they can consistently provide higher accu-

for each bootstrap sample generate a decision tree. At

racy results compared to conventional single strong machine

each split in the tree,

p features out of the p features in

√

learning models (Lotte et al., 2007). All three algorithms are

the training set are chosen to form the basis of the split.

trained on both the ﬁrst principal component of the ICA-

Randomly choosing features in such a way decreases the

preprocessed and of the non-preprocessed data to compare

correlation between each tree and therefore makes random

performance.

4.1 Support vector machines

Support vector machines are considered among the best oﬀ-

the-shelf learning algorithms given their ability to map data

to inﬁnite-dimensional feature space using kernel methods.

Intuitively, SVMs aim to ﬁnd the best separating hyper-

plane to the data projected in high-dimensional space, which

yields a highly non-linear decision boundary in the original
feature space. Given a classiﬁer hw,b(x) = g(wT x+b), where
g(z) = 1 if z ≥ 0 and -1 otherwise, the SVM algorithm ﬁnds
the optimal decision boundary by maximizing the margins

and imposing a cost on every misclassiﬁed training example

(using (cid:96)1 regularization).

m(cid:88)

min
γ,w,b

s.t.

ξi

(cid:107)w(cid:107)2 + C

1
2
y(i)(wT x(i) + b) ≥ 1 − ξi,
ξi ≥ 0,

i = 1, . . . , m

i=1

forests less prone to overﬁtting and high variance problems.

For this particular problem, we choose B = 500 since

improvements were only marginal past that point. Below

is the a description of the random forest algorithm.

Algorithm 1: Random forest classiﬁcation
Data: n observed data points {(x(i), y(i))}
Input: Number of bootstrap samples B, number of

features p

Result: Predicted classiﬁcation ˆy for x

*/

/* Main bagging training loop
for b ∈ {1, . . . , B} do

(Xb, Yb) ← bootstrap sample of n training examples
from {(x(i), y(i))};
fb ← decision tree trained on (Xb, Yb) using
randomly selected features at each split;

√

p

i = 1, . . . , m

end

(cid:80)B

/* Prediction
return ˆy ← 1

B

b=1

In practice, the optimization problem above is solved by

Lagrange duality and applies the kernel method for better

ˆfb(x);

*/

3 of 5

P300-Speller Error Correction Using EEG Data

Felix Boyeaux

Nehan Chatoor

fboyeaux@stanford.edu

nchatoor@stanford.edu

Stanford University

Department of Computer Science

CS 229

1

Introduction

The P300-Speller is a non-intrusive BCI based on the con-

cept of electroencephalography (EEG), and consists of dis-

Brain-computer interfaces (BCI) seek to enable computers

playing 36 characters in a 6-by-6 matrix. When the subject

to predict what action a person wants to accomplish based

focuses on one of the characters in the grid, the electrodes

solely on his or her brain waves as he or she thinks about

placed of the patient’s scalp record the brain-wave patterns

the task at hand. If the computer can be trained to attain a

and recognizes which particular character the subject is try-

high degree of accuracy in such predictions, this technology

ing to choose.

can be applied to a variety of uses and will beneﬁt many, in-

cluding the disabled and speech-impaired by enabling them

to communicate without needing assistance. However, de-

riving information from brain wave data is quite challenging

due to the presence of considerable amount of noise, which

arises as the brain strives to support other functions of our

body in addition to thought. Thus, computers’ predictions

can be fairly erroneous in such interfaces. This paper seeks

to use machine learning algorithms to detect when a speciﬁc

BCI, the P300-Speller, erroneously predicts the next letter

in a word that the person is trying to spell. Being success-

ful in detecting erroneous predictions can in turn be used

to improve the performance of the speller by outputting the

second-best guess in case of error.

Figure 1: Sample EEG reading

1

Figure 2: P300 setup (courtesy of Brunner et al.)

2 Dataset

For the purposes of this paper, we drew inspiration and

obtained our dataset from the study conducted by Perrin et

al. (2012). Their study was comprised of 26 participants,

each of whom were asked to spell twelve ﬁve-letter words

in each of four sessions and twenty ﬁve-letter words in a

ﬁfth session. Each participant spelled a word by thinking

about a letter at a time while attached to scalp electrodes.

The electrical activity in the neurons generated by their

thoughts was captured by EEG, which were then analyzed

by the P300-Speller which then displayed a predicted letter

on the computer screen for 1.3 seconds.

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

Figure 3: Experimental setup

The data for each individual and each session originally

recorded the EEG data for each of the 57 electrodes at a

frequency of 600Hz. Additionally, the dataset included a

ﬂag for the beginning of each feedback event (displaying the

computer’s best guess). Finally, for each feedback event, the

dataset included an indicator variable of whether the com-

puter’s guess was correct or not. This allowed us to use the

tools of supervised earning when deriving our models.

soning behind this hypothesis is that the participant would

have a certain response to the accuracy or the inaccuracy of

the computer’s output, which will be reﬂected in the EEG

readings. At 200Hz, these 1.3 seconds resulted in 260 read-

ings per electrode, for each of the 57 electrodes, or 14,820

features for each of the 5440 feedback events in our training

set. Motivated by Onton and Makeig (2006), we preprocess

the data by running independent component analysis on the

EEG recordings in order to ﬁlter out blink and heartbeat

artifacts. Through ICA, we also hoped to isolated a few

sources that best predict errors of the speller. Moreover, to

reduce the dimensionality of the training set, we conducted

principal component analysis on both the data preprocessed

with ICA and the original data for comparison. We found

that in both cases, ﬁrst principal component explained up

to 90% of the total variance of the data.

Figure 5: Results of PCA for non-ICA data

For the sake of computational eﬃciency, we therefore based

our models on the the ﬁrst principal component of our data,

which allowed us to reduce the dimensionality of the features

Figure 4: EEG electrodes setup

from 14,820 to 260. Out of the 5540 observations, we with-

held 1632 (30% of observations) randomly selected training

examples for the purpose of hold-out cross-validation.

3 Features and Preprocessing

For the purposes of this paper, we used a dataset downsam-

4 Models

pled to 200Hz for computational tractability, and focused

In Perrin et al. (2012), the error detection function uses a

the analysis on the 1.3 seconds after the start of a feedback

Gaussian Discriminant Analysis (GDA) algorithm, which,

event, during which the P300 Speller displays its predic-

based on an area under the receiver operating character-

tion. We hypothesized that it is during this period that the

istic curve (AUROC) metric,

is not statistically signiﬁ-

relevant brain activity for error detection occurs. The rea-

cant from the trivial predictor which randomizes between

2 of 5

Comp.1Comp.3Comp.5Comp.7Comp.9pcaVariances010000002500000Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

the two classes with probability 1/2. We similarly imple-

performance. In our algorithm, we use a cost C = 1, and a

ment GDA for the purpose of having a benchmark pre-

Gaussian kernel, which achieved consistently better perfor-

dictor with which to compare our algorithms. This clas-

mance than a linear kernel.

siﬁer predicts an error (y = 1) if the posterior probability
p(y = 1 | x) ≥ 0.5, where x is the training set, and assum-
ing the priors y ∼ Bernouilli(φ), x | y = 0 ∼ N (µ0, Σ) and
x | y = 1 ∼ N (µ1, Σ). We estimate the parameters φ, µ0, µ1
and Σ using Maximum Likelihood Estimation.

To improve on the GDA benchmark, we implement three

state-of-the-art machine learning classiﬁcation algorithms:

support vector machines (SVM), random forests (RF) and

gradient boosting machines (GBM). The latter two both

use a decision tree as the base learner and are examples of

4.2 Random forests

On a high level, random forests, as developed in Breiman

(2001), grow a multitude of classiﬁcation trees. To classify

a new object for a feature vector, each tree in the forest

classiﬁes the object, and the the classiﬁcation with most

votes is the classiﬁcation chosen by the forest.

Random forests are based on the concept of bootstrap

ensemble methods, which have shown considerable perfor-

aggregating (bagging). To predict the class of a new input,

mance in the classiﬁcation for EEG-based brain-computer

one selects B bootstrap samples from the training set, and

interfaces, since they can consistently provide higher accu-

for each bootstrap sample generate a decision tree. At

racy results compared to conventional single strong machine

each split in the tree,

p features out of the p features in

√

learning models (Lotte et al., 2007). All three algorithms are

the training set are chosen to form the basis of the split.

trained on both the ﬁrst principal component of the ICA-

Randomly choosing features in such a way decreases the

preprocessed and of the non-preprocessed data to compare

correlation between each tree and therefore makes random

performance.

4.1 Support vector machines

Support vector machines are considered among the best oﬀ-

the-shelf learning algorithms given their ability to map data

to inﬁnite-dimensional feature space using kernel methods.

Intuitively, SVMs aim to ﬁnd the best separating hyper-

plane to the data projected in high-dimensional space, which

yields a highly non-linear decision boundary in the original
feature space. Given a classiﬁer hw,b(x) = g(wT x+b), where
g(z) = 1 if z ≥ 0 and -1 otherwise, the SVM algorithm ﬁnds
the optimal decision boundary by maximizing the margins

and imposing a cost on every misclassiﬁed training example

(using (cid:96)1 regularization).

m(cid:88)

min
γ,w,b

s.t.

ξi

(cid:107)w(cid:107)2 + C

1
2
y(i)(wT x(i) + b) ≥ 1 − ξi,
ξi ≥ 0,

i = 1, . . . , m

i=1

forests less prone to overﬁtting and high variance problems.

For this particular problem, we choose B = 500 since

improvements were only marginal past that point. Below

is the a description of the random forest algorithm.

Algorithm 1: Random forest classiﬁcation
Data: n observed data points {(x(i), y(i))}
Input: Number of bootstrap samples B, number of

features p

Result: Predicted classiﬁcation ˆy for x

*/

/* Main bagging training loop
for b ∈ {1, . . . , B} do

(Xb, Yb) ← bootstrap sample of n training examples
from {(x(i), y(i))};
fb ← decision tree trained on (Xb, Yb) using
randomly selected features at each split;

√

p

i = 1, . . . , m

end

(cid:80)B

/* Prediction
return ˆy ← 1

B

b=1

In practice, the optimization problem above is solved by

Lagrange duality and applies the kernel method for better

ˆfb(x);

*/

3 of 5

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

4.3 Gradient boosting machines

training set. The p-value reported below is the p-value test-

Friedman (2001) considers the problem of estimating the
f(cid:55)→ y such that some speciﬁed loss

functional dependence x

function Ψ(y, f ) is minimized:

ing the null hypothesis that the predictor is not diﬀerent

from the trivial predictor that outputs one label 50% of the

time and has AUROC = 0.5. This statistic is based on the

Wilcoxon test.

ˆf (x) = arg min

Ψ(y, f (x))

f (x)

(cid:80)M

i=1

Suppose we parametrize the function estimate ˆf (x) =
ˆfi(x), where each ˆfi is called a boost, we can for-
mulate a greedy stagewise approach that at each itera-
tion estimates ˆft ← ˆft−1 + ρth(x, θt) where h(x, θ) is
the base learner (here a decision tree), and (ρt, θt) =
i=1 Ψ(y(i), ˆft−1) + ρh(x(i), θ). While this opti-
arg minρ,θ
mization problem is hard for general loss function and base

(cid:80)N

learners, Friedman suggest using a new function h(x, θt) to
be the most parallel to the negative gradient along the ob-

served data, whereby the optimization task becomes a clas-

sic least-square minimization.

Algorithm 2: Gradient boosting algorithm
Data: n observed data points {(x(i), y(i))}
Input: Number of iterations M , loss function Ψ(y, f )

and base-learner model h(x, θ)
Result: Predicted classiﬁer ˆf (x) for x

Initialize ˆf0 with a constant;
for t ∈ {1, . . . , M} do

Method

AUROC p-value

Gaussian discriminant analysis

with ICA

Support vector machines

with ICA

Random forests

with ICA

Gradient boosting machines

with ICA

0.512

0.573

0.543

0.633

0.546

0.788

0.542

0.717

0.215

0.001

0.003

0.000

0.002

0.000

0.004

0.000

Table 1: Summary of testing results

As we see from the result, even though the learning algo-

rithms based of a non-ICA-preprocessed sample are statisti-

cally diﬀerent from a useless predictor, the margin by which

they improve the baseline GDA algorithm is very small, on

the order of 3 percentage points.

Compute the negative gradient gt(x);
Fit a new base-learner function h(x, θt);
Find the best gradient descent step-size ρt:

ρt = arg min

ρ

Ψ[y(i), ˆft=1(x(i)) + ρh(x(i), θt)]

N(cid:88)

i=1

Update the function estimate ˆft ← ˆft−1 + ρth(x, θt);

end
return ˆf ← ˆfM ;

5 Results

Figure 6: ROC curves for non-preprocessed data

In contrast, the ICA-preprocessed data signiﬁcantly im-

proves each algorithm. The best performance is from the

ICA-preprocessed random forest algorithm with an area un-

der the ROC curve of 0.79. This indicated that the proba-

bility that a classiﬁer will rank a randomly chosen positive

The results reported here are based oﬀ the cross-validation

instance (error) higher than a randomly chosen negative one

sample of 1632 observations that were omitted from the

(correct guess) is 0.79.

4 of 5

Receiving operating characteristic curvesFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0AlgorithmSVMRFGBMGDAP300-Speller Error Correction Using EEG Data

Felix Boyeaux

Nehan Chatoor

fboyeaux@stanford.edu

nchatoor@stanford.edu

Stanford University

Department of Computer Science

CS 229

1

Introduction

The P300-Speller is a non-intrusive BCI based on the con-

cept of electroencephalography (EEG), and consists of dis-

Brain-computer interfaces (BCI) seek to enable computers

playing 36 characters in a 6-by-6 matrix. When the subject

to predict what action a person wants to accomplish based

focuses on one of the characters in the grid, the electrodes

solely on his or her brain waves as he or she thinks about

placed of the patient’s scalp record the brain-wave patterns

the task at hand. If the computer can be trained to attain a

and recognizes which particular character the subject is try-

high degree of accuracy in such predictions, this technology

ing to choose.

can be applied to a variety of uses and will beneﬁt many, in-

cluding the disabled and speech-impaired by enabling them

to communicate without needing assistance. However, de-

riving information from brain wave data is quite challenging

due to the presence of considerable amount of noise, which

arises as the brain strives to support other functions of our

body in addition to thought. Thus, computers’ predictions

can be fairly erroneous in such interfaces. This paper seeks

to use machine learning algorithms to detect when a speciﬁc

BCI, the P300-Speller, erroneously predicts the next letter

in a word that the person is trying to spell. Being success-

ful in detecting erroneous predictions can in turn be used

to improve the performance of the speller by outputting the

second-best guess in case of error.

Figure 1: Sample EEG reading

1

Figure 2: P300 setup (courtesy of Brunner et al.)

2 Dataset

For the purposes of this paper, we drew inspiration and

obtained our dataset from the study conducted by Perrin et

al. (2012). Their study was comprised of 26 participants,

each of whom were asked to spell twelve ﬁve-letter words

in each of four sessions and twenty ﬁve-letter words in a

ﬁfth session. Each participant spelled a word by thinking

about a letter at a time while attached to scalp electrodes.

The electrical activity in the neurons generated by their

thoughts was captured by EEG, which were then analyzed

by the P300-Speller which then displayed a predicted letter

on the computer screen for 1.3 seconds.

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

Figure 3: Experimental setup

The data for each individual and each session originally

recorded the EEG data for each of the 57 electrodes at a

frequency of 600Hz. Additionally, the dataset included a

ﬂag for the beginning of each feedback event (displaying the

computer’s best guess). Finally, for each feedback event, the

dataset included an indicator variable of whether the com-

puter’s guess was correct or not. This allowed us to use the

tools of supervised earning when deriving our models.

soning behind this hypothesis is that the participant would

have a certain response to the accuracy or the inaccuracy of

the computer’s output, which will be reﬂected in the EEG

readings. At 200Hz, these 1.3 seconds resulted in 260 read-

ings per electrode, for each of the 57 electrodes, or 14,820

features for each of the 5440 feedback events in our training

set. Motivated by Onton and Makeig (2006), we preprocess

the data by running independent component analysis on the

EEG recordings in order to ﬁlter out blink and heartbeat

artifacts. Through ICA, we also hoped to isolated a few

sources that best predict errors of the speller. Moreover, to

reduce the dimensionality of the training set, we conducted

principal component analysis on both the data preprocessed

with ICA and the original data for comparison. We found

that in both cases, ﬁrst principal component explained up

to 90% of the total variance of the data.

Figure 5: Results of PCA for non-ICA data

For the sake of computational eﬃciency, we therefore based

our models on the the ﬁrst principal component of our data,

which allowed us to reduce the dimensionality of the features

Figure 4: EEG electrodes setup

from 14,820 to 260. Out of the 5540 observations, we with-

held 1632 (30% of observations) randomly selected training

examples for the purpose of hold-out cross-validation.

3 Features and Preprocessing

For the purposes of this paper, we used a dataset downsam-

4 Models

pled to 200Hz for computational tractability, and focused

In Perrin et al. (2012), the error detection function uses a

the analysis on the 1.3 seconds after the start of a feedback

Gaussian Discriminant Analysis (GDA) algorithm, which,

event, during which the P300 Speller displays its predic-

based on an area under the receiver operating character-

tion. We hypothesized that it is during this period that the

istic curve (AUROC) metric,

is not statistically signiﬁ-

relevant brain activity for error detection occurs. The rea-

cant from the trivial predictor which randomizes between

2 of 5

Comp.1Comp.3Comp.5Comp.7Comp.9pcaVariances010000002500000Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

the two classes with probability 1/2. We similarly imple-

performance. In our algorithm, we use a cost C = 1, and a

ment GDA for the purpose of having a benchmark pre-

Gaussian kernel, which achieved consistently better perfor-

dictor with which to compare our algorithms. This clas-

mance than a linear kernel.

siﬁer predicts an error (y = 1) if the posterior probability
p(y = 1 | x) ≥ 0.5, where x is the training set, and assum-
ing the priors y ∼ Bernouilli(φ), x | y = 0 ∼ N (µ0, Σ) and
x | y = 1 ∼ N (µ1, Σ). We estimate the parameters φ, µ0, µ1
and Σ using Maximum Likelihood Estimation.

To improve on the GDA benchmark, we implement three

state-of-the-art machine learning classiﬁcation algorithms:

support vector machines (SVM), random forests (RF) and

gradient boosting machines (GBM). The latter two both

use a decision tree as the base learner and are examples of

4.2 Random forests

On a high level, random forests, as developed in Breiman

(2001), grow a multitude of classiﬁcation trees. To classify

a new object for a feature vector, each tree in the forest

classiﬁes the object, and the the classiﬁcation with most

votes is the classiﬁcation chosen by the forest.

Random forests are based on the concept of bootstrap

ensemble methods, which have shown considerable perfor-

aggregating (bagging). To predict the class of a new input,

mance in the classiﬁcation for EEG-based brain-computer

one selects B bootstrap samples from the training set, and

interfaces, since they can consistently provide higher accu-

for each bootstrap sample generate a decision tree. At

racy results compared to conventional single strong machine

each split in the tree,

p features out of the p features in

√

learning models (Lotte et al., 2007). All three algorithms are

the training set are chosen to form the basis of the split.

trained on both the ﬁrst principal component of the ICA-

Randomly choosing features in such a way decreases the

preprocessed and of the non-preprocessed data to compare

correlation between each tree and therefore makes random

performance.

4.1 Support vector machines

Support vector machines are considered among the best oﬀ-

the-shelf learning algorithms given their ability to map data

to inﬁnite-dimensional feature space using kernel methods.

Intuitively, SVMs aim to ﬁnd the best separating hyper-

plane to the data projected in high-dimensional space, which

yields a highly non-linear decision boundary in the original
feature space. Given a classiﬁer hw,b(x) = g(wT x+b), where
g(z) = 1 if z ≥ 0 and -1 otherwise, the SVM algorithm ﬁnds
the optimal decision boundary by maximizing the margins

and imposing a cost on every misclassiﬁed training example

(using (cid:96)1 regularization).

m(cid:88)

min
γ,w,b

s.t.

ξi

(cid:107)w(cid:107)2 + C

1
2
y(i)(wT x(i) + b) ≥ 1 − ξi,
ξi ≥ 0,

i = 1, . . . , m

i=1

forests less prone to overﬁtting and high variance problems.

For this particular problem, we choose B = 500 since

improvements were only marginal past that point. Below

is the a description of the random forest algorithm.

Algorithm 1: Random forest classiﬁcation
Data: n observed data points {(x(i), y(i))}
Input: Number of bootstrap samples B, number of

features p

Result: Predicted classiﬁcation ˆy for x

*/

/* Main bagging training loop
for b ∈ {1, . . . , B} do

(Xb, Yb) ← bootstrap sample of n training examples
from {(x(i), y(i))};
fb ← decision tree trained on (Xb, Yb) using
randomly selected features at each split;

√

p

i = 1, . . . , m

end

(cid:80)B

/* Prediction
return ˆy ← 1

B

b=1

In practice, the optimization problem above is solved by

Lagrange duality and applies the kernel method for better

ˆfb(x);

*/

3 of 5

Boyeaux, Chatoor

P300-Speller Error Correction Using EEG Data

4.3 Gradient boosting machines

training set. The p-value reported below is the p-value test-

Friedman (2001) considers the problem of estimating the
f(cid:55)→ y such that some speciﬁed loss

functional dependence x

function Ψ(y, f ) is minimized:

ing the null hypothesis that the predictor is not diﬀerent

from the trivial predictor that outputs one label 50% of the

time and has AUROC = 0.5. This statistic is based on the

Wilcoxon test.

ˆf (x) = arg min

Ψ(y, f (x))

f (x)

(cid:80)M

i=1

Suppose we parametrize the function estimate ˆf (x) =
ˆfi(x), where each ˆfi is called a boost, we can for-
mulate a greedy stagewise approach that at each itera-
tion estimates ˆft ← ˆft−1 + ρth(x, θt) where h(x, θ) is
the base learner (here a decision tree), and (ρt, θt) =
i=1 Ψ(y(i), ˆft−1) + ρh(x(i), θ). While this opti-
arg minρ,θ
mization problem is hard for general loss function and base

(cid:80)N

learners, Friedman suggest using a new function h(x, θt) to
be the most parallel to the negative gradient along the ob-

served data, whereby the optimization task becomes a clas-

sic least-square minimization.

Algorithm 2: Gradient boosting algorithm
Data: n observed data points {(x(i), y(i))}
Input: Number of iterations M , loss function Ψ(y, f )

and base-learner model h(x, θ)
Result: Predicted classiﬁer ˆf (x) for x

Initialize ˆf0 with a constant;
for t ∈ {1, . . . , M} do

Method

AUROC p-value

Gaussian discriminant analysis

with ICA

Support vector machines

with ICA

Random forests

with ICA

Gradient boosting machines

with ICA

0.512

0.573

0.543

0.633

0.546

0.788

0.542

0.717

0.215

0.001

0.003

0.000

0.002

0.000

0.004

0.000

Table 1: Summary of testing results

As we see from the result, even though the learning algo-

rithms based of a non-ICA-preprocessed sample are statisti-

cally diﬀerent from a useless predictor, the margin by which

they improve the baseline GDA algorithm is very small, on

the order of 3 percentage points.

Compute the negative gradient gt(x);
Fit a new base-learner function h(x, θt);
Find the best gradient descent step-size ρt:

ρt = arg min

ρ

Ψ[y(i), ˆft=1(x(i)) + ρh(x(i), θt)]

N(cid:88)

i=1

Update the function estimate ˆft ← ˆft−1 + ρth(x, θt);

end
return ˆf ← ˆfM ;

5 Results

Figure 6: ROC curves for non-preprocessed data

In contrast, the ICA-preprocessed data signiﬁcantly im-

proves each algorithm. The best performance is from the

ICA-preprocessed random forest algorithm with an area un-

der the ROC curve of 0.79. This indicated that the proba-

bility that a classiﬁer will rank a randomly chosen positive

The results reported here are based oﬀ the cross-validation

instance (error) higher than a randomly chosen negative one

sample of 1632 observations that were omitted from the

(correct guess) is 0.79.

4 of 5

Receiving operating characteristic curvesFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0AlgorithmSVMRFGBMGDAP300-Speller Error Correction Using EEG Data

References

[1] Breiman, L (2001). Random Forests. Machine Learning

45 (1): 5-32.

[2] Perrin, M, et al. (2012). Objective and Subjective

Evaluation of Online Error Correction during P300-

Based Spelling. Advances in Human-Computer Inter-

action 2012 (2012).

[3] Onton, J. and Makeig, S. (2006). Information-based

modeling of event-related brain dynamics. Progress in

Brain Research 159 (2006): 99 - 120.

[4] Lotte, F., et al. (2007). A review of classiﬁcation algo-

rithms for EEG-based brain-computer interfaces. Jour-

nal of Neural Engineering 1 (13): 1-24

[5] Friedman, J.H. (2001). Greedy Function Approxima-

tion: A Gradient Boosting Machine. The Annals of

Statistics 29 (5): 1189-1232

[6] Natekin, A. and Knoll, A. (2013). Gradient Boosting

Machines, A tutorial. Frontiers in Neurorobotics 7 (21)

[7] Miltner, B. and Coles, M. (1997). Event-related brain

potentials following incorrect feedback in a time-

estimation task: evidence for a “generic” neural system

for error detection. Journal of Cognitive Neuroscience

9(6): 788-798

Boyeaux, Chatoor

6 Future

This paper oﬀers a glimpse at the quality of error correction

that can be achieved using EEG data. We suppose that one

of the main reasons random forests performed particularly

well is because of their tendency to avoid overﬁtting. Given

the high-dimensional feature space, we suspect that both

SVM and GBM suﬀer from a high variance problem. How-

ever, more careful analysis of the results would need to be

performed in the future to conﬁrm this. Should it be true,

more eﬀort should be spent on careful feature selection in

order to avoid such problems. Preprocessing the data using

ICA allows us to isolate independent sources from the EEG

data, each one related to a speciﬁc function of the brain

which in turn helps us to ﬁlter out artifacts, and also to use

the most relevant sources in our prediction. Using this, we

therefore suggest exploring using features other than just

the ﬁrst principal component. We would like to isolate the

most important features and base a classiﬁer on those, and

would also consider adding more principal components in

order to capture more variance in the data.

7 Conclusions

To conclude, despite limited computing power available

and the necessity to use principal components analysis for

dimension-reduction in order to have a tractable problem,

the algorithms presented here, especially random forests

trained on data that had previously been unmixed using

independent component analysis, perform well on detect-

ing errors made by the P300-Speller. Therefore, while

the spelling accuracy is fairly poor due to the noisy na-

ture of electroencephalography data, implementing an error-

detecting algorithm such as the one described in this pa-

per, coupled with an error-correction algorithm that cor-

rects a prediction identiﬁed as wrong to the second-best

guess, could dramatically improve the performance of such

a speller. This leaves us conﬁdent that it is possible to

facilitate communication for people suﬀering from speech-

impairment by increasing the rate at which they can form

words correctly.

5 of 5

