What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

tage of this method as opposed to taking screenshots of the
actual movie stream is that the preview window does not re-
quire any buffering time. At the same time, this approach
restricted the data sample rate to one sample per 10 seconds.
The color data that is sampled for each preview frame is the
mean pixel red, green, blue (RGB) values of all the pixels
in the preview frame.

We chose mean color as opposed to other statistical mea-
sures because the Netﬂix preview window pixels are already
down-sampled mean colors of pixels from the actual movie
frame. The resulting ”Color Barcode” feature captured is
similar to the data presented in the Colors of Motion Visu-
alizations [1]. The color barcode is represented as:

r1

g1
b1



r2
g2
b2

...
...
...

ri
gi
bi

...
...
...

rn
gn
bn

Where {ri, gi, bi} are the mean red, green and blue pixel
values of the frame captured at the 10 × ith second, n is
the total number of frames captured for the movie, and 0 ≤
ri, gi, bi ≤ 255. That is,

x=1

m(cid:88)
m(cid:88)
m(cid:88)

x=1

y=1

n(cid:88)
n(cid:88)
n(cid:88)

y=1

x=1

y=1

ri(x,y)

gi(x,y)

bi(x,y)

ri =

1

m × n

gi =

1

m × n

bi =

1

m × n

4. Methods
4.1. Support Vector Machine (SVM)

One of the main algorithms that we use to classify the
movies into genres is the SVM. The SVM is an algorithm
that ﬁnds the optimal decision boundary to separate the data
into two partitions based on its labels. That is, it ﬁnds the
line that maximizes the distance to the points closest to the
boundary(these closest points are called support vectors),
while trying to match the labels of the data points. Mathe-
matically, this can be expressed as:

m(cid:88)

ξi

min
γ,w,b

1
2

||w||2+C

y(i)(cid:16)

s.t.

wT x(i) + b

i=1

(cid:17) ≥ 1 − ξi, i = 1, ..., m

ξi ≥ 0, i = 1, ..., m

In the equation above, the parameter C balances the
two objectives of increasing distance between the decision
boundary and the support vectors, and correctly labeling the
points.

Solving the optimization problem above is difﬁcult, and
it is easier to solve the Lagrangian dual optimization prob-
lem below:

m(cid:88)

i=1

αi − 1
2

m(cid:88)

i,j=1

max

α

W (α) =

y(i)y(j)αiαj(cid:104)x(i), x(j)(cid:105)

Where m × n is the resolution of the preview frame and
{ri(x,y), gi(x,y), bi(x,y)} is the pixel color at pixel coordinate
(x,y) of the preview frame.

s.t. 0 ≤ αi ≤ C, i = 1, ..., m

m(cid:88)

αiy(i) = 0

Our data collection process is outlined in Figure 1 below.

i=1

One of the distinct advantages of the SVM is the option
to use kernels to map the feature vector to a higher dimen-
sion space, which has the potential to separate data that falls
along curved decision boundaries.

To classify between multiple classes, we used the Win-
ner Takes All (WTA) SVM method as described and empir-
ically supported in papers by Duan and Rifkin [6, 8]. That
is, we trained multiple 1-vs-all SVMs, and then to deter-
mine the label of an unlabeled test example, we pass the
unlabeled test example to each of the SVM models, and ob-
tain the score corresponding to each model. This score is the
signed distance from the data point to the decision bound-
ary, hence a large positive score signify that the data point is
both a positive example, and is far from the decision bound-
ary. Therefore to assign a test example to the most probable
class, we label that test example with the label of the model
that had the largest score.

Figure 1. Data Collection process

We collected the color barcode data from 140 movies
from each of the following genres: horror, animation, ro-
mance and action, making a total of 560 data points.

2

What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

tage of this method as opposed to taking screenshots of the
actual movie stream is that the preview window does not re-
quire any buffering time. At the same time, this approach
restricted the data sample rate to one sample per 10 seconds.
The color data that is sampled for each preview frame is the
mean pixel red, green, blue (RGB) values of all the pixels
in the preview frame.

We chose mean color as opposed to other statistical mea-
sures because the Netﬂix preview window pixels are already
down-sampled mean colors of pixels from the actual movie
frame. The resulting ”Color Barcode” feature captured is
similar to the data presented in the Colors of Motion Visu-
alizations [1]. The color barcode is represented as:

r1

g1
b1



r2
g2
b2

...
...
...

ri
gi
bi

...
...
...

rn
gn
bn

Where {ri, gi, bi} are the mean red, green and blue pixel
values of the frame captured at the 10 × ith second, n is
the total number of frames captured for the movie, and 0 ≤
ri, gi, bi ≤ 255. That is,

x=1

m(cid:88)
m(cid:88)
m(cid:88)

x=1

y=1

n(cid:88)
n(cid:88)
n(cid:88)

y=1

x=1

y=1

ri(x,y)

gi(x,y)

bi(x,y)

ri =

1

m × n

gi =

1

m × n

bi =

1

m × n

4. Methods
4.1. Support Vector Machine (SVM)

One of the main algorithms that we use to classify the
movies into genres is the SVM. The SVM is an algorithm
that ﬁnds the optimal decision boundary to separate the data
into two partitions based on its labels. That is, it ﬁnds the
line that maximizes the distance to the points closest to the
boundary(these closest points are called support vectors),
while trying to match the labels of the data points. Mathe-
matically, this can be expressed as:

m(cid:88)

ξi

min
γ,w,b

1
2

||w||2+C

y(i)(cid:16)

s.t.

wT x(i) + b

i=1

(cid:17) ≥ 1 − ξi, i = 1, ..., m

ξi ≥ 0, i = 1, ..., m

In the equation above, the parameter C balances the
two objectives of increasing distance between the decision
boundary and the support vectors, and correctly labeling the
points.

Solving the optimization problem above is difﬁcult, and
it is easier to solve the Lagrangian dual optimization prob-
lem below:

m(cid:88)

i=1

αi − 1
2

m(cid:88)

i,j=1

max

α

W (α) =

y(i)y(j)αiαj(cid:104)x(i), x(j)(cid:105)

Where m × n is the resolution of the preview frame and
{ri(x,y), gi(x,y), bi(x,y)} is the pixel color at pixel coordinate
(x,y) of the preview frame.

s.t. 0 ≤ αi ≤ C, i = 1, ..., m

m(cid:88)

αiy(i) = 0

Our data collection process is outlined in Figure 1 below.

i=1

One of the distinct advantages of the SVM is the option
to use kernels to map the feature vector to a higher dimen-
sion space, which has the potential to separate data that falls
along curved decision boundaries.

To classify between multiple classes, we used the Win-
ner Takes All (WTA) SVM method as described and empir-
ically supported in papers by Duan and Rifkin [6, 8]. That
is, we trained multiple 1-vs-all SVMs, and then to deter-
mine the label of an unlabeled test example, we pass the
unlabeled test example to each of the SVM models, and ob-
tain the score corresponding to each model. This score is the
signed distance from the data point to the decision bound-
ary, hence a large positive score signify that the data point is
both a positive example, and is far from the decision bound-
ary. Therefore to assign a test example to the most probable
class, we label that test example with the label of the model
that had the largest score.

Figure 1. Data Collection process

We collected the color barcode data from 140 movies
from each of the following genres: horror, animation, ro-
mance and action, making a total of 560 data points.

2

4.2. Multinomial Naive Bayes

The Multinomial Naive Bayes model is another super-
vised learning method that we used to classify the movies.
The Naive Bayes model assumes that observing a certain
feature, Xi, is independent of observing another feature,
Xj, given the label, Y . That is

p(Xi, Xj|Y ) = p(Xi|Y )p(Xj|Y ) ∀i (cid:54)= j

With this assumption, we can build a probabilistic model
based on the training examples. Speciﬁcally, we are ﬁnding
the parameters

Φj|Y =k = p(xj = 1|Y = k)
ΦY =k = p(Y = k)

that maximizes the likelihood of the model:

model consistently had a 0% training error, they also had
consistently high generalization errors. For all future dis-
cussion of SVM’s, a linear kernel is used.

5.1.2 Slack Parameter

To determine the optimal value for C, we tried a range of
different values to ﬁnd the value that would result in the
lowest training and generalization error. For example, ﬁg-
ure 2 shows the plots of training and generalization error
plotted against C for the ﬁnal feature vector. In this case,
we notice that the training error is zero right from when
C is small, which implies that the data points are linearly
separable, and hence the weighting coefﬁcient for the slack
parameter is inconsequential. For the subsequent discussion
of SVM’s, the value of C used is 10.

ˆP (Y = k|X1, ..., XP ) =

Φ(Y = k)(cid:81)P
(cid:80)K
k=1 Φ(Y = k)(cid:81)P

j=1 p(Xj|Y = k)

j=1 p(Xj|Y = k)

For each testing example, we can then calculate ˆP (Y =
1|X1, ..., XP ), ˆP (Y = 2|X1, ..., XP ), ..., and label the
training example with the label that has the largest corre-
sponding probability.
4.3. k-means Clustering

k-means clustering is an unsupervised learning method
to identify clusters in a dataset, x(1), x(2), ..., x(m). The
algorithm is initialized by randomly selecting k centroids,
µ1, µ2, ...µk, in the space of the dataset. It then iteratively
labels each point in the dataset with the index of the nearest
centroid, c(i), and subsequently moves the centroid to the
center of those points. That is, for each iteration,

Figure 2. Error for different values of C

5.1.3 Number of Clusters

Part of building our feature vectors involved using k-mean
clusters to group similar colors together. To determine the
value of k, the number of clusters, that was not too large,
and yet results in the lowest error, we ran our movie classi-
ﬁcation algorithm on different values of k. Figure 3 shows
the classiﬁcation errors for the different genres across a
range of values for k.

c(i) := arg min

j

(cid:80)m
||x(i) − µj||2
(cid:80)m
i=1 1{c(i) = j}x(i)
i=1 1{c(i) = j}

µj :=

We run this until the labels for the data points,c(i), and the
location of the centroids,µj, converges and stops varying
between iterations.

5. Results
5.1. Parameters
5.1.1 SVM Kernels

Figure 3. Plot of Generalization error against k

Based on the results presented in ﬁgure 3, and limited by
the amount of computational power we had available, we
used k = 512 for the experiments to be discussed below.
5.2. Color Barcode

We chose to use a linear kernel for the SVM because
higher order kernels (polynomial, Gaussian, RBF) were
over-ﬁtting the data. That is, we observed that while these

The ﬁrst feature vector we tried was the raw sampled
”color barcode” data that was resampled and interpolated to
be of a ﬁxed length. Table 1 shows the confusion matrix of

3

What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

tage of this method as opposed to taking screenshots of the
actual movie stream is that the preview window does not re-
quire any buffering time. At the same time, this approach
restricted the data sample rate to one sample per 10 seconds.
The color data that is sampled for each preview frame is the
mean pixel red, green, blue (RGB) values of all the pixels
in the preview frame.

We chose mean color as opposed to other statistical mea-
sures because the Netﬂix preview window pixels are already
down-sampled mean colors of pixels from the actual movie
frame. The resulting ”Color Barcode” feature captured is
similar to the data presented in the Colors of Motion Visu-
alizations [1]. The color barcode is represented as:

r1

g1
b1



r2
g2
b2

...
...
...

ri
gi
bi

...
...
...

rn
gn
bn

Where {ri, gi, bi} are the mean red, green and blue pixel
values of the frame captured at the 10 × ith second, n is
the total number of frames captured for the movie, and 0 ≤
ri, gi, bi ≤ 255. That is,

x=1

m(cid:88)
m(cid:88)
m(cid:88)

x=1

y=1

n(cid:88)
n(cid:88)
n(cid:88)

y=1

x=1

y=1

ri(x,y)

gi(x,y)

bi(x,y)

ri =

1

m × n

gi =

1

m × n

bi =

1

m × n

4. Methods
4.1. Support Vector Machine (SVM)

One of the main algorithms that we use to classify the
movies into genres is the SVM. The SVM is an algorithm
that ﬁnds the optimal decision boundary to separate the data
into two partitions based on its labels. That is, it ﬁnds the
line that maximizes the distance to the points closest to the
boundary(these closest points are called support vectors),
while trying to match the labels of the data points. Mathe-
matically, this can be expressed as:

m(cid:88)

ξi

min
γ,w,b

1
2

||w||2+C

y(i)(cid:16)

s.t.

wT x(i) + b

i=1

(cid:17) ≥ 1 − ξi, i = 1, ..., m

ξi ≥ 0, i = 1, ..., m

In the equation above, the parameter C balances the
two objectives of increasing distance between the decision
boundary and the support vectors, and correctly labeling the
points.

Solving the optimization problem above is difﬁcult, and
it is easier to solve the Lagrangian dual optimization prob-
lem below:

m(cid:88)

i=1

αi − 1
2

m(cid:88)

i,j=1

max

α

W (α) =

y(i)y(j)αiαj(cid:104)x(i), x(j)(cid:105)

Where m × n is the resolution of the preview frame and
{ri(x,y), gi(x,y), bi(x,y)} is the pixel color at pixel coordinate
(x,y) of the preview frame.

s.t. 0 ≤ αi ≤ C, i = 1, ..., m

m(cid:88)

αiy(i) = 0

Our data collection process is outlined in Figure 1 below.

i=1

One of the distinct advantages of the SVM is the option
to use kernels to map the feature vector to a higher dimen-
sion space, which has the potential to separate data that falls
along curved decision boundaries.

To classify between multiple classes, we used the Win-
ner Takes All (WTA) SVM method as described and empir-
ically supported in papers by Duan and Rifkin [6, 8]. That
is, we trained multiple 1-vs-all SVMs, and then to deter-
mine the label of an unlabeled test example, we pass the
unlabeled test example to each of the SVM models, and ob-
tain the score corresponding to each model. This score is the
signed distance from the data point to the decision bound-
ary, hence a large positive score signify that the data point is
both a positive example, and is far from the decision bound-
ary. Therefore to assign a test example to the most probable
class, we label that test example with the label of the model
that had the largest score.

Figure 1. Data Collection process

We collected the color barcode data from 140 movies
from each of the following genres: horror, animation, ro-
mance and action, making a total of 560 data points.

2

4.2. Multinomial Naive Bayes

The Multinomial Naive Bayes model is another super-
vised learning method that we used to classify the movies.
The Naive Bayes model assumes that observing a certain
feature, Xi, is independent of observing another feature,
Xj, given the label, Y . That is

p(Xi, Xj|Y ) = p(Xi|Y )p(Xj|Y ) ∀i (cid:54)= j

With this assumption, we can build a probabilistic model
based on the training examples. Speciﬁcally, we are ﬁnding
the parameters

Φj|Y =k = p(xj = 1|Y = k)
ΦY =k = p(Y = k)

that maximizes the likelihood of the model:

model consistently had a 0% training error, they also had
consistently high generalization errors. For all future dis-
cussion of SVM’s, a linear kernel is used.

5.1.2 Slack Parameter

To determine the optimal value for C, we tried a range of
different values to ﬁnd the value that would result in the
lowest training and generalization error. For example, ﬁg-
ure 2 shows the plots of training and generalization error
plotted against C for the ﬁnal feature vector. In this case,
we notice that the training error is zero right from when
C is small, which implies that the data points are linearly
separable, and hence the weighting coefﬁcient for the slack
parameter is inconsequential. For the subsequent discussion
of SVM’s, the value of C used is 10.

ˆP (Y = k|X1, ..., XP ) =

Φ(Y = k)(cid:81)P
(cid:80)K
k=1 Φ(Y = k)(cid:81)P

j=1 p(Xj|Y = k)

j=1 p(Xj|Y = k)

For each testing example, we can then calculate ˆP (Y =
1|X1, ..., XP ), ˆP (Y = 2|X1, ..., XP ), ..., and label the
training example with the label that has the largest corre-
sponding probability.
4.3. k-means Clustering

k-means clustering is an unsupervised learning method
to identify clusters in a dataset, x(1), x(2), ..., x(m). The
algorithm is initialized by randomly selecting k centroids,
µ1, µ2, ...µk, in the space of the dataset. It then iteratively
labels each point in the dataset with the index of the nearest
centroid, c(i), and subsequently moves the centroid to the
center of those points. That is, for each iteration,

Figure 2. Error for different values of C

5.1.3 Number of Clusters

Part of building our feature vectors involved using k-mean
clusters to group similar colors together. To determine the
value of k, the number of clusters, that was not too large,
and yet results in the lowest error, we ran our movie classi-
ﬁcation algorithm on different values of k. Figure 3 shows
the classiﬁcation errors for the different genres across a
range of values for k.

c(i) := arg min

j

(cid:80)m
||x(i) − µj||2
(cid:80)m
i=1 1{c(i) = j}x(i)
i=1 1{c(i) = j}

µj :=

We run this until the labels for the data points,c(i), and the
location of the centroids,µj, converges and stops varying
between iterations.

5. Results
5.1. Parameters
5.1.1 SVM Kernels

Figure 3. Plot of Generalization error against k

Based on the results presented in ﬁgure 3, and limited by
the amount of computational power we had available, we
used k = 512 for the experiments to be discussed below.
5.2. Color Barcode

We chose to use a linear kernel for the SVM because
higher order kernels (polynomial, Gaussian, RBF) were
over-ﬁtting the data. That is, we observed that while these

The ﬁrst feature vector we tried was the raw sampled
”color barcode” data that was resampled and interpolated to
be of a ﬁxed length. Table 1 shows the confusion matrix of

3

the Linear SVM classiﬁer tested with 10-fold cross valida-
tion over 100 trials. During each trial, a random permuta-
tion of our data set was split into the ten equally sized par-
titions for cross validation. Each partition had 14 movies.
Thus the training set is always 136 movies and the test set
is always 14 movies. Hence, by the law of large numbers,
the average TP+FN for each genre converges to 14 over 100
trials.

Horror

Animation
Romance
Action

TP
5.33
7.19
6.30
4.08

FP
7.98
4.36
10.75
10.01

FN Precision Recall
38.4%
8.67
51.6%
6.81
45.3%
7.70
9.92
29.3%

40.3%
62.6%
37.1%
29.0%

Table 1. Confusion Matrix for Color Barcode Feature

Animation movies had the highest classiﬁcation accu-

racy with 62.6% precision and 51.6% accuracy.
5.3. Clustered Color Barcode

Since columnizing the R,G,B channels of the the color
barcode conceals and ignores the relationship between the
red, green, and blue intensities, we tried clustering all the
colors in the training dataset using k-Mean Clustering (Re-
fer to Section 5.1.3). After clustering, the R,G,B values for
each in the test dataset color barcodes is replaced by the in-
dex of the centroid that it is the nearest to. We then use this
time sequence of indexes as our feature vector.

Table 2 shows the confusion matrix of the Linear SVM
classiﬁer tested with 10-fold cross validation over 100 tri-
als. The precision and recall values were very close to the
random classiﬁer value of 25% and is worse than the un-
clustered color barcode results.

vector. To generate the clustered color histogram vector, we
binned the colors in a movie’s color barcode to the near-
est of the 512 color cluster centroids by R,G,B distance.
Each element of the feature vector corresponds to the num-
ber of occurrences of that corresponding color. The clus-
tered color histogram for Finding Nemo (with 32 cluster
centroids for visual representation) is shown in Figure 4.
We can see that Finding Nemo’s colors are predominated
by blue hues due to the underwater scenes.

Figure 4. Color Histogram of Finding Nemo

Horror

Animation
Romance
Action

TP
6.29
10.94
5.61
7.18

FP
7.06
4.39
7.85
6.69

FN Precision Recall
45.0%
7.71
78.2%
3.06
40.3%
8.39
6.83
51.3%

47.2%
71.5%
41.9%
51.9%

Table 3. Confusion Matrix for Clustered Color Histogram Feature
using SVM

Horror

TP
3.03
3.37
3.62
3.35

Precision Recall
21.5%
21.1%
24.5%
24.3%
26.6%
26.7%
24.7%
24.0%
Table 2. Confusion Matrix for Clustered Color Barcode Feature
using SVM

Animation
Romance
Action

FN
10.97
10.63
10.38
10.65

FP
11.57
10.43
10.03
10.60

Horror

TP
5.56
11.92
7.28
5.32

FN Precision Recall
39.8%
8.44
85.2%
2.08
52.0%
6.72
8.68
38.1%
Table 4. Confusion Matrix for Clustered Color Histogram Feature
using NB

Animation
Romance
Action

FP
5.641
6.34
6.68
7.25

49.8%
65.5%
52.2%
42.6%

5.4. Clustered Color Histogram

For the color barcode and clustered color barcode fea-
tures, the featured dimension is storngly linked to the po-
sition of the sample within the movie. This representation
may not be ideal since the same movie sampled at slightly
different start and end points will have the color informa-
tion in different dimensions. Thus, we experimented with
removing the temporal information and purely looking at
color distributions ”palettes” of movies. Since color his-
tograms were used in various works to analyze mood of vi-
sual content [11], we tried the color histogram as a feature

The accuracy of the Linear SVM and Naive Bayes clas-
siﬁers tested with 10-fold cross validation over 100 trials
(Table 3 and Table 4) improved for all genres with the color
information unlinked from the temporal location of each
frame. We used the multinomial Naive-Bayes algorithm for
this feature vector because the frequencies are positive inte-
gers.

5.5. Clustered Color Histogram with Dynamics

The clustered color histogram feature performed better
without temporal information than the color barcode and

4

What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

tage of this method as opposed to taking screenshots of the
actual movie stream is that the preview window does not re-
quire any buffering time. At the same time, this approach
restricted the data sample rate to one sample per 10 seconds.
The color data that is sampled for each preview frame is the
mean pixel red, green, blue (RGB) values of all the pixels
in the preview frame.

We chose mean color as opposed to other statistical mea-
sures because the Netﬂix preview window pixels are already
down-sampled mean colors of pixels from the actual movie
frame. The resulting ”Color Barcode” feature captured is
similar to the data presented in the Colors of Motion Visu-
alizations [1]. The color barcode is represented as:

r1

g1
b1



r2
g2
b2

...
...
...

ri
gi
bi

...
...
...

rn
gn
bn

Where {ri, gi, bi} are the mean red, green and blue pixel
values of the frame captured at the 10 × ith second, n is
the total number of frames captured for the movie, and 0 ≤
ri, gi, bi ≤ 255. That is,

x=1

m(cid:88)
m(cid:88)
m(cid:88)

x=1

y=1

n(cid:88)
n(cid:88)
n(cid:88)

y=1

x=1

y=1

ri(x,y)

gi(x,y)

bi(x,y)

ri =

1

m × n

gi =

1

m × n

bi =

1

m × n

4. Methods
4.1. Support Vector Machine (SVM)

One of the main algorithms that we use to classify the
movies into genres is the SVM. The SVM is an algorithm
that ﬁnds the optimal decision boundary to separate the data
into two partitions based on its labels. That is, it ﬁnds the
line that maximizes the distance to the points closest to the
boundary(these closest points are called support vectors),
while trying to match the labels of the data points. Mathe-
matically, this can be expressed as:

m(cid:88)

ξi

min
γ,w,b

1
2

||w||2+C

y(i)(cid:16)

s.t.

wT x(i) + b

i=1

(cid:17) ≥ 1 − ξi, i = 1, ..., m

ξi ≥ 0, i = 1, ..., m

In the equation above, the parameter C balances the
two objectives of increasing distance between the decision
boundary and the support vectors, and correctly labeling the
points.

Solving the optimization problem above is difﬁcult, and
it is easier to solve the Lagrangian dual optimization prob-
lem below:

m(cid:88)

i=1

αi − 1
2

m(cid:88)

i,j=1

max

α

W (α) =

y(i)y(j)αiαj(cid:104)x(i), x(j)(cid:105)

Where m × n is the resolution of the preview frame and
{ri(x,y), gi(x,y), bi(x,y)} is the pixel color at pixel coordinate
(x,y) of the preview frame.

s.t. 0 ≤ αi ≤ C, i = 1, ..., m

m(cid:88)

αiy(i) = 0

Our data collection process is outlined in Figure 1 below.

i=1

One of the distinct advantages of the SVM is the option
to use kernels to map the feature vector to a higher dimen-
sion space, which has the potential to separate data that falls
along curved decision boundaries.

To classify between multiple classes, we used the Win-
ner Takes All (WTA) SVM method as described and empir-
ically supported in papers by Duan and Rifkin [6, 8]. That
is, we trained multiple 1-vs-all SVMs, and then to deter-
mine the label of an unlabeled test example, we pass the
unlabeled test example to each of the SVM models, and ob-
tain the score corresponding to each model. This score is the
signed distance from the data point to the decision bound-
ary, hence a large positive score signify that the data point is
both a positive example, and is far from the decision bound-
ary. Therefore to assign a test example to the most probable
class, we label that test example with the label of the model
that had the largest score.

Figure 1. Data Collection process

We collected the color barcode data from 140 movies
from each of the following genres: horror, animation, ro-
mance and action, making a total of 560 data points.

2

4.2. Multinomial Naive Bayes

The Multinomial Naive Bayes model is another super-
vised learning method that we used to classify the movies.
The Naive Bayes model assumes that observing a certain
feature, Xi, is independent of observing another feature,
Xj, given the label, Y . That is

p(Xi, Xj|Y ) = p(Xi|Y )p(Xj|Y ) ∀i (cid:54)= j

With this assumption, we can build a probabilistic model
based on the training examples. Speciﬁcally, we are ﬁnding
the parameters

Φj|Y =k = p(xj = 1|Y = k)
ΦY =k = p(Y = k)

that maximizes the likelihood of the model:

model consistently had a 0% training error, they also had
consistently high generalization errors. For all future dis-
cussion of SVM’s, a linear kernel is used.

5.1.2 Slack Parameter

To determine the optimal value for C, we tried a range of
different values to ﬁnd the value that would result in the
lowest training and generalization error. For example, ﬁg-
ure 2 shows the plots of training and generalization error
plotted against C for the ﬁnal feature vector. In this case,
we notice that the training error is zero right from when
C is small, which implies that the data points are linearly
separable, and hence the weighting coefﬁcient for the slack
parameter is inconsequential. For the subsequent discussion
of SVM’s, the value of C used is 10.

ˆP (Y = k|X1, ..., XP ) =

Φ(Y = k)(cid:81)P
(cid:80)K
k=1 Φ(Y = k)(cid:81)P

j=1 p(Xj|Y = k)

j=1 p(Xj|Y = k)

For each testing example, we can then calculate ˆP (Y =
1|X1, ..., XP ), ˆP (Y = 2|X1, ..., XP ), ..., and label the
training example with the label that has the largest corre-
sponding probability.
4.3. k-means Clustering

k-means clustering is an unsupervised learning method
to identify clusters in a dataset, x(1), x(2), ..., x(m). The
algorithm is initialized by randomly selecting k centroids,
µ1, µ2, ...µk, in the space of the dataset. It then iteratively
labels each point in the dataset with the index of the nearest
centroid, c(i), and subsequently moves the centroid to the
center of those points. That is, for each iteration,

Figure 2. Error for different values of C

5.1.3 Number of Clusters

Part of building our feature vectors involved using k-mean
clusters to group similar colors together. To determine the
value of k, the number of clusters, that was not too large,
and yet results in the lowest error, we ran our movie classi-
ﬁcation algorithm on different values of k. Figure 3 shows
the classiﬁcation errors for the different genres across a
range of values for k.

c(i) := arg min

j

(cid:80)m
||x(i) − µj||2
(cid:80)m
i=1 1{c(i) = j}x(i)
i=1 1{c(i) = j}

µj :=

We run this until the labels for the data points,c(i), and the
location of the centroids,µj, converges and stops varying
between iterations.

5. Results
5.1. Parameters
5.1.1 SVM Kernels

Figure 3. Plot of Generalization error against k

Based on the results presented in ﬁgure 3, and limited by
the amount of computational power we had available, we
used k = 512 for the experiments to be discussed below.
5.2. Color Barcode

We chose to use a linear kernel for the SVM because
higher order kernels (polynomial, Gaussian, RBF) were
over-ﬁtting the data. That is, we observed that while these

The ﬁrst feature vector we tried was the raw sampled
”color barcode” data that was resampled and interpolated to
be of a ﬁxed length. Table 1 shows the confusion matrix of

3

the Linear SVM classiﬁer tested with 10-fold cross valida-
tion over 100 trials. During each trial, a random permuta-
tion of our data set was split into the ten equally sized par-
titions for cross validation. Each partition had 14 movies.
Thus the training set is always 136 movies and the test set
is always 14 movies. Hence, by the law of large numbers,
the average TP+FN for each genre converges to 14 over 100
trials.

Horror

Animation
Romance
Action

TP
5.33
7.19
6.30
4.08

FP
7.98
4.36
10.75
10.01

FN Precision Recall
38.4%
8.67
51.6%
6.81
45.3%
7.70
9.92
29.3%

40.3%
62.6%
37.1%
29.0%

Table 1. Confusion Matrix for Color Barcode Feature

Animation movies had the highest classiﬁcation accu-

racy with 62.6% precision and 51.6% accuracy.
5.3. Clustered Color Barcode

Since columnizing the R,G,B channels of the the color
barcode conceals and ignores the relationship between the
red, green, and blue intensities, we tried clustering all the
colors in the training dataset using k-Mean Clustering (Re-
fer to Section 5.1.3). After clustering, the R,G,B values for
each in the test dataset color barcodes is replaced by the in-
dex of the centroid that it is the nearest to. We then use this
time sequence of indexes as our feature vector.

Table 2 shows the confusion matrix of the Linear SVM
classiﬁer tested with 10-fold cross validation over 100 tri-
als. The precision and recall values were very close to the
random classiﬁer value of 25% and is worse than the un-
clustered color barcode results.

vector. To generate the clustered color histogram vector, we
binned the colors in a movie’s color barcode to the near-
est of the 512 color cluster centroids by R,G,B distance.
Each element of the feature vector corresponds to the num-
ber of occurrences of that corresponding color. The clus-
tered color histogram for Finding Nemo (with 32 cluster
centroids for visual representation) is shown in Figure 4.
We can see that Finding Nemo’s colors are predominated
by blue hues due to the underwater scenes.

Figure 4. Color Histogram of Finding Nemo

Horror

Animation
Romance
Action

TP
6.29
10.94
5.61
7.18

FP
7.06
4.39
7.85
6.69

FN Precision Recall
45.0%
7.71
78.2%
3.06
40.3%
8.39
6.83
51.3%

47.2%
71.5%
41.9%
51.9%

Table 3. Confusion Matrix for Clustered Color Histogram Feature
using SVM

Horror

TP
3.03
3.37
3.62
3.35

Precision Recall
21.5%
21.1%
24.5%
24.3%
26.6%
26.7%
24.7%
24.0%
Table 2. Confusion Matrix for Clustered Color Barcode Feature
using SVM

Animation
Romance
Action

FN
10.97
10.63
10.38
10.65

FP
11.57
10.43
10.03
10.60

Horror

TP
5.56
11.92
7.28
5.32

FN Precision Recall
39.8%
8.44
85.2%
2.08
52.0%
6.72
8.68
38.1%
Table 4. Confusion Matrix for Clustered Color Histogram Feature
using NB

Animation
Romance
Action

FP
5.641
6.34
6.68
7.25

49.8%
65.5%
52.2%
42.6%

5.4. Clustered Color Histogram

For the color barcode and clustered color barcode fea-
tures, the featured dimension is storngly linked to the po-
sition of the sample within the movie. This representation
may not be ideal since the same movie sampled at slightly
different start and end points will have the color informa-
tion in different dimensions. Thus, we experimented with
removing the temporal information and purely looking at
color distributions ”palettes” of movies. Since color his-
tograms were used in various works to analyze mood of vi-
sual content [11], we tried the color histogram as a feature

The accuracy of the Linear SVM and Naive Bayes clas-
siﬁers tested with 10-fold cross validation over 100 trials
(Table 3 and Table 4) improved for all genres with the color
information unlinked from the temporal location of each
frame. We used the multinomial Naive-Bayes algorithm for
this feature vector because the frequencies are positive inte-
gers.

5.5. Clustered Color Histogram with Dynamics

The clustered color histogram feature performed better
without temporal information than the color barcode and

4

clustered color barcode features which had temporal infor-
mation. Thus, we wanted to introduce temporal information
in a manner that would not be destructive to the clustered
color histogram feature.

We ﬁrst converted the RGB values to CIELUV1 format,
a format that allows us calculate the difference between two
colors as the euclidean distance between color vectors. This
allows us to track the change of color between frames. Fig-
ure 5 shows the change in CIELUV color distances for Find-
ing Nemo over time.

Horror

Animation
Romance
Action

TP
6.51
11.67
7.20
7.56

FP
7.10
3.21
6.93
5.82

FN Precision Recall
46.5%
7.49
83.5%
2.33
51.7%
6.80
6.44
54.2%

48.0%
78.5%
51.2%
56.7%

Table 5. Confusion Matrix for Clustered Color Histogram with
Dynamics Feature using SVM

Horror

Animation
Romance
Action

TP
6.73
12.98
7.82
5.59

FP
5.50
3.98
6.13
7.28

FN Precision Recall
48.2%
7.27
92.7%
1.02
6.18
56.1%
40.0%
8.41

55.4%
76.6%
56.2%
43.7%

Table 6. Confusion Matrix for Clustered Color Histogram with
Dynamics Feature using NB

The accuracy of the Linear SVM and Naive Bayes clas-
siﬁers tested with 10-fold cross validation over 100 trials
(Table 5 and Table 6) improved for all genres with the color
dynamics information.

Figure 5. Color Difference over Time for Finding Nemo

6. Conclusion

We then averaged the color change distances between all
frames to get a mean color change value (color dynamics)
for each movie. The distributions of movie color dynamics
for the four genres in Figure 6.

Figure 6. Distributions of Genre Color Differences

From the color dynamics distributions we can observe
that romance movies generally have a smaller color dynam-
ics value and animation movies have a larger color dynam-
ics value. This makes sense since romance movies have
slower scenes while animated movies are ﬂashier. Based
on this data and the usefulness of color transition in movie
mood studies [11], we added the color dynamics value as a
new element to the clustered color histogram feature vector.

1The 1976 CIELUV color space provides a perceptually uniform color
space. In this color space, the distance between two points approximately
tells how different the colors are in luminance, chroma, and hue[9]

5

The combined clustered histogram and color dynamics
feature processed from the color barcode feature gave us
better results than the unprocessed color barcode feature.
We could correctly classify 13 out of 14 animated movies
among four genres (horror, animation, romance, action)
from the average frame colors sampled 6 times a minute
using a Naive Bayes classiﬁer with a training set of 126
movies. The classiﬁcation accuracy (recall) for other genres
(horror: 48.2%, romance: 56.1%, action: 54.2%) were bet-
ter than the 25% random classiﬁer accuracy indicating that
there is learnable movie genre information in movie colors.
We did some exploration of our dataset through unsuper-
vised K-Means clustering on the unprocessed color barcode
feature. Based on the the clustering results that we obtained,
we observe that an unsupervised learning algorithm (such
as the k-means algorithm) shows promise to successfully
group movies that have similar color schemes.

Clustering movies by combining color cluster histogram
and color dynamics feature can be explored and developed
in the future. One of the potential applications of such
a clustering algorithm would be a movie recommendation
system based on the intrinsic properties of movies, similar
to the Pandora ”Music Genome Project” [2] for music. It
would also be interesting to ﬁnd common words in the sub-
titles of the clustered movies to link movie content to movie
color.

What Can We Learn From Movie Colors?

Ethan Chan

Computer Science
Stanford University

John Lee

Electrical Engineering
Stanford University

ethancys@cs.stanford.edu

johnwlee@stanford.edu

Rajarshi Roy

Electrical Engineering
Stanford University
rroy@stanford.edu

Abstract

gate in this paper.

We applied supervised learning methods to classify movies
into one of four genres based solely on colors present in
the ﬁlm. Data was obtained from screen captures of the
Netﬂix preview window at 10 second intervals. Our ﬁnal
feature was X = {512-color histogram, avg. color change}.
Our genre classes were Y = {Action, Animation, Horror,
Romance}. We attempted Multinomial Naive Bayes and
1-v-all SVM to predict the genres of a ﬁlm based on its
color features. We also attempted Unsupervised Learning
K-Means Clustering algorithm on our movies to observe
patterns across movies.

1. Introduction

It is popular opinion that the mood and the genre of a ﬁlm
is closely related to the color schemes used in the movie.
We can intuitively tell what genre a ﬁlm is just by looking
at its color hues; warm red tones for romances, desaturated
colors for post-apocalyptic ﬁlms[3]. We set out to explore
how movies genres are related to the color characteristics
of a ﬁlm, and investigated this intuition in a thorough and
scientiﬁc way by incorporate machine learning concepts to
predict the genre of ﬁlms based on the color characteristics.

2. Related Work

Existing work in the analysis of colors in ﬁlm can be
broadly split into the following three categories. First, work
has been done to categorize ﬁlms into genres based on con-
tent [5] such as the scenes present [13], and the movie
script [4]. The second group of existing work is the use
of computational tools to analyze the color scheme of ex-
isting movies, and the subsequent manipulation of the color
scheme of ﬁlms [7] or pictures [12] to match the learnt color
scheme. The third category of related work as been to an-
alyze the effect of the color scheme on the mood of ﬁlm
and images[10]. Little work has been done on determining
genre from color alone, which is what we set out to investi-

The most relevant paper to our problem[11] investigated
color characterization of speciﬁc scenes in a movie for
mood analysis. They analyzed 15 movies and tracked how
the mood for each scene transitioned based on color fea-
tures of the movies. The features that they used consist
of two parts. First, they chose 12 basic colors and used
them as the basis for a color histogram for each scene in
the movie. They then associated each color with a different
mood. The second feature they used was a mood dynamics
histogram, where they determined the mood of each scene
based a mood’s associated colors and created a mood dy-
namic histogram based on every possible combination of
transitions between different moods.

The paper identiﬁed its features in a very clear and tech-
nical way which was thoroughly explained and justiﬁed.
This proved to be very useful for our own feature extrac-
tion choices. However, while the paper concluded that the
mood dynamics histogram was the most effective feature to
classify a movie, their limited dataset of 15 movies suggests
that their results might have been biased.

In this paper, the problem we set out to investigate was
predicting the genre of a movie instead of transitions of
moods within a movie, we decided to extract features at a
more global level and set our class labels to be movie gen-
res instead of moods. By only inputting the genre labels
and raw data into our supervised learning algorithms, we
are taking a purely data driven approach unlike the paper
where they hard assigned moods to their 12 color palette.

3. Dataset and Features
3.1. Data Collection

Since our ownership of movies were limited in numbers,
we used the Netﬂix movie streaming service to gather our
movie color data. The Netﬂix user interface contains a low-
resolution preview window that displays keyframes at 10-
second intervals which can be navigated by arrow keys. We
created a script that generates keypresses and gathers data
from the screenshot of the preview window. The advan-

1

tage of this method as opposed to taking screenshots of the
actual movie stream is that the preview window does not re-
quire any buffering time. At the same time, this approach
restricted the data sample rate to one sample per 10 seconds.
The color data that is sampled for each preview frame is the
mean pixel red, green, blue (RGB) values of all the pixels
in the preview frame.

We chose mean color as opposed to other statistical mea-
sures because the Netﬂix preview window pixels are already
down-sampled mean colors of pixels from the actual movie
frame. The resulting ”Color Barcode” feature captured is
similar to the data presented in the Colors of Motion Visu-
alizations [1]. The color barcode is represented as:

r1

g1
b1



r2
g2
b2

...
...
...

ri
gi
bi

...
...
...

rn
gn
bn

Where {ri, gi, bi} are the mean red, green and blue pixel
values of the frame captured at the 10 × ith second, n is
the total number of frames captured for the movie, and 0 ≤
ri, gi, bi ≤ 255. That is,

x=1

m(cid:88)
m(cid:88)
m(cid:88)

x=1

y=1

n(cid:88)
n(cid:88)
n(cid:88)

y=1

x=1

y=1

ri(x,y)

gi(x,y)

bi(x,y)

ri =

1

m × n

gi =

1

m × n

bi =

1

m × n

4. Methods
4.1. Support Vector Machine (SVM)

One of the main algorithms that we use to classify the
movies into genres is the SVM. The SVM is an algorithm
that ﬁnds the optimal decision boundary to separate the data
into two partitions based on its labels. That is, it ﬁnds the
line that maximizes the distance to the points closest to the
boundary(these closest points are called support vectors),
while trying to match the labels of the data points. Mathe-
matically, this can be expressed as:

m(cid:88)

ξi

min
γ,w,b

1
2

||w||2+C

y(i)(cid:16)

s.t.

wT x(i) + b

i=1

(cid:17) ≥ 1 − ξi, i = 1, ..., m

ξi ≥ 0, i = 1, ..., m

In the equation above, the parameter C balances the
two objectives of increasing distance between the decision
boundary and the support vectors, and correctly labeling the
points.

Solving the optimization problem above is difﬁcult, and
it is easier to solve the Lagrangian dual optimization prob-
lem below:

m(cid:88)

i=1

αi − 1
2

m(cid:88)

i,j=1

max

α

W (α) =

y(i)y(j)αiαj(cid:104)x(i), x(j)(cid:105)

Where m × n is the resolution of the preview frame and
{ri(x,y), gi(x,y), bi(x,y)} is the pixel color at pixel coordinate
(x,y) of the preview frame.

s.t. 0 ≤ αi ≤ C, i = 1, ..., m

m(cid:88)

αiy(i) = 0

Our data collection process is outlined in Figure 1 below.

i=1

One of the distinct advantages of the SVM is the option
to use kernels to map the feature vector to a higher dimen-
sion space, which has the potential to separate data that falls
along curved decision boundaries.

To classify between multiple classes, we used the Win-
ner Takes All (WTA) SVM method as described and empir-
ically supported in papers by Duan and Rifkin [6, 8]. That
is, we trained multiple 1-vs-all SVMs, and then to deter-
mine the label of an unlabeled test example, we pass the
unlabeled test example to each of the SVM models, and ob-
tain the score corresponding to each model. This score is the
signed distance from the data point to the decision bound-
ary, hence a large positive score signify that the data point is
both a positive example, and is far from the decision bound-
ary. Therefore to assign a test example to the most probable
class, we label that test example with the label of the model
that had the largest score.

Figure 1. Data Collection process

We collected the color barcode data from 140 movies
from each of the following genres: horror, animation, ro-
mance and action, making a total of 560 data points.

2

4.2. Multinomial Naive Bayes

The Multinomial Naive Bayes model is another super-
vised learning method that we used to classify the movies.
The Naive Bayes model assumes that observing a certain
feature, Xi, is independent of observing another feature,
Xj, given the label, Y . That is

p(Xi, Xj|Y ) = p(Xi|Y )p(Xj|Y ) ∀i (cid:54)= j

With this assumption, we can build a probabilistic model
based on the training examples. Speciﬁcally, we are ﬁnding
the parameters

Φj|Y =k = p(xj = 1|Y = k)
ΦY =k = p(Y = k)

that maximizes the likelihood of the model:

model consistently had a 0% training error, they also had
consistently high generalization errors. For all future dis-
cussion of SVM’s, a linear kernel is used.

5.1.2 Slack Parameter

To determine the optimal value for C, we tried a range of
different values to ﬁnd the value that would result in the
lowest training and generalization error. For example, ﬁg-
ure 2 shows the plots of training and generalization error
plotted against C for the ﬁnal feature vector. In this case,
we notice that the training error is zero right from when
C is small, which implies that the data points are linearly
separable, and hence the weighting coefﬁcient for the slack
parameter is inconsequential. For the subsequent discussion
of SVM’s, the value of C used is 10.

ˆP (Y = k|X1, ..., XP ) =

Φ(Y = k)(cid:81)P
(cid:80)K
k=1 Φ(Y = k)(cid:81)P

j=1 p(Xj|Y = k)

j=1 p(Xj|Y = k)

For each testing example, we can then calculate ˆP (Y =
1|X1, ..., XP ), ˆP (Y = 2|X1, ..., XP ), ..., and label the
training example with the label that has the largest corre-
sponding probability.
4.3. k-means Clustering

k-means clustering is an unsupervised learning method
to identify clusters in a dataset, x(1), x(2), ..., x(m). The
algorithm is initialized by randomly selecting k centroids,
µ1, µ2, ...µk, in the space of the dataset. It then iteratively
labels each point in the dataset with the index of the nearest
centroid, c(i), and subsequently moves the centroid to the
center of those points. That is, for each iteration,

Figure 2. Error for different values of C

5.1.3 Number of Clusters

Part of building our feature vectors involved using k-mean
clusters to group similar colors together. To determine the
value of k, the number of clusters, that was not too large,
and yet results in the lowest error, we ran our movie classi-
ﬁcation algorithm on different values of k. Figure 3 shows
the classiﬁcation errors for the different genres across a
range of values for k.

c(i) := arg min

j

(cid:80)m
||x(i) − µj||2
(cid:80)m
i=1 1{c(i) = j}x(i)
i=1 1{c(i) = j}

µj :=

We run this until the labels for the data points,c(i), and the
location of the centroids,µj, converges and stops varying
between iterations.

5. Results
5.1. Parameters
5.1.1 SVM Kernels

Figure 3. Plot of Generalization error against k

Based on the results presented in ﬁgure 3, and limited by
the amount of computational power we had available, we
used k = 512 for the experiments to be discussed below.
5.2. Color Barcode

We chose to use a linear kernel for the SVM because
higher order kernels (polynomial, Gaussian, RBF) were
over-ﬁtting the data. That is, we observed that while these

The ﬁrst feature vector we tried was the raw sampled
”color barcode” data that was resampled and interpolated to
be of a ﬁxed length. Table 1 shows the confusion matrix of

3

the Linear SVM classiﬁer tested with 10-fold cross valida-
tion over 100 trials. During each trial, a random permuta-
tion of our data set was split into the ten equally sized par-
titions for cross validation. Each partition had 14 movies.
Thus the training set is always 136 movies and the test set
is always 14 movies. Hence, by the law of large numbers,
the average TP+FN for each genre converges to 14 over 100
trials.

Horror

Animation
Romance
Action

TP
5.33
7.19
6.30
4.08

FP
7.98
4.36
10.75
10.01

FN Precision Recall
38.4%
8.67
51.6%
6.81
45.3%
7.70
9.92
29.3%

40.3%
62.6%
37.1%
29.0%

Table 1. Confusion Matrix for Color Barcode Feature

Animation movies had the highest classiﬁcation accu-

racy with 62.6% precision and 51.6% accuracy.
5.3. Clustered Color Barcode

Since columnizing the R,G,B channels of the the color
barcode conceals and ignores the relationship between the
red, green, and blue intensities, we tried clustering all the
colors in the training dataset using k-Mean Clustering (Re-
fer to Section 5.1.3). After clustering, the R,G,B values for
each in the test dataset color barcodes is replaced by the in-
dex of the centroid that it is the nearest to. We then use this
time sequence of indexes as our feature vector.

Table 2 shows the confusion matrix of the Linear SVM
classiﬁer tested with 10-fold cross validation over 100 tri-
als. The precision and recall values were very close to the
random classiﬁer value of 25% and is worse than the un-
clustered color barcode results.

vector. To generate the clustered color histogram vector, we
binned the colors in a movie’s color barcode to the near-
est of the 512 color cluster centroids by R,G,B distance.
Each element of the feature vector corresponds to the num-
ber of occurrences of that corresponding color. The clus-
tered color histogram for Finding Nemo (with 32 cluster
centroids for visual representation) is shown in Figure 4.
We can see that Finding Nemo’s colors are predominated
by blue hues due to the underwater scenes.

Figure 4. Color Histogram of Finding Nemo

Horror

Animation
Romance
Action

TP
6.29
10.94
5.61
7.18

FP
7.06
4.39
7.85
6.69

FN Precision Recall
45.0%
7.71
78.2%
3.06
40.3%
8.39
6.83
51.3%

47.2%
71.5%
41.9%
51.9%

Table 3. Confusion Matrix for Clustered Color Histogram Feature
using SVM

Horror

TP
3.03
3.37
3.62
3.35

Precision Recall
21.5%
21.1%
24.5%
24.3%
26.6%
26.7%
24.7%
24.0%
Table 2. Confusion Matrix for Clustered Color Barcode Feature
using SVM

Animation
Romance
Action

FN
10.97
10.63
10.38
10.65

FP
11.57
10.43
10.03
10.60

Horror

TP
5.56
11.92
7.28
5.32

FN Precision Recall
39.8%
8.44
85.2%
2.08
52.0%
6.72
8.68
38.1%
Table 4. Confusion Matrix for Clustered Color Histogram Feature
using NB

Animation
Romance
Action

FP
5.641
6.34
6.68
7.25

49.8%
65.5%
52.2%
42.6%

5.4. Clustered Color Histogram

For the color barcode and clustered color barcode fea-
tures, the featured dimension is storngly linked to the po-
sition of the sample within the movie. This representation
may not be ideal since the same movie sampled at slightly
different start and end points will have the color informa-
tion in different dimensions. Thus, we experimented with
removing the temporal information and purely looking at
color distributions ”palettes” of movies. Since color his-
tograms were used in various works to analyze mood of vi-
sual content [11], we tried the color histogram as a feature

The accuracy of the Linear SVM and Naive Bayes clas-
siﬁers tested with 10-fold cross validation over 100 trials
(Table 3 and Table 4) improved for all genres with the color
information unlinked from the temporal location of each
frame. We used the multinomial Naive-Bayes algorithm for
this feature vector because the frequencies are positive inte-
gers.

5.5. Clustered Color Histogram with Dynamics

The clustered color histogram feature performed better
without temporal information than the color barcode and

4

clustered color barcode features which had temporal infor-
mation. Thus, we wanted to introduce temporal information
in a manner that would not be destructive to the clustered
color histogram feature.

We ﬁrst converted the RGB values to CIELUV1 format,
a format that allows us calculate the difference between two
colors as the euclidean distance between color vectors. This
allows us to track the change of color between frames. Fig-
ure 5 shows the change in CIELUV color distances for Find-
ing Nemo over time.

Horror

Animation
Romance
Action

TP
6.51
11.67
7.20
7.56

FP
7.10
3.21
6.93
5.82

FN Precision Recall
46.5%
7.49
83.5%
2.33
51.7%
6.80
6.44
54.2%

48.0%
78.5%
51.2%
56.7%

Table 5. Confusion Matrix for Clustered Color Histogram with
Dynamics Feature using SVM

Horror

Animation
Romance
Action

TP
6.73
12.98
7.82
5.59

FP
5.50
3.98
6.13
7.28

FN Precision Recall
48.2%
7.27
92.7%
1.02
6.18
56.1%
40.0%
8.41

55.4%
76.6%
56.2%
43.7%

Table 6. Confusion Matrix for Clustered Color Histogram with
Dynamics Feature using NB

The accuracy of the Linear SVM and Naive Bayes clas-
siﬁers tested with 10-fold cross validation over 100 trials
(Table 5 and Table 6) improved for all genres with the color
dynamics information.

Figure 5. Color Difference over Time for Finding Nemo

6. Conclusion

We then averaged the color change distances between all
frames to get a mean color change value (color dynamics)
for each movie. The distributions of movie color dynamics
for the four genres in Figure 6.

Figure 6. Distributions of Genre Color Differences

From the color dynamics distributions we can observe
that romance movies generally have a smaller color dynam-
ics value and animation movies have a larger color dynam-
ics value. This makes sense since romance movies have
slower scenes while animated movies are ﬂashier. Based
on this data and the usefulness of color transition in movie
mood studies [11], we added the color dynamics value as a
new element to the clustered color histogram feature vector.

1The 1976 CIELUV color space provides a perceptually uniform color
space. In this color space, the distance between two points approximately
tells how different the colors are in luminance, chroma, and hue[9]

5

The combined clustered histogram and color dynamics
feature processed from the color barcode feature gave us
better results than the unprocessed color barcode feature.
We could correctly classify 13 out of 14 animated movies
among four genres (horror, animation, romance, action)
from the average frame colors sampled 6 times a minute
using a Naive Bayes classiﬁer with a training set of 126
movies. The classiﬁcation accuracy (recall) for other genres
(horror: 48.2%, romance: 56.1%, action: 54.2%) were bet-
ter than the 25% random classiﬁer accuracy indicating that
there is learnable movie genre information in movie colors.
We did some exploration of our dataset through unsuper-
vised K-Means clustering on the unprocessed color barcode
feature. Based on the the clustering results that we obtained,
we observe that an unsupervised learning algorithm (such
as the k-means algorithm) shows promise to successfully
group movies that have similar color schemes.

Clustering movies by combining color cluster histogram
and color dynamics feature can be explored and developed
in the future. One of the potential applications of such
a clustering algorithm would be a movie recommendation
system based on the intrinsic properties of movies, similar
to the Pandora ”Music Genome Project” [2] for music. It
would also be interesting to ﬁnd common words in the sub-
titles of the clustered movies to link movie content to movie
color.

References
[1] The colors of motion. http://thecolorsofmotion.

com/films. [Online; accessed 11-December-2015].

[2] The music genome project. https://www.pandora.
com/about/mgp. [Online; accessed 11-December-2015].
[3] P. Bellantoni. If it’s purple someone’s gonna die. Focal Press,

2005.

[4] A. Blackstock and M. Spitz. Classifying movie scripts by

genre with a memm using nlp-based features.

[5] C. Dorai. Automatic genre identiﬁcation for content-based
In Pattern Recognition, 2000. Pro-
video categorization.
ceedings. 15th International Conference on, volume 4, pages
230–233 vol.4, 2000.

[6] K.-B. Duan and S. S. Keerthi. Which is the best multiclass
svm method? an empirical study. In Multiple Classiﬁer Sys-
tems, pages 278–285. Springer, 2005.

[7] S. P. N. Bonneel, K. Sunkavalli and H. Pﬁster. Example-
based video color grading. ACM Transactions on Graphics
(Proc. ACM SIGGRAPH), vol. 32, no. 4., 2013.

[8] R. Rifkin and A. Klautau. In defense of one-vs-all classiﬁ-
cation. The Journal of Machine Learning Research, 5:101–
141, 2004.

[9] J. Schwiegerling. Field guide to visual and ophthalmic op-

tics. SPIE Bellingham, WA, USA, 2004.

[10] M. Solli and C. C. M. Solli. Linkping studies in science and
technology dissertations, no. 1362 color emotions in large
scale content based image indexing.

[11] C.-Y. Wei, N. Dimitrova, and S.-F. Chang. Color-mood anal-
ysis of ﬁlms based on syntactic and psychological models.
In Multimedia and Expo, 2004. ICME’04. 2004 IEEE Inter-
national Conference on, volume 2, pages 831–834. IEEE,
2004.

[12] S. Xue, A. Agarwala, J. Dorsey, and H. Rushmeier. Learn-
ing and applying color styles from feature ﬁlms. Computer
Graphics Forum, 32(7):255–264, 2013.

[13] H. Zhou, T. Hermans, A. V. Karandikar, and J. M. Rehg.
Movie genre classiﬁcation via scene categorization. In Pro-
ceedings of the 18th ACM International Conference on Mul-
timedia, MM ’10, pages 747–750, New York, NY, USA,
2010. ACM.

6

