How can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

How can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

stocks has 13534-day data from January 2, 1962 to
October 21, 2015. For cross validation purpose, I
used the ﬁrst 70% samples as training data set, and
the last 30% samples as validation data set.

2. (Movement trend 2): The second method is to
use K-means to classify the price diﬀerence into
two groups and label the group with large price
diﬀerence as 1 and the other group as −1.

The following steps were performed for data clean-

ing and normalization:

1. I ﬁrst cleaned the data to remove the entry with
incomplete or invalid information. For example,
some entries have 0 volume meaning that on that
day, there is no trading at all. Since the entries
with incomplete/invalid information are few, the
cleaning should not have impact on the model-
ing. The data was saved into a MongoDB, i.e.,
each stock as a collection and the trading infor-
mation on one single day as a document.

2. I developed a Python code to calculate a se-
rial of technical
indicators, e.g., accumula-
tion/distribution line, Aroon, Average direc-
tional index, BandWidth, %B indicator, and et
al.
[3] The moving average of historical prices
and some self-developed indicators are also cal-
culated. In total, there are 253 features in the
feature bag.

3. Since the magnitudes of features range from
O(0.1) to O(105), to avoid the model is dominant
by large magnitude features, all the features are
normalized with their mean and standard devi-
ation as the following formula,

f =

f − mean value of f
standard deviation of f

.

(1)

AA
0.0084

GE
0.0033

HPQ
0.0079

IBM
0.0080

Table 1: Price-diﬀerence boundary from K-means classi-
ﬁcation.

Since my objective is to predict price rises or falls,
to label data samples, I ﬁrst calculated price diﬀer-
ence by subtracting the present close price from the
next trading day close price. I labeled my data with
two methods.

1. (Movement trend 1): The ﬁrst method is to label
a sample as 1 if price diﬀerence is positive, i.e.,
the price raises on the next trading day and −1
if price diﬀerence is negative, i.e., the price falls.

Here, the second method with K-means model
is
equivalent to ﬁnd a new price-diﬀerence boundary to
label the data, whereas the price-diﬀerence bound-
ary in the ﬁrst method is 0. Table 1 lists the price-
diﬀerence boundary of the second method.

Figure 1: Correlation between features and price diﬀer-
ence of AA.

To understand the data, I checked the correlation
between the features and price diﬀerence. Figure 1
shows this correlation of AA as an example. In gen-
eral, there is no obvious strong correlation between
features and price diﬀerence. For the result shown
here, the correlation ranges from −0.03 to 0.04. Most
of the correlation is negative and their magnitude is
about 0.02. The correlation between the features and
price diﬀerence of the rest stocks showed the similar
variation and range.

4 Model

Quality

Assessment

Method

For two-class classiﬁcation problem, based on con-
fusion matrix, i.e., the number of true positive (TP),
true negative (TN), false positive (FP), and false neg-
ative (FN), many metrics are deﬁned to assess the
performance of a model. However, most of metrics
are not reliable. For example, accuracy will yield mis-
leading results if the number of samples in diﬀerent
classes are quite diﬀerent; F1 scores only considers
TP but no TN.

In the present project, I used Mattews correlation
coeﬃcient (MCC) to assess the performance of mod-

2

050100150200250Feature ID−0.04−0.03−0.02−0.010.000.010.020.030.040.05Correlation between price difference and featuresHow can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

stocks has 13534-day data from January 2, 1962 to
October 21, 2015. For cross validation purpose, I
used the ﬁrst 70% samples as training data set, and
the last 30% samples as validation data set.

2. (Movement trend 2): The second method is to
use K-means to classify the price diﬀerence into
two groups and label the group with large price
diﬀerence as 1 and the other group as −1.

The following steps were performed for data clean-

ing and normalization:

1. I ﬁrst cleaned the data to remove the entry with
incomplete or invalid information. For example,
some entries have 0 volume meaning that on that
day, there is no trading at all. Since the entries
with incomplete/invalid information are few, the
cleaning should not have impact on the model-
ing. The data was saved into a MongoDB, i.e.,
each stock as a collection and the trading infor-
mation on one single day as a document.

2. I developed a Python code to calculate a se-
rial of technical
indicators, e.g., accumula-
tion/distribution line, Aroon, Average direc-
tional index, BandWidth, %B indicator, and et
al.
[3] The moving average of historical prices
and some self-developed indicators are also cal-
culated. In total, there are 253 features in the
feature bag.

3. Since the magnitudes of features range from
O(0.1) to O(105), to avoid the model is dominant
by large magnitude features, all the features are
normalized with their mean and standard devi-
ation as the following formula,

f =

f − mean value of f
standard deviation of f

.

(1)

AA
0.0084

GE
0.0033

HPQ
0.0079

IBM
0.0080

Table 1: Price-diﬀerence boundary from K-means classi-
ﬁcation.

Since my objective is to predict price rises or falls,
to label data samples, I ﬁrst calculated price diﬀer-
ence by subtracting the present close price from the
next trading day close price. I labeled my data with
two methods.

1. (Movement trend 1): The ﬁrst method is to label
a sample as 1 if price diﬀerence is positive, i.e.,
the price raises on the next trading day and −1
if price diﬀerence is negative, i.e., the price falls.

Here, the second method with K-means model
is
equivalent to ﬁnd a new price-diﬀerence boundary to
label the data, whereas the price-diﬀerence bound-
ary in the ﬁrst method is 0. Table 1 lists the price-
diﬀerence boundary of the second method.

Figure 1: Correlation between features and price diﬀer-
ence of AA.

To understand the data, I checked the correlation
between the features and price diﬀerence. Figure 1
shows this correlation of AA as an example. In gen-
eral, there is no obvious strong correlation between
features and price diﬀerence. For the result shown
here, the correlation ranges from −0.03 to 0.04. Most
of the correlation is negative and their magnitude is
about 0.02. The correlation between the features and
price diﬀerence of the rest stocks showed the similar
variation and range.

4 Model

Quality

Assessment

Method

For two-class classiﬁcation problem, based on con-
fusion matrix, i.e., the number of true positive (TP),
true negative (TN), false positive (FP), and false neg-
ative (FN), many metrics are deﬁned to assess the
performance of a model. However, most of metrics
are not reliable. For example, accuracy will yield mis-
leading results if the number of samples in diﬀerent
classes are quite diﬀerent; F1 scores only considers
TP but no TN.

In the present project, I used Mattews correlation
coeﬃcient (MCC) to assess the performance of mod-

2

050100150200250Feature ID−0.04−0.03−0.02−0.010.000.010.020.030.040.05Correlation between price difference and features.

(a) Linear: < x, x(cid:48) >
(b) Polynomial: (γ < x, x(cid:48) > +r)d
(c) RBF: exp(−γ|x − x(cid:48)|2
(d) Sigmoid: tanh(γ < x, x(cid:48) > +r)

3. Random forest classiﬁcation model is an ensem-
ble learning method for classiﬁcation. Random
forest model is to train several decision trees
with a random subset of features (feature bag-
ging) and a random sample with replacement of
training sets [4]. The prediction of random for-
est models takes the average of all the decision
tree prediction or the majority vote of all the de-
cision trees in the model. Because random forest
model takes the average result, it decreases the
variance in decision trees prediction.

6 Feature Selection

As introduced in Sec. 3, there are 253 features
in the initial feature bag.
I wanted to know if all
the features are important and if I can use only sub-
set of features without losing prediction accuracy. In
the present project, I applied two feature selection
techniques, i.e., random forest feature selection and
forward search.
6.1 Random forest feature selection

Random forest model can provide ranking scores
for features. The larger the ranking score is, the more
important the feature is. To obtain the ranking sore
of a feature, one needs to: ﬁrst, obtain the average
value of out-of-bag error; second, permute the feature
among the training data and obtain a second out-of-
bag error; and the ranking score is proportional to the
diﬀerence between the two out-of-bag errors.

els [8]. MCC is deﬁned as

(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

T P × T N − F P × F N

M CC =

(2)
As shown, MCC takes into account all the compo-
nents in confusion matrix and is a general balance
measurement regardless the sample number variation
of diﬀerent classes. MCC can be considered as a
“correlation” between predicted value and true value,
i.e.,

1. M CC = 1 means all predictions are right.

2. M CC = 0 means model prediction is no better

than random prediction.

3. M CC = −1 means no prediction is right.
Therefore, the objective of the project is to ﬁnd the
models with the highest MCC value.

5 Models
In this project, I applied logistical regression, SVM,
and random forest models. Due to the space limita-
tion, I brieﬂy introduce them below.

1. Logistical regression is a linear model for classi-

ﬁcation. The hypothese is written as

hθ(x) =

1

1 + e−θT x

.

(3)

To improve the performance of the model, two
cost functions are considered, i.e., L2 penalized
cost function:

min
θ,C

1
2

θT θ + CΣn

i=1 log[exp(−yiθT xi) + 1],

(4)

and L1 penalized cost function:

(cid:107)θ(cid:107)1 + CΣn

i=1 log[exp(−yiθT xi) + 1].

(5)

min
θ,C

2. For SVM model, since the sample set is not lin-

early separable, the primal problem is:

1
2

wT w + CΣn

min
w,b,ζ

(6)
subject to yi(wT φ(xi) + b ≥ 1 − ζi, ζi ≥ 0, i =
1, ..., n. Its dual is

i=1ζi,

Σiαi − 1
2

α

max

ΣiΣjyiyjK(xi, xj),

(7)
subject to yT α = 0, 0 ≤ αi ≤ C, i = 1, ..., n.
Here, K(xi, xj) = φ(xi)T φ(xj). I considered the
following kernel functions:

Figure 2: Variation of validation MCC values when fea-
tures are added gradually in the order of feature ranking
from random forest model.

To check if all the features are important, I grad-
ually added features into feature bags according to

3

050100150200250Feature No.−0.04−0.020.000.020.040.060.08Validation MCCAAGEHPQIBMHow can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

stocks has 13534-day data from January 2, 1962 to
October 21, 2015. For cross validation purpose, I
used the ﬁrst 70% samples as training data set, and
the last 30% samples as validation data set.

2. (Movement trend 2): The second method is to
use K-means to classify the price diﬀerence into
two groups and label the group with large price
diﬀerence as 1 and the other group as −1.

The following steps were performed for data clean-

ing and normalization:

1. I ﬁrst cleaned the data to remove the entry with
incomplete or invalid information. For example,
some entries have 0 volume meaning that on that
day, there is no trading at all. Since the entries
with incomplete/invalid information are few, the
cleaning should not have impact on the model-
ing. The data was saved into a MongoDB, i.e.,
each stock as a collection and the trading infor-
mation on one single day as a document.

2. I developed a Python code to calculate a se-
rial of technical
indicators, e.g., accumula-
tion/distribution line, Aroon, Average direc-
tional index, BandWidth, %B indicator, and et
al.
[3] The moving average of historical prices
and some self-developed indicators are also cal-
culated. In total, there are 253 features in the
feature bag.

3. Since the magnitudes of features range from
O(0.1) to O(105), to avoid the model is dominant
by large magnitude features, all the features are
normalized with their mean and standard devi-
ation as the following formula,

f =

f − mean value of f
standard deviation of f

.

(1)

AA
0.0084

GE
0.0033

HPQ
0.0079

IBM
0.0080

Table 1: Price-diﬀerence boundary from K-means classi-
ﬁcation.

Since my objective is to predict price rises or falls,
to label data samples, I ﬁrst calculated price diﬀer-
ence by subtracting the present close price from the
next trading day close price. I labeled my data with
two methods.

1. (Movement trend 1): The ﬁrst method is to label
a sample as 1 if price diﬀerence is positive, i.e.,
the price raises on the next trading day and −1
if price diﬀerence is negative, i.e., the price falls.

Here, the second method with K-means model
is
equivalent to ﬁnd a new price-diﬀerence boundary to
label the data, whereas the price-diﬀerence bound-
ary in the ﬁrst method is 0. Table 1 lists the price-
diﬀerence boundary of the second method.

Figure 1: Correlation between features and price diﬀer-
ence of AA.

To understand the data, I checked the correlation
between the features and price diﬀerence. Figure 1
shows this correlation of AA as an example. In gen-
eral, there is no obvious strong correlation between
features and price diﬀerence. For the result shown
here, the correlation ranges from −0.03 to 0.04. Most
of the correlation is negative and their magnitude is
about 0.02. The correlation between the features and
price diﬀerence of the rest stocks showed the similar
variation and range.

4 Model

Quality

Assessment

Method

For two-class classiﬁcation problem, based on con-
fusion matrix, i.e., the number of true positive (TP),
true negative (TN), false positive (FP), and false neg-
ative (FN), many metrics are deﬁned to assess the
performance of a model. However, most of metrics
are not reliable. For example, accuracy will yield mis-
leading results if the number of samples in diﬀerent
classes are quite diﬀerent; F1 scores only considers
TP but no TN.

In the present project, I used Mattews correlation
coeﬃcient (MCC) to assess the performance of mod-

2

050100150200250Feature ID−0.04−0.03−0.02−0.010.000.010.020.030.040.05Correlation between price difference and features.

(a) Linear: < x, x(cid:48) >
(b) Polynomial: (γ < x, x(cid:48) > +r)d
(c) RBF: exp(−γ|x − x(cid:48)|2
(d) Sigmoid: tanh(γ < x, x(cid:48) > +r)

3. Random forest classiﬁcation model is an ensem-
ble learning method for classiﬁcation. Random
forest model is to train several decision trees
with a random subset of features (feature bag-
ging) and a random sample with replacement of
training sets [4]. The prediction of random for-
est models takes the average of all the decision
tree prediction or the majority vote of all the de-
cision trees in the model. Because random forest
model takes the average result, it decreases the
variance in decision trees prediction.

6 Feature Selection

As introduced in Sec. 3, there are 253 features
in the initial feature bag.
I wanted to know if all
the features are important and if I can use only sub-
set of features without losing prediction accuracy. In
the present project, I applied two feature selection
techniques, i.e., random forest feature selection and
forward search.
6.1 Random forest feature selection

Random forest model can provide ranking scores
for features. The larger the ranking score is, the more
important the feature is. To obtain the ranking sore
of a feature, one needs to: ﬁrst, obtain the average
value of out-of-bag error; second, permute the feature
among the training data and obtain a second out-of-
bag error; and the ranking score is proportional to the
diﬀerence between the two out-of-bag errors.

els [8]. MCC is deﬁned as

(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

T P × T N − F P × F N

M CC =

(2)
As shown, MCC takes into account all the compo-
nents in confusion matrix and is a general balance
measurement regardless the sample number variation
of diﬀerent classes. MCC can be considered as a
“correlation” between predicted value and true value,
i.e.,

1. M CC = 1 means all predictions are right.

2. M CC = 0 means model prediction is no better

than random prediction.

3. M CC = −1 means no prediction is right.
Therefore, the objective of the project is to ﬁnd the
models with the highest MCC value.

5 Models
In this project, I applied logistical regression, SVM,
and random forest models. Due to the space limita-
tion, I brieﬂy introduce them below.

1. Logistical regression is a linear model for classi-

ﬁcation. The hypothese is written as

hθ(x) =

1

1 + e−θT x

.

(3)

To improve the performance of the model, two
cost functions are considered, i.e., L2 penalized
cost function:

min
θ,C

1
2

θT θ + CΣn

i=1 log[exp(−yiθT xi) + 1],

(4)

and L1 penalized cost function:

(cid:107)θ(cid:107)1 + CΣn

i=1 log[exp(−yiθT xi) + 1].

(5)

min
θ,C

2. For SVM model, since the sample set is not lin-

early separable, the primal problem is:

1
2

wT w + CΣn

min
w,b,ζ

(6)
subject to yi(wT φ(xi) + b ≥ 1 − ζi, ζi ≥ 0, i =
1, ..., n. Its dual is

i=1ζi,

Σiαi − 1
2

α

max

ΣiΣjyiyjK(xi, xj),

(7)
subject to yT α = 0, 0 ≤ αi ≤ C, i = 1, ..., n.
Here, K(xi, xj) = φ(xi)T φ(xj). I considered the
following kernel functions:

Figure 2: Variation of validation MCC values when fea-
tures are added gradually in the order of feature ranking
from random forest model.

To check if all the features are important, I grad-
ually added features into feature bags according to

3

050100150200250Feature No.−0.04−0.020.000.020.040.060.08Validation MCCAAGEHPQIBMtheir ranking scores (important feature is added
ﬁrst), trained the model, and obtained the MCC
value of the validation sample set. Figure 2 plots
the variation of validation MCC value when less im-
portant features are gradually added to the feature
bag.
It shows that in general, the validation MCC
value ﬁrst increases as the feature number increases;
with some magic feature combination, the validation
MCC value reaches its maximum; and then the val-
idation MCC value decreases as the feature number
increases. Comparison among the results of all the
stocks shows that when the validation MCC value
reaches its maximum, the feature combination is dif-
ferent for diﬀerent stocks. For example, GE and HPQ
only needs less than 50 features to reach the maxi-
mum validation MCC value, whereas AA and IBM
needs much more than that. Based on this result, I
chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.
6.2 Forward search

Forward search is a feature selection algorithm to
reduce the number of features. The search procedure
of the forward search is introduced in lecture note
and is not repeated here.

Figure 3: History of the best validation MCC values in
forward search with logistical regression.

In the present project, I applied forward search
with logistical regression. Figure 3 plots the history
of the best validation MCC values in the forward
search. In general, as the feature number increases,
the best validation MCC value increases dramatically
ﬁrst, varies slowly and reaches a maximum value in
the middle, and decreases rapidly when the feature
bag is almost full. Similar to the random forest fea-
ture selection result shown in Sec. 6.1, the validation

4

MCC value of diﬀerent stocks reaches its maximum
with diﬀerent feature combinations. For each stock,
I chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.

7 Model Training and Result Dis-

cussion

In this section, I explained my procedure to train

model and discussed the prediction result.
7.1 Grid search and model training

When I trained models, I applied grid search by
searching a parameter space to ﬁnd the model with
the best performance. For example, for logistical re-
gression, as introduced in Sec. 5, there are two types
of cost functions and a parameter C. I trained model
candidates on two grids: one is with L1 penalized cost
function and C values in [0.001, 0.01, 0.1, 1, 10, 100]
and the second one is with L2 penalized cost func-
tion and C values in [0.001, 0.01, 0.1, 1, 10, 100]. Af-
ter the best model candidate is found, I kept the cost
function unchanged and search C in a smaller range
around the C value of the best candidate; and re-
peated this process until the validation MCC value
does not change much in the neighborhood of the
current best C value. Similar search procedure is
also applied to SVM and random forest.

More speciﬁcally, for each stock, I ﬁrst used all the
features and trained logistical regression model with
L2 penalized cost function and C = 1. This model is
considered as a baseline model. Then I applied grid
search technique to ﬁnd the model with the best per-
formance. The best model candidates by using all the
features, features selected by random forest, and fea-
tures selected by forward search are obtained.
7.2 Result and discussion

Table 2 and table 3 list the result of the base-
line model and the best model for the sample set la-
beled by movement trend 1 and 2 (deﬁned in Sec. 3),
respectively. The best models trained with all the
features, feature selected by random forest, and fea-
ture selected by logistical regression forward search
are listed.

Comparing to the baseline model, model perfor-
mance has been improved signiﬁcantly with the help
of grid search and feature selection techniques. For

050100150200250Feature No.−0.020.000.020.040.060.080.100.120.14Validation MCCAAGEHPQIBMHow can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

stocks has 13534-day data from January 2, 1962 to
October 21, 2015. For cross validation purpose, I
used the ﬁrst 70% samples as training data set, and
the last 30% samples as validation data set.

2. (Movement trend 2): The second method is to
use K-means to classify the price diﬀerence into
two groups and label the group with large price
diﬀerence as 1 and the other group as −1.

The following steps were performed for data clean-

ing and normalization:

1. I ﬁrst cleaned the data to remove the entry with
incomplete or invalid information. For example,
some entries have 0 volume meaning that on that
day, there is no trading at all. Since the entries
with incomplete/invalid information are few, the
cleaning should not have impact on the model-
ing. The data was saved into a MongoDB, i.e.,
each stock as a collection and the trading infor-
mation on one single day as a document.

2. I developed a Python code to calculate a se-
rial of technical
indicators, e.g., accumula-
tion/distribution line, Aroon, Average direc-
tional index, BandWidth, %B indicator, and et
al.
[3] The moving average of historical prices
and some self-developed indicators are also cal-
culated. In total, there are 253 features in the
feature bag.

3. Since the magnitudes of features range from
O(0.1) to O(105), to avoid the model is dominant
by large magnitude features, all the features are
normalized with their mean and standard devi-
ation as the following formula,

f =

f − mean value of f
standard deviation of f

.

(1)

AA
0.0084

GE
0.0033

HPQ
0.0079

IBM
0.0080

Table 1: Price-diﬀerence boundary from K-means classi-
ﬁcation.

Since my objective is to predict price rises or falls,
to label data samples, I ﬁrst calculated price diﬀer-
ence by subtracting the present close price from the
next trading day close price. I labeled my data with
two methods.

1. (Movement trend 1): The ﬁrst method is to label
a sample as 1 if price diﬀerence is positive, i.e.,
the price raises on the next trading day and −1
if price diﬀerence is negative, i.e., the price falls.

Here, the second method with K-means model
is
equivalent to ﬁnd a new price-diﬀerence boundary to
label the data, whereas the price-diﬀerence bound-
ary in the ﬁrst method is 0. Table 1 lists the price-
diﬀerence boundary of the second method.

Figure 1: Correlation between features and price diﬀer-
ence of AA.

To understand the data, I checked the correlation
between the features and price diﬀerence. Figure 1
shows this correlation of AA as an example. In gen-
eral, there is no obvious strong correlation between
features and price diﬀerence. For the result shown
here, the correlation ranges from −0.03 to 0.04. Most
of the correlation is negative and their magnitude is
about 0.02. The correlation between the features and
price diﬀerence of the rest stocks showed the similar
variation and range.

4 Model

Quality

Assessment

Method

For two-class classiﬁcation problem, based on con-
fusion matrix, i.e., the number of true positive (TP),
true negative (TN), false positive (FP), and false neg-
ative (FN), many metrics are deﬁned to assess the
performance of a model. However, most of metrics
are not reliable. For example, accuracy will yield mis-
leading results if the number of samples in diﬀerent
classes are quite diﬀerent; F1 scores only considers
TP but no TN.

In the present project, I used Mattews correlation
coeﬃcient (MCC) to assess the performance of mod-

2

050100150200250Feature ID−0.04−0.03−0.02−0.010.000.010.020.030.040.05Correlation between price difference and features.

(a) Linear: < x, x(cid:48) >
(b) Polynomial: (γ < x, x(cid:48) > +r)d
(c) RBF: exp(−γ|x − x(cid:48)|2
(d) Sigmoid: tanh(γ < x, x(cid:48) > +r)

3. Random forest classiﬁcation model is an ensem-
ble learning method for classiﬁcation. Random
forest model is to train several decision trees
with a random subset of features (feature bag-
ging) and a random sample with replacement of
training sets [4]. The prediction of random for-
est models takes the average of all the decision
tree prediction or the majority vote of all the de-
cision trees in the model. Because random forest
model takes the average result, it decreases the
variance in decision trees prediction.

6 Feature Selection

As introduced in Sec. 3, there are 253 features
in the initial feature bag.
I wanted to know if all
the features are important and if I can use only sub-
set of features without losing prediction accuracy. In
the present project, I applied two feature selection
techniques, i.e., random forest feature selection and
forward search.
6.1 Random forest feature selection

Random forest model can provide ranking scores
for features. The larger the ranking score is, the more
important the feature is. To obtain the ranking sore
of a feature, one needs to: ﬁrst, obtain the average
value of out-of-bag error; second, permute the feature
among the training data and obtain a second out-of-
bag error; and the ranking score is proportional to the
diﬀerence between the two out-of-bag errors.

els [8]. MCC is deﬁned as

(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

T P × T N − F P × F N

M CC =

(2)
As shown, MCC takes into account all the compo-
nents in confusion matrix and is a general balance
measurement regardless the sample number variation
of diﬀerent classes. MCC can be considered as a
“correlation” between predicted value and true value,
i.e.,

1. M CC = 1 means all predictions are right.

2. M CC = 0 means model prediction is no better

than random prediction.

3. M CC = −1 means no prediction is right.
Therefore, the objective of the project is to ﬁnd the
models with the highest MCC value.

5 Models
In this project, I applied logistical regression, SVM,
and random forest models. Due to the space limita-
tion, I brieﬂy introduce them below.

1. Logistical regression is a linear model for classi-

ﬁcation. The hypothese is written as

hθ(x) =

1

1 + e−θT x

.

(3)

To improve the performance of the model, two
cost functions are considered, i.e., L2 penalized
cost function:

min
θ,C

1
2

θT θ + CΣn

i=1 log[exp(−yiθT xi) + 1],

(4)

and L1 penalized cost function:

(cid:107)θ(cid:107)1 + CΣn

i=1 log[exp(−yiθT xi) + 1].

(5)

min
θ,C

2. For SVM model, since the sample set is not lin-

early separable, the primal problem is:

1
2

wT w + CΣn

min
w,b,ζ

(6)
subject to yi(wT φ(xi) + b ≥ 1 − ζi, ζi ≥ 0, i =
1, ..., n. Its dual is

i=1ζi,

Σiαi − 1
2

α

max

ΣiΣjyiyjK(xi, xj),

(7)
subject to yT α = 0, 0 ≤ αi ≤ C, i = 1, ..., n.
Here, K(xi, xj) = φ(xi)T φ(xj). I considered the
following kernel functions:

Figure 2: Variation of validation MCC values when fea-
tures are added gradually in the order of feature ranking
from random forest model.

To check if all the features are important, I grad-
ually added features into feature bags according to

3

050100150200250Feature No.−0.04−0.020.000.020.040.060.08Validation MCCAAGEHPQIBMtheir ranking scores (important feature is added
ﬁrst), trained the model, and obtained the MCC
value of the validation sample set. Figure 2 plots
the variation of validation MCC value when less im-
portant features are gradually added to the feature
bag.
It shows that in general, the validation MCC
value ﬁrst increases as the feature number increases;
with some magic feature combination, the validation
MCC value reaches its maximum; and then the val-
idation MCC value decreases as the feature number
increases. Comparison among the results of all the
stocks shows that when the validation MCC value
reaches its maximum, the feature combination is dif-
ferent for diﬀerent stocks. For example, GE and HPQ
only needs less than 50 features to reach the maxi-
mum validation MCC value, whereas AA and IBM
needs much more than that. Based on this result, I
chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.
6.2 Forward search

Forward search is a feature selection algorithm to
reduce the number of features. The search procedure
of the forward search is introduced in lecture note
and is not repeated here.

Figure 3: History of the best validation MCC values in
forward search with logistical regression.

In the present project, I applied forward search
with logistical regression. Figure 3 plots the history
of the best validation MCC values in the forward
search. In general, as the feature number increases,
the best validation MCC value increases dramatically
ﬁrst, varies slowly and reaches a maximum value in
the middle, and decreases rapidly when the feature
bag is almost full. Similar to the random forest fea-
ture selection result shown in Sec. 6.1, the validation

4

MCC value of diﬀerent stocks reaches its maximum
with diﬀerent feature combinations. For each stock,
I chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.

7 Model Training and Result Dis-

cussion

In this section, I explained my procedure to train

model and discussed the prediction result.
7.1 Grid search and model training

When I trained models, I applied grid search by
searching a parameter space to ﬁnd the model with
the best performance. For example, for logistical re-
gression, as introduced in Sec. 5, there are two types
of cost functions and a parameter C. I trained model
candidates on two grids: one is with L1 penalized cost
function and C values in [0.001, 0.01, 0.1, 1, 10, 100]
and the second one is with L2 penalized cost func-
tion and C values in [0.001, 0.01, 0.1, 1, 10, 100]. Af-
ter the best model candidate is found, I kept the cost
function unchanged and search C in a smaller range
around the C value of the best candidate; and re-
peated this process until the validation MCC value
does not change much in the neighborhood of the
current best C value. Similar search procedure is
also applied to SVM and random forest.

More speciﬁcally, for each stock, I ﬁrst used all the
features and trained logistical regression model with
L2 penalized cost function and C = 1. This model is
considered as a baseline model. Then I applied grid
search technique to ﬁnd the model with the best per-
formance. The best model candidates by using all the
features, features selected by random forest, and fea-
tures selected by forward search are obtained.
7.2 Result and discussion

Table 2 and table 3 list the result of the base-
line model and the best model for the sample set la-
beled by movement trend 1 and 2 (deﬁned in Sec. 3),
respectively. The best models trained with all the
features, feature selected by random forest, and fea-
ture selected by logistical regression forward search
are listed.

Comparing to the baseline model, model perfor-
mance has been improved signiﬁcantly with the help
of grid search and feature selection techniques. For

050100150200250Feature No.−0.020.000.020.040.060.080.100.120.14Validation MCCAAGEHPQIBMbaseline

Val. MCC

-0.0012
-0.0040
-0.014
0.063

AA
GE
HPQ
IBM

All features

RF feature selection

Forward search (LR)

Model

RF

SVM (lin.)

LR
LR

Best Val. MCC

Model

Feature No.

Best Val. MCC

Feature No.

Best Val. MCC

0.052
0.062
0.053
0.10

SVM (RBF)
SVM (RBF)
SVM (lin.)
SVM (RBF)

129
22
47
183

0.019
0.092
0.053
0.11

191
23
30
228

0.072
0.091
0.071
0.084

Table 2: Baseline and best models for the movement trend 1 with feature numbers and best validation MCC.

baseline

All features

RF feature selection

Forward search (LR)

Val. MCC Model

Best Val. MCC

Model

Feature No.

Best Val. MCC

Feature No.

Best Val. MCC

AA
GE
HPQ
IBM
Table 3: Baseline and best models for the movement trend 2 with feature numbers and best validation MCC.

0.0054
0.063
0.15
0.069

0.051
0.13
0.15
0.14

0.079
0.15
0.16
0.10

SVM (Sig.)

LR
LR
LR

43
43
149
85

LR
LR
LR
LR

120
91
36
97

0.11
0.17
0.17
0.15

example, for GE in table 2, the validation MCC value
increases from −0.004 (baseline) to 0.092 (note that
negative MCC value means the model prediction is
worst than random prediction).

Comparing the baseline model with the best model
using all the features of HPQ and IBM in table 2 and
all the stocks in table 3, we can see the grid search
technique helps to ﬁnd better model and largely im-
proves model performance. I also found that the best
model candidate is much diﬀerent among the four
stocks. In table 3, even if all the best models using
all the features are logistical regression, their actual
model forms (i.e., cost function and C value) are quite
diﬀerent (the information on detailed model form is
omitted here due to space limitation). This result
is consistent with previous research that to have the
best prediction, one needs to train models for each
stock instead of train one model using the data of all
stocks [5].

In general, the best models with features selected
by random forest and forward search have better per-
formance than those with all the features. That
means each stocks may be only sensitive to certain
feature combination. The models in table 3 have bet-
ter performance than those in table 2. Hence, a good
data label algorithm is important to the prediction
accuracy.

Metric

F1

recall

precision
accuracy

Baseline model

Best model

0.345
0.391
0.309
0.546

0.399
0.419
0.381
0.615

Table 4: Validation F1 score, recall, precision, and accu-
racy of the baseline and best model of AA in table 3.

To further show model performance improvement,
in table 4, I listed the validation F1 score, recall, pre-
cision, and accuracy of the baseline and best models
of AA in table 3 as an example (the deﬁnitions of

Figure 4: Learning curve of the best logistical regression
model for IBM.

those metrics are omitted here, due to space limita-
tion). Grid search and feature selection techniques
improve not only MCC value but also other metrics
derived from confusion matrix.

In ﬁgure 4, I showed the learning curve of the best
logistical regression model for IBM with samples la-
beled by movement trend 2. The training and vali-
dation error converges to a similar value. If we want
to further improve the model performance, we need
more informative features.

8 Summary and Future Work

In summary,

1. Models with best validation MCC are built up
based on current feature set with the help of grid
search, random forest feature selection, and for-
ward search techniques. MCC and other metrics
are signiﬁcantly improved.

2. Stock prediction is quite feature and stock de-
pendent. Diﬀerent feature subsets and diﬀerent
models are best for diﬀerent stocks.

3. A good classiﬁcation model to label sample may

help to increase prediction accuracy.

4. For more accurate prediction, more features are

needed to provide more useful information.

5

02000400060008000Train data No.0.40.50.60.70.80.91.01.11-MCCTrainValidationHow can machine learning help stock

investment?

Xin Guo

Email: guoxin@stanford.edu

1 Introduction

The million-dollar question for stock investors is
if the price of a stock will rise or not. The ﬂuctu-
ation of stock market is violent and there are many
complicated ﬁnancial indicators. Only people with
extensive experience and knowledge can understand
the meaning of the indicators, use them to make good
prediction to get fortune. Most of other people can
only rely on lucky to earn money from stock trad-
ing. Machine learning is an opportunity for ordinary
people to gain steady fortune from stock market and
also can help experts to dig out the most informative
indicators and make better prediction.

The purpose of the present project is to investigate
the modeling of stock price movement trend and build
up models to predict if the close price of a stock rises
or falls on the next trading day. The problem belongs
to a classiﬁcation problem.

The input to my algorithm includes: 1. mov-
ing average of historical close prices; 2. trading vol-
ume, and open, highest, lowest, and close prices of
the present trading day; 3. ﬁnancial indicators, e.g.,
DecisionPoint Price Momentum Oscillator (PMO),
Money Flow Index (MFI), Percentage Price Oscilla-
tor (PPO), and et al. [3]; and 4. self-developed price
movement trend based on local Taylor expansion and
spline ﬁtting. Totally, there are 253 features in the
initial feature bag.
I then trained logistical regres-
sion, support vector machine (SVM), and Random
Forest models to predict the close price rises or falls
on the next trading day, e.g., 1 means stock price
will rise on the next trading day, −1 means stock
price will fall.

In this project, I used Python (e.g., SciPy [2]) and

MongoDB [1] for calculation and data storage.

2 Related Work

Stock prediction is a complicated and challenging
problem. Most researchers focus on stock selection
problem and the prediction of stock return.

Refenes et al. [9] applied neural networks to pre-

dict stock performance. They found that even simple
neural learning procedures showed better prediction
accuracy than classic statistical techniques, e.g., mul-
tiple linear regression. They also claimed that with
careful network design, model performance can be
further improved.

Levin [7] designed a multilayer feedforward neural
networks to select stocks. He showed that his model
can make good prediction even if data is contami-
nated by large ratio of noise.

Ghosn and Bengio [5] also investigated artiﬁcial
neural networks to predict future returns of stocks.
With a serials of experiments, they concluded that
artiﬁcial neural networks have the best performance,
when the neural networks for diﬀerent stocks do not
share any parameter or only share some parameters.
In another word, to get the best prediction, one al-
ways needs to train model speciﬁcally for each stock
and there is no universal model for all the stocks with
the best performance.

Tsai et al. [10] examined the performance of clas-
siﬁer ensembles on the prediction of stock return and
made comparison with single classiﬁers,
i.e., neu-
ral networks, decision trees, and logistic regression.
They studied the impact of diﬀerent types of classiﬁer
ensembles and majority voting and bagging. They
concluded that in general, classiﬁer ensembles per-
form better than single classiﬁer.

Leung et al. [6] compared the forecasting perfor-
mance of classiﬁcation models to predict the direction
of index return and level estimation models to predict
the value of the return. They concluded that classiﬁ-
cation models always perform better than level esti-
mation models. They also showed that the forecast-
ing from classiﬁcation model can be used to develop
trading strategies for more trading proﬁts.

3 Dataset and Features

The data for the present project was downloaded
from quandl.com through API. The initial data in-
cludes daily stock open, highest, lowest, and close
prices, volume, dividend, and split ratio.
I chose
to focus on 4 stocks with the longest data history,
i.e., American Airline (AA), General Electric (GE),
Hewlett-Packard Company (HPQ), and International
Business Machines Corporation (IBM). Each of the

1

stocks has 13534-day data from January 2, 1962 to
October 21, 2015. For cross validation purpose, I
used the ﬁrst 70% samples as training data set, and
the last 30% samples as validation data set.

2. (Movement trend 2): The second method is to
use K-means to classify the price diﬀerence into
two groups and label the group with large price
diﬀerence as 1 and the other group as −1.

The following steps were performed for data clean-

ing and normalization:

1. I ﬁrst cleaned the data to remove the entry with
incomplete or invalid information. For example,
some entries have 0 volume meaning that on that
day, there is no trading at all. Since the entries
with incomplete/invalid information are few, the
cleaning should not have impact on the model-
ing. The data was saved into a MongoDB, i.e.,
each stock as a collection and the trading infor-
mation on one single day as a document.

2. I developed a Python code to calculate a se-
rial of technical
indicators, e.g., accumula-
tion/distribution line, Aroon, Average direc-
tional index, BandWidth, %B indicator, and et
al.
[3] The moving average of historical prices
and some self-developed indicators are also cal-
culated. In total, there are 253 features in the
feature bag.

3. Since the magnitudes of features range from
O(0.1) to O(105), to avoid the model is dominant
by large magnitude features, all the features are
normalized with their mean and standard devi-
ation as the following formula,

f =

f − mean value of f
standard deviation of f

.

(1)

AA
0.0084

GE
0.0033

HPQ
0.0079

IBM
0.0080

Table 1: Price-diﬀerence boundary from K-means classi-
ﬁcation.

Since my objective is to predict price rises or falls,
to label data samples, I ﬁrst calculated price diﬀer-
ence by subtracting the present close price from the
next trading day close price. I labeled my data with
two methods.

1. (Movement trend 1): The ﬁrst method is to label
a sample as 1 if price diﬀerence is positive, i.e.,
the price raises on the next trading day and −1
if price diﬀerence is negative, i.e., the price falls.

Here, the second method with K-means model
is
equivalent to ﬁnd a new price-diﬀerence boundary to
label the data, whereas the price-diﬀerence bound-
ary in the ﬁrst method is 0. Table 1 lists the price-
diﬀerence boundary of the second method.

Figure 1: Correlation between features and price diﬀer-
ence of AA.

To understand the data, I checked the correlation
between the features and price diﬀerence. Figure 1
shows this correlation of AA as an example. In gen-
eral, there is no obvious strong correlation between
features and price diﬀerence. For the result shown
here, the correlation ranges from −0.03 to 0.04. Most
of the correlation is negative and their magnitude is
about 0.02. The correlation between the features and
price diﬀerence of the rest stocks showed the similar
variation and range.

4 Model

Quality

Assessment

Method

For two-class classiﬁcation problem, based on con-
fusion matrix, i.e., the number of true positive (TP),
true negative (TN), false positive (FP), and false neg-
ative (FN), many metrics are deﬁned to assess the
performance of a model. However, most of metrics
are not reliable. For example, accuracy will yield mis-
leading results if the number of samples in diﬀerent
classes are quite diﬀerent; F1 scores only considers
TP but no TN.

In the present project, I used Mattews correlation
coeﬃcient (MCC) to assess the performance of mod-

2

050100150200250Feature ID−0.04−0.03−0.02−0.010.000.010.020.030.040.05Correlation between price difference and features.

(a) Linear: < x, x(cid:48) >
(b) Polynomial: (γ < x, x(cid:48) > +r)d
(c) RBF: exp(−γ|x − x(cid:48)|2
(d) Sigmoid: tanh(γ < x, x(cid:48) > +r)

3. Random forest classiﬁcation model is an ensem-
ble learning method for classiﬁcation. Random
forest model is to train several decision trees
with a random subset of features (feature bag-
ging) and a random sample with replacement of
training sets [4]. The prediction of random for-
est models takes the average of all the decision
tree prediction or the majority vote of all the de-
cision trees in the model. Because random forest
model takes the average result, it decreases the
variance in decision trees prediction.

6 Feature Selection

As introduced in Sec. 3, there are 253 features
in the initial feature bag.
I wanted to know if all
the features are important and if I can use only sub-
set of features without losing prediction accuracy. In
the present project, I applied two feature selection
techniques, i.e., random forest feature selection and
forward search.
6.1 Random forest feature selection

Random forest model can provide ranking scores
for features. The larger the ranking score is, the more
important the feature is. To obtain the ranking sore
of a feature, one needs to: ﬁrst, obtain the average
value of out-of-bag error; second, permute the feature
among the training data and obtain a second out-of-
bag error; and the ranking score is proportional to the
diﬀerence between the two out-of-bag errors.

els [8]. MCC is deﬁned as

(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

T P × T N − F P × F N

M CC =

(2)
As shown, MCC takes into account all the compo-
nents in confusion matrix and is a general balance
measurement regardless the sample number variation
of diﬀerent classes. MCC can be considered as a
“correlation” between predicted value and true value,
i.e.,

1. M CC = 1 means all predictions are right.

2. M CC = 0 means model prediction is no better

than random prediction.

3. M CC = −1 means no prediction is right.
Therefore, the objective of the project is to ﬁnd the
models with the highest MCC value.

5 Models
In this project, I applied logistical regression, SVM,
and random forest models. Due to the space limita-
tion, I brieﬂy introduce them below.

1. Logistical regression is a linear model for classi-

ﬁcation. The hypothese is written as

hθ(x) =

1

1 + e−θT x

.

(3)

To improve the performance of the model, two
cost functions are considered, i.e., L2 penalized
cost function:

min
θ,C

1
2

θT θ + CΣn

i=1 log[exp(−yiθT xi) + 1],

(4)

and L1 penalized cost function:

(cid:107)θ(cid:107)1 + CΣn

i=1 log[exp(−yiθT xi) + 1].

(5)

min
θ,C

2. For SVM model, since the sample set is not lin-

early separable, the primal problem is:

1
2

wT w + CΣn

min
w,b,ζ

(6)
subject to yi(wT φ(xi) + b ≥ 1 − ζi, ζi ≥ 0, i =
1, ..., n. Its dual is

i=1ζi,

Σiαi − 1
2

α

max

ΣiΣjyiyjK(xi, xj),

(7)
subject to yT α = 0, 0 ≤ αi ≤ C, i = 1, ..., n.
Here, K(xi, xj) = φ(xi)T φ(xj). I considered the
following kernel functions:

Figure 2: Variation of validation MCC values when fea-
tures are added gradually in the order of feature ranking
from random forest model.

To check if all the features are important, I grad-
ually added features into feature bags according to

3

050100150200250Feature No.−0.04−0.020.000.020.040.060.08Validation MCCAAGEHPQIBMtheir ranking scores (important feature is added
ﬁrst), trained the model, and obtained the MCC
value of the validation sample set. Figure 2 plots
the variation of validation MCC value when less im-
portant features are gradually added to the feature
bag.
It shows that in general, the validation MCC
value ﬁrst increases as the feature number increases;
with some magic feature combination, the validation
MCC value reaches its maximum; and then the val-
idation MCC value decreases as the feature number
increases. Comparison among the results of all the
stocks shows that when the validation MCC value
reaches its maximum, the feature combination is dif-
ferent for diﬀerent stocks. For example, GE and HPQ
only needs less than 50 features to reach the maxi-
mum validation MCC value, whereas AA and IBM
needs much more than that. Based on this result, I
chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.
6.2 Forward search

Forward search is a feature selection algorithm to
reduce the number of features. The search procedure
of the forward search is introduced in lecture note
and is not repeated here.

Figure 3: History of the best validation MCC values in
forward search with logistical regression.

In the present project, I applied forward search
with logistical regression. Figure 3 plots the history
of the best validation MCC values in the forward
search. In general, as the feature number increases,
the best validation MCC value increases dramatically
ﬁrst, varies slowly and reaches a maximum value in
the middle, and decreases rapidly when the feature
bag is almost full. Similar to the random forest fea-
ture selection result shown in Sec. 6.1, the validation

4

MCC value of diﬀerent stocks reaches its maximum
with diﬀerent feature combinations. For each stock,
I chose the feature combination with the best valida-
tion MCC value to further train and ﬁnetune models.
The feature number of the best candidate of each
stock is listed in table 2 and table 3 for movement
trend 1 and movement trend 2, respectively.

7 Model Training and Result Dis-

cussion

In this section, I explained my procedure to train

model and discussed the prediction result.
7.1 Grid search and model training

When I trained models, I applied grid search by
searching a parameter space to ﬁnd the model with
the best performance. For example, for logistical re-
gression, as introduced in Sec. 5, there are two types
of cost functions and a parameter C. I trained model
candidates on two grids: one is with L1 penalized cost
function and C values in [0.001, 0.01, 0.1, 1, 10, 100]
and the second one is with L2 penalized cost func-
tion and C values in [0.001, 0.01, 0.1, 1, 10, 100]. Af-
ter the best model candidate is found, I kept the cost
function unchanged and search C in a smaller range
around the C value of the best candidate; and re-
peated this process until the validation MCC value
does not change much in the neighborhood of the
current best C value. Similar search procedure is
also applied to SVM and random forest.

More speciﬁcally, for each stock, I ﬁrst used all the
features and trained logistical regression model with
L2 penalized cost function and C = 1. This model is
considered as a baseline model. Then I applied grid
search technique to ﬁnd the model with the best per-
formance. The best model candidates by using all the
features, features selected by random forest, and fea-
tures selected by forward search are obtained.
7.2 Result and discussion

Table 2 and table 3 list the result of the base-
line model and the best model for the sample set la-
beled by movement trend 1 and 2 (deﬁned in Sec. 3),
respectively. The best models trained with all the
features, feature selected by random forest, and fea-
ture selected by logistical regression forward search
are listed.

Comparing to the baseline model, model perfor-
mance has been improved signiﬁcantly with the help
of grid search and feature selection techniques. For

050100150200250Feature No.−0.020.000.020.040.060.080.100.120.14Validation MCCAAGEHPQIBMbaseline

Val. MCC

-0.0012
-0.0040
-0.014
0.063

AA
GE
HPQ
IBM

All features

RF feature selection

Forward search (LR)

Model

RF

SVM (lin.)

LR
LR

Best Val. MCC

Model

Feature No.

Best Val. MCC

Feature No.

Best Val. MCC

0.052
0.062
0.053
0.10

SVM (RBF)
SVM (RBF)
SVM (lin.)
SVM (RBF)

129
22
47
183

0.019
0.092
0.053
0.11

191
23
30
228

0.072
0.091
0.071
0.084

Table 2: Baseline and best models for the movement trend 1 with feature numbers and best validation MCC.

baseline

All features

RF feature selection

Forward search (LR)

Val. MCC Model

Best Val. MCC

Model

Feature No.

Best Val. MCC

Feature No.

Best Val. MCC

AA
GE
HPQ
IBM
Table 3: Baseline and best models for the movement trend 2 with feature numbers and best validation MCC.

0.0054
0.063
0.15
0.069

0.051
0.13
0.15
0.14

0.079
0.15
0.16
0.10

SVM (Sig.)

LR
LR
LR

43
43
149
85

LR
LR
LR
LR

120
91
36
97

0.11
0.17
0.17
0.15

example, for GE in table 2, the validation MCC value
increases from −0.004 (baseline) to 0.092 (note that
negative MCC value means the model prediction is
worst than random prediction).

Comparing the baseline model with the best model
using all the features of HPQ and IBM in table 2 and
all the stocks in table 3, we can see the grid search
technique helps to ﬁnd better model and largely im-
proves model performance. I also found that the best
model candidate is much diﬀerent among the four
stocks. In table 3, even if all the best models using
all the features are logistical regression, their actual
model forms (i.e., cost function and C value) are quite
diﬀerent (the information on detailed model form is
omitted here due to space limitation). This result
is consistent with previous research that to have the
best prediction, one needs to train models for each
stock instead of train one model using the data of all
stocks [5].

In general, the best models with features selected
by random forest and forward search have better per-
formance than those with all the features. That
means each stocks may be only sensitive to certain
feature combination. The models in table 3 have bet-
ter performance than those in table 2. Hence, a good
data label algorithm is important to the prediction
accuracy.

Metric

F1

recall

precision
accuracy

Baseline model

Best model

0.345
0.391
0.309
0.546

0.399
0.419
0.381
0.615

Table 4: Validation F1 score, recall, precision, and accu-
racy of the baseline and best model of AA in table 3.

To further show model performance improvement,
in table 4, I listed the validation F1 score, recall, pre-
cision, and accuracy of the baseline and best models
of AA in table 3 as an example (the deﬁnitions of

Figure 4: Learning curve of the best logistical regression
model for IBM.

those metrics are omitted here, due to space limita-
tion). Grid search and feature selection techniques
improve not only MCC value but also other metrics
derived from confusion matrix.

In ﬁgure 4, I showed the learning curve of the best
logistical regression model for IBM with samples la-
beled by movement trend 2. The training and vali-
dation error converges to a similar value. If we want
to further improve the model performance, we need
more informative features.

8 Summary and Future Work

In summary,

1. Models with best validation MCC are built up
based on current feature set with the help of grid
search, random forest feature selection, and for-
ward search techniques. MCC and other metrics
are signiﬁcantly improved.

2. Stock prediction is quite feature and stock de-
pendent. Diﬀerent feature subsets and diﬀerent
models are best for diﬀerent stocks.

3. A good classiﬁcation model to label sample may

help to increase prediction accuracy.

4. For more accurate prediction, more features are

needed to provide more useful information.

5

02000400060008000Train data No.0.40.50.60.70.80.91.01.11-MCCTrainValidationReferences
[1] Mongodb. https://www.mongodb.com.
[2] Scikit-learn. http://scikit-learn.org/.
[3] Technical indicators and overlays. http://stockcharts.com/school/doku.php?id=chart_school:

technical_indicators.

[4] Breiman, L. Random foests. Machine Learning 45 (2001), 5–32.
[5] Ghosn, J., and Bengio, Y. Multi-task learning for stock selection. In NIPS. 1997.
[6] Leung, M. T., Daouk, H., and Chen, A.-S. Forecasting stock indices: a comparison of classiﬁcation

and level estimation model. International Journal of Forecasting 16 (2000), 173–190.

[7] Levin, A. U. Stock selection via nonlinear multi-factor models. In NIPS. 1996.
[8] Matthews, B. W. Comparison of the predicted and observed secondary structure of T4 phage lsozyme.

Biochimica et Biophysica Acta 405 (1975), 442–451.

[9] Refenes, A. N., Zapranis, A., and Francis, G. Stock performance modeling using neural networks:

a comparative study with regression models. Neural Networks 7 (1994), 375–388.

[10] Tsai, C.-F., Lin, Y.-C., Yen, D. C., and Chen, Y.-M. Predicting stock returns by classiﬁer

ensembles. Applied Soft Computing 11 (2011), 2452–2459.

6

