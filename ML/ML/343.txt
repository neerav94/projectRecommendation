Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Note that not all quarters of data are available for all stars and furthermore during each quarter there are certain times
when the spacecraft faced technical diﬃculties for which the time-series data has missing values reported as NaN. Removing
these problematic points, our ﬁnal data consists of just under 2000 stars, roughly 20% of which harbour exoplanets, the rest
being false positives. For each of these examples, we are able to retrieve a 25-long feature vector of stellar characteristics, as
well as a set of approximately 4500-long time-series data on stellar intensity (both raw and calibrated for Kepler spacecraft
artifacts) and pixel location (horizontal and vertical). To correct for the imbalance between positive and negative examples
in this dataset, when training we selected a random subset of negative examples equal in size to the positive example set.

Another set of features includes a set of 42 KOI-speciﬁc measurements extracted from the time series data using previously
published algorithms. These data are again available from the MAST servers, and we did not have to calculate them
ourselves. These features include the estimated magnitude and duration of detected transits, estimated radius, temperature,
and eccentricity of the exoplanet, and other similar features which are derived by ﬁtting physical models to the time series
data. These features are speciﬁc to the KOI (rather than to the star), so by using this data, we can directly classiﬂy KOIs as
exoplanets or false positives. We noted there is some overlap between this NASA-generated KOI-speciﬁc data and the star-
speciﬁc data discussed above. Furthermore, the KOI-speciﬁc data had numerous missing values; removing these examples
reduced our dataset to 1200 KOI examples, roughly half of which are conﬁrmed exoplanets.

Our initial tests used only star-speciﬁc features and sought to binary-classify stars as harbouring exoplanets or not. Our
second round of tests used the KOI-speciﬁc data provided by NASA (as well as cross-correlation features we generated
ourselves from the raw time-series data, see below), and sought to classify KOIs as true exoplanets or false positives.

3 Features and Preprocessing

3.1 Extracting features for prediction of stars that harbour true exoplanets

3.1.1 Star-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 25 variables on intrinsic stellar characteristics (derived directly
from the .ﬁts ﬁles), so data reduction was performed by using principal components analysis and selecting the top 22
components to use as features.

3.1.2 Star-speciﬁc time-series processing

Starting from the raw light-curve and stellar characteristics data, a key challenge of this problem is in extracting informative
features with which to predict exoplanet existence. Given that the length of the time-series data is over 4000 data points per
example, which exceeds the total number of examples (and outnumbers positive training examples by more than a factor of
10) it is virtually infeasible to directly use the numerical time-series as a feature vector for classiﬁcation. To gain an intuition
for other strategies of feature extraction, we looked in more detail at the raw light curve data. Strikingly, these light curve
data often appear to have a periodic nature to them, though simply looking for periodic transits themselves can be very
misleading (see Figure 1). Large transits can be seen in both positive and negative data, and a lack of any obvious transits
is present as well in example data from both positive and negative data. We hypothesized that in addition to periodicity
of the transits (or lack thereof), additional information stored in other frequencies of the light-curves might help distinguish
genuine planetary transits from artifacts.

As a basic feature extraction strategy, we attempted to characterize each time series by simple global measurements,
including the mean, median, min, max, standard deviation, and inter-quartile range of the light curve as a whole. Next, we
tried downsampling the ∼4500 pixel intensities over time into a ∼250 long vector. We also tried feature mapping by running
a fast Fourier transform (FFT) on the raw light curves, and sampling a ∼250 dimensional array of the FFT as the new feature
vector. The beneﬁt of this method is that it separates out the long-time variation in the star system’s intensity, which could
be likely due to intrinsic variation in the star’s luminous output, and also isolates much of the high-frequency noise in the
data collection as well. Next, we combined not just the basic light curve data but also measurements on the motion of the
star centroid, which gives an estimate of the wobble caused by a potential exoplanet. That dataset is an entire time series
on its own, but by measuring the correlations between that dataset (for both x and y centroid motion) and the light curves,
we came up with the 6 pairwise correlations between each of the three time series to use as features.

3.2 Extracting features for prediction of KOIs that are true exoplanets

3.2.1 KOI-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 42 KOI-speciﬁc variables and the 25 star-speciﬁc variables
mentioned, so data reduction was performed by combining these into a 67-long vector and using principal components
analysis to select the top 30 components as features.

2

Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Note that not all quarters of data are available for all stars and furthermore during each quarter there are certain times
when the spacecraft faced technical diﬃculties for which the time-series data has missing values reported as NaN. Removing
these problematic points, our ﬁnal data consists of just under 2000 stars, roughly 20% of which harbour exoplanets, the rest
being false positives. For each of these examples, we are able to retrieve a 25-long feature vector of stellar characteristics, as
well as a set of approximately 4500-long time-series data on stellar intensity (both raw and calibrated for Kepler spacecraft
artifacts) and pixel location (horizontal and vertical). To correct for the imbalance between positive and negative examples
in this dataset, when training we selected a random subset of negative examples equal in size to the positive example set.

Another set of features includes a set of 42 KOI-speciﬁc measurements extracted from the time series data using previously
published algorithms. These data are again available from the MAST servers, and we did not have to calculate them
ourselves. These features include the estimated magnitude and duration of detected transits, estimated radius, temperature,
and eccentricity of the exoplanet, and other similar features which are derived by ﬁtting physical models to the time series
data. These features are speciﬁc to the KOI (rather than to the star), so by using this data, we can directly classiﬂy KOIs as
exoplanets or false positives. We noted there is some overlap between this NASA-generated KOI-speciﬁc data and the star-
speciﬁc data discussed above. Furthermore, the KOI-speciﬁc data had numerous missing values; removing these examples
reduced our dataset to 1200 KOI examples, roughly half of which are conﬁrmed exoplanets.

Our initial tests used only star-speciﬁc features and sought to binary-classify stars as harbouring exoplanets or not. Our
second round of tests used the KOI-speciﬁc data provided by NASA (as well as cross-correlation features we generated
ourselves from the raw time-series data, see below), and sought to classify KOIs as true exoplanets or false positives.

3 Features and Preprocessing

3.1 Extracting features for prediction of stars that harbour true exoplanets

3.1.1 Star-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 25 variables on intrinsic stellar characteristics (derived directly
from the .ﬁts ﬁles), so data reduction was performed by using principal components analysis and selecting the top 22
components to use as features.

3.1.2 Star-speciﬁc time-series processing

Starting from the raw light-curve and stellar characteristics data, a key challenge of this problem is in extracting informative
features with which to predict exoplanet existence. Given that the length of the time-series data is over 4000 data points per
example, which exceeds the total number of examples (and outnumbers positive training examples by more than a factor of
10) it is virtually infeasible to directly use the numerical time-series as a feature vector for classiﬁcation. To gain an intuition
for other strategies of feature extraction, we looked in more detail at the raw light curve data. Strikingly, these light curve
data often appear to have a periodic nature to them, though simply looking for periodic transits themselves can be very
misleading (see Figure 1). Large transits can be seen in both positive and negative data, and a lack of any obvious transits
is present as well in example data from both positive and negative data. We hypothesized that in addition to periodicity
of the transits (or lack thereof), additional information stored in other frequencies of the light-curves might help distinguish
genuine planetary transits from artifacts.

As a basic feature extraction strategy, we attempted to characterize each time series by simple global measurements,
including the mean, median, min, max, standard deviation, and inter-quartile range of the light curve as a whole. Next, we
tried downsampling the ∼4500 pixel intensities over time into a ∼250 long vector. We also tried feature mapping by running
a fast Fourier transform (FFT) on the raw light curves, and sampling a ∼250 dimensional array of the FFT as the new feature
vector. The beneﬁt of this method is that it separates out the long-time variation in the star system’s intensity, which could
be likely due to intrinsic variation in the star’s luminous output, and also isolates much of the high-frequency noise in the
data collection as well. Next, we combined not just the basic light curve data but also measurements on the motion of the
star centroid, which gives an estimate of the wobble caused by a potential exoplanet. That dataset is an entire time series
on its own, but by measuring the correlations between that dataset (for both x and y centroid motion) and the light curves,
we came up with the 6 pairwise correlations between each of the three time series to use as features.

3.2 Extracting features for prediction of KOIs that are true exoplanets

3.2.1 KOI-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 42 KOI-speciﬁc variables and the 25 star-speciﬁc variables
mentioned, so data reduction was performed by combining these into a 67-long vector and using principal components
analysis to select the top 30 components as features.

2

Figure 1: Light curves can be misleading. One can see that the left traces represent exoplanet-harbouring stars, whereas the
right traces represent non-exoplanet-harbouring stars; however clear transits (or lack thereof) can be observed in both cases.

3.2.2 KOI-speciﬁc time-series processing

A key variable available from the KOI-speciﬁc data is the timepoint at which planet transit occurs within the raw timeseries
data. Using this, we reduced our ∼4500 dimensional raw timeseries data to the 15 timepoints closest to the transit event.
We then calculated centroid-to-ﬂux cross-correlation using these short time windows, and used the corresponding 29-long
cross-correlation vectors as additional features. Compared to calculating correlations with full time-series, we expected this
technique to much better capture exoplanet-related wobble. To further reduce noise, we ﬁrst applied a ﬂatten / detrend
algorithm to the timeseries data, using the PyKE data package (software developed by NASA for analysing Kepler data).

4 Models and Results

Our problem is one of binary classiﬁcation. The algorithms we used are Naive Bayes, Logistic regression, and SVM (Gaussian
and/or linear kernel, see below for details). The performance of these algorithms was quantiﬁed using 5-fold cross validation
to generate test error rates.

4.1 Initial attempts at classifying stars

In our initial work, we ran a series of classiﬁcation attempts on the star dataset, ultimately with marginal success. First, we
began by exploring the notion of how well the star-speciﬁc features of the star system (no light curve data) could classify
exoplanets. Given that certain types of stars may be intrinsically more likely than others to harbour exoplanets, the ability to
predict exoplanets based on these characteristic features provides a useful baseline. After applying PCA, we ﬁnd that using
these features alone yields 60-65% accuracy in detection, depending on the classiﬁcation algorithm used. Of the classiﬁcation
algorithm types tested, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while Nave Bayes suﬀers from high
variance (high training/test error) so logistic regression emerges as the frontrunner. Following the classiﬁcation algorithms
using just the star features, we re-ran the classiﬁcation algorithms, but added features extracted from the light-curve time-
series in the form of global time-series statistics, downsampled time-series, FFT, and momentum correlations. Using these
additional features did not increase algorithm performance with any of the three classiﬁcation algorithms, as compared to
using only the global star features. As before, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while
Nave Bayes has lost almost all accuracy, and logistic regression test accuracy remains near 65%. A summary of all these
techniques tried with the stellar characteristics, light curve, and centroid data is given in Table 4.1. Note we later re-analysed
this data using linear kernel SVM, which yielded performance similar to Logistic regression (data not shown).

4.2 Classiﬁcation of KOIs
As our initial attempts at binary-classiﬁcation of stars did no better than ∼ 67%, we shifted our focus to the alternate
strategy of classifying KOIs directly using the KOI-speciﬁc (rather than star-speciﬁc) features, applied on the dataset of

3

Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Note that not all quarters of data are available for all stars and furthermore during each quarter there are certain times
when the spacecraft faced technical diﬃculties for which the time-series data has missing values reported as NaN. Removing
these problematic points, our ﬁnal data consists of just under 2000 stars, roughly 20% of which harbour exoplanets, the rest
being false positives. For each of these examples, we are able to retrieve a 25-long feature vector of stellar characteristics, as
well as a set of approximately 4500-long time-series data on stellar intensity (both raw and calibrated for Kepler spacecraft
artifacts) and pixel location (horizontal and vertical). To correct for the imbalance between positive and negative examples
in this dataset, when training we selected a random subset of negative examples equal in size to the positive example set.

Another set of features includes a set of 42 KOI-speciﬁc measurements extracted from the time series data using previously
published algorithms. These data are again available from the MAST servers, and we did not have to calculate them
ourselves. These features include the estimated magnitude and duration of detected transits, estimated radius, temperature,
and eccentricity of the exoplanet, and other similar features which are derived by ﬁtting physical models to the time series
data. These features are speciﬁc to the KOI (rather than to the star), so by using this data, we can directly classiﬂy KOIs as
exoplanets or false positives. We noted there is some overlap between this NASA-generated KOI-speciﬁc data and the star-
speciﬁc data discussed above. Furthermore, the KOI-speciﬁc data had numerous missing values; removing these examples
reduced our dataset to 1200 KOI examples, roughly half of which are conﬁrmed exoplanets.

Our initial tests used only star-speciﬁc features and sought to binary-classify stars as harbouring exoplanets or not. Our
second round of tests used the KOI-speciﬁc data provided by NASA (as well as cross-correlation features we generated
ourselves from the raw time-series data, see below), and sought to classify KOIs as true exoplanets or false positives.

3 Features and Preprocessing

3.1 Extracting features for prediction of stars that harbour true exoplanets

3.1.1 Star-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 25 variables on intrinsic stellar characteristics (derived directly
from the .ﬁts ﬁles), so data reduction was performed by using principal components analysis and selecting the top 22
components to use as features.

3.1.2 Star-speciﬁc time-series processing

Starting from the raw light-curve and stellar characteristics data, a key challenge of this problem is in extracting informative
features with which to predict exoplanet existence. Given that the length of the time-series data is over 4000 data points per
example, which exceeds the total number of examples (and outnumbers positive training examples by more than a factor of
10) it is virtually infeasible to directly use the numerical time-series as a feature vector for classiﬁcation. To gain an intuition
for other strategies of feature extraction, we looked in more detail at the raw light curve data. Strikingly, these light curve
data often appear to have a periodic nature to them, though simply looking for periodic transits themselves can be very
misleading (see Figure 1). Large transits can be seen in both positive and negative data, and a lack of any obvious transits
is present as well in example data from both positive and negative data. We hypothesized that in addition to periodicity
of the transits (or lack thereof), additional information stored in other frequencies of the light-curves might help distinguish
genuine planetary transits from artifacts.

As a basic feature extraction strategy, we attempted to characterize each time series by simple global measurements,
including the mean, median, min, max, standard deviation, and inter-quartile range of the light curve as a whole. Next, we
tried downsampling the ∼4500 pixel intensities over time into a ∼250 long vector. We also tried feature mapping by running
a fast Fourier transform (FFT) on the raw light curves, and sampling a ∼250 dimensional array of the FFT as the new feature
vector. The beneﬁt of this method is that it separates out the long-time variation in the star system’s intensity, which could
be likely due to intrinsic variation in the star’s luminous output, and also isolates much of the high-frequency noise in the
data collection as well. Next, we combined not just the basic light curve data but also measurements on the motion of the
star centroid, which gives an estimate of the wobble caused by a potential exoplanet. That dataset is an entire time series
on its own, but by measuring the correlations between that dataset (for both x and y centroid motion) and the light curves,
we came up with the 6 pairwise correlations between each of the three time series to use as features.

3.2 Extracting features for prediction of KOIs that are true exoplanets

3.2.1 KOI-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 42 KOI-speciﬁc variables and the 25 star-speciﬁc variables
mentioned, so data reduction was performed by combining these into a 67-long vector and using principal components
analysis to select the top 30 components as features.

2

Figure 1: Light curves can be misleading. One can see that the left traces represent exoplanet-harbouring stars, whereas the
right traces represent non-exoplanet-harbouring stars; however clear transits (or lack thereof) can be observed in both cases.

3.2.2 KOI-speciﬁc time-series processing

A key variable available from the KOI-speciﬁc data is the timepoint at which planet transit occurs within the raw timeseries
data. Using this, we reduced our ∼4500 dimensional raw timeseries data to the 15 timepoints closest to the transit event.
We then calculated centroid-to-ﬂux cross-correlation using these short time windows, and used the corresponding 29-long
cross-correlation vectors as additional features. Compared to calculating correlations with full time-series, we expected this
technique to much better capture exoplanet-related wobble. To further reduce noise, we ﬁrst applied a ﬂatten / detrend
algorithm to the timeseries data, using the PyKE data package (software developed by NASA for analysing Kepler data).

4 Models and Results

Our problem is one of binary classiﬁcation. The algorithms we used are Naive Bayes, Logistic regression, and SVM (Gaussian
and/or linear kernel, see below for details). The performance of these algorithms was quantiﬁed using 5-fold cross validation
to generate test error rates.

4.1 Initial attempts at classifying stars

In our initial work, we ran a series of classiﬁcation attempts on the star dataset, ultimately with marginal success. First, we
began by exploring the notion of how well the star-speciﬁc features of the star system (no light curve data) could classify
exoplanets. Given that certain types of stars may be intrinsically more likely than others to harbour exoplanets, the ability to
predict exoplanets based on these characteristic features provides a useful baseline. After applying PCA, we ﬁnd that using
these features alone yields 60-65% accuracy in detection, depending on the classiﬁcation algorithm used. Of the classiﬁcation
algorithm types tested, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while Nave Bayes suﬀers from high
variance (high training/test error) so logistic regression emerges as the frontrunner. Following the classiﬁcation algorithms
using just the star features, we re-ran the classiﬁcation algorithms, but added features extracted from the light-curve time-
series in the form of global time-series statistics, downsampled time-series, FFT, and momentum correlations. Using these
additional features did not increase algorithm performance with any of the three classiﬁcation algorithms, as compared to
using only the global star features. As before, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while
Nave Bayes has lost almost all accuracy, and logistic regression test accuracy remains near 65%. A summary of all these
techniques tried with the stellar characteristics, light curve, and centroid data is given in Table 4.1. Note we later re-analysed
this data using linear kernel SVM, which yielded performance similar to Logistic regression (data not shown).

4.2 Classiﬁcation of KOIs
As our initial attempts at binary-classiﬁcation of stars did no better than ∼ 67%, we shifted our focus to the alternate
strategy of classifying KOIs directly using the KOI-speciﬁc (rather than star-speciﬁc) features, applied on the dataset of

3

Feature mapping
Stellar features only
+Downsampling
+FFT
+Correlations
+Global statistics

Naive Bayes
60.0/57.7
51.0/50.3
51.6/50.5
55.6/55.0
55.2/53.7

SVM (Gaussian kernel) Logistic Regression
89.5/58.9
81.3/60.7
84.6/59.2
97.9/56.2
100.0/51.3

71.2/65.9
71.6/66.3
71.0/66.0
71.3/66.0
71.2/65.1

Table 1: Summary of performance for each classiﬁcation method with the feature set listed in the ﬁrst column. Each table
entry includes as percentages the training accuracy / 5-fold cross-validation accuracy.

KOIs (labelled as conﬁrmed exoplanet or false positive).
As before, we began by exploring the notion of how well the characteristic KOI features (no time-series data) could classify
exoplanets. After applying PCA, we ﬁnd that using these features alone yields ∼ 90% accuracy in detection, depending on
the classiﬁcation algorithm used. Given earlier problems with overﬁtting using Gaussian-kernel SVM, we tried a linear
kernel SVM. Of the classiﬁcation algorithm types tested, logistic regression performs best with a 93% accuracy, but the
performance of SVM and Naive Bayes is not far behind. Training and test accuracies are similar, suggesting that overﬁtting
is not a problem with our current feature set. For details on performance, see Table 2, and the ROC curves shown in Figure
2. The high accuracy suggests that the currently available Kepler features can be directly used to predict exoplanets versus
false positives, even without costly manual follow-up. As a side-note, we did run this dataset with Gaussian-kernel SVM,
and as before we observed major over-ﬁtting (data not shown).

Model

Accuracy (train/test %s) F1 score Area under ROC

SVM (linear kernel)

Naive Bayes

Logistic regression

91.5/90.4
88.3/88.2
94.3/93.2

0.908
0.887
0.933

0.943
0.853
0.968

Table 2: List of accuracies and related characteristics for the classiﬁcation on stellar and KOI characteristics

Figure 2: ROC curves for the classiﬁcation on stellar and KOI characteristics

We further tested whether our features we derived for the earlier attempts could improve the classiﬁcation attempts here.
In particular, we supplemented the stellar and KOI characteristics with the correlations we calculated earlier between the
light curves and the centroid movements. We then reran classiﬁcation with the new feature set (results depicted in Table 3
and in Figure 3). No signiﬁcant improvement is seen in performance with any of the three classiﬁcation algorithms, suggesting
that little if any predictive information is available from the cross-correlation vectors. Again, logistic regression appears to
be be the best-performing algorithm, followed by linear kernel SVM.

5 Discussion and Future directions

Our initial work for this project attempted to classify stars as harboring or not harboring exoplanets based on measurements
from the Kepler spacecraft. This work is applicable to any stars which were measured by the spacecraft, regardless of
whether they were picked out by NASA algorithms as Kepler objects of interest (KOIs). Despite several attempts, our best
classiﬁcation algorithm classiﬁed stars solely based on their intrinsic characteristics, and not by any time series data (light

4

Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Note that not all quarters of data are available for all stars and furthermore during each quarter there are certain times
when the spacecraft faced technical diﬃculties for which the time-series data has missing values reported as NaN. Removing
these problematic points, our ﬁnal data consists of just under 2000 stars, roughly 20% of which harbour exoplanets, the rest
being false positives. For each of these examples, we are able to retrieve a 25-long feature vector of stellar characteristics, as
well as a set of approximately 4500-long time-series data on stellar intensity (both raw and calibrated for Kepler spacecraft
artifacts) and pixel location (horizontal and vertical). To correct for the imbalance between positive and negative examples
in this dataset, when training we selected a random subset of negative examples equal in size to the positive example set.

Another set of features includes a set of 42 KOI-speciﬁc measurements extracted from the time series data using previously
published algorithms. These data are again available from the MAST servers, and we did not have to calculate them
ourselves. These features include the estimated magnitude and duration of detected transits, estimated radius, temperature,
and eccentricity of the exoplanet, and other similar features which are derived by ﬁtting physical models to the time series
data. These features are speciﬁc to the KOI (rather than to the star), so by using this data, we can directly classiﬂy KOIs as
exoplanets or false positives. We noted there is some overlap between this NASA-generated KOI-speciﬁc data and the star-
speciﬁc data discussed above. Furthermore, the KOI-speciﬁc data had numerous missing values; removing these examples
reduced our dataset to 1200 KOI examples, roughly half of which are conﬁrmed exoplanets.

Our initial tests used only star-speciﬁc features and sought to binary-classify stars as harbouring exoplanets or not. Our
second round of tests used the KOI-speciﬁc data provided by NASA (as well as cross-correlation features we generated
ourselves from the raw time-series data, see below), and sought to classify KOIs as true exoplanets or false positives.

3 Features and Preprocessing

3.1 Extracting features for prediction of stars that harbour true exoplanets

3.1.1 Star-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 25 variables on intrinsic stellar characteristics (derived directly
from the .ﬁts ﬁles), so data reduction was performed by using principal components analysis and selecting the top 22
components to use as features.

3.1.2 Star-speciﬁc time-series processing

Starting from the raw light-curve and stellar characteristics data, a key challenge of this problem is in extracting informative
features with which to predict exoplanet existence. Given that the length of the time-series data is over 4000 data points per
example, which exceeds the total number of examples (and outnumbers positive training examples by more than a factor of
10) it is virtually infeasible to directly use the numerical time-series as a feature vector for classiﬁcation. To gain an intuition
for other strategies of feature extraction, we looked in more detail at the raw light curve data. Strikingly, these light curve
data often appear to have a periodic nature to them, though simply looking for periodic transits themselves can be very
misleading (see Figure 1). Large transits can be seen in both positive and negative data, and a lack of any obvious transits
is present as well in example data from both positive and negative data. We hypothesized that in addition to periodicity
of the transits (or lack thereof), additional information stored in other frequencies of the light-curves might help distinguish
genuine planetary transits from artifacts.

As a basic feature extraction strategy, we attempted to characterize each time series by simple global measurements,
including the mean, median, min, max, standard deviation, and inter-quartile range of the light curve as a whole. Next, we
tried downsampling the ∼4500 pixel intensities over time into a ∼250 long vector. We also tried feature mapping by running
a fast Fourier transform (FFT) on the raw light curves, and sampling a ∼250 dimensional array of the FFT as the new feature
vector. The beneﬁt of this method is that it separates out the long-time variation in the star system’s intensity, which could
be likely due to intrinsic variation in the star’s luminous output, and also isolates much of the high-frequency noise in the
data collection as well. Next, we combined not just the basic light curve data but also measurements on the motion of the
star centroid, which gives an estimate of the wobble caused by a potential exoplanet. That dataset is an entire time series
on its own, but by measuring the correlations between that dataset (for both x and y centroid motion) and the light curves,
we came up with the 6 pairwise correlations between each of the three time series to use as features.

3.2 Extracting features for prediction of KOIs that are true exoplanets

3.2.1 KOI-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 42 KOI-speciﬁc variables and the 25 star-speciﬁc variables
mentioned, so data reduction was performed by combining these into a 67-long vector and using principal components
analysis to select the top 30 components as features.

2

Figure 1: Light curves can be misleading. One can see that the left traces represent exoplanet-harbouring stars, whereas the
right traces represent non-exoplanet-harbouring stars; however clear transits (or lack thereof) can be observed in both cases.

3.2.2 KOI-speciﬁc time-series processing

A key variable available from the KOI-speciﬁc data is the timepoint at which planet transit occurs within the raw timeseries
data. Using this, we reduced our ∼4500 dimensional raw timeseries data to the 15 timepoints closest to the transit event.
We then calculated centroid-to-ﬂux cross-correlation using these short time windows, and used the corresponding 29-long
cross-correlation vectors as additional features. Compared to calculating correlations with full time-series, we expected this
technique to much better capture exoplanet-related wobble. To further reduce noise, we ﬁrst applied a ﬂatten / detrend
algorithm to the timeseries data, using the PyKE data package (software developed by NASA for analysing Kepler data).

4 Models and Results

Our problem is one of binary classiﬁcation. The algorithms we used are Naive Bayes, Logistic regression, and SVM (Gaussian
and/or linear kernel, see below for details). The performance of these algorithms was quantiﬁed using 5-fold cross validation
to generate test error rates.

4.1 Initial attempts at classifying stars

In our initial work, we ran a series of classiﬁcation attempts on the star dataset, ultimately with marginal success. First, we
began by exploring the notion of how well the star-speciﬁc features of the star system (no light curve data) could classify
exoplanets. Given that certain types of stars may be intrinsically more likely than others to harbour exoplanets, the ability to
predict exoplanets based on these characteristic features provides a useful baseline. After applying PCA, we ﬁnd that using
these features alone yields 60-65% accuracy in detection, depending on the classiﬁcation algorithm used. Of the classiﬁcation
algorithm types tested, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while Nave Bayes suﬀers from high
variance (high training/test error) so logistic regression emerges as the frontrunner. Following the classiﬁcation algorithms
using just the star features, we re-ran the classiﬁcation algorithms, but added features extracted from the light-curve time-
series in the form of global time-series statistics, downsampled time-series, FFT, and momentum correlations. Using these
additional features did not increase algorithm performance with any of the three classiﬁcation algorithms, as compared to
using only the global star features. As before, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while
Nave Bayes has lost almost all accuracy, and logistic regression test accuracy remains near 65%. A summary of all these
techniques tried with the stellar characteristics, light curve, and centroid data is given in Table 4.1. Note we later re-analysed
this data using linear kernel SVM, which yielded performance similar to Logistic regression (data not shown).

4.2 Classiﬁcation of KOIs
As our initial attempts at binary-classiﬁcation of stars did no better than ∼ 67%, we shifted our focus to the alternate
strategy of classifying KOIs directly using the KOI-speciﬁc (rather than star-speciﬁc) features, applied on the dataset of

3

Feature mapping
Stellar features only
+Downsampling
+FFT
+Correlations
+Global statistics

Naive Bayes
60.0/57.7
51.0/50.3
51.6/50.5
55.6/55.0
55.2/53.7

SVM (Gaussian kernel) Logistic Regression
89.5/58.9
81.3/60.7
84.6/59.2
97.9/56.2
100.0/51.3

71.2/65.9
71.6/66.3
71.0/66.0
71.3/66.0
71.2/65.1

Table 1: Summary of performance for each classiﬁcation method with the feature set listed in the ﬁrst column. Each table
entry includes as percentages the training accuracy / 5-fold cross-validation accuracy.

KOIs (labelled as conﬁrmed exoplanet or false positive).
As before, we began by exploring the notion of how well the characteristic KOI features (no time-series data) could classify
exoplanets. After applying PCA, we ﬁnd that using these features alone yields ∼ 90% accuracy in detection, depending on
the classiﬁcation algorithm used. Given earlier problems with overﬁtting using Gaussian-kernel SVM, we tried a linear
kernel SVM. Of the classiﬁcation algorithm types tested, logistic regression performs best with a 93% accuracy, but the
performance of SVM and Naive Bayes is not far behind. Training and test accuracies are similar, suggesting that overﬁtting
is not a problem with our current feature set. For details on performance, see Table 2, and the ROC curves shown in Figure
2. The high accuracy suggests that the currently available Kepler features can be directly used to predict exoplanets versus
false positives, even without costly manual follow-up. As a side-note, we did run this dataset with Gaussian-kernel SVM,
and as before we observed major over-ﬁtting (data not shown).

Model

Accuracy (train/test %s) F1 score Area under ROC

SVM (linear kernel)

Naive Bayes

Logistic regression

91.5/90.4
88.3/88.2
94.3/93.2

0.908
0.887
0.933

0.943
0.853
0.968

Table 2: List of accuracies and related characteristics for the classiﬁcation on stellar and KOI characteristics

Figure 2: ROC curves for the classiﬁcation on stellar and KOI characteristics

We further tested whether our features we derived for the earlier attempts could improve the classiﬁcation attempts here.
In particular, we supplemented the stellar and KOI characteristics with the correlations we calculated earlier between the
light curves and the centroid movements. We then reran classiﬁcation with the new feature set (results depicted in Table 3
and in Figure 3). No signiﬁcant improvement is seen in performance with any of the three classiﬁcation algorithms, suggesting
that little if any predictive information is available from the cross-correlation vectors. Again, logistic regression appears to
be be the best-performing algorithm, followed by linear kernel SVM.

5 Discussion and Future directions

Our initial work for this project attempted to classify stars as harboring or not harboring exoplanets based on measurements
from the Kepler spacecraft. This work is applicable to any stars which were measured by the spacecraft, regardless of
whether they were picked out by NASA algorithms as Kepler objects of interest (KOIs). Despite several attempts, our best
classiﬁcation algorithm classiﬁed stars solely based on their intrinsic characteristics, and not by any time series data (light

4

Model

Accuracy (train/test %s) F1 score Area under ROC

SVM (linear kernel)

Naive Bayes

Logistic regression

90.5/90.4
80.6/80.8
95.1/93.3

0.909
0.8273
0.934

0.936
0.7654
0.960

Table 3: List of accuracies and related characteristics for the classiﬁcation on stellar and KOI characteristics plus our
correlation features

Figure 3: ROC curves for the classiﬁcation on stellar and KOI characteristics plus our correlation features

curves and centroid data). Interestingly, this still achieved an accuracy of 65%, which indicates that either certain types of
stars are more likely to harbor exoplanets (certainly possible given that a neutron star has little in common with a red giant,
for example), but could also indicate that NASA’s algorithms for KOI detection has a bias for certain types of stars. Given
the ﬁrst case, we could run our algorithm on unclassiﬁed data to obtain an order-of-magnitude estimate (with 66% accuracy)
for the number of planet-harboring stars. Such orders of magnitude are of interest to astronomers. Given the second case,
NASA’s algorithms could beneﬁt from a correction of such bias.

Our subsequent work for this project attempted to directly classify KOIs as conﬁrmed or false exoplanets based on
measurements from the Kepler spacecraft. As such, this work is not applicable to all stars for which Kepler took measurements,
only those identiﬁed by NASA’s transit detection algorithms. Our classiﬁcation algorithm can be used as another step in
the planet-ﬁnding pipeline, where it serves to weed out false positives prior to follow-up measurements. Given that the
manual follow-up measurements can be quite costly, there is a real need for algorithms which reduce the large number of false
positive KOIs. To demonstrate that ability, we ran our logistic regression classiﬁer with the KOI-speciﬁc feature set (ignoring
the added correlation features) on 2212 currently unclassiﬁed KOIs for which suﬃcient data was available. Of those, 644
were classiﬁed as true exoplanets, and 1568 were weeded out as false positives. A list of the predicted exoplanets and false
negatives is given in the appendix; we hope these serve as useful starting points for other planet hunters.

Given the variability in the data and relatively high accuracy achieved on KOI classiﬁcation using logistic regression, it
seems unlikely that a simple classiﬁcation algorithm will yield signiﬁcant improvements. Future possible directions could be
to ﬁnd better feature mappings to make use of the time-series data, such as hidden Markov models for transit detection and
dynamic time-warping for detecting similarities in time-series data. Further classiﬁcation algorithms can also be explored,
such as random forest and neural networks for deep-learning of time-series data.

References

[1] D. Fraquelli and S. E. Thompson Kepler Archive Manual. (KDMC-10008-005) 2014

[2] M. Still and T. Barclay, PyKE: Reduction and analysis of Kepler Simple Aperture Photometry data. Astrophysics Source

Code Library. Provided by the SAO/NASA Astrophysics Data System 2012

[3] K. Mandel and E. Agol Analytic light curves for planetary transit transit searches. The Astrophysical Journal. 580,

171-175, 2002

[4] L. Walkowicz, et al. Mining the Kepler Data using Machine Learning. American Astronomical Society. AAS Meeting 223,

2014

[5] T. Lee, et al. Feature extraction methods for time series data in SAS Enterprise Miner. SAS Institute Inc. 2014

5

Searching for exoplanets in the Kepler public data

Xiaofan Jin

David Glass

December 12, 2014

Abstract

NASA’s Kepler mission to search for extrasolar planets has collected data from hundreds of thousands of star systems,
and has discovered nearly 1000 conﬁrmed exoplanets to date in addition to over 3000 unconﬁrmed candidates. The mission
detects exoplanets using transit photometry, which detects the transit of a planet in front of a star as transient drops in
stellar intensity. Raw data is collected in the form of a sequence of stellar images, which are processed into “light-curves”
tracking the brightness of a star over time. An algorithm automatically searches for periodic planetary transits in these
light curves, but spurious intensity dips and other noise in the data due to non-planetary stellar variability has led to high
false-positive rates for detecting transits. As the initial planetary candidates found by this search method require extensive
and costly subsequent validation, there is a need to reduce the error rate in exoplanet candidate identiﬁcation. We present
here an algorithm to classify Kepler Objects of Interest (KOIs) as conﬁrmed exoplanets or false positives, using publicly
available Kepler data. The algorithm achieves a 93% accuracy, and uses previously generated features extracted from the
lightcurve time-series data, as well as newly generated autocorrelation features derived from the time-series speciﬁcally
during planetary transit.

1 Introduction

NASA’s Kepler spacecraft spent over four years collecting data on hundreds of thousands of star systems in search of
exoplanets. This data was collected by taking images of a constant patch of space every 30 minutes on a continuous basis
for 3 months (i.e. 1 quarter). Every 3 months the spacecraft was recalibrated and the cycle was repeated for 17 separate
quarters before the Kepler spacecraft failed. From these images, the pixels corresponding to stars were isolated, and the
pixel location and intensity values were recorded over time. Taken together, this generated a series of light-curves for each
tracked star, from which exoplanets would be detected using transit photometry by looking for characteristic intensity dips
as planets transit in front of the star.

Currently, these light curves are further processed to remove instrument-related artifacts (known as Presearch Data
Conditioning or PDC), before being fed into a wavelet-based ﬁlter (known as Transiting Planet Search or TPS) that detects
the periodic dips characteristic of planetary transits. These automatic algorithms generate a series of exoplanet candidates
known as KOIs (Kepler Objects of Interest), and manual follow-up measurements are conducted either to conﬁrm KOIs as
exoplanets or false positives. So far, ∼7000 KOIs have been identiﬁed, out of which ∼4000 have been followed-up on. The
results of the follow-up observation has yielded a large false positive rate, as only ∼1000 exoplanets have been conﬁrmed.
Note that some systems contain more than one KOI, and so accounting by stars, Kepler has identiﬁed ∼4000 stars with
KOIs, out of which ∼400 have been conﬁrmed to actually harbour exoplanets. False positives come from a variety of sources,
such as intrinsic stellar variability (eg. bursting), random background objects, or from binary star systems, in which one star
transits in front of another .

Given the time-consuming and costly nature of follow-up experiments (much of the analysis is done manually), better
algorithms are needed to predict from the raw light-curve data whether or not a star system contains exoplanets. For our
project, we sought to produce a learning algorithm that can predict whether a KOI is a false positive or a conﬁrmed exoplanet,
ideally producing as few false negatives as possible (high sensitivity so as to not miss exoplanets), while reducing the number
of false positives that require expensive follow-up studies.

2 Data
Light-curve ﬁles for the ∼4000 classiﬁed KOIs are publicly available from NASA’s MAST servers, in the form of .ﬁts ﬁles
(an astronomy standard). These .ﬁts ﬁles store time-series data on stellar intensity and pixel location, as well as various
other data such as measurement uncertainties and data quality ﬂags. Note that since multiple KOIs can be based around
the same star, diﬀerent KOIs can have identical .ﬁts data (there is only one set of .ﬁts time series for each star). Over the
course of a 3 month-long quarter, ∼4500 data points are gathered in the time-series (one cadence every 30 minutes). In
addition to the time-series data, the .ﬁts ﬁles are supplemented by previously gathered spectroscopic and other potentially
relevant information on the stars of interest (eg. size, temperature, etc), reported as 25 numerical features. Using this set
of data, it makes sense to classify stars as harbouring (or not harbouring) exoplanets, rather than classify KOIs themselves.

1

Note that not all quarters of data are available for all stars and furthermore during each quarter there are certain times
when the spacecraft faced technical diﬃculties for which the time-series data has missing values reported as NaN. Removing
these problematic points, our ﬁnal data consists of just under 2000 stars, roughly 20% of which harbour exoplanets, the rest
being false positives. For each of these examples, we are able to retrieve a 25-long feature vector of stellar characteristics, as
well as a set of approximately 4500-long time-series data on stellar intensity (both raw and calibrated for Kepler spacecraft
artifacts) and pixel location (horizontal and vertical). To correct for the imbalance between positive and negative examples
in this dataset, when training we selected a random subset of negative examples equal in size to the positive example set.

Another set of features includes a set of 42 KOI-speciﬁc measurements extracted from the time series data using previously
published algorithms. These data are again available from the MAST servers, and we did not have to calculate them
ourselves. These features include the estimated magnitude and duration of detected transits, estimated radius, temperature,
and eccentricity of the exoplanet, and other similar features which are derived by ﬁtting physical models to the time series
data. These features are speciﬁc to the KOI (rather than to the star), so by using this data, we can directly classiﬂy KOIs as
exoplanets or false positives. We noted there is some overlap between this NASA-generated KOI-speciﬁc data and the star-
speciﬁc data discussed above. Furthermore, the KOI-speciﬁc data had numerous missing values; removing these examples
reduced our dataset to 1200 KOI examples, roughly half of which are conﬁrmed exoplanets.

Our initial tests used only star-speciﬁc features and sought to binary-classify stars as harbouring exoplanets or not. Our
second round of tests used the KOI-speciﬁc data provided by NASA (as well as cross-correlation features we generated
ourselves from the raw time-series data, see below), and sought to classify KOIs as true exoplanets or false positives.

3 Features and Preprocessing

3.1 Extracting features for prediction of stars that harbour true exoplanets

3.1.1 Star-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 25 variables on intrinsic stellar characteristics (derived directly
from the .ﬁts ﬁles), so data reduction was performed by using principal components analysis and selecting the top 22
components to use as features.

3.1.2 Star-speciﬁc time-series processing

Starting from the raw light-curve and stellar characteristics data, a key challenge of this problem is in extracting informative
features with which to predict exoplanet existence. Given that the length of the time-series data is over 4000 data points per
example, which exceeds the total number of examples (and outnumbers positive training examples by more than a factor of
10) it is virtually infeasible to directly use the numerical time-series as a feature vector for classiﬁcation. To gain an intuition
for other strategies of feature extraction, we looked in more detail at the raw light curve data. Strikingly, these light curve
data often appear to have a periodic nature to them, though simply looking for periodic transits themselves can be very
misleading (see Figure 1). Large transits can be seen in both positive and negative data, and a lack of any obvious transits
is present as well in example data from both positive and negative data. We hypothesized that in addition to periodicity
of the transits (or lack thereof), additional information stored in other frequencies of the light-curves might help distinguish
genuine planetary transits from artifacts.

As a basic feature extraction strategy, we attempted to characterize each time series by simple global measurements,
including the mean, median, min, max, standard deviation, and inter-quartile range of the light curve as a whole. Next, we
tried downsampling the ∼4500 pixel intensities over time into a ∼250 long vector. We also tried feature mapping by running
a fast Fourier transform (FFT) on the raw light curves, and sampling a ∼250 dimensional array of the FFT as the new feature
vector. The beneﬁt of this method is that it separates out the long-time variation in the star system’s intensity, which could
be likely due to intrinsic variation in the star’s luminous output, and also isolates much of the high-frequency noise in the
data collection as well. Next, we combined not just the basic light curve data but also measurements on the motion of the
star centroid, which gives an estimate of the wobble caused by a potential exoplanet. That dataset is an entire time series
on its own, but by measuring the correlations between that dataset (for both x and y centroid motion) and the light curves,
we came up with the 6 pairwise correlations between each of the three time series to use as features.

3.2 Extracting features for prediction of KOIs that are true exoplanets

3.2.1 KOI-speciﬁc characteristics

We discovered that there is signiﬁcant dependence among the 42 KOI-speciﬁc variables and the 25 star-speciﬁc variables
mentioned, so data reduction was performed by combining these into a 67-long vector and using principal components
analysis to select the top 30 components as features.

2

Figure 1: Light curves can be misleading. One can see that the left traces represent exoplanet-harbouring stars, whereas the
right traces represent non-exoplanet-harbouring stars; however clear transits (or lack thereof) can be observed in both cases.

3.2.2 KOI-speciﬁc time-series processing

A key variable available from the KOI-speciﬁc data is the timepoint at which planet transit occurs within the raw timeseries
data. Using this, we reduced our ∼4500 dimensional raw timeseries data to the 15 timepoints closest to the transit event.
We then calculated centroid-to-ﬂux cross-correlation using these short time windows, and used the corresponding 29-long
cross-correlation vectors as additional features. Compared to calculating correlations with full time-series, we expected this
technique to much better capture exoplanet-related wobble. To further reduce noise, we ﬁrst applied a ﬂatten / detrend
algorithm to the timeseries data, using the PyKE data package (software developed by NASA for analysing Kepler data).

4 Models and Results

Our problem is one of binary classiﬁcation. The algorithms we used are Naive Bayes, Logistic regression, and SVM (Gaussian
and/or linear kernel, see below for details). The performance of these algorithms was quantiﬁed using 5-fold cross validation
to generate test error rates.

4.1 Initial attempts at classifying stars

In our initial work, we ran a series of classiﬁcation attempts on the star dataset, ultimately with marginal success. First, we
began by exploring the notion of how well the star-speciﬁc features of the star system (no light curve data) could classify
exoplanets. Given that certain types of stars may be intrinsically more likely than others to harbour exoplanets, the ability to
predict exoplanets based on these characteristic features provides a useful baseline. After applying PCA, we ﬁnd that using
these features alone yields 60-65% accuracy in detection, depending on the classiﬁcation algorithm used. Of the classiﬁcation
algorithm types tested, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while Nave Bayes suﬀers from high
variance (high training/test error) so logistic regression emerges as the frontrunner. Following the classiﬁcation algorithms
using just the star features, we re-ran the classiﬁcation algorithms, but added features extracted from the light-curve time-
series in the form of global time-series statistics, downsampled time-series, FFT, and momentum correlations. Using these
additional features did not increase algorithm performance with any of the three classiﬁcation algorithms, as compared to
using only the global star features. As before, SVM appears to suﬀer from overﬁtting (training error (cid:28) test error) while
Nave Bayes has lost almost all accuracy, and logistic regression test accuracy remains near 65%. A summary of all these
techniques tried with the stellar characteristics, light curve, and centroid data is given in Table 4.1. Note we later re-analysed
this data using linear kernel SVM, which yielded performance similar to Logistic regression (data not shown).

4.2 Classiﬁcation of KOIs
As our initial attempts at binary-classiﬁcation of stars did no better than ∼ 67%, we shifted our focus to the alternate
strategy of classifying KOIs directly using the KOI-speciﬁc (rather than star-speciﬁc) features, applied on the dataset of

3

Feature mapping
Stellar features only
+Downsampling
+FFT
+Correlations
+Global statistics

Naive Bayes
60.0/57.7
51.0/50.3
51.6/50.5
55.6/55.0
55.2/53.7

SVM (Gaussian kernel) Logistic Regression
89.5/58.9
81.3/60.7
84.6/59.2
97.9/56.2
100.0/51.3

71.2/65.9
71.6/66.3
71.0/66.0
71.3/66.0
71.2/65.1

Table 1: Summary of performance for each classiﬁcation method with the feature set listed in the ﬁrst column. Each table
entry includes as percentages the training accuracy / 5-fold cross-validation accuracy.

KOIs (labelled as conﬁrmed exoplanet or false positive).
As before, we began by exploring the notion of how well the characteristic KOI features (no time-series data) could classify
exoplanets. After applying PCA, we ﬁnd that using these features alone yields ∼ 90% accuracy in detection, depending on
the classiﬁcation algorithm used. Given earlier problems with overﬁtting using Gaussian-kernel SVM, we tried a linear
kernel SVM. Of the classiﬁcation algorithm types tested, logistic regression performs best with a 93% accuracy, but the
performance of SVM and Naive Bayes is not far behind. Training and test accuracies are similar, suggesting that overﬁtting
is not a problem with our current feature set. For details on performance, see Table 2, and the ROC curves shown in Figure
2. The high accuracy suggests that the currently available Kepler features can be directly used to predict exoplanets versus
false positives, even without costly manual follow-up. As a side-note, we did run this dataset with Gaussian-kernel SVM,
and as before we observed major over-ﬁtting (data not shown).

Model

Accuracy (train/test %s) F1 score Area under ROC

SVM (linear kernel)

Naive Bayes

Logistic regression

91.5/90.4
88.3/88.2
94.3/93.2

0.908
0.887
0.933

0.943
0.853
0.968

Table 2: List of accuracies and related characteristics for the classiﬁcation on stellar and KOI characteristics

Figure 2: ROC curves for the classiﬁcation on stellar and KOI characteristics

We further tested whether our features we derived for the earlier attempts could improve the classiﬁcation attempts here.
In particular, we supplemented the stellar and KOI characteristics with the correlations we calculated earlier between the
light curves and the centroid movements. We then reran classiﬁcation with the new feature set (results depicted in Table 3
and in Figure 3). No signiﬁcant improvement is seen in performance with any of the three classiﬁcation algorithms, suggesting
that little if any predictive information is available from the cross-correlation vectors. Again, logistic regression appears to
be be the best-performing algorithm, followed by linear kernel SVM.

5 Discussion and Future directions

Our initial work for this project attempted to classify stars as harboring or not harboring exoplanets based on measurements
from the Kepler spacecraft. This work is applicable to any stars which were measured by the spacecraft, regardless of
whether they were picked out by NASA algorithms as Kepler objects of interest (KOIs). Despite several attempts, our best
classiﬁcation algorithm classiﬁed stars solely based on their intrinsic characteristics, and not by any time series data (light

4

Model

Accuracy (train/test %s) F1 score Area under ROC

SVM (linear kernel)

Naive Bayes

Logistic regression

90.5/90.4
80.6/80.8
95.1/93.3

0.909
0.8273
0.934

0.936
0.7654
0.960

Table 3: List of accuracies and related characteristics for the classiﬁcation on stellar and KOI characteristics plus our
correlation features

Figure 3: ROC curves for the classiﬁcation on stellar and KOI characteristics plus our correlation features

curves and centroid data). Interestingly, this still achieved an accuracy of 65%, which indicates that either certain types of
stars are more likely to harbor exoplanets (certainly possible given that a neutron star has little in common with a red giant,
for example), but could also indicate that NASA’s algorithms for KOI detection has a bias for certain types of stars. Given
the ﬁrst case, we could run our algorithm on unclassiﬁed data to obtain an order-of-magnitude estimate (with 66% accuracy)
for the number of planet-harboring stars. Such orders of magnitude are of interest to astronomers. Given the second case,
NASA’s algorithms could beneﬁt from a correction of such bias.

Our subsequent work for this project attempted to directly classify KOIs as conﬁrmed or false exoplanets based on
measurements from the Kepler spacecraft. As such, this work is not applicable to all stars for which Kepler took measurements,
only those identiﬁed by NASA’s transit detection algorithms. Our classiﬁcation algorithm can be used as another step in
the planet-ﬁnding pipeline, where it serves to weed out false positives prior to follow-up measurements. Given that the
manual follow-up measurements can be quite costly, there is a real need for algorithms which reduce the large number of false
positive KOIs. To demonstrate that ability, we ran our logistic regression classiﬁer with the KOI-speciﬁc feature set (ignoring
the added correlation features) on 2212 currently unclassiﬁed KOIs for which suﬃcient data was available. Of those, 644
were classiﬁed as true exoplanets, and 1568 were weeded out as false positives. A list of the predicted exoplanets and false
negatives is given in the appendix; we hope these serve as useful starting points for other planet hunters.

Given the variability in the data and relatively high accuracy achieved on KOI classiﬁcation using logistic regression, it
seems unlikely that a simple classiﬁcation algorithm will yield signiﬁcant improvements. Future possible directions could be
to ﬁnd better feature mappings to make use of the time-series data, such as hidden Markov models for transit detection and
dynamic time-warping for detecting similarities in time-series data. Further classiﬁcation algorithms can also be explored,
such as random forest and neural networks for deep-learning of time-series data.

References

[1] D. Fraquelli and S. E. Thompson Kepler Archive Manual. (KDMC-10008-005) 2014

[2] M. Still and T. Barclay, PyKE: Reduction and analysis of Kepler Simple Aperture Photometry data. Astrophysics Source

Code Library. Provided by the SAO/NASA Astrophysics Data System 2012

[3] K. Mandel and E. Agol Analytic light curves for planetary transit transit searches. The Astrophysical Journal. 580,

171-175, 2002

[4] L. Walkowicz, et al. Mining the Kepler Data using Machine Learning. American Astronomical Society. AAS Meeting 223,

2014

[5] T. Lee, et al. Feature extraction methods for time series data in SAS Enterprise Miner. SAS Institute Inc. 2014

5

Appendix: Exoplanet predictions 

Predicted Positive KOIs 

K00051.01, K00099.01, K00129.01, K00208.01, K00211.01, K00212.01, K00249.01, K00266.01, K00285.03, K00288.01, K00289.01, K002 94.01, K00296.01, K00304.02, K00306.01, K00307.01, K00330.01, K00333.01, K00339.02, K00364.01, K00365.01, K00366.01, K00373.01, K00384.01, K00409.01, K00416.03,  K00417.01, K00419.01, 
K00422.01, K00427.02, K00427.03, K00435.01, K00449.01, K00452.01, K00454.01, K00458.01, K00463.01, K00466.01 , K00467.01, K00487.01, K00488.01, K00490.02, K00490.04, K00496.01, K00499.01, K00500.05, K00503.01, K00507.01, K00512.01, K0 0521.01, K00525.01, K00530.01, K00531.01, K00538.01, K00541.01, K00548.01, 
K00550.01, K00568.02, K00592.01, K00612.03, K00624.03, K00625.01, K00626.02, K00633.01, K00639.01, K00641.01, K00647.01, K00649.02, K00650.01, K00659.01, K00680.01, K00686.01, K0068 7.01, K00689.01, K00709.01, K00717.01, K00728.01, K00734.01, K00734.02, K00755.01, K00758.01, K00764.01, K00772.01, K00774.01 , 
K00780.01, K00791.01, K00794.01, K00795.01, K00802.01, K00813.01, K00824.01, K00833.01, K00838.01, K00845.01, K00846.01, K00855.0 1, K00856.01, K00863.01, K00891.01, K00892.01, K00893.01, K00900.01, K00901.01, K00910.01, K00911.01, K00913.01, K00923.01, K 00924.01, K00926.01, K00928.01, K00929.01, K00942.01, 
K00943.01, K00945.01, K00945.03, K00969.01, K00974.01, K00977.01, K00987.01, K00991.01, K00992.02, K00994.01, K01007.01, K010 15.03, K01017.01, K01029.01, K01059.01, K01063.01, K01067.01, K01070.03, K01083.01,  K01096.01, K01117.01, K01129.01, K01145.01, K01146.01, K01151.05, K01170.01, K01194.02, K01202.01, 
K01207.01, K01218.01, K01220.01, K01226.01, K01227.01, K01232.01, K01239.01, K01242.01, K01246.01, K01261.01, K01273.01, K013 03.01, K01304.01, K01308.01, K01309.01, K01310.02, K01311.01, K01315.01, K01320.01, K01329.01, K01335.01, K01336.04, K01341.01, K01351.01, K01355.01, K01356 .01, K01358.01, K01375.01, 
K01378.01, K01379.01, K01397.01, K01403.01, K01405.01, K01406.01, K01411.01, K01420.01, K01427.01, K0142 8.01, K01431.01, K01445.02, K01456.01, K01457.01, K01465.01, K01472.01, K01476.01, K01478.01, K01483.01, K01491.01, K01495.01 , K01503.01, K01506.01, K01516.01, K01520.01, K01522.01, K01530.01, K01532.01, 
K01533.01, K01534.01, K01535.01, K01546.01, K01563.03, K01564.01, K01573.01, K01574.03, K01581.02, K01584.01, K01587.01, K01590.01, K01590.03, K01609.01, K01616.02, K01626.01, K 01632.01, K01637.01, K01646.01, K01651.01, K01669.01, K01683.01, K01693.01, K01702.01, K01708.01, K01710.01, K01716.01, K0171 8.01, 
K01722.01, K01724.01, K01731.01, K01747.01, K01771.01, K01773.01, K01781.03, K01782.01, K01783.01, K01784.01, K01786.01, K017 88.02, K01790.01, K01792.01, K01792.03, K01803.01, K01808.01, K01812.01, K01813.01, K01814.01, K01818.01, K01822.01, K01828.0 1, K01829.01, K01830.02, K01831.04, K01838.01, K01841.01, 
K01842.01, K01843.01, K01846.01, K01848.01, K01852.01, K01856.01, K01857.01, K01858.02, K01860.03, K01863.01, K01864.01, K018 72.01, K01875.01, K01875.02, K01876.01, K01879.01, K01880.01, K01882.01, K01884.02, K01885.01, K01886.01, K01897.01, K01898.01, K01899.01, K01904.01, K01910.01, K01913.01, K01914.01, 
K01921.01, K01922.03, K01933.01, K01935.01, K01940.02, K01944.01, K01957.01, K01961.01, K01962.01, K01965.01, K01967.01, K019 69.01, K01972.01, K01974.01, K01979.01, K01980.01, K01986.02, K01996.01, K01996.02, K01997.01, K02001.01, K02004.03, K02005.01, K02007.02, K02016.01, K0 2019.01, K02021.01, K02023.01, 
K02024.01, K02029.03, K02032.01, K02033.01, K02034.01, K02034.02, K02037.03, K02039.01, K02042.01, K02043.01, K02044.01, K02052.01, K02055.02, K02055.04, K02059.02, K02061.02, K02064.01, K02065.01, K02067.01, K02072.01, K0207 8.01, K02081.01, K02082.01, K02091.01, K02093.01, K02094.01, K02095.01, K02098.02, 
K02102.01, K02108.01, K02110.01, K02114.01, K02121.01, K02122.01, K02123.01, K02125.01, K02126.01, K02130.01, K02131.01, K02140.01, K02144.01, K02154.01, K02155.01, K02158.0 1, K02160.02, K02163.03, K02164.01, K02167.03, K02177.01, K02180.01, K02183.03, K02189.01, K02191.01, K02193.01, K02194.03, K 02202.01, 
K02205.01, K02206.01, K02210.01, K02210.02, K02216.01, K02217.01, K02220.05, K02224.02, K02225.01, K02229.01, K02232.01, K022 37.01, K02241.01, K02246.01, K02248.01, K02255.01, K02256.01, K02257.01, K02261.01, K02281.01, K02293.01, K02303.01, K02303.0 2, K02304.01, K02307.01, K02308.01, K02309.01, K02311.01, 
K02311.02, K02314.01, K02317.01, K02319.01, K02323.01, K02327.01, K02328.01, K02332.01, K02335.01, K02337.01, K02338.01, K023 39.01, K02340.01, K02352.03, K02353.01, K02354.01, K02355.01, K02357.01, K02357.02, K02358.01, K02362.02, K02370.01, K02371.01, K02372.01, K02373.01, K02376.01, K02377.01, K02392.01, 
K02393.01, K02393.02, K02399.01, K02401.01, K02403.01, K02407.01, K02408.01, K02409.01, K02410.01, K02411.01, K02415.01, K024 18.01, K02422.02, K02424.01, K02432.01, K02433.06, K02439.01, K02449.01, K02450.02, K02457.01, K02461.01, K02463.01, K02472.01, K02483.01, K02484.01 , K02485.03, K02489.01, K02490.01, 
K02491.01, K02493.01, K02516.01, K02519.01, K02521.01, K02522.01, K02523.01, K02524.01, K02528.0 1, K02531.01, K02535.01, K02538.01, K02547.01, K02551.01, K02552.01, K02563.01, K02580.01, K02585.03, K02597.03, K02601.01, K 02610.02, K02612.02, K02615.01, K02619.01, K02623.01, K02624.01, K02626.01, K02627.01, 
K02628.01, K02634.01, K02637.01, K02639.01, K02639.02, K02641.01, K02647.01, K02649.01, K02652.01, K02654.01, K02656.01, K02658.01, K02659.01, K02662.01, K02666.01, K026 75.01, K02682.01, K02683.01, K02687.01, K02687.02, K02690.01, K02691.01, K02696.02, K02698.01, K02699.01, K02704.02, K02714.0 3, K02716.02, 
K02717.01, K02720.01, K02732.04, K02742.01, K02743.01, K02753.01, K02754.01, K02755.01, K02762.01, K02763.01, K02778.01, K027 80.01, K02805.01, K02817.01, K02822.01, K02828.01, K02835.01, K02840.02, K02845.01, K02848.01, K02851.01, K02853.01, K02859 .02, K02859.04, K02913.01, K02915.01, K02926.03, K02933.01, 
K02961.01, K02977.01, K02992.01, K03050.01, K03068.01, K03071.01, K03077.01, K03077.02, K03083.01, K03083.03, K03088.01, K030 91.01, K03095.01, K03101.01, K03108.01, K03111.01, K03111.02, K03112.01, K03113.01, K03116.01, K03117.01, K03119.01, K03123.01, K03127.01, K03128.01, K03130.01, K03138.01, K03142.01, 
K03146.01, K03147.01, K03158.01, K03158.02, K03158.05, K03194.01, K03196.01, K03203.01, K03209.01, K03214.02, K03225.01, K032 37.01, K03246.01, K03255.01, K03258.01, K03260.01, K03261.01, K03263.01, K03264.01, K03266.01, K03267.01, K03274.01, K03277.01, K03279.01, K0328 3.02, K03284.01, K03286.01, K03298.01, 
K03303.01, K03305.01, K03306.01, K03307.01, K03308.02, K03309.01, K03311.01, K03315.01, K03323.01, K03329.01, K03334.01, K03344.01, K03347.01, K03354.01, K03355.01, K03357.01, K03363.01, K03370.01, K03377.01, K03379.0 1, K03396.01, K03397.01, K03398.01, K03404.01, K03408.01, K03420.01, K03420.02, K03428.01, 
K03443.01, K03444.03, K03455.01, K03474.01, K03486.01, K03493.01, K03495.01, K03495.02, K03496.01, K03496.02, K03500.01, K03500.02, K03508.01, K03520.01, K03527.01,  K03541.01, K03545.01, K03554.01, K03557.01, K03605.01, K03608.01, K03627.02, K03647.01, K03652.01, K03675.01, K03678.01, K036 80.01, K03681.01 

Predicted Negative KOIs 

K00005.01, K00005.02, K00012.01, K00049.01, K00075.01, K00089.01, K00089.02, K00092.01, K00100.01, K00103.01, K00105.01, K001 07.01, K00110.01, K00112.01, K00112.02, K00115.03, K00118.01, K00131.01, K00138.01, K00141.01, K00144.01, K00145.01, K00149.0 1, K00151.01, K00155.01, K00161.01, K00162.01, K00165.01, 
K00166.01, K00167.01, K00173.01, K00174.01, K00176.01, K00177.01, K00179.01, K00179.02, K00180.01, K00186.01, K00189.01, K001 90.01, K00191.01, K00191.02, K00191.03, K00191.04, K00193.01, K00197.01, K00198.01, K00199.01, K00201.01, K00205.01, K00206.01, K00219.01, K00221.01, K00221.02, K00225.01, K00226.01, 
K00227.01, K00234.01, K00235.01, K00237.01, K00240.01, K00242.01, K00247.01, K00252.01, K00253.01, K00253.02, K00255.01, K002 55.02, K00256.01, K00257.01, K00265.01, K00266.02, K00268.01, K00269.01, K00270.01, K00270.02, K00273.01, K00276.01, K00279.01, K00279.02, K00279.03, K0 0280.01, K00281.01, K00284.04, 
K00289.02, K00297.01, K00298.01, K00298.02, K00303.01, K00304.01, K00307.02, K00308.01, K00315.01, K00316.03, K00317.01, K00318.01, K00319.01, K00323.01, K00326.01, K00326.02, K00330.02, K00331.01, K00332.01, K00332.02, K0033 7.01, K00337.02, K00339.01, K00340.01, K00344.01, K00345.01, K00346.01, K00348.01, 
K00349.01, K00350.01, K00351.07, K00353.01, K00353.02, K00353.03, K00354.01, K00354.02, K00355.01, K00356.01, K00361.01, K00367.01, K00368.01, K00371.01, K00372.01, K00374.0 1, K00375.01, K00379.02, K00385.01, K00387.01, K00388.01, K00393.01, K00398.01, K00403.01, K00410.01, K00412.01, K00415.01, K 00420.01, 
K00421.01, K00425.01, K00426.01, K00427.01, K00429.01, K00430.01, K00430.02, K00432.01, K00433.01, K00433.02, K00435.02, K004 35.04, K00435.06, K00436.01, K00439.01, K00442.03, K00443.01, K00444.01, K00460.01, K00464.01, K00464.02, K00468.01, K00469.0 1, K00470.01, K00473.01, K00474.03, K00476.01, K00477.01, 
K00478.01, K00479.01, K00480.01, K00481.02, K00483.01, K00484.01, K00486.01, K00492.01, K00492.02, K00494.01, K00501.01, K005 13.01, K00517.01, K00520.04, K00524.01, K00526.01, K00532.01, K00533.01, K00533.02, K00535.01, K00536.01, K00537.01, K00547.01, K00554.01, K00555.01, K00555.02, K00557.01, K00558.01, 
K00560.01, K00561.01, K00563.01, K00564.01, K00564.02, K00564.03, K00566.01, K00568.01, K00575.01, K00577.01, K00577.02, K005 78.01, K00580.01, K00581.01, K00581.02, K00582.01, K00583.01, K00584.03, K00585.01, K00586.01, K00587.01, K00588.01, K00593.01, K00593.02, K00593.03 , K00596.01, K00599.01, K00600.01, 
K00600.02, K00601.01, K00601.02, K00601.03, K00602.01, K00605.01, K00605.02, K00607.01, K00610.0 1, K00611.01, K00614.01, K00617.01, K00618.01, K00626.01, K00627.01, K00627.02, K00628.01, K00629.01, K00632.01, K00635.01, K 00640.01, K00645.01, K00645.02, K00647.02, K00649.01, K00652.01, K00660.01, K00662.01, 
K00666.01, K00670.01, K00673.01, K00674.01, K00682.01, K00683.01, K00684.01, K00685.01, K00688.01, K00691.01, K00691.02, K00694.01, K00695.01, K00697.01, K00698.01, K007 04.01, K00710.03, K00711.03, K00714.01, K00716.01, K00717.02, K00721.01, K00722.01, K00732.01, K00732.02, K00732.03, K00735.0 1, K00739.01, 
K00740.01, K00744.01, K00746.01, K00747.01, K00750.01, K00750.02, K00750.03, K00751.01, K00753.01, K00760.01, K00762.01, K007 63.01, K00765.01, K00766.01, K00767.01, K00769.01, K00771.01, K00773.01, K00776.01, K00777.01, K00778.01, K00780.02, K00781 .01, K00782.01, K00783.01, K00785.01, K00786.01, K00788.01, 
K00797.01, K00801.01, K00804.01, K00805.01, K00809.01, K00810.01, K00811.01, K00814.01, K00815.01, K00816.01, K00818.01, K008 21.01, K00823.01, K00826.01, K00841.03, K00841.04, K00843.01, K00844.01, K00847.01, K00849.01, K00850.01, K00851.01, K00852.01, K00854.01, K00858.01, K00861.01, K00865.01, K00867.01, 
K00868.01, K00869.04, K00871.01, K00873.01, K00875.01, K00878.01, K00881.01, K00881.02, K00883.01, K00887.01, K00890.01, K008 92.02, K00895.01, K00896.03, K00897.01, K00902.01, K00908.01, K00911.02, K00914.01, K00916.01, K00918.01, K00920.01, K00922.01, K00931.01, K0093 5.04, K00936.01, K00936.02, K00937.01, 
K00938.02, K00940.01, K00945.02, K00947.01, K00948.01, K00949.01, K00953.01, K00955.01, K00956.01, K00972.01, K00972.02, K00976.01, K00984.01, K00989.03, K00992.01, K00993.03, K01002.01, K01005.01, K01014.01, K01015.0 1, K01015.02, K01020.01, K01022.01, K01024.01, K01030.01, K01031.01, K01032.01, K01050.01, 
K01050.02, K01051.01, K01053.01, K01053.02, K01061.01, K01066.01, K01069.01, K01069.02, K01072.01, K01074.01, K01081.01, K01082.01, K01082.02, K01082.03, K01082.04,  K01085.01, K01086.01, K01089.02, K01094.01, K01095.01, K01099.01, K01101.01, K01101.02, K01106.01, K01106.02, K01108.01, K011 08.02, K01110.01, 
K01115.01, K01116.01, K01118.01, K01127.03, K01128.01, K01137.01, K01141.01, K01142.01, K01150.01, K01151.03, K01151.04, K011 59.01, K01160.01, K01162.01, K01165.01, K01165.02, K01166.01, K01168.01, K01169.01, K01174.01, K01175.01, K01175.02, K0 1176.01, K01191.01, K01192.01, K01193.01, K01198.04, K01199.01, 
K01201.01, K01204.01, K01205.01, K01206.01, K01208.01, K01209.01, K01210.01, K01212.01, K01214.01, K01216.01, K01230.01, K012 38.01, K01239.02, K01245.01, K01255.01, K01258.03, K01261.02, K01264.01, K01266.01, K01268.01, K01271.01, K01275.01, K01276.01, K01276.02, K01279.01, K01279.02, K01281.01, K01282.01, 
K01283.01, K01288.01, K01300.01, K01302.01, K01310.01, K01312.01, K01314.01, K01316.01, K01316.02, K01323.01, K01325.01, K013 26.01, K01328.01, K01331.01, K01337.01, K01338.01, K01338.02, K01338.03, K01339.01, K01342.02, K01344.01, K01357.01, K01358.02, K01358.03, K 01358.04, K01359.01, K01359.02, K01360.03, 
K01362.01, K01367.01, K01369.01, K01370.01, K01377.01, K01385.01, K01387.01, K01391.01, K01393.01, K01395.01, K01398.01, K01399.01, K01402.01, K01404.01, K01404.02, K01408.01, K01409.01, K01410.01, K01412.01, K014 21.01, K01423.01, K01424.01, K01425.01, K01426.03, K01429.01, K01433.01, K01434.01, K01437.01, 
K01438.01, K01439.01, K01440.01, K01441.01, K01444.01, K01445.01, K01445.03, K01452.01, K01458.01, K01463.01, K01466.01, K01470.01, K01473.01, K01475.01, K01475. 02, K01475.03, K01477.01, K01480.01, K01480.02, K01481.01, K01484.01, K01488.01, K01489.01, K01494.01, K01496.01, K01498.01,  K01498.02, K01499.01, 
K01499.02, K01499.03, K01501.01, K01505.01, K01507.01, K01508.01, K01510.01, K01511.01, K01517.01, K01518.01, K01519.01, K015 19.02, K01521.01, K01522.02, K01525.01, K01525.02, K01526.01, K01527.01, K01528.01, K01531.01, K01534.02, K01536.01 , K01537.01, K01547.01, K01549.01, K01552.01, K01553.01, K01557.04, 
K01558.01, K01561.01, K01562.02, K01569.01, K01570.01, K01572.01, K01573.02, K01576.03, K01577.01, K01581.01, K01582.01, K015 83.01, K01585.01, K01586.01, K01588.01, K01590.02, K01591.01, K01595.01, K01597.01, K01599.01, K01599.02, K01601.01, K01601.02, K01602.01, K01603.01, K01606.01, K01608.03, K01613.01, 
K01613.02, K01615.01, K01616.01, K01618.01, K01619.01, K01621.01, K01622.01, K01627.01, K01627.02, K01627.03, K01629.01, K016 30.01, K01633.01, K01639.02, K01641.01, K01643.01, K01645.01, K01647.03, K01648.01, K01649.01, K01650.01, K01650.02, K01655.01, K01656.0 1, K01659.01, K01660.01, K01662.01, K01665.01, 
K01665.02, K01672.01, K01675.01, K01677.01, K01677.02, K01681.01, K01681.02, K01681.03, K01684.01, K01685.01, K01687.01, K01688.01, K01691.01, K01695.01, K01700.01, K01701.01, K01704.01, K01705.01, K01706.01,  K01711.01, K01715.01, K01717.01, K01718.02, K01720.01, K01721.01, K01723.01, K01725.01, K01726.01, 
K01727.01, K01732.01, K01733.01, K01736.01, K01738.01, K01739.01, K01746.01, K01749.01, K01750.01, K01750.02, K01751.01, K01751.02, K01754.01, K01758.01, K017 61.01, K01762.01, K01772.01, K01781.01, K01783.02, K01787.01, K01788.01, K01793.01, K01796.01, K01797.01, K01798.01, K01799.0 1, K01800.01, K01801.01, 
K01802.01, K01804.01, K01815.01, K01816.01, K01819.01, K01821.01, K01825.01, K01826.01, K01830.01, K01831.03, K01833.01, K018 33.02, K01833.03, K01837.01, K01837.02, K01839.01, K01839.02, K01840.01, K01843.02, K01845.01, K01845.02, K0184 7.01, K01849.01, K01850.01, K01851.01, K01853.01, K01854.01, K01858.01, 
K01860.04, K01861.01, K01862.01, K01866.01, K01868.01, K01870.01, K01871.01, K01871.02, K01877.01, K01878.01, K01881.01, K018 83.01, K01884.01, K01889.01, K01889.02, K01890.01, K01892.01, K01893.01, K01894.01, K01899.02, K01900.01, K01901.01, K01902.01, K01906.01, K01907.01, K01911.01, K01917.01, K01920.01, 
K01920.02, K01922.01, K01922.02, K01923.01, K01928.01, K01934.01, K01937.01, K01938.01, K01939.01, K01940.01, K01942.01, K019 45.01, K01945.02, K01946.01, K01950.01, K01951.01, K01955.03, K01959.01, K01963.01, K01964.01, K01968.01, K01971.01, K01972.02, K019 73.01, K01975.01, K01976.01, K01981.01, K01982.01, 
K01984.01, K01985.01, K01986.01, K01988.01, K01989.01, K01990.01, K01992.03, K01998.01, K02000.01, K02002.01, K02004.01, K02004.02, K02006.01, K02009.01, K02010.01, K02012.01, K02012.02, K02013.01, K02014. 01, K02017.01, K02018.01, K02020.01, K02026.01, K02028.03, K02029.04, K02031.01, K02035.01, K02037.01, 
K02037.02, K02039.02, K02040.01, K02046.01, K02047.01, K02048.01, K02048.02, K02049.01, K02055.01, K02055.03, K02056.01, K02057.01, K02058.01, K02059.01,  K02060.01, K02061.01, K02062.01, K02063.01, K02066.01, K02069.01, K02071.01, K02074.01, K02075.01, K02076.01, K02076.02, K020 78.02, K02079.01, K02083.01, 
K02084.01, K02087.01, K02090.01, K02093.02, K02094.02, K02096.01, K02097.01, K02098.01, K02099.01, K02100.01, K02101.01, K021 03.01, K02104.01, K02105.01, K02106.01, K02107.01, K02109.01, K02116.01, K02117.01, K02119.01, K02120.01, K02124.01, K02128.01, K02129.01, K02132.01, K02134.01, K02135.02, K02137.01, 
K02138.01, K02143.01, K02145.01, K02146.01, K02149.01, K02150.01, K02150.02, K02152.01, K02156.01, K02158.02, K02159.01, K021 60.01, K02162.01, K02162.02, K02166.01, K02167.01, K02167.02, K02169.01, K02169.02, K02169.03, K02169.04, K02171.01, K02172.01, K02174.01, K02174.02, K02174.03, K02181.01, K02182.0 1, 
K02184.02, K02185.01, K02186.01, K02188.02, K02193.02, K02198.01, K02199.01, K02200.01, K02201.01, K02204.01, K02208.01, K022 09.01, K02209.02, K02212.01, K02213.01, K02214.01, K02215.01, K02219.01, K02220.04, K02221.01, K02222.01, K02224.01, K02226.01,  K02227.01, K02238.01, K02242.01, K02243.01, K02243.02, 
K02245.01, K02247.01, K02248.02, K02248.03, K02248.04, K02250.01, K02250.02, K02252.01, K02253.01, K02257.02, K02259.01, K02260.01, K02261.02, K02263.01, K02263.02, K02264.01, K02266.01, K02269.01, K022 71.01, K02272.01, K02273.01, K02274.01, K02276.01, K02280.01, K02282.01, K02283.01, K02285.01, K02286.01, 
K02288.01, K02290.01, K02291.01, K02294.01, K02295.01, K02296.01, K02297.01, K02298.01, K02299.01, K02300.01, K02302.01, K02305.01, K02306.01, K02310 .01, K02311.03, K02312.01, K02313.01, K02315.01, K02316.01, K02318.01, K02321.01, K02324.01, K02325.01, K02327.02, K02329.01,  K02331.01, K02339.02, K02342.01, 
K02343.01, K02344.01, K02345.01, K02346.01, K02347.01, K02348.01, K02350.01, K02351.01, K02356.01, K02361.01, K02363.01, K023 64.01, K02366.01, K02367.01, K02368.01, K02369.01, K02369.02, K02378.01, K02379.01, K02380.01, K02383.0 1, K02386.01, K02387.01, K02389.01, K02390.01, K02396.01, K02397.01, K02398.01, 
K02400.01, K02402.01, K02404.01, K02406.01, K02410.02, K02416.01, K02417.01, K02419.01, K02420.01, K02420.02, K02421.01, K024 22.01, K02423.01, K02426.01, K02430.01, K02433.03, K02433.04, K02433.07, K02436.01, K02437.01, K02440.01, K02444.01, K02445.01, K02448.01, K02450.01, K02451.01, K02453.01, K024 58.01, 
K02458.02, K02460.01, K02462.01, K02467.01, K02468.01, K02469.01, K02470.01, K02471.01, K02474.01, K02477.01, K02479.01, K02 480.01, K02481.01, K02482.01, K02485.01, K02485.02, K02486.01, K02487.01, K02488.01, K02492.01, K02494.01, K02497.01, K02503. 01, K02504.01, K02506.01, K02507.01, K02508.01, K02509.01, 
K02512.01, K02513.01, K02517.01, K02520.01, K02521.02, K02525.01, K02527.01, K02529.01, K02529.02, K02530.01, K02532.01, K02533.01, K02533.03, K02534.01, K02534.02, K02536.01, K02542.01, K02543.01,  K02544.01, K02545.01, K02548.01, K02550.01, K02553.01, K02554.01, K02554.02, K02555.01, K02556.01, K02559.01, 
K02560.01, K02561.01, K02563.02, K02564.01, K02569.01, K02571.01, K02572.01, K02573.01, K02577.01, K02578.01, K02579.01, K02579.02, K02579.03, K0 2581.01, K02582.01, K02583.01, K02586.01, K02587.01, K02588.01, K02589.01, K02590.02, K02592.01, K02593.01, K02594.01, K02598 .01, K02602.01, K02603.01, K02604.01, 
K02607.01, K02608.01, K02610.01, K02612.01, K02613.01, K02617.01, K02620.01, K02625.01, K02631.01, K02632.01, K02635.01, K026 36.01, K02638.01, K02640.01, K02655.01, K02657.01, K02660.01, K02664.01, K02668.01, K02674.01, K02674.02, K02674.03, K02675.02, K02677.01, K02678.01, K02679.01, K02680.01, K02686.01, 
K02688.01, K02689.01, K02693.03, K02694.01, K02694.02, K02696.01, K02700.01, K02703.01, K02704.01, K02705.01, K02706.01, K027 08.01, K02712.01, K02715.01, K02715.02, K02715.03, K02716.01, K02719.01, K02721.01, K02722.05, K02723.01, K02728.01, K02729.01, K02730.01, K02732.02, K02733.01, K02734.01,  K02735.01, 
K02736.01, K02739.01, K02739.02, K02744.01, K02744.02, K02745.01, K02747.01, K02748.01, K02748.02, K02750.01, K02751.01,  K02756.01, K02757.01, K02758.01, K02759.01, K02760.01, K02764.01, K02770.01, K02775.01, K02779.01, K02785.01, K02786.01, K027 89.01, K02790.01, K02791.01, K02792.01, K02793.01, K02793.02, 
K02795.01, K02796.01, K02797.01, K02798.01, K02801.01, K02802.01, K02803.01, K02806.01, K02807.01, K02812.01, K02813.01, K02816.01, K02820.01, K02821.01, K02827.01, K02828.02, K02829.01, K02830 .01, K02832.01, K02833.01, K02834.01, K02836.01, K02837.01, K02838.02, K02839.01, K02840.01, K02841.01, K02849.01, 
K02851.02, K02852.01, K02855.01, K02856.01, K02857.01, K02857.02, K02859.01, K02859.03, K02860.01, K02862.01, K02865.01, K02866.01, K02867.02 , K02868.01, K02869.01, K02869.02, K02871.01, K02871.02, K02871.03, K02874.01, K02875.01, K02876.01, K02877.01, K02878.01, K0 2882.01, K02882.02, K02883.01, K02886.01, 
K02890.01, K02894.01, K02898.01, K02899.01, K02900.01, K02904.01, K02906.01, K02906.02, K02910.01, K02914.01, K02916.01, K029 19.01, K02920.01, K02921.01, K02923.01, K02924.01, K02925.01, K02926.01, K02926.02, K02926.04, K02927.01, K02931.01, K02935.01, K02936.01, K02942.01, K02942.02, K02943.01, K02945.01, 
K02946.01, K02948.01, K02949.01, K02949.02, K02950.01, K02951.01, K02956.01, K02957.01, K02958.01, K02959.01, K02962.01, K029 63.01, K02963.02, K02964.01, K02967.01, K02968.01, K02970.01, K02971.01, K02971.02, K02972.01, K02972.02, K02975.01, K02976.01, K02977.02, K02980.01, K02981.01, K02982. 01, K02984.01, 
K02989.01, K02990.01, K02994.01, K02995.01, K02996.01, K02998.01, K03004.01, K03004.02, K03007.01, K03008.01, K03009 .01, K03010.01, K03013.01, K03014.01, K03015.01, K03017.01, K03019.01, K03020.01, K03022.01, K03022.02, K03026.01, K03027.01,  K03028.02, K03029.01, K03029.02, K03031.01, K03034.01, K03037.01, 
K03038.01, K03039.01, K03040.01, K03041.01, K03042.01, K03043.01, K03043.02, K03045.01, K03048.01, K03049.01, K03051.01, K03052.01, K03052.02, K03053.01, K03056.01, K03060.01, K03061.01, K0 3061.02, K03063.01, K03065.01, K03066.01, K03069.01, K03072.01, K03073.01, K03075.01, K03078.01, K03083.02, K03086.01, 
K03088.02, K03089.01, K03093.01, K03094.01, K03096.01, K03102.01, K03104.01, K03105.01, K03106.01, K03109.01, K03110.01, K03115.01, K0312 0.01, K03122.01, K03125.01, K03130.02, K03131.01, K03136.01, K03137.01, K03140.01, K03141.01, K03144.01, K03145.01, K03145.02 , K03158.03, K03158.04, K03161.01, K03165.01, 
K03168.01, K03179.01, K03184.01, K03190.01, K03196.02, K03202.01, K03204.01, K03208.01, K03214.01, K03224.01, K03232.01, K032 34.01, K03236.01, K03242.01, K03245.01, K03248.01, K03259.01, K03262.01, K03268.01, K03271.01, K03271.02, K03280.01, K03281.01, K03282.01, K03283.03, K03287.01, K03288.01, K03296.01, 
K03301.01, K03308.01, K03310.01, K03312.01, K03313.01, K03316.01, K03318.02, K03319.01, K03319.02, K03319.03, K03320.01, K033 24.01, K03330.01, K03331.01, K03335.01, K03337.01, K03340.01, K03340.02, K03341.01, K03341.02, K03342.01, K03343.01, K03344.02, K03345.01, K03346.01, K03348.01, K033 49.01, K03352.01, 
K03353.01, K03356.01, K03358.01, K03361.01, K03365.01, K03367.01, K03370.02, K03371.01, K03371.02, K03372.01, K0 3374.01, K03374.02, K03375.01, K03383.01, K03384.01, K03384.02, K03385.01, K03386.01, K03389.01, K03391.01, K03393.01, K03394 .01, K03395.01, K03398.02, K03398.03, K03401.01, K03401.02, K03403.01, 
K03403.02, K03407.01, K03410.01, K03410.02, K03411.01, K03412.01, K03413.01, K03414.01, K03415.01, K03416.01, K03417.01, K03418.01, K03419.01, K03421.01, K03423.01, K03425.01, K03425.02 , K03426.01, K03429.01, K03429.02, K03430.01, K03432.01, K03433.01, K03434.01, K03436.01, K03437.01, K03437.02, K03438.01, 
K03439.01, K03440.01, K03440.02, K03444.01, K03444.02, K03444.04, K03445.01, K03448.01, K03449.01, K03451.01, K03456.01, K03456.02, K 03458.01, K03459.01, K03460.01, K03462.01, K03462.02, K03463.01, K03465.01, K03467.01, K03468.01, K03470.01, K03470.02, K0347 2.01, K03473.01, K03478.01, K03480.01, K03481.01, 
K03482.01, K03483.01, K03484.01, K03487.01, K03494.01, K03497.01, K03503.01, K03503.02, K03504.02, K03506.01, K03515.01, K035 22.01, K03528.01, K03531.01, K03536.01, K03560.01, K03565.01, K03573.01, K03583.01, K03602.01, K03606.01, K03611.01, K03617.01, K03620.01, K03626.01, K03649.01, K03660.01, K03674.01,  

KOIs with Insufficient Data 

K00005.02, K00049.01, K00051.01, K00099.01, K00102.01, K00102.02, K00115.03, K00151.01, K00179.02, K00191.01, K00191.04, K002 27.01, K00239.01, K00239.02, K00266.01, K00266.02, K00268.01, K00270.01, K00270.02, K00279.03, K00285.03, K00288.01, K002 89.01, K00289.02, K00298.01, K00298.02, K00304.02, K00319.01, 
K00326.01, K00326.02, K00337.02, K00351.07, K00353.03, K00364.01, K00366.01, K00375.01, K00387.01, K00388.01, K00403.01, K004 22.01, K00435.02, K00490.02, K00490.04, K00492.02, K00504.01, K00520.04, K00521.01, K00533.02, K00564.01, K00577.01, K00593.01, K00593.02, K00593.03, K00600.02, K00601.02, K00622.01, 
K00649.02, K00682.01, K00698.01, K00710.03, K00717.02, K00732.02, K00750.02, K00750.03, K00771.01, K00780.02, K00823.01, K008 41.04, K00896.03, K00935.04, K00945.03, K00969.01, K00976.01, K00977.01, K00989.03, K00992.02, K00993.03, K01015.03, K01032.01, K01053.02, K010 60.01, K01060.02, K01060.03, K01060.04, 
K01063.01, K01070.03, K01082.04, K01096.01, K01101.01, K01103.01, K01127.03, K01168.01, K01174.01, K01192.01, K01198.04, K01206.01, K01208.01, K01209.01, K01255.01, K01283.01, K01310.01, K01310.02, K01316.01, K01316 .02, K01337.01, K01351.01, K01356.01, K01360.03, K01375.01, K01378.01, K01411.01, K01421.01, 
K01445.02, K01445.03, K01463.01, K01475.03, K01480.02, K01498.02, K01499.02, K01519.02, K01522.02, K01537.01, K01546.01, K01561.01, K01562.02, K01576.03, K01597.01 , K01599.01, K01608.03, K01613.01, K01613.02, K01616.02, K01637.01, K01639.02, K01647.03, K01662.01, K01665.02, K01677.02, K0 1681.03, K01725.01, 
K01739.01, K01750.02, K01754.01, K01792.01, K01796.01, K01831.03, K01839.02, K01845.01, K01845.02, K01852.01, K01858.02, K018 60.04, K01875.01, K01884.01, K01899.02, K01920.02, K01922.02, K01940.02, K01945.02, K01962.01, K01992.03, K01995.01, K01996.02, K02004.03, K02012.02, K02039.02, K02055.04, K02059.02, 
K02061.02, K02069.01, K02160.02, K02163.03, K02167.02, K02169.04, K02174.03, K02183.03, K02184.02, K02188.02, K02193.02, K021 94.03, K02206.01, K02208.01, K02209.02, K02210.02, K02215.01, K02220.04, K02220.05, K02222.01, K02223.01, K02224.02, K02248.02, K02248.04, K02261.02, K02303.01, K02303.02, K02311.01, 
K02311.02, K02311.03, K02312.01, K02323.01, K02324.01, K02327.02, K02339.02, K02352.03, K02357.02, K02369.02, K02393.02, K023 96.01, K02409.01, K02410.01, K02410.02, K02411.01, K02417.01, K02420.02, K02433.06, K02433.07, K02450.02, K02453.01, K02474.01, K02481.01,  K02486.01, K02497.01, K02533.03, K02554.01, 
K02563.02, K02593.01, K02603.01, K02608.01, K02610.01, K02610.02, K02636.01, K02639.01, K02639.02, K02640.01, K02659.01, K02682.01, K02688.01, K02704.01, K02704.02, K02705.01, K02714.03, K02739.02, K02750.01, K0 2754.01, K02828.02, K02842.01, K02842.02, K02842.03, K02859.04, K02867.02, K02869.02, K02871.03, 
K02874.01, K02875.01, K02882.02, K02883.01, K02906.01, K02906.02, K02915.01, K02916.01, K02926.03, K02926.04, K02949.02, K02950.01, K02957.01, K02968.01, K0297 1.02, K03004.02, K03009.01, K03017.01, K03022.02, K03028.02, K03029.02, K03038.01, K03041.01, K03042.01, K03043.02, K03061.02 , K03065.01, K03075.01, 
K03078.01, K03083.02, K03083.03, K03088.02, K03089.01, K03095.01, K03102.01, K03104.01, K03105.01, K03106.01, K03109.01, K031 12.01, K03116.01, K03128.01, K03137.01, K03138.01, K03141.01, K03158.01, K03158.02, K03158.03, K03158.04, K03158.05, K03161.01, K03179.01, K03184.01, K03190.01, K03204.01, K03208.01, 
K03214.02, K03225.01, K03283.02, K03283.03, K03313.01, K03339.01, K03370.01, K03370.02, K03371.02, K03401.02, K03404.01, K034 10.02, K03420.01, K03425.01, K03425.02, K03430.01, K03440.02, K03444.04, K03456.02, K03458.01, K03462.01, K03462.02, K03483.01, K03495.02, K03496.01, K03496.02, K03497.01, K03500.02, 
K03503.02, K03504.02, K03520.01, K03528.01, K03536.01, K03541.01, K03545.01, K03554.01, K03560.01, K03649.01, K03660.01, K036 78.01, K03681.01, K03681.02, K03735.01, K03738.01, K03741.02, K03741.03, K03741.04, K03767.01, K03783.01, K03818.01, K03855.01, K03875 .01, K03878.02, K03880.01, K03909.01, K03947.02, 
K03954.02, K04009.01, K04009.02, K04032.01, K04032.02, K04032.03, K04032.04, K04034.02, K04066.01, K04097.02, K04103.02, K04135.01, K04149.01, K04149.02, K04188.01, K04189.01, K04192.02, K04198.01, K04230.01 , K04246.02, K04253.01, K04259.01, K04267.01, K04268.01, K04269.02, K04276.01, K04287.02, K04290.01, 
K04294.01, K04298.01, K04325.01, K04327.01, K04331.01, K04333.01, K04341.01, K04351.01, K04357.01, K04363.01, K04366.01, K04382.02, K04385.02, K04385.03, K 04389.01, K04393.01, K04395.01, K04407.01, K04418.01, K04424.01, K04426.01, K04428.01, K04431.01, K04435.02, K04447.01, K0446 2.01, K04477.01, K04487.01, 
K04500.01, K04500.02, K04503.01, K04504.02, K04506.01, K04512.01, K04524.02, K04541.02, K04545.01, K04546.01, K04549.01, K045 56.01, K04557.01, K04558.01, K04563.01, K04566.01, K04567.02, K04582.01, K04583.01, K04587.01, K04588.01, K04 591.01, K04595.01, K04597.01, K04602.01, K04613.01, K04625.01, K04637.01, 
K04643.01, K04647.02, K04650.01, K04651.01, K04656.01, K04657.02, K04663.01, K04666.01, K04674.01, K04676.01, K04691.01, K046 93.01, K04700.01, K04705.01, K04709.01, K04711.01, K04713.01, K04714.01, K04715.01, K04717.01, K04735.01, K04744.01, K04749.01, K04754.01, K04755.01, K04756.01, K04758.01, K04768.01,  
K04772.01, K04772.02, K04773.01, K04774.01, K04780.01, K04782.01, K04790.01, K04792.01, K04793.01, K04797.01, K04801.01, K048 13.01, K04815.01, K04818.01, K04822.01, K04823.01, K04826.01, K04829.01, K04834.01, K04837.01, K04839.01, K04848.01, K04849.01, K0 4850.01, K04852.01, K04854.01, K04855.01, K04857.01, 
K04859.01, K04862.01, K04864.01, K04871.01, K04875.01, K04877.01, K04881.01, K04886.01, K04890.01, K04893.01, K04895.02, K04896.01, K04904.01, K04907.01, K04912.01, K04913.01, K04913.02, K04923.01, K0492 6.01, K04927.01, K04928.01, K04936.01, K04938.01, K04939.01, K04958.01, K04959.01, K04960.01, K04961.01, 
K04967.01, K04968.01, K04972.01, K04975.01, K04976.01, K04977.01, K04978.01, K04980.01, K04982.01, K04986.01, K04988.01, K04991.01, K04992.01, K04999.0 1, K05004.01, K05007.01, K05017.01, K05018.01, K05021.01, K05023.01, K05027.01, K05030.01, K05033.01, K05034.01, K05040.01, K 05046.01, K05047.01, K05048.01, 
K05052.01, K05057.01, K05058.01, K05059.01, K05067.01, K05068.01, K05071.01, K05079.01, K05083.01, K05084.01, K05085.01, K050 86.01, K05087.01, K05088.01, K05092.01, K05093.01, K05098.01, K05099.01, K05101.01, K05104.01, K05107.01,  K05109.01, K05110.01, K05115.01, K05117.01, K05119.01, K05121.01, K05124.01, 
K05126.01, K05127.01, K05129.01, K05131.01, K05132.01, K05135.01, K05138.01, K05142.01, K05149.01, K05155.01, K05156.01, K051 58.01, K05164.01, K05169.01, K05176.01, K05178.01, K05179.01, K05192.01, K05196.01, K05202.01, K05205.01, K05206.01, K05207.01, K05211.01, K05216.01, K05219.01, K05220.01, K05223 .01, 
K05224.01, K05228.01, K05230.01, K05231.01, K05232.01, K05236.01, K05237.01, K05241.01, K05243.01, K05245.01, K05247.01, K052 48.01, K05249.01, K05254.01, K05255.01, K05267.01, K05269.01, K05274.01, K05275.01, K05278.01, K05279.01, K05281.01, K05283.01 , K05284.01, K05287.01, K05288.01, K05290.01, K05296.01, 
K05297.01, K05298.01, K05300.01, K05308.01, K05310.01, K05317.01, K05321.01, K05322.01, K05323.01, K05324.01, K05326.01, K05327.01, K05328.01, K05329.01, K05331.01, K05332.01, K05333.01, K05335.01, K 05336.01, K05339.01, K05341.01, K05344.01, K05351.01, K05358.01, K05359.01, K05360.01, K05369.01, K05372.01, 
K05373.01, K05375.01, K05379.01, K05380.01, K05384.01, K05387.01, K05388.01, K05390.01, K05393.01, K05398.01, K05403.01, K05406.01, K05408.01, K054 09.01, K05410.01, K05411.01, K05412.01, K05413.01, K05416.01, K05417.01, K05418.01, K05423.01, K05426.01, K05433.01, K05435.0 1, K05436.01, K05440.01, K05445.01, 
K05451.01, K05454.01, K05458.01, K05459.01, K05461.01, K05466.01, K05471.01, K05472.01, K05476.01, K05478.01, K05479.01, K054 80.01, K05482.01, K05483.01, K05485.01, K05486.01, K05487.01, K05497.01, K05498.01, K05499.01, K05500 .01, K05506.01, K05508.01, K05509.01, K05511.01, K05514.01, K05515.01, K05517.01, 
K05520.01, K05521.01, K05527.01, K05528.01, K05529.01, K05532.01, K05533.01, K05541.01, K05543.01, K05545.01, K05546.01, K055 52.01, K05553.01, K05554.01, K05556.01, K05564.01, K05566.01, K05567.01, K05568.01, K05570.01, K05572.01, K05574.01, K05577.01, K05578.01, K05579.01, K05581.01, K05583.01, K0 5585.01, 
K05587.01, K05591.01, K05592.01, K05597.01, K05602.01, K05603.01, K05604.01, K05605.01, K05606.01, K05608.01, K05612.01, K 05613.01, K05622.01, K05623.01, K05625.01, K05626.01, K05628.01, K05629.01, K05632.01, K05633.01, K05638.01, K05639.01, K0564 0.01, K05642.01, K05645.01, K05649.01, K05651.01, K05652.01, 
K05653.01, K05656.01, K05657.01, K05660.01, K05663.01, K05665.01, K05666.01, K05671.01, K05672.01, K05677.01, K05680.01, K05682.01, K05683.01, K05684.01, K05685.01, K05688.01, K05689.01, K05692.0 1, K05694.01, K05695.01, K05702.01, K05704.01, K05706.01, K05707.01, K05708.01, K05712.01, K05713.01, K05717.01, 
K05718.01, K05719.01, K05722.01, K05727.01, K05732.01, K05736.01, K05737.01, K05740.01, K05744.01, K05745.01, K05747.01, K05748.01, K05749.01,  K05752.01, K05753.01, K05758.01, K05761.01, K05762.01, K05769.01, K05772.01, K05774.01, K05776.01, K05782.01, K05785.01, K057 86.01, K05787.01, K05788.01, K05790.01, 
K05792.01, K05795.01, K05796.01, K05797.01, K05798.01, K05799.01, K05800.01, K05801.01, K05802.01, K05805.01, K05806.01, K058 07.01, K05810.01, K05812.01, K05814.01, K05815.01, K05816.01, K05817.01, K05819.01, K05822.01, K05825.01, K05826.01, K05827.01, K05829.01, K05830.01, K05831.01, K05833.01, K05834.01, 
K05835.01, K05837.01, K05839.01, K05842.01, K05849.01, K05850.01, K05852.01, K05854.01, K05855.01, K05856.01, K05863.01, K058 68.01, K05869.01, K05874.01, K05875.01, K05877.01, K05884.01, K05885.01, K05888.01, K05889.01, K05892.01, K05895.01, K05899.01, K05901.01, K05902.01, K05904.01, K05909.01 , K05911.01, 
K05913.01, K05918.01, K05919.01, K05920.01, K05924.01, K05925.01, K05927.01, K05929.01, K05932.01, K05935.01, K05936.0 1, K05938.01, K05939.01, K05940.01, K05941.01, K05943.01, K05944.01, K05948.01, K05949.01, K05950.01, K05952.01, K05953.01, K 05954.01, K05959.01, K05960.01, K05961.01, K05964.01, K05965.01, 
K05966.01, K05968.01, K05971.01, K05974.01, K05976.01, K06028.01, K06036.01, K06047.01, K06064.01, K06066.01, K06079.01, K06093.01, K06093.02, K06101.01, K06102.01, K06103.01, K06103.02, K061 08.01, K06109.01, K06109.02, K06111.01, K06112.01, K06115.01, K06118.02, K06120.01, K06120.02, K06121.01, K06130.01, 
K06132.01, K06132.02, K06134.01, K06137.01, K06137.02, K06141.01, K06145.01, K06145.02, K06145.03, K06150.01, K06151.01, K06164.01, K06166. 01, K06166.02, K06172.01, K06175.01, K06176.01, K06178.01, K06178.02, K06179.01, K06180.01, K06182.01, K06182.02, K06183.01,  K06186.01, K06188.01, K06189.01, K06191.01, 
K06191.02, K06194.01, K06195.01, K06202.01, K06209.01, K06209.02, K06210.01, K06216.02, K06217.01, K06219.01, K06223.01, K062 24.01, K06228.01, K06235.01, K06238.01, K06239.01, K06242.01, K06242.02, K06242.03, K06245.02, K06246.01, K06248.01, K06251.01 

