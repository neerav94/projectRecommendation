Quantifying decision impact in MOBA games

Edward Gan
Justin Huang
Frederic Ren

Abstract

In this project we quantify the importance and ef-
fectiveness of item-purchase decisions in League
of Legends, focusing on the early game. We ﬁnd
that stepwise sequences of classiﬁers are unable
to take advantage of the information provided by
early-game item choices in general, suggesting
that items as a whole are fairly well balanced.
However, a more reﬁned propensity score match-
ing is able to detect a mild but signiﬁcant effects
for speciﬁc items.

1. Introduction
MOBA games such as League of legends offer a unique
mix of challenges to their players. League of legends
(league) in particular is a game between 2 human teams
of 5 players. At a strategic level players must choose be-
tween different champion (character archetype) and item
(equipment) options while at a tactical level players must
maneuver around and eliminate the opposing team.
The strategic choices are especially difﬁcult since they
must take into account the current game state but have
no immediate impact on their own. Players often won-
der which of the many strategic decisions they made con-
tributed the most to a win or a loss. In this project we focus
on understanding the causal effect different item purchases
have on the result of League games.
We examine the relative importance and effectiveness of
different item purchases player make. We construct a vari-
ety of classiﬁers which try to predict win or loss based on
team champion choices, player gold and experience lev-
els, and player item choice to isolate the effect of item
choice. We also use propensity score matching to correct
for confounding variables while predicting win rate based
on whether or not a certain item was bought.

CS229 Final Project, 2015

EGAN1@STANFORD.EDU
JTHUANG@STANFORD.EDU
FREN@STANFORD.EDU

2. Related Work
The concept of instrumental variables is useful for under-
standing the independent impact that item decisions have
on a match. In our setting, gold, xp and champion choice
are instrumental variables which give us a handle on an
underlying game state, since game state is a confounding
variable for both match result and item choice.
In (Foster, 1997), the authors discuss how 2-stage least
squares (2SLS) can be used to account for confounding
variables by ﬁrst modeling results w.r.t. only the instrumen-
tal variables. However, the speciﬁc formulas used do not
generalize to SVMs, trees, etc... so we combine their high
level approach with ideas from forward feature-selection
(Guyon & Elisseeff, 2003) to formulate 2SLS-like staged
classiﬁer models described in section 4.1.
Within the domain of predicting match results, the authors
in (Joseph et al., 2006) used a variety of methods on a high
dimensional feature set similar to ours, including decision
trees, but did not obtain very high predictive accuracy with
any of the methods. Thus, we do not expect very high
win/loss accuracy either but that is not necessary for our
research question.
In the speciﬁc area of analyzing items in league-of-legends,
the state of the art metric is raw winrate for each items, as
can be seen in third-party apps endorsed by Riot such as
(KateOfSpades & Kai). We believe that our methods will
be able to give more realistic insight since they will take
confounding variable into account.
There is substantial literature on the combination of ma-
chine learning and traditional econometric techniques to
yield causal estimates.
(Athey & Imbens, 2015) dis-
cusses empirical methods for combining propensity score
matching and machine learning tools such as cross valida-
tion to estimate treatment effects, particularly in observa-
tional studies with heterogeneous users. (Athey & Mobius,
2012) is an example of an observational study that employs
propensity score matching. The authors aim to estimate
the causal effect of adding local news content to Google
news feeds, where opting into local news is a choice that
users make. They build a propensity score model of opt-
ing into local news as a function of past browsing behavior

Quantifying decision impact in MOBA games

Edward Gan
Justin Huang
Frederic Ren

Abstract

In this project we quantify the importance and ef-
fectiveness of item-purchase decisions in League
of Legends, focusing on the early game. We ﬁnd
that stepwise sequences of classiﬁers are unable
to take advantage of the information provided by
early-game item choices in general, suggesting
that items as a whole are fairly well balanced.
However, a more reﬁned propensity score match-
ing is able to detect a mild but signiﬁcant effects
for speciﬁc items.

1. Introduction
MOBA games such as League of legends offer a unique
mix of challenges to their players. League of legends
(league) in particular is a game between 2 human teams
of 5 players. At a strategic level players must choose be-
tween different champion (character archetype) and item
(equipment) options while at a tactical level players must
maneuver around and eliminate the opposing team.
The strategic choices are especially difﬁcult since they
must take into account the current game state but have
no immediate impact on their own. Players often won-
der which of the many strategic decisions they made con-
tributed the most to a win or a loss. In this project we focus
on understanding the causal effect different item purchases
have on the result of League games.
We examine the relative importance and effectiveness of
different item purchases player make. We construct a vari-
ety of classiﬁers which try to predict win or loss based on
team champion choices, player gold and experience lev-
els, and player item choice to isolate the effect of item
choice. We also use propensity score matching to correct
for confounding variables while predicting win rate based
on whether or not a certain item was bought.

CS229 Final Project, 2015

EGAN1@STANFORD.EDU
JTHUANG@STANFORD.EDU
FREN@STANFORD.EDU

2. Related Work
The concept of instrumental variables is useful for under-
standing the independent impact that item decisions have
on a match. In our setting, gold, xp and champion choice
are instrumental variables which give us a handle on an
underlying game state, since game state is a confounding
variable for both match result and item choice.
In (Foster, 1997), the authors discuss how 2-stage least
squares (2SLS) can be used to account for confounding
variables by ﬁrst modeling results w.r.t. only the instrumen-
tal variables. However, the speciﬁc formulas used do not
generalize to SVMs, trees, etc... so we combine their high
level approach with ideas from forward feature-selection
(Guyon & Elisseeff, 2003) to formulate 2SLS-like staged
classiﬁer models described in section 4.1.
Within the domain of predicting match results, the authors
in (Joseph et al., 2006) used a variety of methods on a high
dimensional feature set similar to ours, including decision
trees, but did not obtain very high predictive accuracy with
any of the methods. Thus, we do not expect very high
win/loss accuracy either but that is not necessary for our
research question.
In the speciﬁc area of analyzing items in league-of-legends,
the state of the art metric is raw winrate for each items, as
can be seen in third-party apps endorsed by Riot such as
(KateOfSpades & Kai). We believe that our methods will
be able to give more realistic insight since they will take
confounding variable into account.
There is substantial literature on the combination of ma-
chine learning and traditional econometric techniques to
yield causal estimates.
(Athey & Imbens, 2015) dis-
cusses empirical methods for combining propensity score
matching and machine learning tools such as cross valida-
tion to estimate treatment effects, particularly in observa-
tional studies with heterogeneous users. (Athey & Mobius,
2012) is an example of an observational study that employs
propensity score matching. The authors aim to estimate
the causal effect of adding local news content to Google
news feeds, where opting into local news is a choice that
users make. They build a propensity score model of opt-
ing into local news as a function of past browsing behavior

Quantifying decision impact in MOBA games

and condition on this information to match users and form
a quasi-experiment to test effects on readership.

3. Data
The Riot API (rio) gives us access to a variety of informa-
tion on a given League match, but does not provide direct
access to recent matches, so we began by crawling player-
to-player connections to obtain a list of 2,000 North Amer-
ican players in ”Silver Tier”. All players in silver tier are
ranked to have roughly the same (mid-level amateur) skill
level. Up to 10 recent matches were pulled for each player
for a total of 12,000 matches.
Each match is played between two teams of 5, and each
player makes their own item purchase decisions. Since
we are modeling individual player choices, we extracted
a single sample from each match for a total of 12,000 data
points. Extracting more data points from each match would
introducing misleading correlations in the data.
We extracted a number of both categorical and numerical
features for each match from the json provided by the api:
Category
Ally champions
Opponent champtions
Items total
Items @ 10 minutes
Gold @ x min
XP @ x min
Win / Loss
Each team consists of 5 out of 128 possible champions,
and similarly each player can purchase any number of dis-
tinct items. We encoded the presence or absence of each
champion on each team as a binary feature, for a total of
2*2*128 features. Similarly whether or not the player had
bought each item by speciﬁc points in time is encoded as a
binary feature. Cumulative Gold and XP numerical values
were measured at 5 minute intervals and each value repre-
sented by its own feature.

Example Features
ally alistar: 1, ally elise: 0, ...
opp alistar: 0, opp elise: 1, ...
boots: 1, longsword: 1, ...
boots 10: 1, longsword 10: 0, ...
gold 5: 23, gold 10: 250, ...
xp 5: 43, xp 10: 66, ...
win: 1

4. Methods
4.1. Predictive Classiﬁers

Our method for quantifying the overall impact of item pur-
chases is inspired by both forward-search feature selection
and 2-stage least squares modeling. The goal here is to
limit the effect of game state, which is a confounding vari-
able since it inﬂuences both the ﬁnal outcome of a match
and the items one might choose or be able to buy.
In section 4.1 we limit ourselves to the ﬁrst 10 minutes of
the game to limit variation in game state, and we use cham-
pion choices and gold and xp values at 10 minutes as in-

strumental variables to stand in for the game state. Then, to
distinguish the effect of item choices from these, we build
three successive models which take into account more fea-
tures roughly in the order they begin to have an impact

Figure 1. Successive Classiﬁer Models

Figure 1 illustrates how each model takes an additional set
of features into account. Model 1 only takes champion
choice into account, model 2 adds gold and xp data, while
model 3 includes all of the above as well as item choice
data. We hope to quantify the overall impact of item choice
with the difference in predictive power between model 3
and model 2.
Impact ∼ Model 3 Acc − Model 2 Acc
The speciﬁc algorithms we used for each model were l1-
regularized logistic regression, l2-regularized linear SVM,
and Adaboost decision tree ensembles. The logistic regres-
sion minimized the error:

i log(cid:2)exp(cid:0)−yi

(cid:0)X T
i w + c(cid:1)(cid:1) + 1(cid:3)

Regularized Linear SVM minimizes the error:

|w| + C(cid:80)n
2 wT w + C(cid:80)n

1

i=1 ξi

where yi(wT xi + b) ≥ 1 − ξi.
Adaboost trees calculate weights β for decision trees ht(x)
and then classiﬁes based on the sum of the weighted tree
decisions:

(cid:80)

t(log 1/βt)ht(x)

4.2. Propensity Score Matching

A more principled way of isolating causal effects for spe-
ciﬁc item choices is Propensity Score Matching (PSM).
PSM is a method for estimating treatment effects in
datasets where assignment to a binary treatment is endoge-
neous. Our example of this is the purchase of an expensive
item (treatment) in League of Legends. Expensive items
are frequently only affordable to the team that is ahead,
and thus their purchase might be correlated with winning
the game even when their actual effect is minor.
The goal of propensity score matching is to estimate the
effect of binary treatment X on outcome Y in the pres-
ence of endogeneous variables Z. The concern is that Z,
which in our case are game state variables, have an effect

Champion Selection (C)Gold + XP(GS)Early Item Purchases(IP)Model 1:Win ~ CModel 2:Win ~ C + GSModel 3:Win ~ C + GS + IPQuantifying decision impact in MOBA games

Edward Gan
Justin Huang
Frederic Ren

Abstract

In this project we quantify the importance and ef-
fectiveness of item-purchase decisions in League
of Legends, focusing on the early game. We ﬁnd
that stepwise sequences of classiﬁers are unable
to take advantage of the information provided by
early-game item choices in general, suggesting
that items as a whole are fairly well balanced.
However, a more reﬁned propensity score match-
ing is able to detect a mild but signiﬁcant effects
for speciﬁc items.

1. Introduction
MOBA games such as League of legends offer a unique
mix of challenges to their players. League of legends
(league) in particular is a game between 2 human teams
of 5 players. At a strategic level players must choose be-
tween different champion (character archetype) and item
(equipment) options while at a tactical level players must
maneuver around and eliminate the opposing team.
The strategic choices are especially difﬁcult since they
must take into account the current game state but have
no immediate impact on their own. Players often won-
der which of the many strategic decisions they made con-
tributed the most to a win or a loss. In this project we focus
on understanding the causal effect different item purchases
have on the result of League games.
We examine the relative importance and effectiveness of
different item purchases player make. We construct a vari-
ety of classiﬁers which try to predict win or loss based on
team champion choices, player gold and experience lev-
els, and player item choice to isolate the effect of item
choice. We also use propensity score matching to correct
for confounding variables while predicting win rate based
on whether or not a certain item was bought.

CS229 Final Project, 2015

EGAN1@STANFORD.EDU
JTHUANG@STANFORD.EDU
FREN@STANFORD.EDU

2. Related Work
The concept of instrumental variables is useful for under-
standing the independent impact that item decisions have
on a match. In our setting, gold, xp and champion choice
are instrumental variables which give us a handle on an
underlying game state, since game state is a confounding
variable for both match result and item choice.
In (Foster, 1997), the authors discuss how 2-stage least
squares (2SLS) can be used to account for confounding
variables by ﬁrst modeling results w.r.t. only the instrumen-
tal variables. However, the speciﬁc formulas used do not
generalize to SVMs, trees, etc... so we combine their high
level approach with ideas from forward feature-selection
(Guyon & Elisseeff, 2003) to formulate 2SLS-like staged
classiﬁer models described in section 4.1.
Within the domain of predicting match results, the authors
in (Joseph et al., 2006) used a variety of methods on a high
dimensional feature set similar to ours, including decision
trees, but did not obtain very high predictive accuracy with
any of the methods. Thus, we do not expect very high
win/loss accuracy either but that is not necessary for our
research question.
In the speciﬁc area of analyzing items in league-of-legends,
the state of the art metric is raw winrate for each items, as
can be seen in third-party apps endorsed by Riot such as
(KateOfSpades & Kai). We believe that our methods will
be able to give more realistic insight since they will take
confounding variable into account.
There is substantial literature on the combination of ma-
chine learning and traditional econometric techniques to
yield causal estimates.
(Athey & Imbens, 2015) dis-
cusses empirical methods for combining propensity score
matching and machine learning tools such as cross valida-
tion to estimate treatment effects, particularly in observa-
tional studies with heterogeneous users. (Athey & Mobius,
2012) is an example of an observational study that employs
propensity score matching. The authors aim to estimate
the causal effect of adding local news content to Google
news feeds, where opting into local news is a choice that
users make. They build a propensity score model of opt-
ing into local news as a function of past browsing behavior

Quantifying decision impact in MOBA games

and condition on this information to match users and form
a quasi-experiment to test effects on readership.

3. Data
The Riot API (rio) gives us access to a variety of informa-
tion on a given League match, but does not provide direct
access to recent matches, so we began by crawling player-
to-player connections to obtain a list of 2,000 North Amer-
ican players in ”Silver Tier”. All players in silver tier are
ranked to have roughly the same (mid-level amateur) skill
level. Up to 10 recent matches were pulled for each player
for a total of 12,000 matches.
Each match is played between two teams of 5, and each
player makes their own item purchase decisions. Since
we are modeling individual player choices, we extracted
a single sample from each match for a total of 12,000 data
points. Extracting more data points from each match would
introducing misleading correlations in the data.
We extracted a number of both categorical and numerical
features for each match from the json provided by the api:
Category
Ally champions
Opponent champtions
Items total
Items @ 10 minutes
Gold @ x min
XP @ x min
Win / Loss
Each team consists of 5 out of 128 possible champions,
and similarly each player can purchase any number of dis-
tinct items. We encoded the presence or absence of each
champion on each team as a binary feature, for a total of
2*2*128 features. Similarly whether or not the player had
bought each item by speciﬁc points in time is encoded as a
binary feature. Cumulative Gold and XP numerical values
were measured at 5 minute intervals and each value repre-
sented by its own feature.

Example Features
ally alistar: 1, ally elise: 0, ...
opp alistar: 0, opp elise: 1, ...
boots: 1, longsword: 1, ...
boots 10: 1, longsword 10: 0, ...
gold 5: 23, gold 10: 250, ...
xp 5: 43, xp 10: 66, ...
win: 1

4. Methods
4.1. Predictive Classiﬁers

Our method for quantifying the overall impact of item pur-
chases is inspired by both forward-search feature selection
and 2-stage least squares modeling. The goal here is to
limit the effect of game state, which is a confounding vari-
able since it inﬂuences both the ﬁnal outcome of a match
and the items one might choose or be able to buy.
In section 4.1 we limit ourselves to the ﬁrst 10 minutes of
the game to limit variation in game state, and we use cham-
pion choices and gold and xp values at 10 minutes as in-

strumental variables to stand in for the game state. Then, to
distinguish the effect of item choices from these, we build
three successive models which take into account more fea-
tures roughly in the order they begin to have an impact

Figure 1. Successive Classiﬁer Models

Figure 1 illustrates how each model takes an additional set
of features into account. Model 1 only takes champion
choice into account, model 2 adds gold and xp data, while
model 3 includes all of the above as well as item choice
data. We hope to quantify the overall impact of item choice
with the difference in predictive power between model 3
and model 2.
Impact ∼ Model 3 Acc − Model 2 Acc
The speciﬁc algorithms we used for each model were l1-
regularized logistic regression, l2-regularized linear SVM,
and Adaboost decision tree ensembles. The logistic regres-
sion minimized the error:

i log(cid:2)exp(cid:0)−yi

(cid:0)X T
i w + c(cid:1)(cid:1) + 1(cid:3)

Regularized Linear SVM minimizes the error:

|w| + C(cid:80)n
2 wT w + C(cid:80)n

1

i=1 ξi

where yi(wT xi + b) ≥ 1 − ξi.
Adaboost trees calculate weights β for decision trees ht(x)
and then classiﬁes based on the sum of the weighted tree
decisions:

(cid:80)

t(log 1/βt)ht(x)

4.2. Propensity Score Matching

A more principled way of isolating causal effects for spe-
ciﬁc item choices is Propensity Score Matching (PSM).
PSM is a method for estimating treatment effects in
datasets where assignment to a binary treatment is endoge-
neous. Our example of this is the purchase of an expensive
item (treatment) in League of Legends. Expensive items
are frequently only affordable to the team that is ahead,
and thus their purchase might be correlated with winning
the game even when their actual effect is minor.
The goal of propensity score matching is to estimate the
effect of binary treatment X on outcome Y in the pres-
ence of endogeneous variables Z. The concern is that Z,
which in our case are game state variables, have an effect

Champion Selection (C)Gold + XP(GS)Early Item Purchases(IP)Model 1:Win ~ CModel 2:Win ~ C + GSModel 3:Win ~ C + GS + IPQuantifying decision impact in MOBA games

5.1.1. LINEAR MODELS

We started by evaluating the performance of regularized lo-
gistic regression and linear SVMS. We evaluated each clas-
siﬁer by its overall accuracy via 5-fold cross-validation. L1
loss yielded the best results for logistic regression while L2
loss worked best for SVMs. We also tried a variety of regu-
larization parameters C ranging from 1e-4 to 1e4, and C=1
was close to optimal.
In ﬁgure 2 we compare the accuracy of logistic and linear
SVM classiﬁers for the models described in section 4.1.
The two methods perform very comparably. Champion
choice in model 1 gives us reasonable predictive power,
adding in game state in model 2 helps us signiﬁcantly, but
further adding in early game item choice in model 3 does
not improve performance.

on the game outcome Y and inﬂuence the item choice X.
Then our typical ordinary least squares assumptions would
be violated, as the error term  in the estimated model of
Y = β1 ∗ X +  is now correlated with X. PSM handles
this endogeneity by modeling the probability of being allo-
cated to the treatment X (buying item) via logistic regres-
sion on Z (game state). The logistic regression of X on
Z yields propensity scores P (X = x|Z) for each obser-
vation. Observations are then paired based on propensity
scores via nearest neighbors, such that observations i, j in
which Xi = 1 are paired with those in which Xj = 0
and P (Xi|Zi) ≈ P (Xj|Zj) and covariates Z are counter-
balanced across the entire group. This procedure yields a
new dataset where X⊥Z, allowing unbiased estimates of
the causal effect of X on Y via ordinary least squares re-
gression.
The following provides a (hypothetical) graphical illustra-
tion of propensity score matching. Table 1 is hypotheti-
cal representative data, where the expensive item Mejai’s
Soulstealer is more commonly bought by the winning team.
Regression of this dataset would assign coefﬁcients which
conﬂate the role of Mejai’s Soulstealer on game outcome
when gold lead is correlated with both item purchase and
winning the game. Table 2 shows what the dataset might
look like after the matching process has concluded. We see
that both observables and propensity scores are approxi-
mately balanced (within some tolerance) between the treat-
ment (Mejai purchased) and control (Mejai not purchased)
groups.

Table 1. Representative (Unmatched) Data

P (X|Z)

ID Mejai
32
93
420
96

1
1
0
0

Gold
+5284
+2745
-340
-3890

.56
.42
.15
.02

.56
.57
.15
.15

Table 2. Propensity Score Matched Data
P (X|Z)

ID Mejai
32
742
420
278

1
0
0
1

Gold
+5284
+5350
-340
-328

5. Results
5.1. Predictive Classiﬁers

As described in the methods, we tried to predict match wins
in terms of various subsets of the champion, early game
state, and early item features.

Figure 2. Linear Classiﬁer performance

Table 3 presents the confusion matrix for logistic regression
evaluated on a separate test set. The results for linearSVM
are very similar and the two methods appear to do slightly
better predicting games where the player won.

Table 3. Linear Model Confusion Matrix
Predicted Loss

Predicted Win

Win
Loss

742
506

464
683

5.1.2. NONLINEAR MODELS

Though item choice did not improve predictive perfor-
mance in linear models, we hoped to see more signiﬁcant
results for nonlinear models which could take into account
the situation effectiveness of different items.
In ﬁgure 3 we compare the accuracy of SVM using linear,
degree-2 polynomial and degree-2 radial basis function ker-
nels, for the models described in section 4.1. The numbers

123Model0.500.520.540.560.580.600.620.645-fold CV AccuracyModel Accuracy for Linear clasifiersLogisticSVMQuantifying decision impact in MOBA games

Edward Gan
Justin Huang
Frederic Ren

Abstract

In this project we quantify the importance and ef-
fectiveness of item-purchase decisions in League
of Legends, focusing on the early game. We ﬁnd
that stepwise sequences of classiﬁers are unable
to take advantage of the information provided by
early-game item choices in general, suggesting
that items as a whole are fairly well balanced.
However, a more reﬁned propensity score match-
ing is able to detect a mild but signiﬁcant effects
for speciﬁc items.

1. Introduction
MOBA games such as League of legends offer a unique
mix of challenges to their players. League of legends
(league) in particular is a game between 2 human teams
of 5 players. At a strategic level players must choose be-
tween different champion (character archetype) and item
(equipment) options while at a tactical level players must
maneuver around and eliminate the opposing team.
The strategic choices are especially difﬁcult since they
must take into account the current game state but have
no immediate impact on their own. Players often won-
der which of the many strategic decisions they made con-
tributed the most to a win or a loss. In this project we focus
on understanding the causal effect different item purchases
have on the result of League games.
We examine the relative importance and effectiveness of
different item purchases player make. We construct a vari-
ety of classiﬁers which try to predict win or loss based on
team champion choices, player gold and experience lev-
els, and player item choice to isolate the effect of item
choice. We also use propensity score matching to correct
for confounding variables while predicting win rate based
on whether or not a certain item was bought.

CS229 Final Project, 2015

EGAN1@STANFORD.EDU
JTHUANG@STANFORD.EDU
FREN@STANFORD.EDU

2. Related Work
The concept of instrumental variables is useful for under-
standing the independent impact that item decisions have
on a match. In our setting, gold, xp and champion choice
are instrumental variables which give us a handle on an
underlying game state, since game state is a confounding
variable for both match result and item choice.
In (Foster, 1997), the authors discuss how 2-stage least
squares (2SLS) can be used to account for confounding
variables by ﬁrst modeling results w.r.t. only the instrumen-
tal variables. However, the speciﬁc formulas used do not
generalize to SVMs, trees, etc... so we combine their high
level approach with ideas from forward feature-selection
(Guyon & Elisseeff, 2003) to formulate 2SLS-like staged
classiﬁer models described in section 4.1.
Within the domain of predicting match results, the authors
in (Joseph et al., 2006) used a variety of methods on a high
dimensional feature set similar to ours, including decision
trees, but did not obtain very high predictive accuracy with
any of the methods. Thus, we do not expect very high
win/loss accuracy either but that is not necessary for our
research question.
In the speciﬁc area of analyzing items in league-of-legends,
the state of the art metric is raw winrate for each items, as
can be seen in third-party apps endorsed by Riot such as
(KateOfSpades & Kai). We believe that our methods will
be able to give more realistic insight since they will take
confounding variable into account.
There is substantial literature on the combination of ma-
chine learning and traditional econometric techniques to
yield causal estimates.
(Athey & Imbens, 2015) dis-
cusses empirical methods for combining propensity score
matching and machine learning tools such as cross valida-
tion to estimate treatment effects, particularly in observa-
tional studies with heterogeneous users. (Athey & Mobius,
2012) is an example of an observational study that employs
propensity score matching. The authors aim to estimate
the causal effect of adding local news content to Google
news feeds, where opting into local news is a choice that
users make. They build a propensity score model of opt-
ing into local news as a function of past browsing behavior

Quantifying decision impact in MOBA games

and condition on this information to match users and form
a quasi-experiment to test effects on readership.

3. Data
The Riot API (rio) gives us access to a variety of informa-
tion on a given League match, but does not provide direct
access to recent matches, so we began by crawling player-
to-player connections to obtain a list of 2,000 North Amer-
ican players in ”Silver Tier”. All players in silver tier are
ranked to have roughly the same (mid-level amateur) skill
level. Up to 10 recent matches were pulled for each player
for a total of 12,000 matches.
Each match is played between two teams of 5, and each
player makes their own item purchase decisions. Since
we are modeling individual player choices, we extracted
a single sample from each match for a total of 12,000 data
points. Extracting more data points from each match would
introducing misleading correlations in the data.
We extracted a number of both categorical and numerical
features for each match from the json provided by the api:
Category
Ally champions
Opponent champtions
Items total
Items @ 10 minutes
Gold @ x min
XP @ x min
Win / Loss
Each team consists of 5 out of 128 possible champions,
and similarly each player can purchase any number of dis-
tinct items. We encoded the presence or absence of each
champion on each team as a binary feature, for a total of
2*2*128 features. Similarly whether or not the player had
bought each item by speciﬁc points in time is encoded as a
binary feature. Cumulative Gold and XP numerical values
were measured at 5 minute intervals and each value repre-
sented by its own feature.

Example Features
ally alistar: 1, ally elise: 0, ...
opp alistar: 0, opp elise: 1, ...
boots: 1, longsword: 1, ...
boots 10: 1, longsword 10: 0, ...
gold 5: 23, gold 10: 250, ...
xp 5: 43, xp 10: 66, ...
win: 1

4. Methods
4.1. Predictive Classiﬁers

Our method for quantifying the overall impact of item pur-
chases is inspired by both forward-search feature selection
and 2-stage least squares modeling. The goal here is to
limit the effect of game state, which is a confounding vari-
able since it inﬂuences both the ﬁnal outcome of a match
and the items one might choose or be able to buy.
In section 4.1 we limit ourselves to the ﬁrst 10 minutes of
the game to limit variation in game state, and we use cham-
pion choices and gold and xp values at 10 minutes as in-

strumental variables to stand in for the game state. Then, to
distinguish the effect of item choices from these, we build
three successive models which take into account more fea-
tures roughly in the order they begin to have an impact

Figure 1. Successive Classiﬁer Models

Figure 1 illustrates how each model takes an additional set
of features into account. Model 1 only takes champion
choice into account, model 2 adds gold and xp data, while
model 3 includes all of the above as well as item choice
data. We hope to quantify the overall impact of item choice
with the difference in predictive power between model 3
and model 2.
Impact ∼ Model 3 Acc − Model 2 Acc
The speciﬁc algorithms we used for each model were l1-
regularized logistic regression, l2-regularized linear SVM,
and Adaboost decision tree ensembles. The logistic regres-
sion minimized the error:

i log(cid:2)exp(cid:0)−yi

(cid:0)X T
i w + c(cid:1)(cid:1) + 1(cid:3)

Regularized Linear SVM minimizes the error:

|w| + C(cid:80)n
2 wT w + C(cid:80)n

1

i=1 ξi

where yi(wT xi + b) ≥ 1 − ξi.
Adaboost trees calculate weights β for decision trees ht(x)
and then classiﬁes based on the sum of the weighted tree
decisions:

(cid:80)

t(log 1/βt)ht(x)

4.2. Propensity Score Matching

A more principled way of isolating causal effects for spe-
ciﬁc item choices is Propensity Score Matching (PSM).
PSM is a method for estimating treatment effects in
datasets where assignment to a binary treatment is endoge-
neous. Our example of this is the purchase of an expensive
item (treatment) in League of Legends. Expensive items
are frequently only affordable to the team that is ahead,
and thus their purchase might be correlated with winning
the game even when their actual effect is minor.
The goal of propensity score matching is to estimate the
effect of binary treatment X on outcome Y in the pres-
ence of endogeneous variables Z. The concern is that Z,
which in our case are game state variables, have an effect

Champion Selection (C)Gold + XP(GS)Early Item Purchases(IP)Model 1:Win ~ CModel 2:Win ~ C + GSModel 3:Win ~ C + GS + IPQuantifying decision impact in MOBA games

5.1.1. LINEAR MODELS

We started by evaluating the performance of regularized lo-
gistic regression and linear SVMS. We evaluated each clas-
siﬁer by its overall accuracy via 5-fold cross-validation. L1
loss yielded the best results for logistic regression while L2
loss worked best for SVMs. We also tried a variety of regu-
larization parameters C ranging from 1e-4 to 1e4, and C=1
was close to optimal.
In ﬁgure 2 we compare the accuracy of logistic and linear
SVM classiﬁers for the models described in section 4.1.
The two methods perform very comparably. Champion
choice in model 1 gives us reasonable predictive power,
adding in game state in model 2 helps us signiﬁcantly, but
further adding in early game item choice in model 3 does
not improve performance.

on the game outcome Y and inﬂuence the item choice X.
Then our typical ordinary least squares assumptions would
be violated, as the error term  in the estimated model of
Y = β1 ∗ X +  is now correlated with X. PSM handles
this endogeneity by modeling the probability of being allo-
cated to the treatment X (buying item) via logistic regres-
sion on Z (game state). The logistic regression of X on
Z yields propensity scores P (X = x|Z) for each obser-
vation. Observations are then paired based on propensity
scores via nearest neighbors, such that observations i, j in
which Xi = 1 are paired with those in which Xj = 0
and P (Xi|Zi) ≈ P (Xj|Zj) and covariates Z are counter-
balanced across the entire group. This procedure yields a
new dataset where X⊥Z, allowing unbiased estimates of
the causal effect of X on Y via ordinary least squares re-
gression.
The following provides a (hypothetical) graphical illustra-
tion of propensity score matching. Table 1 is hypotheti-
cal representative data, where the expensive item Mejai’s
Soulstealer is more commonly bought by the winning team.
Regression of this dataset would assign coefﬁcients which
conﬂate the role of Mejai’s Soulstealer on game outcome
when gold lead is correlated with both item purchase and
winning the game. Table 2 shows what the dataset might
look like after the matching process has concluded. We see
that both observables and propensity scores are approxi-
mately balanced (within some tolerance) between the treat-
ment (Mejai purchased) and control (Mejai not purchased)
groups.

Table 1. Representative (Unmatched) Data

P (X|Z)

ID Mejai
32
93
420
96

1
1
0
0

Gold
+5284
+2745
-340
-3890

.56
.42
.15
.02

.56
.57
.15
.15

Table 2. Propensity Score Matched Data
P (X|Z)

ID Mejai
32
742
420
278

1
0
0
1

Gold
+5284
+5350
-340
-328

5. Results
5.1. Predictive Classiﬁers

As described in the methods, we tried to predict match wins
in terms of various subsets of the champion, early game
state, and early item features.

Figure 2. Linear Classiﬁer performance

Table 3 presents the confusion matrix for logistic regression
evaluated on a separate test set. The results for linearSVM
are very similar and the two methods appear to do slightly
better predicting games where the player won.

Table 3. Linear Model Confusion Matrix
Predicted Loss

Predicted Win

Win
Loss

742
506

464
683

5.1.2. NONLINEAR MODELS

Though item choice did not improve predictive perfor-
mance in linear models, we hoped to see more signiﬁcant
results for nonlinear models which could take into account
the situation effectiveness of different items.
In ﬁgure 3 we compare the accuracy of SVM using linear,
degree-2 polynomial and degree-2 radial basis function ker-
nels, for the models described in section 4.1. The numbers

123Model0.500.520.540.560.580.600.620.645-fold CV AccuracyModel Accuracy for Linear clasifiersLogisticSVMQuantifying decision impact in MOBA games

here are slightly different than in the previous ﬁgure since
they were obtained from an independent experiment. The
linear kernel has the highest accuracy, though it only out-
performs the degree-2 RBF slightly (0.01 for model 3). The
degree-2 polynomial kernel is signiﬁcantly worse than the
other two. Again, adding game state in model 2 improves
accuracy by 0.04 for the linear kernel, further adding item
choice in model 3 only improves performance by 0.01.

Figure 4. AdaBoost depth parameter tuning

Figure 3. Accuracy of SVM kernels

Along the same vein, we also tried decision trees to see
if we could identify context-dependent item choice im-
pact. We evaluated Random Forests, Gradient Boosted de-
cision trees, as well as AdaBoost tree ensembles. For depth
d=1,2,3, the AdaBoost algorithm had the best accuracy on
5-way cross validation.
To ﬁnd the optimal tree depth in ﬁgure 4 we compare 5
way CV scores for model 3 (win ∼ champions + state +
items) and see that depth 1 trees perform the best. Increas-
ing the depth yields higher training accuracy but worse test
accuracy. For instance, in ﬁgure 5 we compare training and
test accuracy for depth 3 and see that there is substantial
overﬁtting even in model 1.
The breakdown of the impact provided by the champion
choice, state, and items is then given in ﬁgure 6. The results
are very similar to what we saw for linear classiﬁers.

5.1.3. PREDICTIVE CLASSIFIER ANALYSIS

It appears that any additional predictive power provided by
item choice is outweighed by the overﬁtting that occurs.
This is especially true for decision trees where any addi-
tional depth beyond d=1 yielded worse results. Both deci-
sion trees and kernel SVMs were unable to learn any of the
truly nonlinear effects of item choice. We tried to reduce
dimensionality the by considering only the most frequently
purchased 40 items and most frequently played 60 cham-

Figure 5. AdaBoost Overﬁtting at depth 3

pions but the results did not improve; Principal component
analysis was not helpful because each feature only accounts
for a small independent fraction of total variance.

5.2. Propensity Score Matching

We implement Propensity Score Matching on our dataset
in order to estimate the causal impact of items chosen to
be most predictive of winning games via logistic regres-
sion. We balance selection into purchasing these items
across the observed covariates related to game state: gold5,
gold10, xp5, xp10, champion, role, lane, xp differential,
damage differential. Logistic regression is used to gen-
erate propensity scores and observations are paired based
on nearest neighbors using propensity score. The below
diagram displays propensity scores both before and after
propensity score matching. We see that the distribution of
propensity scores is much more similar between treatment
and control groups after matching.

123SVM Kernel ComparisonModel5 Fold CV Accuracy0.500.520.540.560.580.60linearpoly−deg2radial−deg212345Tree Depth0.500.520.540.560.580.600.620.645-fold CV AccuracyModel 3 Accuracy wrt Tree Depth123Model0.50.60.70.80.91.0Raw AccuracyOverfitting for Depth-3 AdaboostTest SetTraining SetQuantifying decision impact in MOBA games

Edward Gan
Justin Huang
Frederic Ren

Abstract

In this project we quantify the importance and ef-
fectiveness of item-purchase decisions in League
of Legends, focusing on the early game. We ﬁnd
that stepwise sequences of classiﬁers are unable
to take advantage of the information provided by
early-game item choices in general, suggesting
that items as a whole are fairly well balanced.
However, a more reﬁned propensity score match-
ing is able to detect a mild but signiﬁcant effects
for speciﬁc items.

1. Introduction
MOBA games such as League of legends offer a unique
mix of challenges to their players. League of legends
(league) in particular is a game between 2 human teams
of 5 players. At a strategic level players must choose be-
tween different champion (character archetype) and item
(equipment) options while at a tactical level players must
maneuver around and eliminate the opposing team.
The strategic choices are especially difﬁcult since they
must take into account the current game state but have
no immediate impact on their own. Players often won-
der which of the many strategic decisions they made con-
tributed the most to a win or a loss. In this project we focus
on understanding the causal effect different item purchases
have on the result of League games.
We examine the relative importance and effectiveness of
different item purchases player make. We construct a vari-
ety of classiﬁers which try to predict win or loss based on
team champion choices, player gold and experience lev-
els, and player item choice to isolate the effect of item
choice. We also use propensity score matching to correct
for confounding variables while predicting win rate based
on whether or not a certain item was bought.

CS229 Final Project, 2015

EGAN1@STANFORD.EDU
JTHUANG@STANFORD.EDU
FREN@STANFORD.EDU

2. Related Work
The concept of instrumental variables is useful for under-
standing the independent impact that item decisions have
on a match. In our setting, gold, xp and champion choice
are instrumental variables which give us a handle on an
underlying game state, since game state is a confounding
variable for both match result and item choice.
In (Foster, 1997), the authors discuss how 2-stage least
squares (2SLS) can be used to account for confounding
variables by ﬁrst modeling results w.r.t. only the instrumen-
tal variables. However, the speciﬁc formulas used do not
generalize to SVMs, trees, etc... so we combine their high
level approach with ideas from forward feature-selection
(Guyon & Elisseeff, 2003) to formulate 2SLS-like staged
classiﬁer models described in section 4.1.
Within the domain of predicting match results, the authors
in (Joseph et al., 2006) used a variety of methods on a high
dimensional feature set similar to ours, including decision
trees, but did not obtain very high predictive accuracy with
any of the methods. Thus, we do not expect very high
win/loss accuracy either but that is not necessary for our
research question.
In the speciﬁc area of analyzing items in league-of-legends,
the state of the art metric is raw winrate for each items, as
can be seen in third-party apps endorsed by Riot such as
(KateOfSpades & Kai). We believe that our methods will
be able to give more realistic insight since they will take
confounding variable into account.
There is substantial literature on the combination of ma-
chine learning and traditional econometric techniques to
yield causal estimates.
(Athey & Imbens, 2015) dis-
cusses empirical methods for combining propensity score
matching and machine learning tools such as cross valida-
tion to estimate treatment effects, particularly in observa-
tional studies with heterogeneous users. (Athey & Mobius,
2012) is an example of an observational study that employs
propensity score matching. The authors aim to estimate
the causal effect of adding local news content to Google
news feeds, where opting into local news is a choice that
users make. They build a propensity score model of opt-
ing into local news as a function of past browsing behavior

Quantifying decision impact in MOBA games

and condition on this information to match users and form
a quasi-experiment to test effects on readership.

3. Data
The Riot API (rio) gives us access to a variety of informa-
tion on a given League match, but does not provide direct
access to recent matches, so we began by crawling player-
to-player connections to obtain a list of 2,000 North Amer-
ican players in ”Silver Tier”. All players in silver tier are
ranked to have roughly the same (mid-level amateur) skill
level. Up to 10 recent matches were pulled for each player
for a total of 12,000 matches.
Each match is played between two teams of 5, and each
player makes their own item purchase decisions. Since
we are modeling individual player choices, we extracted
a single sample from each match for a total of 12,000 data
points. Extracting more data points from each match would
introducing misleading correlations in the data.
We extracted a number of both categorical and numerical
features for each match from the json provided by the api:
Category
Ally champions
Opponent champtions
Items total
Items @ 10 minutes
Gold @ x min
XP @ x min
Win / Loss
Each team consists of 5 out of 128 possible champions,
and similarly each player can purchase any number of dis-
tinct items. We encoded the presence or absence of each
champion on each team as a binary feature, for a total of
2*2*128 features. Similarly whether or not the player had
bought each item by speciﬁc points in time is encoded as a
binary feature. Cumulative Gold and XP numerical values
were measured at 5 minute intervals and each value repre-
sented by its own feature.

Example Features
ally alistar: 1, ally elise: 0, ...
opp alistar: 0, opp elise: 1, ...
boots: 1, longsword: 1, ...
boots 10: 1, longsword 10: 0, ...
gold 5: 23, gold 10: 250, ...
xp 5: 43, xp 10: 66, ...
win: 1

4. Methods
4.1. Predictive Classiﬁers

Our method for quantifying the overall impact of item pur-
chases is inspired by both forward-search feature selection
and 2-stage least squares modeling. The goal here is to
limit the effect of game state, which is a confounding vari-
able since it inﬂuences both the ﬁnal outcome of a match
and the items one might choose or be able to buy.
In section 4.1 we limit ourselves to the ﬁrst 10 minutes of
the game to limit variation in game state, and we use cham-
pion choices and gold and xp values at 10 minutes as in-

strumental variables to stand in for the game state. Then, to
distinguish the effect of item choices from these, we build
three successive models which take into account more fea-
tures roughly in the order they begin to have an impact

Figure 1. Successive Classiﬁer Models

Figure 1 illustrates how each model takes an additional set
of features into account. Model 1 only takes champion
choice into account, model 2 adds gold and xp data, while
model 3 includes all of the above as well as item choice
data. We hope to quantify the overall impact of item choice
with the difference in predictive power between model 3
and model 2.
Impact ∼ Model 3 Acc − Model 2 Acc
The speciﬁc algorithms we used for each model were l1-
regularized logistic regression, l2-regularized linear SVM,
and Adaboost decision tree ensembles. The logistic regres-
sion minimized the error:

i log(cid:2)exp(cid:0)−yi

(cid:0)X T
i w + c(cid:1)(cid:1) + 1(cid:3)

Regularized Linear SVM minimizes the error:

|w| + C(cid:80)n
2 wT w + C(cid:80)n

1

i=1 ξi

where yi(wT xi + b) ≥ 1 − ξi.
Adaboost trees calculate weights β for decision trees ht(x)
and then classiﬁes based on the sum of the weighted tree
decisions:

(cid:80)

t(log 1/βt)ht(x)

4.2. Propensity Score Matching

A more principled way of isolating causal effects for spe-
ciﬁc item choices is Propensity Score Matching (PSM).
PSM is a method for estimating treatment effects in
datasets where assignment to a binary treatment is endoge-
neous. Our example of this is the purchase of an expensive
item (treatment) in League of Legends. Expensive items
are frequently only affordable to the team that is ahead,
and thus their purchase might be correlated with winning
the game even when their actual effect is minor.
The goal of propensity score matching is to estimate the
effect of binary treatment X on outcome Y in the pres-
ence of endogeneous variables Z. The concern is that Z,
which in our case are game state variables, have an effect

Champion Selection (C)Gold + XP(GS)Early Item Purchases(IP)Model 1:Win ~ CModel 2:Win ~ C + GSModel 3:Win ~ C + GS + IPQuantifying decision impact in MOBA games

5.1.1. LINEAR MODELS

We started by evaluating the performance of regularized lo-
gistic regression and linear SVMS. We evaluated each clas-
siﬁer by its overall accuracy via 5-fold cross-validation. L1
loss yielded the best results for logistic regression while L2
loss worked best for SVMs. We also tried a variety of regu-
larization parameters C ranging from 1e-4 to 1e4, and C=1
was close to optimal.
In ﬁgure 2 we compare the accuracy of logistic and linear
SVM classiﬁers for the models described in section 4.1.
The two methods perform very comparably. Champion
choice in model 1 gives us reasonable predictive power,
adding in game state in model 2 helps us signiﬁcantly, but
further adding in early game item choice in model 3 does
not improve performance.

on the game outcome Y and inﬂuence the item choice X.
Then our typical ordinary least squares assumptions would
be violated, as the error term  in the estimated model of
Y = β1 ∗ X +  is now correlated with X. PSM handles
this endogeneity by modeling the probability of being allo-
cated to the treatment X (buying item) via logistic regres-
sion on Z (game state). The logistic regression of X on
Z yields propensity scores P (X = x|Z) for each obser-
vation. Observations are then paired based on propensity
scores via nearest neighbors, such that observations i, j in
which Xi = 1 are paired with those in which Xj = 0
and P (Xi|Zi) ≈ P (Xj|Zj) and covariates Z are counter-
balanced across the entire group. This procedure yields a
new dataset where X⊥Z, allowing unbiased estimates of
the causal effect of X on Y via ordinary least squares re-
gression.
The following provides a (hypothetical) graphical illustra-
tion of propensity score matching. Table 1 is hypotheti-
cal representative data, where the expensive item Mejai’s
Soulstealer is more commonly bought by the winning team.
Regression of this dataset would assign coefﬁcients which
conﬂate the role of Mejai’s Soulstealer on game outcome
when gold lead is correlated with both item purchase and
winning the game. Table 2 shows what the dataset might
look like after the matching process has concluded. We see
that both observables and propensity scores are approxi-
mately balanced (within some tolerance) between the treat-
ment (Mejai purchased) and control (Mejai not purchased)
groups.

Table 1. Representative (Unmatched) Data

P (X|Z)

ID Mejai
32
93
420
96

1
1
0
0

Gold
+5284
+2745
-340
-3890

.56
.42
.15
.02

.56
.57
.15
.15

Table 2. Propensity Score Matched Data
P (X|Z)

ID Mejai
32
742
420
278

1
0
0
1

Gold
+5284
+5350
-340
-328

5. Results
5.1. Predictive Classiﬁers

As described in the methods, we tried to predict match wins
in terms of various subsets of the champion, early game
state, and early item features.

Figure 2. Linear Classiﬁer performance

Table 3 presents the confusion matrix for logistic regression
evaluated on a separate test set. The results for linearSVM
are very similar and the two methods appear to do slightly
better predicting games where the player won.

Table 3. Linear Model Confusion Matrix
Predicted Loss

Predicted Win

Win
Loss

742
506

464
683

5.1.2. NONLINEAR MODELS

Though item choice did not improve predictive perfor-
mance in linear models, we hoped to see more signiﬁcant
results for nonlinear models which could take into account
the situation effectiveness of different items.
In ﬁgure 3 we compare the accuracy of SVM using linear,
degree-2 polynomial and degree-2 radial basis function ker-
nels, for the models described in section 4.1. The numbers

123Model0.500.520.540.560.580.600.620.645-fold CV AccuracyModel Accuracy for Linear clasifiersLogisticSVMQuantifying decision impact in MOBA games

here are slightly different than in the previous ﬁgure since
they were obtained from an independent experiment. The
linear kernel has the highest accuracy, though it only out-
performs the degree-2 RBF slightly (0.01 for model 3). The
degree-2 polynomial kernel is signiﬁcantly worse than the
other two. Again, adding game state in model 2 improves
accuracy by 0.04 for the linear kernel, further adding item
choice in model 3 only improves performance by 0.01.

Figure 4. AdaBoost depth parameter tuning

Figure 3. Accuracy of SVM kernels

Along the same vein, we also tried decision trees to see
if we could identify context-dependent item choice im-
pact. We evaluated Random Forests, Gradient Boosted de-
cision trees, as well as AdaBoost tree ensembles. For depth
d=1,2,3, the AdaBoost algorithm had the best accuracy on
5-way cross validation.
To ﬁnd the optimal tree depth in ﬁgure 4 we compare 5
way CV scores for model 3 (win ∼ champions + state +
items) and see that depth 1 trees perform the best. Increas-
ing the depth yields higher training accuracy but worse test
accuracy. For instance, in ﬁgure 5 we compare training and
test accuracy for depth 3 and see that there is substantial
overﬁtting even in model 1.
The breakdown of the impact provided by the champion
choice, state, and items is then given in ﬁgure 6. The results
are very similar to what we saw for linear classiﬁers.

5.1.3. PREDICTIVE CLASSIFIER ANALYSIS

It appears that any additional predictive power provided by
item choice is outweighed by the overﬁtting that occurs.
This is especially true for decision trees where any addi-
tional depth beyond d=1 yielded worse results. Both deci-
sion trees and kernel SVMs were unable to learn any of the
truly nonlinear effects of item choice. We tried to reduce
dimensionality the by considering only the most frequently
purchased 40 items and most frequently played 60 cham-

Figure 5. AdaBoost Overﬁtting at depth 3

pions but the results did not improve; Principal component
analysis was not helpful because each feature only accounts
for a small independent fraction of total variance.

5.2. Propensity Score Matching

We implement Propensity Score Matching on our dataset
in order to estimate the causal impact of items chosen to
be most predictive of winning games via logistic regres-
sion. We balance selection into purchasing these items
across the observed covariates related to game state: gold5,
gold10, xp5, xp10, champion, role, lane, xp differential,
damage differential. Logistic regression is used to gen-
erate propensity scores and observations are paired based
on nearest neighbors using propensity score. The below
diagram displays propensity scores both before and after
propensity score matching. We see that the distribution of
propensity scores is much more similar between treatment
and control groups after matching.

123SVM Kernel ComparisonModel5 Fold CV Accuracy0.500.520.540.560.580.60linearpoly−deg2radial−deg212345Tree Depth0.500.520.540.560.580.600.620.645-fold CV AccuracyModel 3 Accuracy wrt Tree Depth123Model0.50.60.70.80.91.0Raw AccuracyOverfitting for Depth-3 AdaboostTest SetTraining SetQuantifying decision impact in MOBA games

the relative coefﬁcients weightings and sign are notewor-
thy.
The negative logistic regression coefﬁcient on Hunter’s Po-
tion, for example, would suggest that the item is commonly
bought by the losing team. On the other hand, the pos-
itive PSM coefﬁcient on the item would suggest that in
similar situations with comparable champions and game
state, players who bought Hunter’s Potion fared better. This
agrees with general player intuition on the item, as Hunter’s
Potion is considered a catch-up item that provides good
value when behind but lesser value when already winning
the game.

6. Conclusions
Predictive classiﬁers introduced in section 4.1 overﬁt and
perform poorly in taking advantage of item choice data.
This suggests that items as a whole are fairly well balanced
so that it is hard to distinguish truly powerful items from
noise.
Nevertheless, when we focus on speciﬁc items, even af-
ter correcting for endogenous confounding variables in the
game state using propensity score matching, we see that
certain items such as the Inﬁnity Edge appear to have a
modest but signiﬁcant impact on the game.

References
Riot games api. https://developer.riotgames.

com/api/methods. Accessed: 2015-11-11.

Athey, Susan and Imbens, Guido. Machine learning meth-
ods for estimating heterogeneous causal effects. 2015.
http://arxiv.org/abs/1504.01132.

Athey, Susan and Mobius, Markus. The impact of news
aggregators on internet news consumption: The case of
localization, working. Technical report, 2012.

Foster, E.Michael.

Instrumental variables for logistic re-
gression: An illustration. Social Science Research, 26
(4):487 – 504, 1997.
doi: http:
//dx.doi.org/10.1006/ssre.1997.0606.

ISSN 0049-089X.

Guyon, Isabelle and Elisseeff, Andr´e. An introduction to
variable and feature selection. J. Mach. Learn. Res., 3:
1157–1182, March 2003. ISSN 1532-4435.

Joseph, A., Fenton, N. E., and Neil, M. Predicting football
results using bayesian nets and other machine learning
techniques. Know.-Based Syst., 19(7):544–553, Novem-
ber 2006. ISSN 0950-7051.

Figure 6. AdaBoost results

Figure 7. Propensity Scores before and after matching

We then use least squares regression on the matched dataset
in order to estimate a causal effect of item purchase on sub-
sequent game outcome. Since this process is relatively time
intensive and must be performed with a covariate/item at a
time, we decided to look at the most predictive items found
via regularized logistic regression and compare those coef-
ﬁcient estimates with the coefﬁcients we ﬁnd from PSM.

3031 (Inﬁnity Edge)

1306 (Enchantment: Alacrity)

Table 4. PSM vs Logistic Regression Item Coefﬁcients
Raw
.5088
.4407
.3859
.4407
-.4792
-.3723

PSM
.06288
.03737
-.0086
.00801
.01491
-.0645

1317 (Enchantment: Captain)

Item ID (Name)

3706 (Stalker’s Blade)

3004 (Manamune)

2032 (Hunter’s Potion)

From table 4, we see that items do not always map well
from their logistic regression coefﬁcient to their PSM coef-
ﬁcient. While we cannot directly compare the magnitudes,

KateOfSpades and Kai, Praetor. Ripples item analysis.
http://maryschmidt.github.io/ripples/.
Accessed: 2015-11-11.

123Model0.500.520.540.560.580.600.620.645-fold CV AccuracyModel Accuracy for Depth-1 Adaboost Trees