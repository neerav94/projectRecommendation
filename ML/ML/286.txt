CS 229 Project: Using Vector Representations to Augment Sentiment

Analysis Training Data
Andrew McLeod∗, Lucas Peeters†

Abstract

While the accuracy of supervised sentiment classiﬁcation algorithms has steadily increased in recent years, acquiring
new human-labeled sentiment data remains expensive. In this paper, we explore the effectiveness of increasing the
training data set size for sentiment classiﬁcation algorithms by adding unlabeled phrases whose sentiments are inferred
by their proximity to labeled training phrases. This study was carried out in the context of two softmax classiﬁers, each
trained on movie review phrases with sentiments labeled between 1 (very negative) and 5 (very positive), using pre-
trained vectors to represent individual words. We ﬁnd that augmenting the training data of these softmax classiﬁers can
improve the classiﬁcation accuracy of one of our models by up to 5%, while the other neither improves nor deteriorates.

Introduction
Sentiment analysis is an active ﬁeld of machine learning
research in which the goal is to ﬁnd the opinion or emo-
tion expressed by a text with regard to a speciﬁc entity
[2]. This analysis can be carried out at the level of indi-
vidual words, whereby one associates a sentiment to each
word separately, or at the level of full sentences or even
texts. Methods aimed at performing the task of assigning
sentiments to full sentences will then commonly contain
two key components: a way to represent and predict the
sentiments of individual words, and a way to represent
and predict the sentiments of phrases using these word
representations.

In this project, we set out to improve the predictions
made by these types of sentiment classiﬁers in situations
where the amount of labeled sentiment data is limited.
This is attempted by representing words and phrases as
vectors and using the notion of distance in these vector
spaces to infer the sentiments of the nearest unlabeled
neighbors of the training phrases; these newly labeled
phrases can thereby be added to the original training data.
We tested this idea on two classiﬁers—one in which the
vectors representing phrases were constructed by aver-
aging the vectors corresponding the phrase’s constituent
words, and another in which these word vectors were con-
catenated.
Data
Both of our classiﬁers were trained and tested on

∗ajmcleod@stanford.edu
†lpeeters@stanford.edu

1

the Stanford Sentiment Treebank (SST), a database of
movie review phrases. This database is comprised of
11,855 full sentences parsed into a total of 215,154
unique phrases, all of which have been annotated by three
human judges with a sentiment ranging from 0 to 1 [3].
Following previous work on this data set, we discretize
the sentiment into ﬁve evenly spaced bins, where 1 is very
negative and 5 is very positive. The data is split into 8,544
training, 1,101 development, and 2,210 test sentences—
however, due to the fact that some phrases are found in
multiple sentences, individual phrases can be found in
one, two, or all three splits. For the same reason, some
phrases are repeated within the same split; accordingly,
accuracies can either be reported on the full (redundant)
splits, or on just the unique phrases occurring in them,
leading to very different reported numbers. Unless oth-
erwise noted, the accuracies reported in this paper were
computed using the redundant splits so that direct com-
parison could be made with the results reported in [3].

We chose to represent the words within these phrases
using vectors trained by GloVe [4], an unsupervised
learning algorithm for obtaining such vectors. GloVe
is able to capture signiﬁcant semantic and linguistic
relationships—for instance, the difference vector between
‘man’ and ‘woman’ is found to be approximately paral-
lel to the difference vector between ’king’ and ’queen’—
making it well-suited to our task.
The vectors we
used were pulled from a publicly available set of ﬁfty-
dimensional vectors trained on Wikipedia articles.

CS 229 Project: Using Vector Representations to Augment Sentiment

Analysis Training Data
Andrew McLeod∗, Lucas Peeters†

Abstract

While the accuracy of supervised sentiment classiﬁcation algorithms has steadily increased in recent years, acquiring
new human-labeled sentiment data remains expensive. In this paper, we explore the effectiveness of increasing the
training data set size for sentiment classiﬁcation algorithms by adding unlabeled phrases whose sentiments are inferred
by their proximity to labeled training phrases. This study was carried out in the context of two softmax classiﬁers, each
trained on movie review phrases with sentiments labeled between 1 (very negative) and 5 (very positive), using pre-
trained vectors to represent individual words. We ﬁnd that augmenting the training data of these softmax classiﬁers can
improve the classiﬁcation accuracy of one of our models by up to 5%, while the other neither improves nor deteriorates.

Introduction
Sentiment analysis is an active ﬁeld of machine learning
research in which the goal is to ﬁnd the opinion or emo-
tion expressed by a text with regard to a speciﬁc entity
[2]. This analysis can be carried out at the level of indi-
vidual words, whereby one associates a sentiment to each
word separately, or at the level of full sentences or even
texts. Methods aimed at performing the task of assigning
sentiments to full sentences will then commonly contain
two key components: a way to represent and predict the
sentiments of individual words, and a way to represent
and predict the sentiments of phrases using these word
representations.

In this project, we set out to improve the predictions
made by these types of sentiment classiﬁers in situations
where the amount of labeled sentiment data is limited.
This is attempted by representing words and phrases as
vectors and using the notion of distance in these vector
spaces to infer the sentiments of the nearest unlabeled
neighbors of the training phrases; these newly labeled
phrases can thereby be added to the original training data.
We tested this idea on two classiﬁers—one in which the
vectors representing phrases were constructed by aver-
aging the vectors corresponding the phrase’s constituent
words, and another in which these word vectors were con-
catenated.
Data
Both of our classiﬁers were trained and tested on

∗ajmcleod@stanford.edu
†lpeeters@stanford.edu

1

the Stanford Sentiment Treebank (SST), a database of
movie review phrases. This database is comprised of
11,855 full sentences parsed into a total of 215,154
unique phrases, all of which have been annotated by three
human judges with a sentiment ranging from 0 to 1 [3].
Following previous work on this data set, we discretize
the sentiment into ﬁve evenly spaced bins, where 1 is very
negative and 5 is very positive. The data is split into 8,544
training, 1,101 development, and 2,210 test sentences—
however, due to the fact that some phrases are found in
multiple sentences, individual phrases can be found in
one, two, or all three splits. For the same reason, some
phrases are repeated within the same split; accordingly,
accuracies can either be reported on the full (redundant)
splits, or on just the unique phrases occurring in them,
leading to very different reported numbers. Unless oth-
erwise noted, the accuracies reported in this paper were
computed using the redundant splits so that direct com-
parison could be made with the results reported in [3].

We chose to represent the words within these phrases
using vectors trained by GloVe [4], an unsupervised
learning algorithm for obtaining such vectors. GloVe
is able to capture signiﬁcant semantic and linguistic
relationships—for instance, the difference vector between
‘man’ and ‘woman’ is found to be approximately paral-
lel to the difference vector between ’king’ and ’queen’—
making it well-suited to our task.
The vectors we
used were pulled from a publicly available set of ﬁfty-
dimensional vectors trained on Wikipedia articles.

Methods
The softmax classiﬁers
Both of our classiﬁers are trained using a softmax training
algorithm. Denoting our phrase (or word) vectors as xk,
we optimize θl for each sentiment bin l ∈ {0, 1, 2, 3, 4}
by maximizing our objective function

(cid:88)

(cid:88)

(cid:18)

J (θ) = − 1
m

k

l

1(sk = l) log

(cid:19)(cid:19)

(cid:18) exp (θl · xk)
(cid:80)
m exp (θm · xk)
+ λ|θ|2

(1)

where the k sum runs over all training phrases, and sk
is the known sentiment for each training phrase xk. The
regularization term λ|θ|2 is proportional to the square of
the Euclidean norm of θ, deﬁned as the vector formed by
concatenating the ﬁve θl vectors. We carried out this op-
timization using the Adaptive Gradient Algorithm (Ada-
Grad) [1], which reduces the step size of gradient de-
scent for a given parameter the more that parameter is
updated. Convergence is assumed to be attained when the
Euclidean norm of the change in θ after one batch step is
smaller than a user-deﬁned fraction of the norm of θ it-
self. Once our θl are trained, the predicted sentiment ˜sk
of the vector xk is

˜sk = argmax

l

exp (θl · xk)

(2)

where l again runs over our ﬁve sentiment bins.

While the pre-trained GloVe vectors already capture
some of the semantic relations between the words occur-
ring in the SST, they are not optimized for this partic-
ular task. Thus, we initialize our word vectors to their
pre-trained GloVe values (after normalization), but then
adjust them through backpropagation. That is, we max-
imize our objective function with respect to these word
vectors as well as θ, thereby training both sets of vectors
simultaneously. These word vector optimizations were

also carried out using AdaGrad.
Word Vector Averaging Model
Our ﬁrst classiﬁer constructs phrase vectors by averaging
over all word vectors in a phrase. Phrases are thereby rep-
resented in the same ﬁfty-dimensional space as individual
words, and both phrases and words are used to train a sin-
gle set of model parameters θl. Word vector backpropa-
gation is only carried out when training on words (not on
phrases), and words that are found in the SST but not in
the GloVe database are initialized to a random unit vec-
tor. Training was carried out both on the full SST train-
ing set, and on restricted training sets with sizes logarith-
mically distributed between 1 and 1000. When training
on these restricted training sets, we augment the training
data with the k nearest neighbors of each training phrase
(pulled from the remainder of the training set), labeling
these neighbors with the same sentiment as the original
training phrase.
Word Vector Concatenation Model
Conversely, our second classiﬁer represents phrases of
different length in different spaces by setting phrase vec-
tors equal to the concatenation of their constituent word
vectors. Due to the different resultant vector lengths, a
separate set of softmax parameters θl is trained on the
phrases of each length. This is done by ﬁrst training the
phrase length-one softmax using word vector backprop-
agation, and then computing the k nearest neighbors of
all word vectors in our current (possibly restricted) train-
ing set (where k may be 0). A softmax is then trained on
each set of phrases with length greater than one as well
as their nearest neighbors, where the nearest neighbors of
a phrase are constructed by replacing each word in the
phrase with its k nearest neighbors (never replacing more
than one word at a time). This gives us a (k × L)-fold
increase in our training set size for phrases of length L.

Figure 1: Comparison of the accuracy achieved by our vector averaging and vector concatenation approaches as a function of phrase length
(without adding nearest neighbors). Green represents the vector averaging model, blue the vector concatenation model, and dark turquoise their
overlap.

2

1234567891011121314151617181920212223242526272829303132333435363738394041424344454612345678910111213141516171819202122232425262728293031323334353637383940414243444546PhraseLength0.20.40.60.81.0AccuracyCS 229 Project: Using Vector Representations to Augment Sentiment

Analysis Training Data
Andrew McLeod∗, Lucas Peeters†

Abstract

While the accuracy of supervised sentiment classiﬁcation algorithms has steadily increased in recent years, acquiring
new human-labeled sentiment data remains expensive. In this paper, we explore the effectiveness of increasing the
training data set size for sentiment classiﬁcation algorithms by adding unlabeled phrases whose sentiments are inferred
by their proximity to labeled training phrases. This study was carried out in the context of two softmax classiﬁers, each
trained on movie review phrases with sentiments labeled between 1 (very negative) and 5 (very positive), using pre-
trained vectors to represent individual words. We ﬁnd that augmenting the training data of these softmax classiﬁers can
improve the classiﬁcation accuracy of one of our models by up to 5%, while the other neither improves nor deteriorates.

Introduction
Sentiment analysis is an active ﬁeld of machine learning
research in which the goal is to ﬁnd the opinion or emo-
tion expressed by a text with regard to a speciﬁc entity
[2]. This analysis can be carried out at the level of indi-
vidual words, whereby one associates a sentiment to each
word separately, or at the level of full sentences or even
texts. Methods aimed at performing the task of assigning
sentiments to full sentences will then commonly contain
two key components: a way to represent and predict the
sentiments of individual words, and a way to represent
and predict the sentiments of phrases using these word
representations.

In this project, we set out to improve the predictions
made by these types of sentiment classiﬁers in situations
where the amount of labeled sentiment data is limited.
This is attempted by representing words and phrases as
vectors and using the notion of distance in these vector
spaces to infer the sentiments of the nearest unlabeled
neighbors of the training phrases; these newly labeled
phrases can thereby be added to the original training data.
We tested this idea on two classiﬁers—one in which the
vectors representing phrases were constructed by aver-
aging the vectors corresponding the phrase’s constituent
words, and another in which these word vectors were con-
catenated.
Data
Both of our classiﬁers were trained and tested on

∗ajmcleod@stanford.edu
†lpeeters@stanford.edu

1

the Stanford Sentiment Treebank (SST), a database of
movie review phrases. This database is comprised of
11,855 full sentences parsed into a total of 215,154
unique phrases, all of which have been annotated by three
human judges with a sentiment ranging from 0 to 1 [3].
Following previous work on this data set, we discretize
the sentiment into ﬁve evenly spaced bins, where 1 is very
negative and 5 is very positive. The data is split into 8,544
training, 1,101 development, and 2,210 test sentences—
however, due to the fact that some phrases are found in
multiple sentences, individual phrases can be found in
one, two, or all three splits. For the same reason, some
phrases are repeated within the same split; accordingly,
accuracies can either be reported on the full (redundant)
splits, or on just the unique phrases occurring in them,
leading to very different reported numbers. Unless oth-
erwise noted, the accuracies reported in this paper were
computed using the redundant splits so that direct com-
parison could be made with the results reported in [3].

We chose to represent the words within these phrases
using vectors trained by GloVe [4], an unsupervised
learning algorithm for obtaining such vectors. GloVe
is able to capture signiﬁcant semantic and linguistic
relationships—for instance, the difference vector between
‘man’ and ‘woman’ is found to be approximately paral-
lel to the difference vector between ’king’ and ’queen’—
making it well-suited to our task.
The vectors we
used were pulled from a publicly available set of ﬁfty-
dimensional vectors trained on Wikipedia articles.

Methods
The softmax classiﬁers
Both of our classiﬁers are trained using a softmax training
algorithm. Denoting our phrase (or word) vectors as xk,
we optimize θl for each sentiment bin l ∈ {0, 1, 2, 3, 4}
by maximizing our objective function

(cid:88)

(cid:88)

(cid:18)

J (θ) = − 1
m

k

l

1(sk = l) log

(cid:19)(cid:19)

(cid:18) exp (θl · xk)
(cid:80)
m exp (θm · xk)
+ λ|θ|2

(1)

where the k sum runs over all training phrases, and sk
is the known sentiment for each training phrase xk. The
regularization term λ|θ|2 is proportional to the square of
the Euclidean norm of θ, deﬁned as the vector formed by
concatenating the ﬁve θl vectors. We carried out this op-
timization using the Adaptive Gradient Algorithm (Ada-
Grad) [1], which reduces the step size of gradient de-
scent for a given parameter the more that parameter is
updated. Convergence is assumed to be attained when the
Euclidean norm of the change in θ after one batch step is
smaller than a user-deﬁned fraction of the norm of θ it-
self. Once our θl are trained, the predicted sentiment ˜sk
of the vector xk is

˜sk = argmax

l

exp (θl · xk)

(2)

where l again runs over our ﬁve sentiment bins.

While the pre-trained GloVe vectors already capture
some of the semantic relations between the words occur-
ring in the SST, they are not optimized for this partic-
ular task. Thus, we initialize our word vectors to their
pre-trained GloVe values (after normalization), but then
adjust them through backpropagation. That is, we max-
imize our objective function with respect to these word
vectors as well as θ, thereby training both sets of vectors
simultaneously. These word vector optimizations were

also carried out using AdaGrad.
Word Vector Averaging Model
Our ﬁrst classiﬁer constructs phrase vectors by averaging
over all word vectors in a phrase. Phrases are thereby rep-
resented in the same ﬁfty-dimensional space as individual
words, and both phrases and words are used to train a sin-
gle set of model parameters θl. Word vector backpropa-
gation is only carried out when training on words (not on
phrases), and words that are found in the SST but not in
the GloVe database are initialized to a random unit vec-
tor. Training was carried out both on the full SST train-
ing set, and on restricted training sets with sizes logarith-
mically distributed between 1 and 1000. When training
on these restricted training sets, we augment the training
data with the k nearest neighbors of each training phrase
(pulled from the remainder of the training set), labeling
these neighbors with the same sentiment as the original
training phrase.
Word Vector Concatenation Model
Conversely, our second classiﬁer represents phrases of
different length in different spaces by setting phrase vec-
tors equal to the concatenation of their constituent word
vectors. Due to the different resultant vector lengths, a
separate set of softmax parameters θl is trained on the
phrases of each length. This is done by ﬁrst training the
phrase length-one softmax using word vector backprop-
agation, and then computing the k nearest neighbors of
all word vectors in our current (possibly restricted) train-
ing set (where k may be 0). A softmax is then trained on
each set of phrases with length greater than one as well
as their nearest neighbors, where the nearest neighbors of
a phrase are constructed by replacing each word in the
phrase with its k nearest neighbors (never replacing more
than one word at a time). This gives us a (k × L)-fold
increase in our training set size for phrases of length L.

Figure 1: Comparison of the accuracy achieved by our vector averaging and vector concatenation approaches as a function of phrase length
(without adding nearest neighbors). Green represents the vector averaging model, blue the vector concatenation model, and dark turquoise their
overlap.

2

1234567891011121314151617181920212223242526272829303132333435363738394041424344454612345678910111213141516171819202122232425262728293031323334353637383940414243444546PhraseLength0.20.40.60.81.0AccuracyBase Model Performance
Before testing the effect of augmenting our training data,
we ran both classiﬁers on the full SST training data to
compare our baseline results to previously reported accu-
racies achieved on this data set. This comparison is found
in Table 1. Although neither of our models is able to
match the best classiﬁer reported in [3], our concatenated
vector model did outperform all non-neural net models
reported therein (including Naive Bayes and SVMs). Fig-
ure 1 compares the vector averaged and concatenated vec-
tor models for each phrase length separately. We see there
that the concatenated vector model mainly attains higher
accuracy on the phrases of length 10 to 20. For very long
phrase length (beyond 30), the number of training phrases
is limited and thus the statistics are not very reliable.

Model

Vector Averaged

Concatenated Vector

Recursive Neural Tensor Network

Accuracy
68.8%
77.3%
80.7%

Table 1: The accuracy achieved by our two classiﬁers when
trained on the full SST training set without adding nearest
neighbors, compared to the highest accuracy reported in [3],
which was attained using a Recursive Neural Tensor Network.

.

Nearest Neighbor Results
The effects of adding nearest neighbors to the training set
of our two classiﬁers was tested by running a large num-
ber of trials with variable training set sizes and number
of nearest neighbors. The restricted training set was ran-
domly selected from the SST training phrases for each
trial, and the phrases within it were required to be unique.
Word Vector Averaging Model
The accuracy achieved by our vector averaging model as
a function of training set size is shown for 0, 5, and 10
nearest neighbors in Figure 2. Gains of approximately
2% are achieved by adding 5 nearest neighbors, but only
marginal improvements are made by going from 5 to
10 nearest neighbors. Note that these accuracies were
achieved by testing on only the unique phrases in the rel-
evant data split, not on the full (redundant) set; the 68.8%
reported in Figure 1 (on the redundant set) corresponds to
50.1% on the set of unique phrases. The relative accuracy
for 0 through 10 nearest neighbors is also plotted in Fig-
ure 3. We see there that our classiﬁers with augmented
training sets do up to 5% better than our baseline (k = 0)
model for training sets with 100 or fewer training exam-
ples, but that this improvement is mitigated to below 2%
once training set sizes grow to around 1000.

Figure 2: Accuracy attained by the vector averaged model on the unique phrases in the relevant data split as a function of training set size, for
k = 0, 5 and 10 nearest neighbors. The plotted accuracies represent values averaged over 300 trials, and the error bars denote the standard error of
the mean of these trials. Note that the obtained accuracies are obtained using unique phrases, which severely inﬂuences the accuracy, as discussed
in the text.

3

22471002164651000Training set size4446485052Accuracy (in %)k=0k=5k=10CS 229 Project: Using Vector Representations to Augment Sentiment

Analysis Training Data
Andrew McLeod∗, Lucas Peeters†

Abstract

While the accuracy of supervised sentiment classiﬁcation algorithms has steadily increased in recent years, acquiring
new human-labeled sentiment data remains expensive. In this paper, we explore the effectiveness of increasing the
training data set size for sentiment classiﬁcation algorithms by adding unlabeled phrases whose sentiments are inferred
by their proximity to labeled training phrases. This study was carried out in the context of two softmax classiﬁers, each
trained on movie review phrases with sentiments labeled between 1 (very negative) and 5 (very positive), using pre-
trained vectors to represent individual words. We ﬁnd that augmenting the training data of these softmax classiﬁers can
improve the classiﬁcation accuracy of one of our models by up to 5%, while the other neither improves nor deteriorates.

Introduction
Sentiment analysis is an active ﬁeld of machine learning
research in which the goal is to ﬁnd the opinion or emo-
tion expressed by a text with regard to a speciﬁc entity
[2]. This analysis can be carried out at the level of indi-
vidual words, whereby one associates a sentiment to each
word separately, or at the level of full sentences or even
texts. Methods aimed at performing the task of assigning
sentiments to full sentences will then commonly contain
two key components: a way to represent and predict the
sentiments of individual words, and a way to represent
and predict the sentiments of phrases using these word
representations.

In this project, we set out to improve the predictions
made by these types of sentiment classiﬁers in situations
where the amount of labeled sentiment data is limited.
This is attempted by representing words and phrases as
vectors and using the notion of distance in these vector
spaces to infer the sentiments of the nearest unlabeled
neighbors of the training phrases; these newly labeled
phrases can thereby be added to the original training data.
We tested this idea on two classiﬁers—one in which the
vectors representing phrases were constructed by aver-
aging the vectors corresponding the phrase’s constituent
words, and another in which these word vectors were con-
catenated.
Data
Both of our classiﬁers were trained and tested on

∗ajmcleod@stanford.edu
†lpeeters@stanford.edu

1

the Stanford Sentiment Treebank (SST), a database of
movie review phrases. This database is comprised of
11,855 full sentences parsed into a total of 215,154
unique phrases, all of which have been annotated by three
human judges with a sentiment ranging from 0 to 1 [3].
Following previous work on this data set, we discretize
the sentiment into ﬁve evenly spaced bins, where 1 is very
negative and 5 is very positive. The data is split into 8,544
training, 1,101 development, and 2,210 test sentences—
however, due to the fact that some phrases are found in
multiple sentences, individual phrases can be found in
one, two, or all three splits. For the same reason, some
phrases are repeated within the same split; accordingly,
accuracies can either be reported on the full (redundant)
splits, or on just the unique phrases occurring in them,
leading to very different reported numbers. Unless oth-
erwise noted, the accuracies reported in this paper were
computed using the redundant splits so that direct com-
parison could be made with the results reported in [3].

We chose to represent the words within these phrases
using vectors trained by GloVe [4], an unsupervised
learning algorithm for obtaining such vectors. GloVe
is able to capture signiﬁcant semantic and linguistic
relationships—for instance, the difference vector between
‘man’ and ‘woman’ is found to be approximately paral-
lel to the difference vector between ’king’ and ’queen’—
making it well-suited to our task.
The vectors we
used were pulled from a publicly available set of ﬁfty-
dimensional vectors trained on Wikipedia articles.

Methods
The softmax classiﬁers
Both of our classiﬁers are trained using a softmax training
algorithm. Denoting our phrase (or word) vectors as xk,
we optimize θl for each sentiment bin l ∈ {0, 1, 2, 3, 4}
by maximizing our objective function

(cid:88)

(cid:88)

(cid:18)

J (θ) = − 1
m

k

l

1(sk = l) log

(cid:19)(cid:19)

(cid:18) exp (θl · xk)
(cid:80)
m exp (θm · xk)
+ λ|θ|2

(1)

where the k sum runs over all training phrases, and sk
is the known sentiment for each training phrase xk. The
regularization term λ|θ|2 is proportional to the square of
the Euclidean norm of θ, deﬁned as the vector formed by
concatenating the ﬁve θl vectors. We carried out this op-
timization using the Adaptive Gradient Algorithm (Ada-
Grad) [1], which reduces the step size of gradient de-
scent for a given parameter the more that parameter is
updated. Convergence is assumed to be attained when the
Euclidean norm of the change in θ after one batch step is
smaller than a user-deﬁned fraction of the norm of θ it-
self. Once our θl are trained, the predicted sentiment ˜sk
of the vector xk is

˜sk = argmax

l

exp (θl · xk)

(2)

where l again runs over our ﬁve sentiment bins.

While the pre-trained GloVe vectors already capture
some of the semantic relations between the words occur-
ring in the SST, they are not optimized for this partic-
ular task. Thus, we initialize our word vectors to their
pre-trained GloVe values (after normalization), but then
adjust them through backpropagation. That is, we max-
imize our objective function with respect to these word
vectors as well as θ, thereby training both sets of vectors
simultaneously. These word vector optimizations were

also carried out using AdaGrad.
Word Vector Averaging Model
Our ﬁrst classiﬁer constructs phrase vectors by averaging
over all word vectors in a phrase. Phrases are thereby rep-
resented in the same ﬁfty-dimensional space as individual
words, and both phrases and words are used to train a sin-
gle set of model parameters θl. Word vector backpropa-
gation is only carried out when training on words (not on
phrases), and words that are found in the SST but not in
the GloVe database are initialized to a random unit vec-
tor. Training was carried out both on the full SST train-
ing set, and on restricted training sets with sizes logarith-
mically distributed between 1 and 1000. When training
on these restricted training sets, we augment the training
data with the k nearest neighbors of each training phrase
(pulled from the remainder of the training set), labeling
these neighbors with the same sentiment as the original
training phrase.
Word Vector Concatenation Model
Conversely, our second classiﬁer represents phrases of
different length in different spaces by setting phrase vec-
tors equal to the concatenation of their constituent word
vectors. Due to the different resultant vector lengths, a
separate set of softmax parameters θl is trained on the
phrases of each length. This is done by ﬁrst training the
phrase length-one softmax using word vector backprop-
agation, and then computing the k nearest neighbors of
all word vectors in our current (possibly restricted) train-
ing set (where k may be 0). A softmax is then trained on
each set of phrases with length greater than one as well
as their nearest neighbors, where the nearest neighbors of
a phrase are constructed by replacing each word in the
phrase with its k nearest neighbors (never replacing more
than one word at a time). This gives us a (k × L)-fold
increase in our training set size for phrases of length L.

Figure 1: Comparison of the accuracy achieved by our vector averaging and vector concatenation approaches as a function of phrase length
(without adding nearest neighbors). Green represents the vector averaging model, blue the vector concatenation model, and dark turquoise their
overlap.

2

1234567891011121314151617181920212223242526272829303132333435363738394041424344454612345678910111213141516171819202122232425262728293031323334353637383940414243444546PhraseLength0.20.40.60.81.0AccuracyBase Model Performance
Before testing the effect of augmenting our training data,
we ran both classiﬁers on the full SST training data to
compare our baseline results to previously reported accu-
racies achieved on this data set. This comparison is found
in Table 1. Although neither of our models is able to
match the best classiﬁer reported in [3], our concatenated
vector model did outperform all non-neural net models
reported therein (including Naive Bayes and SVMs). Fig-
ure 1 compares the vector averaged and concatenated vec-
tor models for each phrase length separately. We see there
that the concatenated vector model mainly attains higher
accuracy on the phrases of length 10 to 20. For very long
phrase length (beyond 30), the number of training phrases
is limited and thus the statistics are not very reliable.

Model

Vector Averaged

Concatenated Vector

Recursive Neural Tensor Network

Accuracy
68.8%
77.3%
80.7%

Table 1: The accuracy achieved by our two classiﬁers when
trained on the full SST training set without adding nearest
neighbors, compared to the highest accuracy reported in [3],
which was attained using a Recursive Neural Tensor Network.

.

Nearest Neighbor Results
The effects of adding nearest neighbors to the training set
of our two classiﬁers was tested by running a large num-
ber of trials with variable training set sizes and number
of nearest neighbors. The restricted training set was ran-
domly selected from the SST training phrases for each
trial, and the phrases within it were required to be unique.
Word Vector Averaging Model
The accuracy achieved by our vector averaging model as
a function of training set size is shown for 0, 5, and 10
nearest neighbors in Figure 2. Gains of approximately
2% are achieved by adding 5 nearest neighbors, but only
marginal improvements are made by going from 5 to
10 nearest neighbors. Note that these accuracies were
achieved by testing on only the unique phrases in the rel-
evant data split, not on the full (redundant) set; the 68.8%
reported in Figure 1 (on the redundant set) corresponds to
50.1% on the set of unique phrases. The relative accuracy
for 0 through 10 nearest neighbors is also plotted in Fig-
ure 3. We see there that our classiﬁers with augmented
training sets do up to 5% better than our baseline (k = 0)
model for training sets with 100 or fewer training exam-
ples, but that this improvement is mitigated to below 2%
once training set sizes grow to around 1000.

Figure 2: Accuracy attained by the vector averaged model on the unique phrases in the relevant data split as a function of training set size, for
k = 0, 5 and 10 nearest neighbors. The plotted accuracies represent values averaged over 300 trials, and the error bars denote the standard error of
the mean of these trials. Note that the obtained accuracies are obtained using unique phrases, which severely inﬂuences the accuracy, as discussed
in the text.

3

22471002164651000Training set size4446485052Accuracy (in %)k=0k=5k=10Figure 3: Relative gain in accuracy as a function of training set size for k = 0 through k = 10. Plotted values were averaged over 300 runs, and
the error bars denote the standard error of the mean.

Word Vector Concatenation Model

A similar set of trials was run for our vector concatena-
tion model. However, unlike the vector averaged model,
no statistically signiﬁcant increase or decrease in accu-
racy was observed.

Improving the Sentiment Classiﬁcation of Near-
est Neighbors

By adding the k nearest neighbors to our training sets in
the above manner, we increase our training set size by a
factor of k (or more, in the concatenated model). The rea-
son our gains remain limited despite this k-fold increase
is that phrases are only loosely clustered by sentiment;
assigning the nearest neighbor of each phrase in the SST
training set (using a Euclidean metric) only achieves an
accuracy of 35.0%. To improve on our above results, we
therefore need to improve our ability to predict nearest
neighbor sentiments. Our ﬁrst attempt to do this was to
compare the confusion matrices of nearest neighbor as-
signments for different metrics on this space. Some of
the results of this comparison are found in Table 2. Given
the accuracy achieved by each metric for each sentiment
label, we can maximize our overall accuracy by choos-
ing the best-performing metric as a function of training
phrase sentiment. However, doing this only boosts the
overall nearest neighbor sentiment prediction accuracy to
36.0%. A second approach consists of training a new

set of ﬁve softmax classiﬁers to predict the sentiments of
nearest neighbors—one for each sentiment label (of the
labeled training phrase). The input used to train these
classiﬁers was a concatenation of the original training
vector and the neighboring vector. Training these clas-
siﬁers on all phrases in the SST training split using the
ﬁve nearest neighbors of each phrase, and testing on the
ﬁve nearest neighbors of phrases in the SST development
split, we achieve an overall nearest-neighbor classiﬁca-
tion accuracy of 62%.

Sentiment LN N

2

LN N

1

LN N∞

5
4
3
2
1

0.046
0.176
0.509
0.210
0.059

0.047
0.178
0.513
0.204
0.056

0.048
0.190
0.508
0.199
0.055

Training Set

Fraction
0.0490
0.185
0.509
0.203
0.055

Table 2: The accuracies achieved by the L1, L2, and L∞ norms
when assigning the same sentiment to the nearest neighbor of vec-
tors in the SST training set. These accuracies can be compared to the
fraction of the training set associated with each sentiment label.

Future Work
There are a few directions in which this work can be
taken. A new set of trials should be run using our recently
developed nearest neighbor sentiment classiﬁers in con-
junction with our vector averaged model to see if perfor-

4

22471002164651000Training set size12345Relative gain in accuracy (in %)k=1 / k=0k=2 / k=0k=3 / k=0k=4 / k=0k=5 / k=0k=6 / k=0k=7 / k=0k=8 / k=0k=9 / k=0k=10 / k=0CS 229 Project: Using Vector Representations to Augment Sentiment

Analysis Training Data
Andrew McLeod∗, Lucas Peeters†

Abstract

While the accuracy of supervised sentiment classiﬁcation algorithms has steadily increased in recent years, acquiring
new human-labeled sentiment data remains expensive. In this paper, we explore the effectiveness of increasing the
training data set size for sentiment classiﬁcation algorithms by adding unlabeled phrases whose sentiments are inferred
by their proximity to labeled training phrases. This study was carried out in the context of two softmax classiﬁers, each
trained on movie review phrases with sentiments labeled between 1 (very negative) and 5 (very positive), using pre-
trained vectors to represent individual words. We ﬁnd that augmenting the training data of these softmax classiﬁers can
improve the classiﬁcation accuracy of one of our models by up to 5%, while the other neither improves nor deteriorates.

Introduction
Sentiment analysis is an active ﬁeld of machine learning
research in which the goal is to ﬁnd the opinion or emo-
tion expressed by a text with regard to a speciﬁc entity
[2]. This analysis can be carried out at the level of indi-
vidual words, whereby one associates a sentiment to each
word separately, or at the level of full sentences or even
texts. Methods aimed at performing the task of assigning
sentiments to full sentences will then commonly contain
two key components: a way to represent and predict the
sentiments of individual words, and a way to represent
and predict the sentiments of phrases using these word
representations.

In this project, we set out to improve the predictions
made by these types of sentiment classiﬁers in situations
where the amount of labeled sentiment data is limited.
This is attempted by representing words and phrases as
vectors and using the notion of distance in these vector
spaces to infer the sentiments of the nearest unlabeled
neighbors of the training phrases; these newly labeled
phrases can thereby be added to the original training data.
We tested this idea on two classiﬁers—one in which the
vectors representing phrases were constructed by aver-
aging the vectors corresponding the phrase’s constituent
words, and another in which these word vectors were con-
catenated.
Data
Both of our classiﬁers were trained and tested on

∗ajmcleod@stanford.edu
†lpeeters@stanford.edu

1

the Stanford Sentiment Treebank (SST), a database of
movie review phrases. This database is comprised of
11,855 full sentences parsed into a total of 215,154
unique phrases, all of which have been annotated by three
human judges with a sentiment ranging from 0 to 1 [3].
Following previous work on this data set, we discretize
the sentiment into ﬁve evenly spaced bins, where 1 is very
negative and 5 is very positive. The data is split into 8,544
training, 1,101 development, and 2,210 test sentences—
however, due to the fact that some phrases are found in
multiple sentences, individual phrases can be found in
one, two, or all three splits. For the same reason, some
phrases are repeated within the same split; accordingly,
accuracies can either be reported on the full (redundant)
splits, or on just the unique phrases occurring in them,
leading to very different reported numbers. Unless oth-
erwise noted, the accuracies reported in this paper were
computed using the redundant splits so that direct com-
parison could be made with the results reported in [3].

We chose to represent the words within these phrases
using vectors trained by GloVe [4], an unsupervised
learning algorithm for obtaining such vectors. GloVe
is able to capture signiﬁcant semantic and linguistic
relationships—for instance, the difference vector between
‘man’ and ‘woman’ is found to be approximately paral-
lel to the difference vector between ’king’ and ’queen’—
making it well-suited to our task.
The vectors we
used were pulled from a publicly available set of ﬁfty-
dimensional vectors trained on Wikipedia articles.

Methods
The softmax classiﬁers
Both of our classiﬁers are trained using a softmax training
algorithm. Denoting our phrase (or word) vectors as xk,
we optimize θl for each sentiment bin l ∈ {0, 1, 2, 3, 4}
by maximizing our objective function

(cid:88)

(cid:88)

(cid:18)

J (θ) = − 1
m

k

l

1(sk = l) log

(cid:19)(cid:19)

(cid:18) exp (θl · xk)
(cid:80)
m exp (θm · xk)
+ λ|θ|2

(1)

where the k sum runs over all training phrases, and sk
is the known sentiment for each training phrase xk. The
regularization term λ|θ|2 is proportional to the square of
the Euclidean norm of θ, deﬁned as the vector formed by
concatenating the ﬁve θl vectors. We carried out this op-
timization using the Adaptive Gradient Algorithm (Ada-
Grad) [1], which reduces the step size of gradient de-
scent for a given parameter the more that parameter is
updated. Convergence is assumed to be attained when the
Euclidean norm of the change in θ after one batch step is
smaller than a user-deﬁned fraction of the norm of θ it-
self. Once our θl are trained, the predicted sentiment ˜sk
of the vector xk is

˜sk = argmax

l

exp (θl · xk)

(2)

where l again runs over our ﬁve sentiment bins.

While the pre-trained GloVe vectors already capture
some of the semantic relations between the words occur-
ring in the SST, they are not optimized for this partic-
ular task. Thus, we initialize our word vectors to their
pre-trained GloVe values (after normalization), but then
adjust them through backpropagation. That is, we max-
imize our objective function with respect to these word
vectors as well as θ, thereby training both sets of vectors
simultaneously. These word vector optimizations were

also carried out using AdaGrad.
Word Vector Averaging Model
Our ﬁrst classiﬁer constructs phrase vectors by averaging
over all word vectors in a phrase. Phrases are thereby rep-
resented in the same ﬁfty-dimensional space as individual
words, and both phrases and words are used to train a sin-
gle set of model parameters θl. Word vector backpropa-
gation is only carried out when training on words (not on
phrases), and words that are found in the SST but not in
the GloVe database are initialized to a random unit vec-
tor. Training was carried out both on the full SST train-
ing set, and on restricted training sets with sizes logarith-
mically distributed between 1 and 1000. When training
on these restricted training sets, we augment the training
data with the k nearest neighbors of each training phrase
(pulled from the remainder of the training set), labeling
these neighbors with the same sentiment as the original
training phrase.
Word Vector Concatenation Model
Conversely, our second classiﬁer represents phrases of
different length in different spaces by setting phrase vec-
tors equal to the concatenation of their constituent word
vectors. Due to the different resultant vector lengths, a
separate set of softmax parameters θl is trained on the
phrases of each length. This is done by ﬁrst training the
phrase length-one softmax using word vector backprop-
agation, and then computing the k nearest neighbors of
all word vectors in our current (possibly restricted) train-
ing set (where k may be 0). A softmax is then trained on
each set of phrases with length greater than one as well
as their nearest neighbors, where the nearest neighbors of
a phrase are constructed by replacing each word in the
phrase with its k nearest neighbors (never replacing more
than one word at a time). This gives us a (k × L)-fold
increase in our training set size for phrases of length L.

Figure 1: Comparison of the accuracy achieved by our vector averaging and vector concatenation approaches as a function of phrase length
(without adding nearest neighbors). Green represents the vector averaging model, blue the vector concatenation model, and dark turquoise their
overlap.

2

1234567891011121314151617181920212223242526272829303132333435363738394041424344454612345678910111213141516171819202122232425262728293031323334353637383940414243444546PhraseLength0.20.40.60.81.0AccuracyBase Model Performance
Before testing the effect of augmenting our training data,
we ran both classiﬁers on the full SST training data to
compare our baseline results to previously reported accu-
racies achieved on this data set. This comparison is found
in Table 1. Although neither of our models is able to
match the best classiﬁer reported in [3], our concatenated
vector model did outperform all non-neural net models
reported therein (including Naive Bayes and SVMs). Fig-
ure 1 compares the vector averaged and concatenated vec-
tor models for each phrase length separately. We see there
that the concatenated vector model mainly attains higher
accuracy on the phrases of length 10 to 20. For very long
phrase length (beyond 30), the number of training phrases
is limited and thus the statistics are not very reliable.

Model

Vector Averaged

Concatenated Vector

Recursive Neural Tensor Network

Accuracy
68.8%
77.3%
80.7%

Table 1: The accuracy achieved by our two classiﬁers when
trained on the full SST training set without adding nearest
neighbors, compared to the highest accuracy reported in [3],
which was attained using a Recursive Neural Tensor Network.

.

Nearest Neighbor Results
The effects of adding nearest neighbors to the training set
of our two classiﬁers was tested by running a large num-
ber of trials with variable training set sizes and number
of nearest neighbors. The restricted training set was ran-
domly selected from the SST training phrases for each
trial, and the phrases within it were required to be unique.
Word Vector Averaging Model
The accuracy achieved by our vector averaging model as
a function of training set size is shown for 0, 5, and 10
nearest neighbors in Figure 2. Gains of approximately
2% are achieved by adding 5 nearest neighbors, but only
marginal improvements are made by going from 5 to
10 nearest neighbors. Note that these accuracies were
achieved by testing on only the unique phrases in the rel-
evant data split, not on the full (redundant) set; the 68.8%
reported in Figure 1 (on the redundant set) corresponds to
50.1% on the set of unique phrases. The relative accuracy
for 0 through 10 nearest neighbors is also plotted in Fig-
ure 3. We see there that our classiﬁers with augmented
training sets do up to 5% better than our baseline (k = 0)
model for training sets with 100 or fewer training exam-
ples, but that this improvement is mitigated to below 2%
once training set sizes grow to around 1000.

Figure 2: Accuracy attained by the vector averaged model on the unique phrases in the relevant data split as a function of training set size, for
k = 0, 5 and 10 nearest neighbors. The plotted accuracies represent values averaged over 300 trials, and the error bars denote the standard error of
the mean of these trials. Note that the obtained accuracies are obtained using unique phrases, which severely inﬂuences the accuracy, as discussed
in the text.

3

22471002164651000Training set size4446485052Accuracy (in %)k=0k=5k=10Figure 3: Relative gain in accuracy as a function of training set size for k = 0 through k = 10. Plotted values were averaged over 300 runs, and
the error bars denote the standard error of the mean.

Word Vector Concatenation Model

A similar set of trials was run for our vector concatena-
tion model. However, unlike the vector averaged model,
no statistically signiﬁcant increase or decrease in accu-
racy was observed.

Improving the Sentiment Classiﬁcation of Near-
est Neighbors

By adding the k nearest neighbors to our training sets in
the above manner, we increase our training set size by a
factor of k (or more, in the concatenated model). The rea-
son our gains remain limited despite this k-fold increase
is that phrases are only loosely clustered by sentiment;
assigning the nearest neighbor of each phrase in the SST
training set (using a Euclidean metric) only achieves an
accuracy of 35.0%. To improve on our above results, we
therefore need to improve our ability to predict nearest
neighbor sentiments. Our ﬁrst attempt to do this was to
compare the confusion matrices of nearest neighbor as-
signments for different metrics on this space. Some of
the results of this comparison are found in Table 2. Given
the accuracy achieved by each metric for each sentiment
label, we can maximize our overall accuracy by choos-
ing the best-performing metric as a function of training
phrase sentiment. However, doing this only boosts the
overall nearest neighbor sentiment prediction accuracy to
36.0%. A second approach consists of training a new

set of ﬁve softmax classiﬁers to predict the sentiments of
nearest neighbors—one for each sentiment label (of the
labeled training phrase). The input used to train these
classiﬁers was a concatenation of the original training
vector and the neighboring vector. Training these clas-
siﬁers on all phrases in the SST training split using the
ﬁve nearest neighbors of each phrase, and testing on the
ﬁve nearest neighbors of phrases in the SST development
split, we achieve an overall nearest-neighbor classiﬁca-
tion accuracy of 62%.

Sentiment LN N

2

LN N

1

LN N∞

5
4
3
2
1

0.046
0.176
0.509
0.210
0.059

0.047
0.178
0.513
0.204
0.056

0.048
0.190
0.508
0.199
0.055

Training Set

Fraction
0.0490
0.185
0.509
0.203
0.055

Table 2: The accuracies achieved by the L1, L2, and L∞ norms
when assigning the same sentiment to the nearest neighbor of vec-
tors in the SST training set. These accuracies can be compared to the
fraction of the training set associated with each sentiment label.

Future Work
There are a few directions in which this work can be
taken. A new set of trials should be run using our recently
developed nearest neighbor sentiment classiﬁers in con-
junction with our vector averaged model to see if perfor-

4

22471002164651000Training set size12345Relative gain in accuracy (in %)k=1 / k=0k=2 / k=0k=3 / k=0k=4 / k=0k=5 / k=0k=6 / k=0k=7 / k=0k=8 / k=0k=9 / k=0k=10 / k=0mance improves. We can also try adding different types
of nearest neighbors to our concatenated vector model,
for instance by selecting nearest neighbor phrases from
the remainder of the SST training data like is done in the
vector averaged model. Finally, this line of research into
augmented training data sets can be continued on to neu-
ral net models, which will increase the overall accuracy
of our classiﬁers.
Conclusions
We have shown that, for small training set sizes, the use of
nearest-neighbor vectors allows for an increase in phrase
sentiment classiﬁcation accuracy by several percent with
respect to our baseline vector averaging method. We did

not ﬁnd that this result extended to our vector concate-
nation method, at least for the types of nearest neigh-
bors constructed in this model. Without adding nearest
neighbors, our concatenation model outperforms all re-
ported methods on this dataset except for neural network
methods (notably the Recursive Neural Tensor Network,
which achieves 80.7%) [3]. Whether or not it would be
possible to increase the accuracy of neural network meth-
ods by augmenting their training data with nearest neigh-
bors remains a question for future work.
Acknowledgments
We would like to acknowledge Richard Socher for advis-
ing us on this project.

References and Notes
[1] J. Duchi et al., Adaptive Subgradient Methods for Online Learning and Stochastic Optimization, JMLR 12, p. 2121-

2159 (2011).

[2] R. Feldman, Comm. ACM 56 (4), p. 82-89 (2013).

[3] R. Socher et al., Reasoning With Neural Tensor Networks for Knowledge Base Completion, Adv. NIPS 26, 2013.

[4] J. Pennington et al., GloVe: Global Vectors for Word Representation, Proc. EMNLP, 2014.

5

