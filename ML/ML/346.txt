Algorithmic Trading of Futures via
Machine Learning

David Montague, davmont@stanford.edu

Algorithmic trading of securities has become

a staple of modern approaches to ﬁnancial
investment. In this project, I attempt to
obtain an eﬀective strategy for trading a collec-
tion of 27 ﬁnancial futures based solely on their
past trading data. All of the strategies that I con-
sider are based on predictions of the future price
and volatility of the various securities under con-
sideration, and so the majority of the eﬀort in
this project has been directed toward using ma-
chine learning techniques to obtain predictions
for future price and volatility. This project was
inspired by the Quantiacs futures competition,
to which I submitted a number of the trading
strategies I obtained during my work on this
project.

Introduction

The Contest

The goal of this project was to obtain a high-
performing trading strategy for the Quantiacs futures
contest [1]. Quantiacs is a quantitative trading plat-
form that invests in crowdsourced trading systems,
and connects users trading systems with institutional
investors, [sharing] a performance fee with the devel-
oper. The Quantiacs futures contest was a competition
to obtain a trading strategy which invests in a collec-
tion of futures securities and attempts to maximize
the Sharpe ratio (a measure of risk-adjusted return)
over both a training period (Jan. 1, 2001 Nov. 30,
2014) and a live trading period (Dec. 1, 2014 Jan.
31, 2015). Trading systems are ranked using the min-
imum of the performance over these two intervals,
and the top three performing strategies (determined
January 31, 2015) will receive guaranteed minimum

investments ($250,000 for third place, $500,000 for
second, and $1,000,000 for ﬁrst).

The Trading Model

The trading model employed by Quantiacs is somewhat
simpliﬁed relative to a real-world trading scenario. In
particular, the daily closing price is what is used to
determine the buying/selling price when orders are
placed on a given day, and orders may only be placed
once per day. However, the model does include small
fees meant to simulate the eﬀects of slippage and trad-
ing commissions, and so may oﬀer a relatively realistic
trading simulation for relatively long term investment
strategies (where trades are being performed on a daily
basis, as opposed to high frequency approaches with
many trades being performed each second).

The Data

The backtesting data for the contest consisted of ap-
proximately 3800 days of trading price and volume
data (from Jan. 1, 2001 to the present day) provided
by Quantiacs for 27 diﬀerent futures contracts (includ-
ing various currencies, precious metals, agricultural
products, etc.). More speciﬁcally, the data contained
the daily high, low, opening, and closing prices, and
daily trading volumes over this time period. In addi-
tion, the rules of the competition speciﬁed that on any
given day, the only legal input into the trading strat-
egy was the previous 504 trading days worth of this
data for each of the 27 securities under consideration.

The Objective

As mentioned above, the goal in the Quantiacs futures
competition is to obtain a trading strategy with opti-

Page 1 of 5

Algorithmic Trading of Futures via
Machine Learning

David Montague, davmont@stanford.edu

Algorithmic trading of securities has become

a staple of modern approaches to ﬁnancial
investment. In this project, I attempt to
obtain an eﬀective strategy for trading a collec-
tion of 27 ﬁnancial futures based solely on their
past trading data. All of the strategies that I con-
sider are based on predictions of the future price
and volatility of the various securities under con-
sideration, and so the majority of the eﬀort in
this project has been directed toward using ma-
chine learning techniques to obtain predictions
for future price and volatility. This project was
inspired by the Quantiacs futures competition,
to which I submitted a number of the trading
strategies I obtained during my work on this
project.

Introduction

The Contest

The goal of this project was to obtain a high-
performing trading strategy for the Quantiacs futures
contest [1]. Quantiacs is a quantitative trading plat-
form that invests in crowdsourced trading systems,
and connects users trading systems with institutional
investors, [sharing] a performance fee with the devel-
oper. The Quantiacs futures contest was a competition
to obtain a trading strategy which invests in a collec-
tion of futures securities and attempts to maximize
the Sharpe ratio (a measure of risk-adjusted return)
over both a training period (Jan. 1, 2001 Nov. 30,
2014) and a live trading period (Dec. 1, 2014 Jan.
31, 2015). Trading systems are ranked using the min-
imum of the performance over these two intervals,
and the top three performing strategies (determined
January 31, 2015) will receive guaranteed minimum

investments ($250,000 for third place, $500,000 for
second, and $1,000,000 for ﬁrst).

The Trading Model

The trading model employed by Quantiacs is somewhat
simpliﬁed relative to a real-world trading scenario. In
particular, the daily closing price is what is used to
determine the buying/selling price when orders are
placed on a given day, and orders may only be placed
once per day. However, the model does include small
fees meant to simulate the eﬀects of slippage and trad-
ing commissions, and so may oﬀer a relatively realistic
trading simulation for relatively long term investment
strategies (where trades are being performed on a daily
basis, as opposed to high frequency approaches with
many trades being performed each second).

The Data

The backtesting data for the contest consisted of ap-
proximately 3800 days of trading price and volume
data (from Jan. 1, 2001 to the present day) provided
by Quantiacs for 27 diﬀerent futures contracts (includ-
ing various currencies, precious metals, agricultural
products, etc.). More speciﬁcally, the data contained
the daily high, low, opening, and closing prices, and
daily trading volumes over this time period. In addi-
tion, the rules of the competition speciﬁed that on any
given day, the only legal input into the trading strat-
egy was the previous 504 trading days worth of this
data for each of the 27 securities under consideration.

The Objective

As mentioned above, the goal in the Quantiacs futures
competition is to obtain a trading strategy with opti-

Page 1 of 5

mal performance as measured by the strategy’s Sharpe
ratio. The Sharpe ratio is determined by the ratio of
average return to average volatility. More speciﬁcally,
the Sharpe ratio is computed as follows: Let (ej)n
j=0 be
the set of equity values of our portfolio over a period
of n trading days (starting with value e0). Deﬁne a
vector of daily (percent) returns (dj)n

j=1 by

dj =

ej − ej−1

ej−1

,

and compute the average daily and yearly return (using
the fact that there are 252 trading days in a calendar
year) by

(cid:19)1/n − 1,

(cid:18) en

e0

 n(cid:89)

j=1

1/n

rdaily =

1 + dj

− 1 =

ryearly = (1 + rdaily)252 − 1.

Next, compute the volatility by the formula

voladaily = StDev({d1, ..., dn}),

and estimate yearly volatility from this by assuming
that daily volatility is independent, obtaining

√

volayearly =

252voladaily.

Finally, deﬁne the Sharpe ratio by

Sharpe(e) =

ryearly

volayearly

.

The various entries in the Quantiacs futures compe-
tition are ranked in ascending order according to the
minimum of their Sharpe ratio over the evaluation
period (Jan. 1, 2001 to Nov. 30, 2014) and their
Sharpe ratio over the live trading period (Dec. 1, 2014
to Jan. 31, 2015). Thus, it is important to obtain a
strategy which both performs well on the backtesting
data from the past, and which also generalizes well to
live trading data.

Supervised Learning Problems

One of the guiding principles behind my approach to
the contest was that accurate oredictions of the return
and volatility for each of the individual futures were
suﬃcient inputs to obtain an eﬀective trading algo-
rithm (where eﬀectiveness is measured by the Sharpe
ratio obtained). I also made the implicit assumption
that the various securities could be analyzed indepen-
dently, so that predictions for a given security’s future

return and volatility need only depend on that par-
ticular security’s past performance. In reality, it is
certainly not the case that the returns of the various
securities behave independently, but I still believe this
is a reasonable simplifying assumption for a prediction
model.

Based on the above, I decided to attempt to predict
the future return and volatility of each of the futures
independently based on its past performance.

Training Examples

On each trading day, the trading strategy is allowed
to use as input the past 504 days worth of trading
data for each future. In order to reduce the redun-
dancy of my set of training examples, I downsample
the trading days, generating a new training example
only once every ﬁve trading days for each security.
Because of my assumption that each of the futures
behaves independently, I obtained one training exam-
ple for each security and each downsampled trading
day for which data was available suﬃciently far into
the future (so that future return and volatility could
be computed). The raw training feature vector is
the 2,520-dimensional vector of the past 504 days of
daily high, low, closing, and opening prices and trad-
ing volumes, but signiﬁcant dimensionality reduction
was performed in order to make the problem more
tractable.

Learning Objectives

While I have deﬁned the Sharpe ratio for the portfolio
as a whole, the deﬁnition can also be readily applied
to individual securities, and provides some guidance
on how to choose return and volatility prediction ob-
jectives. In particular, inspired by the deﬁnition of the
Sharpe ratio, I chose to use the following two super-
vised learning objectives for the return and volatility
prediction respectively:

• For return prediction, I consider a one-parameter
family of objective functions. As shown above,
the quantity rdaily can be computed directly from
the quantity en/e0, the performance of a given
future over n trading days (here e represents the
price of the speciﬁc futures contract). Therefore,
I use Rn := en/e0, the percent increase in price
n days in the future, as the prediction objective.
Here n is a freely chosen parameter, and after
some experimentation I settled on the choice n =
20, although given more time a more principled
approach to the selection of this parameter may
be merited.

Page 2 of 5

Algorithmic Trading of Futures via
Machine Learning

David Montague, davmont@stanford.edu

Algorithmic trading of securities has become

a staple of modern approaches to ﬁnancial
investment. In this project, I attempt to
obtain an eﬀective strategy for trading a collec-
tion of 27 ﬁnancial futures based solely on their
past trading data. All of the strategies that I con-
sider are based on predictions of the future price
and volatility of the various securities under con-
sideration, and so the majority of the eﬀort in
this project has been directed toward using ma-
chine learning techniques to obtain predictions
for future price and volatility. This project was
inspired by the Quantiacs futures competition,
to which I submitted a number of the trading
strategies I obtained during my work on this
project.

Introduction

The Contest

The goal of this project was to obtain a high-
performing trading strategy for the Quantiacs futures
contest [1]. Quantiacs is a quantitative trading plat-
form that invests in crowdsourced trading systems,
and connects users trading systems with institutional
investors, [sharing] a performance fee with the devel-
oper. The Quantiacs futures contest was a competition
to obtain a trading strategy which invests in a collec-
tion of futures securities and attempts to maximize
the Sharpe ratio (a measure of risk-adjusted return)
over both a training period (Jan. 1, 2001 Nov. 30,
2014) and a live trading period (Dec. 1, 2014 Jan.
31, 2015). Trading systems are ranked using the min-
imum of the performance over these two intervals,
and the top three performing strategies (determined
January 31, 2015) will receive guaranteed minimum

investments ($250,000 for third place, $500,000 for
second, and $1,000,000 for ﬁrst).

The Trading Model

The trading model employed by Quantiacs is somewhat
simpliﬁed relative to a real-world trading scenario. In
particular, the daily closing price is what is used to
determine the buying/selling price when orders are
placed on a given day, and orders may only be placed
once per day. However, the model does include small
fees meant to simulate the eﬀects of slippage and trad-
ing commissions, and so may oﬀer a relatively realistic
trading simulation for relatively long term investment
strategies (where trades are being performed on a daily
basis, as opposed to high frequency approaches with
many trades being performed each second).

The Data

The backtesting data for the contest consisted of ap-
proximately 3800 days of trading price and volume
data (from Jan. 1, 2001 to the present day) provided
by Quantiacs for 27 diﬀerent futures contracts (includ-
ing various currencies, precious metals, agricultural
products, etc.). More speciﬁcally, the data contained
the daily high, low, opening, and closing prices, and
daily trading volumes over this time period. In addi-
tion, the rules of the competition speciﬁed that on any
given day, the only legal input into the trading strat-
egy was the previous 504 trading days worth of this
data for each of the 27 securities under consideration.

The Objective

As mentioned above, the goal in the Quantiacs futures
competition is to obtain a trading strategy with opti-

Page 1 of 5

mal performance as measured by the strategy’s Sharpe
ratio. The Sharpe ratio is determined by the ratio of
average return to average volatility. More speciﬁcally,
the Sharpe ratio is computed as follows: Let (ej)n
j=0 be
the set of equity values of our portfolio over a period
of n trading days (starting with value e0). Deﬁne a
vector of daily (percent) returns (dj)n

j=1 by

dj =

ej − ej−1

ej−1

,

and compute the average daily and yearly return (using
the fact that there are 252 trading days in a calendar
year) by

(cid:19)1/n − 1,

(cid:18) en

e0

 n(cid:89)

j=1

1/n

rdaily =

1 + dj

− 1 =

ryearly = (1 + rdaily)252 − 1.

Next, compute the volatility by the formula

voladaily = StDev({d1, ..., dn}),

and estimate yearly volatility from this by assuming
that daily volatility is independent, obtaining

√

volayearly =

252voladaily.

Finally, deﬁne the Sharpe ratio by

Sharpe(e) =

ryearly

volayearly

.

The various entries in the Quantiacs futures compe-
tition are ranked in ascending order according to the
minimum of their Sharpe ratio over the evaluation
period (Jan. 1, 2001 to Nov. 30, 2014) and their
Sharpe ratio over the live trading period (Dec. 1, 2014
to Jan. 31, 2015). Thus, it is important to obtain a
strategy which both performs well on the backtesting
data from the past, and which also generalizes well to
live trading data.

Supervised Learning Problems

One of the guiding principles behind my approach to
the contest was that accurate oredictions of the return
and volatility for each of the individual futures were
suﬃcient inputs to obtain an eﬀective trading algo-
rithm (where eﬀectiveness is measured by the Sharpe
ratio obtained). I also made the implicit assumption
that the various securities could be analyzed indepen-
dently, so that predictions for a given security’s future

return and volatility need only depend on that par-
ticular security’s past performance. In reality, it is
certainly not the case that the returns of the various
securities behave independently, but I still believe this
is a reasonable simplifying assumption for a prediction
model.

Based on the above, I decided to attempt to predict
the future return and volatility of each of the futures
independently based on its past performance.

Training Examples

On each trading day, the trading strategy is allowed
to use as input the past 504 days worth of trading
data for each future. In order to reduce the redun-
dancy of my set of training examples, I downsample
the trading days, generating a new training example
only once every ﬁve trading days for each security.
Because of my assumption that each of the futures
behaves independently, I obtained one training exam-
ple for each security and each downsampled trading
day for which data was available suﬃciently far into
the future (so that future return and volatility could
be computed). The raw training feature vector is
the 2,520-dimensional vector of the past 504 days of
daily high, low, closing, and opening prices and trad-
ing volumes, but signiﬁcant dimensionality reduction
was performed in order to make the problem more
tractable.

Learning Objectives

While I have deﬁned the Sharpe ratio for the portfolio
as a whole, the deﬁnition can also be readily applied
to individual securities, and provides some guidance
on how to choose return and volatility prediction ob-
jectives. In particular, inspired by the deﬁnition of the
Sharpe ratio, I chose to use the following two super-
vised learning objectives for the return and volatility
prediction respectively:

• For return prediction, I consider a one-parameter
family of objective functions. As shown above,
the quantity rdaily can be computed directly from
the quantity en/e0, the performance of a given
future over n trading days (here e represents the
price of the speciﬁc futures contract). Therefore,
I use Rn := en/e0, the percent increase in price
n days in the future, as the prediction objective.
Here n is a freely chosen parameter, and after
some experimentation I settled on the choice n =
20, although given more time a more principled
approach to the selection of this parameter may
be merited.

Page 2 of 5

• For volatility, I take an approach similar to re-
turn, using the quantity used to measure volatil-
ity when computing the Sharpe ratio as the
volatility prediction. More speciﬁcally, I use
Vn := voladaily := StDev({d1, ..., dn}) as the one-
parameter family of objective functions (where dj
is deﬁned the same as it was for the Sharpe ratio).
Also, I again made the (unprincipled) parameter
choice of n = 20.

Formulation of the problems

Let xik represent the feature vector on day i for fu-
tures contract k, and let Rn(i, k) be the value of Rn
(the percent change in price n days in the future) for
security k starting on day i, and deﬁne Vn(i, k) sim-
ilarly. To obtain return and volatility predictions, I
applied a variety of machine learning algorithms to
obtain prediction functions R∗ and V ∗ which attempt
to minimize the mean squared error, i.e., minimize the

(cid:88)
quantities(cid:88)
(cid:88)
(cid:88)

k

i

(R∗(xik) − Rn(i, k))2, and

(V ∗(xik) − Vn(i, k))2

i

k

respectively.

Features

As noted above, the raw feature vector is 2,520-
dimensional, which is far too large for eﬀective use of
most machine learning algorithms (especially consid-
ering that I only have approximately 12,000 training
examples). As a result, it is necessary to use a modi-
ﬁed, lower-dimensional feature vector. I consider two
distinct approaches to feature selection:

1. I applied PCA to a normalization of a 250-
dimensional time-downsampled subvector of the
original feature vector, obtained by taking the
values of each of the ﬁve types of variable every 3
days for the past 150, and dividing it by the cur-
rent day’s value. I decided on the speciﬁc number
of principal components to use by cross-validation
(I go into more detail in the results section).

2. I also generated a vector of 18 standard technical
indicators used by professional ﬁnancial analysts
(normalizing them appropriately for comparison
between securities). The technical indicators I
used consisted of the Average True Range (ATR)
computed over 14 and 45 trading days; the ratio
of the Exponential Moving Average over 12, 26,

and 50 trading days to the Exponential Moving
Average over 100 trading days; the On Balance
Volume indicator over 5, 15, and 60 days; the Per-
centage Price Oscillator (PPO); the Percentage
Volume Oscillator (PVO); the Rate of Change
(ROC) over 5, 21, and 125 days; the ratio of the
Simple Moving Average (SMA) over 100 days to
the SMA over 200 days, the Relative Strength In-
dex (RSI) over 14 days, and William %R over 14,
45, and 125 days. Deﬁnitions of these indicators
may be found in [2].

Results

For both volatility and return prediction, I consid-
ered four regression algorithms: linear and regularized
(ridge) linear regression (implemented myself); Neu-
ral Networks (using the MATLAB Neural Network
toolbox); Random Forests (using the MATLAB Tree-
Bagger function); and gradient-boosted decision trees
(using the R package GBM).

As I show below, the volatility prediction problem
was signiﬁcantly more tractable than the problem of
return prediction, so I began by performing feature
selection on the volatility prediction problem, and used
the results of that for the return prediction problem.
For both problems, I used a training set consisting
of 9424 examples (80% of the data), and a test set
consisting of 2356 examples (20% of the data). The
training vs. test division was chronological, so that the
training examples consisted of the initial 80% of the
data, and the test examples consisted of the ﬁnal 20%
(it is important to segregate the data by time period
since the performance of the various futures is not
independent over the same time period). In addition,
wherever I refer to cross-validation, I performed 10-
fold cross-validation on the initial 80% of the data (the
training data set), where each of the cross-validation
folds was chosen to be a contiguous time block.

Volatility Prediction

Before comparing the performance of the various ma-
chine learning algorithms, I performed feature selection
using linear regression. The results are contained in
the following table:

Features Training r2 CV r2 Test r2
0.473
PCA (82)
0.637
0.639

0.490
0.645
0.647

0.631
0.710
0.713

TI (18)
TI (7)

Here PCA stands for principal components analy-
sis, and TI for technical indicators. The number in

Page 3 of 5

Algorithmic Trading of Futures via
Machine Learning

David Montague, davmont@stanford.edu

Algorithmic trading of securities has become

a staple of modern approaches to ﬁnancial
investment. In this project, I attempt to
obtain an eﬀective strategy for trading a collec-
tion of 27 ﬁnancial futures based solely on their
past trading data. All of the strategies that I con-
sider are based on predictions of the future price
and volatility of the various securities under con-
sideration, and so the majority of the eﬀort in
this project has been directed toward using ma-
chine learning techniques to obtain predictions
for future price and volatility. This project was
inspired by the Quantiacs futures competition,
to which I submitted a number of the trading
strategies I obtained during my work on this
project.

Introduction

The Contest

The goal of this project was to obtain a high-
performing trading strategy for the Quantiacs futures
contest [1]. Quantiacs is a quantitative trading plat-
form that invests in crowdsourced trading systems,
and connects users trading systems with institutional
investors, [sharing] a performance fee with the devel-
oper. The Quantiacs futures contest was a competition
to obtain a trading strategy which invests in a collec-
tion of futures securities and attempts to maximize
the Sharpe ratio (a measure of risk-adjusted return)
over both a training period (Jan. 1, 2001 Nov. 30,
2014) and a live trading period (Dec. 1, 2014 Jan.
31, 2015). Trading systems are ranked using the min-
imum of the performance over these two intervals,
and the top three performing strategies (determined
January 31, 2015) will receive guaranteed minimum

investments ($250,000 for third place, $500,000 for
second, and $1,000,000 for ﬁrst).

The Trading Model

The trading model employed by Quantiacs is somewhat
simpliﬁed relative to a real-world trading scenario. In
particular, the daily closing price is what is used to
determine the buying/selling price when orders are
placed on a given day, and orders may only be placed
once per day. However, the model does include small
fees meant to simulate the eﬀects of slippage and trad-
ing commissions, and so may oﬀer a relatively realistic
trading simulation for relatively long term investment
strategies (where trades are being performed on a daily
basis, as opposed to high frequency approaches with
many trades being performed each second).

The Data

The backtesting data for the contest consisted of ap-
proximately 3800 days of trading price and volume
data (from Jan. 1, 2001 to the present day) provided
by Quantiacs for 27 diﬀerent futures contracts (includ-
ing various currencies, precious metals, agricultural
products, etc.). More speciﬁcally, the data contained
the daily high, low, opening, and closing prices, and
daily trading volumes over this time period. In addi-
tion, the rules of the competition speciﬁed that on any
given day, the only legal input into the trading strat-
egy was the previous 504 trading days worth of this
data for each of the 27 securities under consideration.

The Objective

As mentioned above, the goal in the Quantiacs futures
competition is to obtain a trading strategy with opti-

Page 1 of 5

mal performance as measured by the strategy’s Sharpe
ratio. The Sharpe ratio is determined by the ratio of
average return to average volatility. More speciﬁcally,
the Sharpe ratio is computed as follows: Let (ej)n
j=0 be
the set of equity values of our portfolio over a period
of n trading days (starting with value e0). Deﬁne a
vector of daily (percent) returns (dj)n

j=1 by

dj =

ej − ej−1

ej−1

,

and compute the average daily and yearly return (using
the fact that there are 252 trading days in a calendar
year) by

(cid:19)1/n − 1,

(cid:18) en

e0

 n(cid:89)

j=1

1/n

rdaily =

1 + dj

− 1 =

ryearly = (1 + rdaily)252 − 1.

Next, compute the volatility by the formula

voladaily = StDev({d1, ..., dn}),

and estimate yearly volatility from this by assuming
that daily volatility is independent, obtaining

√

volayearly =

252voladaily.

Finally, deﬁne the Sharpe ratio by

Sharpe(e) =

ryearly

volayearly

.

The various entries in the Quantiacs futures compe-
tition are ranked in ascending order according to the
minimum of their Sharpe ratio over the evaluation
period (Jan. 1, 2001 to Nov. 30, 2014) and their
Sharpe ratio over the live trading period (Dec. 1, 2014
to Jan. 31, 2015). Thus, it is important to obtain a
strategy which both performs well on the backtesting
data from the past, and which also generalizes well to
live trading data.

Supervised Learning Problems

One of the guiding principles behind my approach to
the contest was that accurate oredictions of the return
and volatility for each of the individual futures were
suﬃcient inputs to obtain an eﬀective trading algo-
rithm (where eﬀectiveness is measured by the Sharpe
ratio obtained). I also made the implicit assumption
that the various securities could be analyzed indepen-
dently, so that predictions for a given security’s future

return and volatility need only depend on that par-
ticular security’s past performance. In reality, it is
certainly not the case that the returns of the various
securities behave independently, but I still believe this
is a reasonable simplifying assumption for a prediction
model.

Based on the above, I decided to attempt to predict
the future return and volatility of each of the futures
independently based on its past performance.

Training Examples

On each trading day, the trading strategy is allowed
to use as input the past 504 days worth of trading
data for each future. In order to reduce the redun-
dancy of my set of training examples, I downsample
the trading days, generating a new training example
only once every ﬁve trading days for each security.
Because of my assumption that each of the futures
behaves independently, I obtained one training exam-
ple for each security and each downsampled trading
day for which data was available suﬃciently far into
the future (so that future return and volatility could
be computed). The raw training feature vector is
the 2,520-dimensional vector of the past 504 days of
daily high, low, closing, and opening prices and trad-
ing volumes, but signiﬁcant dimensionality reduction
was performed in order to make the problem more
tractable.

Learning Objectives

While I have deﬁned the Sharpe ratio for the portfolio
as a whole, the deﬁnition can also be readily applied
to individual securities, and provides some guidance
on how to choose return and volatility prediction ob-
jectives. In particular, inspired by the deﬁnition of the
Sharpe ratio, I chose to use the following two super-
vised learning objectives for the return and volatility
prediction respectively:

• For return prediction, I consider a one-parameter
family of objective functions. As shown above,
the quantity rdaily can be computed directly from
the quantity en/e0, the performance of a given
future over n trading days (here e represents the
price of the speciﬁc futures contract). Therefore,
I use Rn := en/e0, the percent increase in price
n days in the future, as the prediction objective.
Here n is a freely chosen parameter, and after
some experimentation I settled on the choice n =
20, although given more time a more principled
approach to the selection of this parameter may
be merited.

Page 2 of 5

• For volatility, I take an approach similar to re-
turn, using the quantity used to measure volatil-
ity when computing the Sharpe ratio as the
volatility prediction. More speciﬁcally, I use
Vn := voladaily := StDev({d1, ..., dn}) as the one-
parameter family of objective functions (where dj
is deﬁned the same as it was for the Sharpe ratio).
Also, I again made the (unprincipled) parameter
choice of n = 20.

Formulation of the problems

Let xik represent the feature vector on day i for fu-
tures contract k, and let Rn(i, k) be the value of Rn
(the percent change in price n days in the future) for
security k starting on day i, and deﬁne Vn(i, k) sim-
ilarly. To obtain return and volatility predictions, I
applied a variety of machine learning algorithms to
obtain prediction functions R∗ and V ∗ which attempt
to minimize the mean squared error, i.e., minimize the

(cid:88)
quantities(cid:88)
(cid:88)
(cid:88)

k

i

(R∗(xik) − Rn(i, k))2, and

(V ∗(xik) − Vn(i, k))2

i

k

respectively.

Features

As noted above, the raw feature vector is 2,520-
dimensional, which is far too large for eﬀective use of
most machine learning algorithms (especially consid-
ering that I only have approximately 12,000 training
examples). As a result, it is necessary to use a modi-
ﬁed, lower-dimensional feature vector. I consider two
distinct approaches to feature selection:

1. I applied PCA to a normalization of a 250-
dimensional time-downsampled subvector of the
original feature vector, obtained by taking the
values of each of the ﬁve types of variable every 3
days for the past 150, and dividing it by the cur-
rent day’s value. I decided on the speciﬁc number
of principal components to use by cross-validation
(I go into more detail in the results section).

2. I also generated a vector of 18 standard technical
indicators used by professional ﬁnancial analysts
(normalizing them appropriately for comparison
between securities). The technical indicators I
used consisted of the Average True Range (ATR)
computed over 14 and 45 trading days; the ratio
of the Exponential Moving Average over 12, 26,

and 50 trading days to the Exponential Moving
Average over 100 trading days; the On Balance
Volume indicator over 5, 15, and 60 days; the Per-
centage Price Oscillator (PPO); the Percentage
Volume Oscillator (PVO); the Rate of Change
(ROC) over 5, 21, and 125 days; the ratio of the
Simple Moving Average (SMA) over 100 days to
the SMA over 200 days, the Relative Strength In-
dex (RSI) over 14 days, and William %R over 14,
45, and 125 days. Deﬁnitions of these indicators
may be found in [2].

Results

For both volatility and return prediction, I consid-
ered four regression algorithms: linear and regularized
(ridge) linear regression (implemented myself); Neu-
ral Networks (using the MATLAB Neural Network
toolbox); Random Forests (using the MATLAB Tree-
Bagger function); and gradient-boosted decision trees
(using the R package GBM).

As I show below, the volatility prediction problem
was signiﬁcantly more tractable than the problem of
return prediction, so I began by performing feature
selection on the volatility prediction problem, and used
the results of that for the return prediction problem.
For both problems, I used a training set consisting
of 9424 examples (80% of the data), and a test set
consisting of 2356 examples (20% of the data). The
training vs. test division was chronological, so that the
training examples consisted of the initial 80% of the
data, and the test examples consisted of the ﬁnal 20%
(it is important to segregate the data by time period
since the performance of the various futures is not
independent over the same time period). In addition,
wherever I refer to cross-validation, I performed 10-
fold cross-validation on the initial 80% of the data (the
training data set), where each of the cross-validation
folds was chosen to be a contiguous time block.

Volatility Prediction

Before comparing the performance of the various ma-
chine learning algorithms, I performed feature selection
using linear regression. The results are contained in
the following table:

Features Training r2 CV r2 Test r2
0.473
PCA (82)
0.637
0.639

0.490
0.645
0.647

0.631
0.710
0.713

TI (18)
TI (7)

Here PCA stands for principal components analy-
sis, and TI for technical indicators. The number in

Page 3 of 5

parentheses is the dimension of the feature vector.

After performing principal components analysis on
the 250-dimensional subsampled and normalized fea-
ture vector, I obtained through cross-validation an op-
timal number of principal components of 82, but even
after choosing this optimal number of principal compo-
nents, linear regression using the 18-dimensional fea-
ture vector of all technical indicators performed much
better, and greedy backward-elimination allowed me
to obtain a subset of seven of the technical indicators
which also gave some small improvements.

I interpreted the results of this feature selection
procedure as signifying that the 18-dimensional fea-
ture vector of technical indicators had much greater
explanatory power of the futures’ behavior, and so
decided to use these features when comparing the var-
ious machine learning algorithms’ performance when
predicting both volatility and return.

The following table contains the performance re-
sults for the various algorithms for volatility predic-
tion, using only the seven features remaining after
backwards-elimination during the variable selection
process.

Algorithm Training r2 CV r2 Test r2
0.639
0.632
0.649
0.638

0.647
0.660
0.664
0.666

0.713
0.734
0.731
0.701

LR
NN
RF

GBM

Here LR refers to linear regression, NN to neural
networks, RF to random forests, and GBM to the
gradient boosted decision trees.

Note that although I only report the r2 values, rather
than the MSE, the two are related in such a way
that a higher r2 corresponds precisely to a smaller
MSE, so that considering the r2 value is suﬃcient to
analyze algorithm performance. Considering both the
performance on the cross-validation and the test data
set, the Random Forest model seemed to oﬀer the
best performance, though this performance was only
marginally better than the linear regression model.

Return Prediction

The following table contains the results of using the
various algorithms to predict return performance using
the 18 technical indicators as the feature vector:

Algorithm Training r CV r Test r
0.138
-0.088
-0.102
0.028

0.169
0.088
0.236
0.328

0.142
0.013
0.069
0.154

RR
NN
RF

GBM

Figure 1: Performance of grid-search optimized strategy.

Here the algorithm acronyms represent the same
things, except that RR here represents ridge regres-
sion, which oﬀered some small improvements here over
ordinary least squares linear regression.

Unsurprisingly, return prediction is much more chal-
lenging than volatility prediction – note that we have
reported values of r, rather than r2 in the table above.
However, as I attempt to demonstrate later in the
section on theoretical algorithm performance, even
predictions with a relatively low value of r can gener-
ate surprisingly eﬀective trading algorithms as long as
there is some correlation.

Unfortunately, only gradient-boosted decision trees
performed comparably to ridge regression in cross-
validation, and none of the algorithms performed close
to as well as ridge regression on the test set, with Ran-
dom Forests and Neural Networks in fact performing
worse than using the mean for prediction. As a result,
I used the ridge regression predictions in my trading
algorithms, but I still believe there is signiﬁcant poten-
tial for improvements in these predictions, and I think
such improvements are one of the primary ways that
I could improve my trading algorithm performance.

Trading Algorithms

Description of algorithms

To make use of the volatility and return predictions, I
created a 3-parameter trading algorithm which weights
the predicted returns by a power of the predicted
volatility, and uses this as the desired portfolio dis-
tribution. The chart below plots the performance of
this strategy for one speciﬁc choice of these three pa-
rameters, chosen by grid search to obtain the optimal
Sharpe ratio.

Figure 1 shows the performance of this optimal

Page 4 of 5

Algorithmic Trading of Futures via
Machine Learning

David Montague, davmont@stanford.edu

Algorithmic trading of securities has become

a staple of modern approaches to ﬁnancial
investment. In this project, I attempt to
obtain an eﬀective strategy for trading a collec-
tion of 27 ﬁnancial futures based solely on their
past trading data. All of the strategies that I con-
sider are based on predictions of the future price
and volatility of the various securities under con-
sideration, and so the majority of the eﬀort in
this project has been directed toward using ma-
chine learning techniques to obtain predictions
for future price and volatility. This project was
inspired by the Quantiacs futures competition,
to which I submitted a number of the trading
strategies I obtained during my work on this
project.

Introduction

The Contest

The goal of this project was to obtain a high-
performing trading strategy for the Quantiacs futures
contest [1]. Quantiacs is a quantitative trading plat-
form that invests in crowdsourced trading systems,
and connects users trading systems with institutional
investors, [sharing] a performance fee with the devel-
oper. The Quantiacs futures contest was a competition
to obtain a trading strategy which invests in a collec-
tion of futures securities and attempts to maximize
the Sharpe ratio (a measure of risk-adjusted return)
over both a training period (Jan. 1, 2001 Nov. 30,
2014) and a live trading period (Dec. 1, 2014 Jan.
31, 2015). Trading systems are ranked using the min-
imum of the performance over these two intervals,
and the top three performing strategies (determined
January 31, 2015) will receive guaranteed minimum

investments ($250,000 for third place, $500,000 for
second, and $1,000,000 for ﬁrst).

The Trading Model

The trading model employed by Quantiacs is somewhat
simpliﬁed relative to a real-world trading scenario. In
particular, the daily closing price is what is used to
determine the buying/selling price when orders are
placed on a given day, and orders may only be placed
once per day. However, the model does include small
fees meant to simulate the eﬀects of slippage and trad-
ing commissions, and so may oﬀer a relatively realistic
trading simulation for relatively long term investment
strategies (where trades are being performed on a daily
basis, as opposed to high frequency approaches with
many trades being performed each second).

The Data

The backtesting data for the contest consisted of ap-
proximately 3800 days of trading price and volume
data (from Jan. 1, 2001 to the present day) provided
by Quantiacs for 27 diﬀerent futures contracts (includ-
ing various currencies, precious metals, agricultural
products, etc.). More speciﬁcally, the data contained
the daily high, low, opening, and closing prices, and
daily trading volumes over this time period. In addi-
tion, the rules of the competition speciﬁed that on any
given day, the only legal input into the trading strat-
egy was the previous 504 trading days worth of this
data for each of the 27 securities under consideration.

The Objective

As mentioned above, the goal in the Quantiacs futures
competition is to obtain a trading strategy with opti-

Page 1 of 5

mal performance as measured by the strategy’s Sharpe
ratio. The Sharpe ratio is determined by the ratio of
average return to average volatility. More speciﬁcally,
the Sharpe ratio is computed as follows: Let (ej)n
j=0 be
the set of equity values of our portfolio over a period
of n trading days (starting with value e0). Deﬁne a
vector of daily (percent) returns (dj)n

j=1 by

dj =

ej − ej−1

ej−1

,

and compute the average daily and yearly return (using
the fact that there are 252 trading days in a calendar
year) by

(cid:19)1/n − 1,

(cid:18) en

e0

 n(cid:89)

j=1

1/n

rdaily =

1 + dj

− 1 =

ryearly = (1 + rdaily)252 − 1.

Next, compute the volatility by the formula

voladaily = StDev({d1, ..., dn}),

and estimate yearly volatility from this by assuming
that daily volatility is independent, obtaining

√

volayearly =

252voladaily.

Finally, deﬁne the Sharpe ratio by

Sharpe(e) =

ryearly

volayearly

.

The various entries in the Quantiacs futures compe-
tition are ranked in ascending order according to the
minimum of their Sharpe ratio over the evaluation
period (Jan. 1, 2001 to Nov. 30, 2014) and their
Sharpe ratio over the live trading period (Dec. 1, 2014
to Jan. 31, 2015). Thus, it is important to obtain a
strategy which both performs well on the backtesting
data from the past, and which also generalizes well to
live trading data.

Supervised Learning Problems

One of the guiding principles behind my approach to
the contest was that accurate oredictions of the return
and volatility for each of the individual futures were
suﬃcient inputs to obtain an eﬀective trading algo-
rithm (where eﬀectiveness is measured by the Sharpe
ratio obtained). I also made the implicit assumption
that the various securities could be analyzed indepen-
dently, so that predictions for a given security’s future

return and volatility need only depend on that par-
ticular security’s past performance. In reality, it is
certainly not the case that the returns of the various
securities behave independently, but I still believe this
is a reasonable simplifying assumption for a prediction
model.

Based on the above, I decided to attempt to predict
the future return and volatility of each of the futures
independently based on its past performance.

Training Examples

On each trading day, the trading strategy is allowed
to use as input the past 504 days worth of trading
data for each future. In order to reduce the redun-
dancy of my set of training examples, I downsample
the trading days, generating a new training example
only once every ﬁve trading days for each security.
Because of my assumption that each of the futures
behaves independently, I obtained one training exam-
ple for each security and each downsampled trading
day for which data was available suﬃciently far into
the future (so that future return and volatility could
be computed). The raw training feature vector is
the 2,520-dimensional vector of the past 504 days of
daily high, low, closing, and opening prices and trad-
ing volumes, but signiﬁcant dimensionality reduction
was performed in order to make the problem more
tractable.

Learning Objectives

While I have deﬁned the Sharpe ratio for the portfolio
as a whole, the deﬁnition can also be readily applied
to individual securities, and provides some guidance
on how to choose return and volatility prediction ob-
jectives. In particular, inspired by the deﬁnition of the
Sharpe ratio, I chose to use the following two super-
vised learning objectives for the return and volatility
prediction respectively:

• For return prediction, I consider a one-parameter
family of objective functions. As shown above,
the quantity rdaily can be computed directly from
the quantity en/e0, the performance of a given
future over n trading days (here e represents the
price of the speciﬁc futures contract). Therefore,
I use Rn := en/e0, the percent increase in price
n days in the future, as the prediction objective.
Here n is a freely chosen parameter, and after
some experimentation I settled on the choice n =
20, although given more time a more principled
approach to the selection of this parameter may
be merited.

Page 2 of 5

• For volatility, I take an approach similar to re-
turn, using the quantity used to measure volatil-
ity when computing the Sharpe ratio as the
volatility prediction. More speciﬁcally, I use
Vn := voladaily := StDev({d1, ..., dn}) as the one-
parameter family of objective functions (where dj
is deﬁned the same as it was for the Sharpe ratio).
Also, I again made the (unprincipled) parameter
choice of n = 20.

Formulation of the problems

Let xik represent the feature vector on day i for fu-
tures contract k, and let Rn(i, k) be the value of Rn
(the percent change in price n days in the future) for
security k starting on day i, and deﬁne Vn(i, k) sim-
ilarly. To obtain return and volatility predictions, I
applied a variety of machine learning algorithms to
obtain prediction functions R∗ and V ∗ which attempt
to minimize the mean squared error, i.e., minimize the

(cid:88)
quantities(cid:88)
(cid:88)
(cid:88)

k

i

(R∗(xik) − Rn(i, k))2, and

(V ∗(xik) − Vn(i, k))2

i

k

respectively.

Features

As noted above, the raw feature vector is 2,520-
dimensional, which is far too large for eﬀective use of
most machine learning algorithms (especially consid-
ering that I only have approximately 12,000 training
examples). As a result, it is necessary to use a modi-
ﬁed, lower-dimensional feature vector. I consider two
distinct approaches to feature selection:

1. I applied PCA to a normalization of a 250-
dimensional time-downsampled subvector of the
original feature vector, obtained by taking the
values of each of the ﬁve types of variable every 3
days for the past 150, and dividing it by the cur-
rent day’s value. I decided on the speciﬁc number
of principal components to use by cross-validation
(I go into more detail in the results section).

2. I also generated a vector of 18 standard technical
indicators used by professional ﬁnancial analysts
(normalizing them appropriately for comparison
between securities). The technical indicators I
used consisted of the Average True Range (ATR)
computed over 14 and 45 trading days; the ratio
of the Exponential Moving Average over 12, 26,

and 50 trading days to the Exponential Moving
Average over 100 trading days; the On Balance
Volume indicator over 5, 15, and 60 days; the Per-
centage Price Oscillator (PPO); the Percentage
Volume Oscillator (PVO); the Rate of Change
(ROC) over 5, 21, and 125 days; the ratio of the
Simple Moving Average (SMA) over 100 days to
the SMA over 200 days, the Relative Strength In-
dex (RSI) over 14 days, and William %R over 14,
45, and 125 days. Deﬁnitions of these indicators
may be found in [2].

Results

For both volatility and return prediction, I consid-
ered four regression algorithms: linear and regularized
(ridge) linear regression (implemented myself); Neu-
ral Networks (using the MATLAB Neural Network
toolbox); Random Forests (using the MATLAB Tree-
Bagger function); and gradient-boosted decision trees
(using the R package GBM).

As I show below, the volatility prediction problem
was signiﬁcantly more tractable than the problem of
return prediction, so I began by performing feature
selection on the volatility prediction problem, and used
the results of that for the return prediction problem.
For both problems, I used a training set consisting
of 9424 examples (80% of the data), and a test set
consisting of 2356 examples (20% of the data). The
training vs. test division was chronological, so that the
training examples consisted of the initial 80% of the
data, and the test examples consisted of the ﬁnal 20%
(it is important to segregate the data by time period
since the performance of the various futures is not
independent over the same time period). In addition,
wherever I refer to cross-validation, I performed 10-
fold cross-validation on the initial 80% of the data (the
training data set), where each of the cross-validation
folds was chosen to be a contiguous time block.

Volatility Prediction

Before comparing the performance of the various ma-
chine learning algorithms, I performed feature selection
using linear regression. The results are contained in
the following table:

Features Training r2 CV r2 Test r2
0.473
PCA (82)
0.637
0.639

0.490
0.645
0.647

0.631
0.710
0.713

TI (18)
TI (7)

Here PCA stands for principal components analy-
sis, and TI for technical indicators. The number in

Page 3 of 5

parentheses is the dimension of the feature vector.

After performing principal components analysis on
the 250-dimensional subsampled and normalized fea-
ture vector, I obtained through cross-validation an op-
timal number of principal components of 82, but even
after choosing this optimal number of principal compo-
nents, linear regression using the 18-dimensional fea-
ture vector of all technical indicators performed much
better, and greedy backward-elimination allowed me
to obtain a subset of seven of the technical indicators
which also gave some small improvements.

I interpreted the results of this feature selection
procedure as signifying that the 18-dimensional fea-
ture vector of technical indicators had much greater
explanatory power of the futures’ behavior, and so
decided to use these features when comparing the var-
ious machine learning algorithms’ performance when
predicting both volatility and return.

The following table contains the performance re-
sults for the various algorithms for volatility predic-
tion, using only the seven features remaining after
backwards-elimination during the variable selection
process.

Algorithm Training r2 CV r2 Test r2
0.639
0.632
0.649
0.638

0.647
0.660
0.664
0.666

0.713
0.734
0.731
0.701

LR
NN
RF

GBM

Here LR refers to linear regression, NN to neural
networks, RF to random forests, and GBM to the
gradient boosted decision trees.

Note that although I only report the r2 values, rather
than the MSE, the two are related in such a way
that a higher r2 corresponds precisely to a smaller
MSE, so that considering the r2 value is suﬃcient to
analyze algorithm performance. Considering both the
performance on the cross-validation and the test data
set, the Random Forest model seemed to oﬀer the
best performance, though this performance was only
marginally better than the linear regression model.

Return Prediction

The following table contains the results of using the
various algorithms to predict return performance using
the 18 technical indicators as the feature vector:

Algorithm Training r CV r Test r
0.138
-0.088
-0.102
0.028

0.169
0.088
0.236
0.328

0.142
0.013
0.069
0.154

RR
NN
RF

GBM

Figure 1: Performance of grid-search optimized strategy.

Here the algorithm acronyms represent the same
things, except that RR here represents ridge regres-
sion, which oﬀered some small improvements here over
ordinary least squares linear regression.

Unsurprisingly, return prediction is much more chal-
lenging than volatility prediction – note that we have
reported values of r, rather than r2 in the table above.
However, as I attempt to demonstrate later in the
section on theoretical algorithm performance, even
predictions with a relatively low value of r can gener-
ate surprisingly eﬀective trading algorithms as long as
there is some correlation.

Unfortunately, only gradient-boosted decision trees
performed comparably to ridge regression in cross-
validation, and none of the algorithms performed close
to as well as ridge regression on the test set, with Ran-
dom Forests and Neural Networks in fact performing
worse than using the mean for prediction. As a result,
I used the ridge regression predictions in my trading
algorithms, but I still believe there is signiﬁcant poten-
tial for improvements in these predictions, and I think
such improvements are one of the primary ways that
I could improve my trading algorithm performance.

Trading Algorithms

Description of algorithms

To make use of the volatility and return predictions, I
created a 3-parameter trading algorithm which weights
the predicted returns by a power of the predicted
volatility, and uses this as the desired portfolio dis-
tribution. The chart below plots the performance of
this strategy for one speciﬁc choice of these three pa-
rameters, chosen by grid search to obtain the optimal
Sharpe ratio.

Figure 1 shows the performance of this optimal

Page 4 of 5

strategy, which obtained a yearly return of 6.63%
and a yearly volatility of 5.58%, for a Sharpe ratio of
1.18. To demonstrate the eﬀectiveness of this approach
to strategy selection, I performed a similar selection
procedure on only the ﬁrst half of the data, and was
able to obtain a strategy obtaining a Sharpe ratio of
1.33 on the ﬁrst half of the data, and this strategy
obtained a Sharpe ratio of 0.73 over the second half.
This shows that we should not expect the strategy
from Figure 1 to perform equally well in the future,
but that it should still work to some extent.

Theoretical algorithm performance

I now consider the performance of an extremely basic
trading strategy using as input only corrupted versions
of the predicted returns, with noise added to obtain
a speciﬁed correlation coeﬃcient r. Speciﬁcally, the
strategy just takes the predicted returns and uses an
appropriate scaling as the desired equity distribution
(noting that negative numbers correspond to “selling
short”). For each choice of r, thirty separate instances
of the random predictions were generated, and the
mean and standard deviations of the Sharpe ratio of
the resulting strategies are included in the table.

r

0

Mean -0.36
0.26

SD

0.1
0.09
0.48

0.15
0.41
0.44

0.2
0.97
0.33

0.3
1.90
0.29

0.5
3.62
0.31

This table demonstrates that even a small value of
r2 is enough to obtain a good trading strategy, with
r2 = 0.1 (r ≈ 0.3) being good enough for this very
basic strategy to be very eﬀective. As a result, it
seems that an appropriately chosen strategy (which
also takes volatility into account) could reasonably
reliably achieve a Sharpe ratio of 1 or greater with
return predictions only slightly more accurate than
those I obtained from ridge regression (which achieved
r ≈ 0.14 in cross-validation and on the test data).

This is a somewhat disappointing conclusion, but
there are several ways that I think the work could be
improved with additional work that could lead to the
generation of more eﬀective strategies:

• More eﬀort could be put into the choice of pre-
diction objective – in particular, I have only in-
vestigated predictions for n = 20 days in advance.
Other choices may lead to more reliable predic-
tions.

• In both of the supervised learning problems, I
have only considered models which predict future
return and volatility for each security indepen-
dently. However, the various securities seem to
exhibit dependency over a ﬁxed period of time.
I think a model which incorporates such depen-
dence might be able to generate more eﬀective
predictions, and is worth investigating.

• Recall that the feature vector of technical indi-
cators already led to much improved predictions
of volatility over the PCA approach to the raw
data. Similarly, I suspect that another set of fea-
tures could also lead to improved predictions of
return, and I believe that further investigation
into feature generation and selection could lead
to improved return predictions (and therefore im-
proved Sharpe ratios).

• For the sake of just obtaining a high-performing
strategy (which may not be a legal submission
to the Quantiacs competition), I believe that it
would be very beneﬁcial to include outside data
that does not consist solely of past trading perfor-
mance (for example, sentiment analysis of news
articles related to the securities in question). In
addition, using data from more than just the 27
futures under consideration in this competition
to train the model could also lead to performance
improvements.

Discussion and Future Work

References

According to [3], a Sharpe ratio of “1 or better is con-
sidered good, 2 or better is very good, and 3 or better
is considered excellent.” As a result, the strategies
I obtained through my work on this project leave a
bit to be desired since they have achieved a Sharpe
ratio of at best about 1.2 on the backtesting data, and
appear to perform less well on future data (though
still obtaining some positive returns). While it seems
that these strategies will still generate positive returns
on future data, I would not expect them to obtain a
Sharpe ratio greater than 1 with very high probability.

[1] Quantiacs – Futures Contest Rules https://
quantiacs.com/Contest/FuturesContestRules.
aspx

[2] Technical

Indicators

and

Overlays

http://stockcharts.com/school/doku.php?
id=chart_school:technical_indicators

[3] Understanding The

http:
//www.investopedia.com/articles/07/sharpe_
ratio.asp

Sharpe Ratio

Page 5 of 5

