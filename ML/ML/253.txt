CS 229 Final Project (cid:15) Autumn 2014

Identifying Gender From Images of Faces

Abhimanyu Bannerjee and Asha Chigurupati

Stanford University

Abstract

The objective of this project is to identify the gender of a person by looking at his/her photograph. This is a case of
supervised learning where the algorithm is ﬁrst trained on a set of female and male faces, and then used to classify new data.
We have not taken genders other than Male and Female into account. A preliminary algorithm is run to make sure that an
image is that of a human before classiﬁcation begins.

I.

Introduction

matical equations governing these methods will not be
discussed in this report.

Previous research has shown that our brain has special-
ized nerve cells responding to speciﬁc local features
of a scene, such as lines, edges, angles or movement.
Our visual cortex combines these scattered pieces of
information into useful patterns. Automatic face recog-
nition aims to extract these meaningful pieces of infor-
mation and put them together into a useful representa-
tion in order to perform a classiﬁcation/identiﬁcation
task on them.

While we attempt to identify gender from facial
features, we are often curious about what features of
the face are most important in determining gender.
Are localized features such as eyes, nose and ears more
important or overall features such as head shape, hair
line and face contour more important?

There are a plethora of successful and robut face
recognition algorithms on the web. Instead of using
the inbuilt tools that they provide, we start building
various algorithms from scratch to gain a rich learning
experience.

for classiﬁcation :

duced space of PCA

In this project, the following methods were used
(cid:15) Eigenface Method
(cid:15) K-means
(cid:15) GDA that performs supervised learning on re-
(cid:15) SVM that performs supervised learning on re-
duces space of PCA
(cid:15) Fisherfaces Method
(cid:15) SVM that performs supervised learning on fea-
tures provided by the Histogram of Oriented
Gradients (HOG) method

We look at how these methods perform on our
data, discuss the relative advantages and disadvan-
tages of these methods and investigate the limitations
on accuracy posed by the dataset itself. The mathe-

II. Data Set and Processing

The data we have is a set of high resolution colour im-
ages of 396 female faces and 389 male faces obtained
from the MUCT database. All images are frontal views
of the face. The database provides diversity of lighting,
age and ethnicity.

The images also have variations in :
(cid:15) subject’s head rotation and tilt
(cid:15) subject’s facial expression
(cid:15) subject’s face/Hair accessories
(cid:15) position of the face in the image
However, this challenging database was chosen to

make room for imrpovements in the algorithm.

This data has been used in four different ways
on a single algorithm so that we can study how sen-
sitive it is to the data quality. We run a python
script to center all the images in our database - by
centering the images the faces are aligned at the
axis of symmetry of the face. Hehce, we have a
set of centered and uncentered images. We also
use coloured (RGB) and B/W versions of the given
images. Colour images have been compressed to
140x140 pixels and B/W to 64x48 pixels. We now
have four different datasets: Dataset1(centered, RGB),
Dataset2(centered,B/W), Dataset3(uncentered,RGB)
and Dataset4(uncentered, B/W).

The dataset has been split into training set and test

set as summarized in the following table:

1

CS 229 Final Project (cid:15) Autumn 2014

Identifying Gender From Images of Faces

Abhimanyu Bannerjee and Asha Chigurupati

Stanford University

Abstract

The objective of this project is to identify the gender of a person by looking at his/her photograph. This is a case of
supervised learning where the algorithm is ﬁrst trained on a set of female and male faces, and then used to classify new data.
We have not taken genders other than Male and Female into account. A preliminary algorithm is run to make sure that an
image is that of a human before classiﬁcation begins.

I.

Introduction

matical equations governing these methods will not be
discussed in this report.

Previous research has shown that our brain has special-
ized nerve cells responding to speciﬁc local features
of a scene, such as lines, edges, angles or movement.
Our visual cortex combines these scattered pieces of
information into useful patterns. Automatic face recog-
nition aims to extract these meaningful pieces of infor-
mation and put them together into a useful representa-
tion in order to perform a classiﬁcation/identiﬁcation
task on them.

While we attempt to identify gender from facial
features, we are often curious about what features of
the face are most important in determining gender.
Are localized features such as eyes, nose and ears more
important or overall features such as head shape, hair
line and face contour more important?

There are a plethora of successful and robut face
recognition algorithms on the web. Instead of using
the inbuilt tools that they provide, we start building
various algorithms from scratch to gain a rich learning
experience.

for classiﬁcation :

duced space of PCA

In this project, the following methods were used
(cid:15) Eigenface Method
(cid:15) K-means
(cid:15) GDA that performs supervised learning on re-
(cid:15) SVM that performs supervised learning on re-
duces space of PCA
(cid:15) Fisherfaces Method
(cid:15) SVM that performs supervised learning on fea-
tures provided by the Histogram of Oriented
Gradients (HOG) method

We look at how these methods perform on our
data, discuss the relative advantages and disadvan-
tages of these methods and investigate the limitations
on accuracy posed by the dataset itself. The mathe-

II. Data Set and Processing

The data we have is a set of high resolution colour im-
ages of 396 female faces and 389 male faces obtained
from the MUCT database. All images are frontal views
of the face. The database provides diversity of lighting,
age and ethnicity.

The images also have variations in :
(cid:15) subject’s head rotation and tilt
(cid:15) subject’s facial expression
(cid:15) subject’s face/Hair accessories
(cid:15) position of the face in the image
However, this challenging database was chosen to

make room for imrpovements in the algorithm.

This data has been used in four different ways
on a single algorithm so that we can study how sen-
sitive it is to the data quality. We run a python
script to center all the images in our database - by
centering the images the faces are aligned at the
axis of symmetry of the face. Hehce, we have a
set of centered and uncentered images. We also
use coloured (RGB) and B/W versions of the given
images. Colour images have been compressed to
140x140 pixels and B/W to 64x48 pixels. We now
have four different datasets: Dataset1(centered, RGB),
Dataset2(centered,B/W), Dataset3(uncentered,RGB)
and Dataset4(uncentered, B/W).

The dataset has been split into training set and test

set as summarized in the following table:

1

CS 229 Final Project (cid:15) Autumn 2014

Table 1: Dataset of faces

Gender Training Set Test Set
169
Male
Female
189

200
200

female subjects who have short hair, hair tied back or
in a scarf were almost always labeled male. Having
insufﬁcient examples for them to train on might have
resulted in this outcome. Another key observation is
that, the male faces are better centered and hence male
faces have a more reliable eigenspace.

In this project, we deﬁne misclassiﬁcation error as:

Error (cid:61)

No.

o f

images miscclassi f ied

No.

o f

images

(1)

III. Eigenface Method

A popular method in face recognition is the Eigenface
algorithm. It takes a holistic approach by processing
the entire face and coming up with an eigenface basis.
In this method, a Principle Component Analysis (PCA)
is performed to reduce the dimensionality of

The performance of this algorithm is discussed

here:

Table 2: Eigenface Method on Dataset 4

Gender Training Error Test Error
0.03
Male
Female
0.28

0.8
0.14

Table 3: Eigenface Method on Dataset 3

Gender Training Error Test Error
0.14
Male
Female
0.16

0.6
0.11

On Dataset 4, the algorithm shows very good recog-
nition for males but a very poor one for females. We
conclude here that the algorithm is basically identi-
fying almost every new face to be male, hence con-
tributing to the large error for females. The ﬁgure
below demonstrates this. When a male face is pro-
jected onto the male eigenspace, the resultant reduced-
dimension vector matches the other male faces very
well. But when a female face is projected onto the
female eigenspace, the resultant reduced-dimension
vector does not match the female faces very well. In-
fact, it favours females over males only about 28 % of
the time.

One disadvantage of PCA is that it cannot give
you an intuitive sense of why the algorithm is favour-
ing males. But upon looking at the data where the
algorithm misclassiﬁes the person, we conclude that

Figure 1: Plot of nearest distance of female faces in test set from

female(red) and male(blue) Eigenfaces

Figure 2: Plot of nearest distance of male faces in test set from

female(red) and male(blue) Eigenfaces

Running the same algorithm on Dataset 3 reduced
the excessive bias towards males, as now the female
faces were equally well-centered.

In all cases, the number of principal components
was chosen to be 200. We obtained this result by elimi-
nating all eigen values whose value is zero. A k-fold
cross validation was performed to decide the number
of dimensions in the reduced space more precisely.
This resulted in a reduced dimension of 170.

Below is a ﬁgure showing some images in the train-

ing set and the corresponding Eigenfaces:

Figure 3: A sample of training set data

2

CS 229 Final Project (cid:15) Autumn 2014

Identifying Gender From Images of Faces

Abhimanyu Bannerjee and Asha Chigurupati

Stanford University

Abstract

The objective of this project is to identify the gender of a person by looking at his/her photograph. This is a case of
supervised learning where the algorithm is ﬁrst trained on a set of female and male faces, and then used to classify new data.
We have not taken genders other than Male and Female into account. A preliminary algorithm is run to make sure that an
image is that of a human before classiﬁcation begins.

I.

Introduction

matical equations governing these methods will not be
discussed in this report.

Previous research has shown that our brain has special-
ized nerve cells responding to speciﬁc local features
of a scene, such as lines, edges, angles or movement.
Our visual cortex combines these scattered pieces of
information into useful patterns. Automatic face recog-
nition aims to extract these meaningful pieces of infor-
mation and put them together into a useful representa-
tion in order to perform a classiﬁcation/identiﬁcation
task on them.

While we attempt to identify gender from facial
features, we are often curious about what features of
the face are most important in determining gender.
Are localized features such as eyes, nose and ears more
important or overall features such as head shape, hair
line and face contour more important?

There are a plethora of successful and robut face
recognition algorithms on the web. Instead of using
the inbuilt tools that they provide, we start building
various algorithms from scratch to gain a rich learning
experience.

for classiﬁcation :

duced space of PCA

In this project, the following methods were used
(cid:15) Eigenface Method
(cid:15) K-means
(cid:15) GDA that performs supervised learning on re-
(cid:15) SVM that performs supervised learning on re-
duces space of PCA
(cid:15) Fisherfaces Method
(cid:15) SVM that performs supervised learning on fea-
tures provided by the Histogram of Oriented
Gradients (HOG) method

We look at how these methods perform on our
data, discuss the relative advantages and disadvan-
tages of these methods and investigate the limitations
on accuracy posed by the dataset itself. The mathe-

II. Data Set and Processing

The data we have is a set of high resolution colour im-
ages of 396 female faces and 389 male faces obtained
from the MUCT database. All images are frontal views
of the face. The database provides diversity of lighting,
age and ethnicity.

The images also have variations in :
(cid:15) subject’s head rotation and tilt
(cid:15) subject’s facial expression
(cid:15) subject’s face/Hair accessories
(cid:15) position of the face in the image
However, this challenging database was chosen to

make room for imrpovements in the algorithm.

This data has been used in four different ways
on a single algorithm so that we can study how sen-
sitive it is to the data quality. We run a python
script to center all the images in our database - by
centering the images the faces are aligned at the
axis of symmetry of the face. Hehce, we have a
set of centered and uncentered images. We also
use coloured (RGB) and B/W versions of the given
images. Colour images have been compressed to
140x140 pixels and B/W to 64x48 pixels. We now
have four different datasets: Dataset1(centered, RGB),
Dataset2(centered,B/W), Dataset3(uncentered,RGB)
and Dataset4(uncentered, B/W).

The dataset has been split into training set and test

set as summarized in the following table:

1

CS 229 Final Project (cid:15) Autumn 2014

Table 1: Dataset of faces

Gender Training Set Test Set
169
Male
Female
189

200
200

female subjects who have short hair, hair tied back or
in a scarf were almost always labeled male. Having
insufﬁcient examples for them to train on might have
resulted in this outcome. Another key observation is
that, the male faces are better centered and hence male
faces have a more reliable eigenspace.

In this project, we deﬁne misclassiﬁcation error as:

Error (cid:61)

No.

o f

images miscclassi f ied

No.

o f

images

(1)

III. Eigenface Method

A popular method in face recognition is the Eigenface
algorithm. It takes a holistic approach by processing
the entire face and coming up with an eigenface basis.
In this method, a Principle Component Analysis (PCA)
is performed to reduce the dimensionality of

The performance of this algorithm is discussed

here:

Table 2: Eigenface Method on Dataset 4

Gender Training Error Test Error
0.03
Male
Female
0.28

0.8
0.14

Table 3: Eigenface Method on Dataset 3

Gender Training Error Test Error
0.14
Male
Female
0.16

0.6
0.11

On Dataset 4, the algorithm shows very good recog-
nition for males but a very poor one for females. We
conclude here that the algorithm is basically identi-
fying almost every new face to be male, hence con-
tributing to the large error for females. The ﬁgure
below demonstrates this. When a male face is pro-
jected onto the male eigenspace, the resultant reduced-
dimension vector matches the other male faces very
well. But when a female face is projected onto the
female eigenspace, the resultant reduced-dimension
vector does not match the female faces very well. In-
fact, it favours females over males only about 28 % of
the time.

One disadvantage of PCA is that it cannot give
you an intuitive sense of why the algorithm is favour-
ing males. But upon looking at the data where the
algorithm misclassiﬁes the person, we conclude that

Figure 1: Plot of nearest distance of female faces in test set from

female(red) and male(blue) Eigenfaces

Figure 2: Plot of nearest distance of male faces in test set from

female(red) and male(blue) Eigenfaces

Running the same algorithm on Dataset 3 reduced
the excessive bias towards males, as now the female
faces were equally well-centered.

In all cases, the number of principal components
was chosen to be 200. We obtained this result by elimi-
nating all eigen values whose value is zero. A k-fold
cross validation was performed to decide the number
of dimensions in the reduced space more precisely.
This resulted in a reduced dimension of 170.

Below is a ﬁgure showing some images in the train-

ing set and the corresponding Eigenfaces:

Figure 3: A sample of training set data

2

CS 229 Final Project (cid:15) Autumn 2014

Table 6: PCA and GDA method on Dataset 2

Gender Test Error
Male
Female

0.11
0.11

Table 7: PCA and GDA on Dataset 1

Gender Test Error
Male
Female

0.55
0.7

A k-fold cross validation was done to determine the
number of PCAs required, and we found the optimal
value to be 100. In order to visualize how GDA works
with this data, we take 3 Principal Components and
obtain the following plot:

Figure 5: Implementing GDA for K = 3

VI. PCA with SVM

SVM is yet another way of performing supervised
learning over the reduced space. A k-fold cross-
validation was performed to chose the number of PCAs
and 150 was found to be optimum. Cross validation
was done for k = (10,20,30..200). This interval was
arrived at after random sampling of k’s.

The PCA was applied to reduce dimensionality of
the vectors that serve as inputs to the SVM. The SVM
then does supervised learning. Sometimes this method
is called the ﬁsher discriminant analysis. Visualizing
this data in the large dimensional space is hard, so we
do it in 2D. We clearly need more attributes to classify
the data.

3

Figure 4: Eigenfaces of the above sample

IV. K-means

We apply K-means directly on the pixel data that we
get from images to obtain 10 clusters for female faces
and 10 for male faces. We would like to call these the
10 most representative female and male faces. We then
run the K Nearest Neighbours algorithm to classify our
test images. K was chosen to be 5 after analysing the
performance of the algorithm (using cross validation)
for all possible values of K.

This is done on Dataset 3 and Dataset 4. We get the

following results:

Table 4: K-means on Dataset 4

Gender Test Error
Male
Female

0.22
0.16

Table 5: K-means on Dataset 3

Gender Test Error
Male
Female

0.12
0.13

V. PCA with GDA

The Eigenface method classiﬁes new data based on
what the nearest vector is in terms of euclidean dis-
tance. Instead of using the nearest neighbour approach,
we can perform supervised learning over the reduced
space. GDA is one such attempt.

CS 229 Final Project (cid:15) Autumn 2014

Identifying Gender From Images of Faces

Abhimanyu Bannerjee and Asha Chigurupati

Stanford University

Abstract

The objective of this project is to identify the gender of a person by looking at his/her photograph. This is a case of
supervised learning where the algorithm is ﬁrst trained on a set of female and male faces, and then used to classify new data.
We have not taken genders other than Male and Female into account. A preliminary algorithm is run to make sure that an
image is that of a human before classiﬁcation begins.

I.

Introduction

matical equations governing these methods will not be
discussed in this report.

Previous research has shown that our brain has special-
ized nerve cells responding to speciﬁc local features
of a scene, such as lines, edges, angles or movement.
Our visual cortex combines these scattered pieces of
information into useful patterns. Automatic face recog-
nition aims to extract these meaningful pieces of infor-
mation and put them together into a useful representa-
tion in order to perform a classiﬁcation/identiﬁcation
task on them.

While we attempt to identify gender from facial
features, we are often curious about what features of
the face are most important in determining gender.
Are localized features such as eyes, nose and ears more
important or overall features such as head shape, hair
line and face contour more important?

There are a plethora of successful and robut face
recognition algorithms on the web. Instead of using
the inbuilt tools that they provide, we start building
various algorithms from scratch to gain a rich learning
experience.

for classiﬁcation :

duced space of PCA

In this project, the following methods were used
(cid:15) Eigenface Method
(cid:15) K-means
(cid:15) GDA that performs supervised learning on re-
(cid:15) SVM that performs supervised learning on re-
duces space of PCA
(cid:15) Fisherfaces Method
(cid:15) SVM that performs supervised learning on fea-
tures provided by the Histogram of Oriented
Gradients (HOG) method

We look at how these methods perform on our
data, discuss the relative advantages and disadvan-
tages of these methods and investigate the limitations
on accuracy posed by the dataset itself. The mathe-

II. Data Set and Processing

The data we have is a set of high resolution colour im-
ages of 396 female faces and 389 male faces obtained
from the MUCT database. All images are frontal views
of the face. The database provides diversity of lighting,
age and ethnicity.

The images also have variations in :
(cid:15) subject’s head rotation and tilt
(cid:15) subject’s facial expression
(cid:15) subject’s face/Hair accessories
(cid:15) position of the face in the image
However, this challenging database was chosen to

make room for imrpovements in the algorithm.

This data has been used in four different ways
on a single algorithm so that we can study how sen-
sitive it is to the data quality. We run a python
script to center all the images in our database - by
centering the images the faces are aligned at the
axis of symmetry of the face. Hehce, we have a
set of centered and uncentered images. We also
use coloured (RGB) and B/W versions of the given
images. Colour images have been compressed to
140x140 pixels and B/W to 64x48 pixels. We now
have four different datasets: Dataset1(centered, RGB),
Dataset2(centered,B/W), Dataset3(uncentered,RGB)
and Dataset4(uncentered, B/W).

The dataset has been split into training set and test

set as summarized in the following table:

1

CS 229 Final Project (cid:15) Autumn 2014

Table 1: Dataset of faces

Gender Training Set Test Set
169
Male
Female
189

200
200

female subjects who have short hair, hair tied back or
in a scarf were almost always labeled male. Having
insufﬁcient examples for them to train on might have
resulted in this outcome. Another key observation is
that, the male faces are better centered and hence male
faces have a more reliable eigenspace.

In this project, we deﬁne misclassiﬁcation error as:

Error (cid:61)

No.

o f

images miscclassi f ied

No.

o f

images

(1)

III. Eigenface Method

A popular method in face recognition is the Eigenface
algorithm. It takes a holistic approach by processing
the entire face and coming up with an eigenface basis.
In this method, a Principle Component Analysis (PCA)
is performed to reduce the dimensionality of

The performance of this algorithm is discussed

here:

Table 2: Eigenface Method on Dataset 4

Gender Training Error Test Error
0.03
Male
Female
0.28

0.8
0.14

Table 3: Eigenface Method on Dataset 3

Gender Training Error Test Error
0.14
Male
Female
0.16

0.6
0.11

On Dataset 4, the algorithm shows very good recog-
nition for males but a very poor one for females. We
conclude here that the algorithm is basically identi-
fying almost every new face to be male, hence con-
tributing to the large error for females. The ﬁgure
below demonstrates this. When a male face is pro-
jected onto the male eigenspace, the resultant reduced-
dimension vector matches the other male faces very
well. But when a female face is projected onto the
female eigenspace, the resultant reduced-dimension
vector does not match the female faces very well. In-
fact, it favours females over males only about 28 % of
the time.

One disadvantage of PCA is that it cannot give
you an intuitive sense of why the algorithm is favour-
ing males. But upon looking at the data where the
algorithm misclassiﬁes the person, we conclude that

Figure 1: Plot of nearest distance of female faces in test set from

female(red) and male(blue) Eigenfaces

Figure 2: Plot of nearest distance of male faces in test set from

female(red) and male(blue) Eigenfaces

Running the same algorithm on Dataset 3 reduced
the excessive bias towards males, as now the female
faces were equally well-centered.

In all cases, the number of principal components
was chosen to be 200. We obtained this result by elimi-
nating all eigen values whose value is zero. A k-fold
cross validation was performed to decide the number
of dimensions in the reduced space more precisely.
This resulted in a reduced dimension of 170.

Below is a ﬁgure showing some images in the train-

ing set and the corresponding Eigenfaces:

Figure 3: A sample of training set data

2

CS 229 Final Project (cid:15) Autumn 2014

Table 6: PCA and GDA method on Dataset 2

Gender Test Error
Male
Female

0.11
0.11

Table 7: PCA and GDA on Dataset 1

Gender Test Error
Male
Female

0.55
0.7

A k-fold cross validation was done to determine the
number of PCAs required, and we found the optimal
value to be 100. In order to visualize how GDA works
with this data, we take 3 Principal Components and
obtain the following plot:

Figure 5: Implementing GDA for K = 3

VI. PCA with SVM

SVM is yet another way of performing supervised
learning over the reduced space. A k-fold cross-
validation was performed to chose the number of PCAs
and 150 was found to be optimum. Cross validation
was done for k = (10,20,30..200). This interval was
arrived at after random sampling of k’s.

The PCA was applied to reduce dimensionality of
the vectors that serve as inputs to the SVM. The SVM
then does supervised learning. Sometimes this method
is called the ﬁsher discriminant analysis. Visualizing
this data in the large dimensional space is hard, so we
do it in 2D. We clearly need more attributes to classify
the data.

3

Figure 4: Eigenfaces of the above sample

IV. K-means

We apply K-means directly on the pixel data that we
get from images to obtain 10 clusters for female faces
and 10 for male faces. We would like to call these the
10 most representative female and male faces. We then
run the K Nearest Neighbours algorithm to classify our
test images. K was chosen to be 5 after analysing the
performance of the algorithm (using cross validation)
for all possible values of K.

This is done on Dataset 3 and Dataset 4. We get the

following results:

Table 4: K-means on Dataset 4

Gender Test Error
Male
Female

0.22
0.16

Table 5: K-means on Dataset 3

Gender Test Error
Male
Female

0.12
0.13

V. PCA with GDA

The Eigenface method classiﬁes new data based on
what the nearest vector is in terms of euclidean dis-
tance. Instead of using the nearest neighbour approach,
we can perform supervised learning over the reduced
space. GDA is one such attempt.

CS 229 Final Project (cid:15) Autumn 2014

Figure 6: Implementing SVM for K = 2

Performance of this algorithm is :

Table 8: PCA and SVM on Dataset 4

Gender Test Error
Male
Female

0.10
0.13

Table 9: PCA and SVM on Dataset 3

Gender Test Error
Male
Female

0.90
0.10

VII. Fischer Faces

When PCA reduces the dimension in which we work,
it deﬁnitely obtains the most representative reduced
space. But it does nothing to make sure that these at-
tributes also represent the salient differences between
the male class and female class. Our algorithm’s main
aim should be to identify these features and give them
highest priority while classifying them.

Fisherfaces instead tries to maximize the variance
between classes, instead of variance within a class.
Hence it is much better suited for the gender classiﬁca-
tion task.

As expected, Fisher Faces gives us remarkable re-
sults of 10 % on uncentered data and 3 % on centered
data. ALso 10 % is what all the algorithms converge
to when used on uncentered data. This throws light
on the importance of centering it, as information about
features can be very crucial in classifying it correctly.

Table 10: Fisherface Method on Dataset 4

Gender Test Error
Male
Female

0.90
0.11

Table 11: Fishface Method on Dataset 3

Gender Test Error
Male
Female

0.25
0.40

VIII. Histogram of Oriented Gradients

and SVM

As a foray into applying advanced and effective gender
classiﬁcation algorithms, we have used supervise SVM
learning after extracting HOG descriptors of human
faces. For this particular algorithm, we used code that
was available online.

We carry out the scheme in B/W space and use
L-2 normalization for block normalization. For this
method,
images were not normalized during pre-
processing. Also, the images were not centered because
this method is invariant to geometric transformations
of images.

A plot of gradients show what the most descriptive
cues are that the SVM learns over. This is the only algo-
rithm that can give us an insight as to which physical
part of the face contributes most to gender detection.
The accuracy that this algorithm provides is the
best of all. The algorithm also does not seem to be
limited by the challenges that the data poses, giving us
equally good results for both centered and uncentered
data.

Table 12: Fisherface Method on Dataset 3

Gender Test Error
Male
Female

0.17
0.20

Table 13: Fishface Method on Dataset 4

Gender Test Error
Male
Female

0.20
0.23

The gradient images of our dataset tells us that
these are the fundamental differences between male
and female faces:

(cid:15) The interior of a female face has softer face con-

tours

(cid:15) Female features are spread over larger areas than

male features

4

CS 229 Final Project (cid:15) Autumn 2014

Identifying Gender From Images of Faces

Abhimanyu Bannerjee and Asha Chigurupati

Stanford University

Abstract

The objective of this project is to identify the gender of a person by looking at his/her photograph. This is a case of
supervised learning where the algorithm is ﬁrst trained on a set of female and male faces, and then used to classify new data.
We have not taken genders other than Male and Female into account. A preliminary algorithm is run to make sure that an
image is that of a human before classiﬁcation begins.

I.

Introduction

matical equations governing these methods will not be
discussed in this report.

Previous research has shown that our brain has special-
ized nerve cells responding to speciﬁc local features
of a scene, such as lines, edges, angles or movement.
Our visual cortex combines these scattered pieces of
information into useful patterns. Automatic face recog-
nition aims to extract these meaningful pieces of infor-
mation and put them together into a useful representa-
tion in order to perform a classiﬁcation/identiﬁcation
task on them.

While we attempt to identify gender from facial
features, we are often curious about what features of
the face are most important in determining gender.
Are localized features such as eyes, nose and ears more
important or overall features such as head shape, hair
line and face contour more important?

There are a plethora of successful and robut face
recognition algorithms on the web. Instead of using
the inbuilt tools that they provide, we start building
various algorithms from scratch to gain a rich learning
experience.

for classiﬁcation :

duced space of PCA

In this project, the following methods were used
(cid:15) Eigenface Method
(cid:15) K-means
(cid:15) GDA that performs supervised learning on re-
(cid:15) SVM that performs supervised learning on re-
duces space of PCA
(cid:15) Fisherfaces Method
(cid:15) SVM that performs supervised learning on fea-
tures provided by the Histogram of Oriented
Gradients (HOG) method

We look at how these methods perform on our
data, discuss the relative advantages and disadvan-
tages of these methods and investigate the limitations
on accuracy posed by the dataset itself. The mathe-

II. Data Set and Processing

The data we have is a set of high resolution colour im-
ages of 396 female faces and 389 male faces obtained
from the MUCT database. All images are frontal views
of the face. The database provides diversity of lighting,
age and ethnicity.

The images also have variations in :
(cid:15) subject’s head rotation and tilt
(cid:15) subject’s facial expression
(cid:15) subject’s face/Hair accessories
(cid:15) position of the face in the image
However, this challenging database was chosen to

make room for imrpovements in the algorithm.

This data has been used in four different ways
on a single algorithm so that we can study how sen-
sitive it is to the data quality. We run a python
script to center all the images in our database - by
centering the images the faces are aligned at the
axis of symmetry of the face. Hehce, we have a
set of centered and uncentered images. We also
use coloured (RGB) and B/W versions of the given
images. Colour images have been compressed to
140x140 pixels and B/W to 64x48 pixels. We now
have four different datasets: Dataset1(centered, RGB),
Dataset2(centered,B/W), Dataset3(uncentered,RGB)
and Dataset4(uncentered, B/W).

The dataset has been split into training set and test

set as summarized in the following table:

1

CS 229 Final Project (cid:15) Autumn 2014

Table 1: Dataset of faces

Gender Training Set Test Set
169
Male
Female
189

200
200

female subjects who have short hair, hair tied back or
in a scarf were almost always labeled male. Having
insufﬁcient examples for them to train on might have
resulted in this outcome. Another key observation is
that, the male faces are better centered and hence male
faces have a more reliable eigenspace.

In this project, we deﬁne misclassiﬁcation error as:

Error (cid:61)

No.

o f

images miscclassi f ied

No.

o f

images

(1)

III. Eigenface Method

A popular method in face recognition is the Eigenface
algorithm. It takes a holistic approach by processing
the entire face and coming up with an eigenface basis.
In this method, a Principle Component Analysis (PCA)
is performed to reduce the dimensionality of

The performance of this algorithm is discussed

here:

Table 2: Eigenface Method on Dataset 4

Gender Training Error Test Error
0.03
Male
Female
0.28

0.8
0.14

Table 3: Eigenface Method on Dataset 3

Gender Training Error Test Error
0.14
Male
Female
0.16

0.6
0.11

On Dataset 4, the algorithm shows very good recog-
nition for males but a very poor one for females. We
conclude here that the algorithm is basically identi-
fying almost every new face to be male, hence con-
tributing to the large error for females. The ﬁgure
below demonstrates this. When a male face is pro-
jected onto the male eigenspace, the resultant reduced-
dimension vector matches the other male faces very
well. But when a female face is projected onto the
female eigenspace, the resultant reduced-dimension
vector does not match the female faces very well. In-
fact, it favours females over males only about 28 % of
the time.

One disadvantage of PCA is that it cannot give
you an intuitive sense of why the algorithm is favour-
ing males. But upon looking at the data where the
algorithm misclassiﬁes the person, we conclude that

Figure 1: Plot of nearest distance of female faces in test set from

female(red) and male(blue) Eigenfaces

Figure 2: Plot of nearest distance of male faces in test set from

female(red) and male(blue) Eigenfaces

Running the same algorithm on Dataset 3 reduced
the excessive bias towards males, as now the female
faces were equally well-centered.

In all cases, the number of principal components
was chosen to be 200. We obtained this result by elimi-
nating all eigen values whose value is zero. A k-fold
cross validation was performed to decide the number
of dimensions in the reduced space more precisely.
This resulted in a reduced dimension of 170.

Below is a ﬁgure showing some images in the train-

ing set and the corresponding Eigenfaces:

Figure 3: A sample of training set data

2

CS 229 Final Project (cid:15) Autumn 2014

Table 6: PCA and GDA method on Dataset 2

Gender Test Error
Male
Female

0.11
0.11

Table 7: PCA and GDA on Dataset 1

Gender Test Error
Male
Female

0.55
0.7

A k-fold cross validation was done to determine the
number of PCAs required, and we found the optimal
value to be 100. In order to visualize how GDA works
with this data, we take 3 Principal Components and
obtain the following plot:

Figure 5: Implementing GDA for K = 3

VI. PCA with SVM

SVM is yet another way of performing supervised
learning over the reduced space. A k-fold cross-
validation was performed to chose the number of PCAs
and 150 was found to be optimum. Cross validation
was done for k = (10,20,30..200). This interval was
arrived at after random sampling of k’s.

The PCA was applied to reduce dimensionality of
the vectors that serve as inputs to the SVM. The SVM
then does supervised learning. Sometimes this method
is called the ﬁsher discriminant analysis. Visualizing
this data in the large dimensional space is hard, so we
do it in 2D. We clearly need more attributes to classify
the data.

3

Figure 4: Eigenfaces of the above sample

IV. K-means

We apply K-means directly on the pixel data that we
get from images to obtain 10 clusters for female faces
and 10 for male faces. We would like to call these the
10 most representative female and male faces. We then
run the K Nearest Neighbours algorithm to classify our
test images. K was chosen to be 5 after analysing the
performance of the algorithm (using cross validation)
for all possible values of K.

This is done on Dataset 3 and Dataset 4. We get the

following results:

Table 4: K-means on Dataset 4

Gender Test Error
Male
Female

0.22
0.16

Table 5: K-means on Dataset 3

Gender Test Error
Male
Female

0.12
0.13

V. PCA with GDA

The Eigenface method classiﬁes new data based on
what the nearest vector is in terms of euclidean dis-
tance. Instead of using the nearest neighbour approach,
we can perform supervised learning over the reduced
space. GDA is one such attempt.

CS 229 Final Project (cid:15) Autumn 2014

Figure 6: Implementing SVM for K = 2

Performance of this algorithm is :

Table 8: PCA and SVM on Dataset 4

Gender Test Error
Male
Female

0.10
0.13

Table 9: PCA and SVM on Dataset 3

Gender Test Error
Male
Female

0.90
0.10

VII. Fischer Faces

When PCA reduces the dimension in which we work,
it deﬁnitely obtains the most representative reduced
space. But it does nothing to make sure that these at-
tributes also represent the salient differences between
the male class and female class. Our algorithm’s main
aim should be to identify these features and give them
highest priority while classifying them.

Fisherfaces instead tries to maximize the variance
between classes, instead of variance within a class.
Hence it is much better suited for the gender classiﬁca-
tion task.

As expected, Fisher Faces gives us remarkable re-
sults of 10 % on uncentered data and 3 % on centered
data. ALso 10 % is what all the algorithms converge
to when used on uncentered data. This throws light
on the importance of centering it, as information about
features can be very crucial in classifying it correctly.

Table 10: Fisherface Method on Dataset 4

Gender Test Error
Male
Female

0.90
0.11

Table 11: Fishface Method on Dataset 3

Gender Test Error
Male
Female

0.25
0.40

VIII. Histogram of Oriented Gradients

and SVM

As a foray into applying advanced and effective gender
classiﬁcation algorithms, we have used supervise SVM
learning after extracting HOG descriptors of human
faces. For this particular algorithm, we used code that
was available online.

We carry out the scheme in B/W space and use
L-2 normalization for block normalization. For this
method,
images were not normalized during pre-
processing. Also, the images were not centered because
this method is invariant to geometric transformations
of images.

A plot of gradients show what the most descriptive
cues are that the SVM learns over. This is the only algo-
rithm that can give us an insight as to which physical
part of the face contributes most to gender detection.
The accuracy that this algorithm provides is the
best of all. The algorithm also does not seem to be
limited by the challenges that the data poses, giving us
equally good results for both centered and uncentered
data.

Table 12: Fisherface Method on Dataset 3

Gender Test Error
Male
Female

0.17
0.20

Table 13: Fishface Method on Dataset 4

Gender Test Error
Male
Female

0.20
0.23

The gradient images of our dataset tells us that
these are the fundamental differences between male
and female faces:

(cid:15) The interior of a female face has softer face con-

tours

(cid:15) Female features are spread over larger areas than

male features

4

