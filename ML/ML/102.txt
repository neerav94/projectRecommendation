KPI-Driven Predictive ML Models Approach 
Towards Municipal Budgeting Optimization 

Bo Shen 

Pradipta A. B. Hendri 

Kun Shao 

{boshen, dip, kunshao}@stanford.edu 

(CS229 Machine Learning Project Final Report) 

Abstractâ€”  this  project  aims  to  use  machine  learning 
techniques  to  predict  citiesâ€™  Key  Performance  Indicators 
(KPI)  based  on  municipal  governmental  budget  compo-
nents towards segments including education, public safety, 
and  health.    The  project  started  with  building  prediction 
model  for  the  City  of  Palo  Alto  and  then  generalized  the 
model  for  a  cluster  of  cities  that  contains  the  City  of  Palo 
Alto.   The result shows that autoregressive linear models 
can predict Crime Index and Health Index reasonably well.  
By building satisfactory KPI prediction models, this project 
sets a path towards municipal budgeting optimization. 

I. INTRODUCTION 

Key Performance Indicators (KPIs) of a city are a set of met-
rics used to evaluate factors that are crucial to the success of a 
city. Government annual budgets name and prioritize regional 
KPI.  Through  agency  sub-budgets  and  programs,  agency  mis-
sions are turned into programs addressing single or multiple cit-
izen concerns about economic development, education, energy, 
environment,  health,  housing,  shared  infrastructure,  public 
safety and other factors. 

Budgets  reveal  spending  by  a  single  program  in  isolation.  
Given the complexities of urban life, a single KPI (for instance, 
health) can be the function of multiple other elements (such as 
environmental and food pollutants, housing quality, transporta-
tion use, and education). Likewise, strategies of improving any 
given KPI can be ways of budget allocation across multiple agen-
cies. 

The project aims to use machine learning to predict KPI using 
municipal budget data and  set  a path to  optimize a part of  or 
entire budget towards certain KPIs. 

II. METHODOLOGIES 

As an overview, we began with accumulating budgeting and 
KPI data for different cities in the US.   We started with building 
prediction model for  the City  of Palo  Altoâ€™s Crime Index.     We 
then applied unsupervised clustering on demographics data of 
these cities to identify similarity groups and attempted to gen-
eralize the prediction model. The cluster to which Palo Alto be-
longs was chosen as the group to which we generalized our anal-
ysis. 

A.  KPIs 

Cities  and  other  independent  parties  evaluate  the  perfor-

mance using metrics such as the following. 

1.  Crime rate, as a measure of safety 
2.  Proportion of residents self-reporting better than fair or 

poor health, as a measure of health of city residents  

3.  Ratio  of average household income to  cost-of-living in-

dex (COLI), as a measure of affordability 

4.  Ethnicity diversity index, which is a normalized measure 
of ethnicity composition deviation index relative to state-
wide ethnicity composition 

It is the interest of municipal government to develop the nec-
essary  infrastructure and environment to  bring the maximum 
benefit  for  the  inhabitants,  and  KPI-driven  approach is  a  suc-
cinct method to  summarize the  performance of a city  when it 
comes to numerical calculations within a data-driven decision 
support system. 

B.  Budget Components 

Municipalities produce Comprehensive Annual Financial Re-
port (CAFR) that they publish on online and printed media. The 
CAFR segments city financial budgeting as follows. 

Category of CAFR components 

Revenues 

Expenses 

Sales and Use Tax Revenues 
Property Tax Revenues 
Other Tax Revenues 
Charges for Services 
Licenses and Fees 
Intergovernmental Grants 
Investment Earnings 
Miscellaneous Revenues 
Total Revenues 

General Government Expenses 
Human Resources Expenses 
Public Safety Expenses 
Public Service Expenses 
Public Works Expenses 
Environmental Expenses 
Other Program Expenses 
Capital Outlay 
Principal Debt Service 
Interest Debt Service 
Total Operating Expenses 

Category of CAFR components (continued) 

Sources & Uses  Change in Fund Balances 

Ratios 

NEGLECTED 

NEGLECTED 

NEGLECTED 

KPI-Driven Predictive ML Models Approach 
Towards Municipal Budgeting Optimization 

Bo Shen 

Pradipta A. B. Hendri 

Kun Shao 

{boshen, dip, kunshao}@stanford.edu 

(CS229 Machine Learning Project Final Report) 

Abstractâ€”  this  project  aims  to  use  machine  learning 
techniques  to  predict  citiesâ€™  Key  Performance  Indicators 
(KPI)  based  on  municipal  governmental  budget  compo-
nents towards segments including education, public safety, 
and  health.    The  project  started  with  building  prediction 
model  for  the  City  of  Palo  Alto  and  then  generalized  the 
model  for  a  cluster  of  cities  that  contains  the  City  of  Palo 
Alto.   The result shows that autoregressive linear models 
can predict Crime Index and Health Index reasonably well.  
By building satisfactory KPI prediction models, this project 
sets a path towards municipal budgeting optimization. 

I. INTRODUCTION 

Key Performance Indicators (KPIs) of a city are a set of met-
rics used to evaluate factors that are crucial to the success of a 
city. Government annual budgets name and prioritize regional 
KPI.  Through  agency  sub-budgets  and  programs,  agency  mis-
sions are turned into programs addressing single or multiple cit-
izen concerns about economic development, education, energy, 
environment,  health,  housing,  shared  infrastructure,  public 
safety and other factors. 

Budgets  reveal  spending  by  a  single  program  in  isolation.  
Given the complexities of urban life, a single KPI (for instance, 
health) can be the function of multiple other elements (such as 
environmental and food pollutants, housing quality, transporta-
tion use, and education). Likewise, strategies of improving any 
given KPI can be ways of budget allocation across multiple agen-
cies. 

The project aims to use machine learning to predict KPI using 
municipal budget data and  set  a path to  optimize a part of  or 
entire budget towards certain KPIs. 

II. METHODOLOGIES 

As an overview, we began with accumulating budgeting and 
KPI data for different cities in the US.   We started with building 
prediction model for  the City  of Palo  Altoâ€™s Crime Index.     We 
then applied unsupervised clustering on demographics data of 
these cities to identify similarity groups and attempted to gen-
eralize the prediction model. The cluster to which Palo Alto be-
longs was chosen as the group to which we generalized our anal-
ysis. 

A.  KPIs 

Cities  and  other  independent  parties  evaluate  the  perfor-

mance using metrics such as the following. 

1.  Crime rate, as a measure of safety 
2.  Proportion of residents self-reporting better than fair or 

poor health, as a measure of health of city residents  

3.  Ratio  of average household income to  cost-of-living in-

dex (COLI), as a measure of affordability 

4.  Ethnicity diversity index, which is a normalized measure 
of ethnicity composition deviation index relative to state-
wide ethnicity composition 

It is the interest of municipal government to develop the nec-
essary  infrastructure and environment to  bring the maximum 
benefit  for  the  inhabitants,  and  KPI-driven  approach is  a  suc-
cinct method to  summarize the  performance of a city  when it 
comes to numerical calculations within a data-driven decision 
support system. 

B.  Budget Components 

Municipalities produce Comprehensive Annual Financial Re-
port (CAFR) that they publish on online and printed media. The 
CAFR segments city financial budgeting as follows. 

Category of CAFR components 

Revenues 

Expenses 

Sales and Use Tax Revenues 
Property Tax Revenues 
Other Tax Revenues 
Charges for Services 
Licenses and Fees 
Intergovernmental Grants 
Investment Earnings 
Miscellaneous Revenues 
Total Revenues 

General Government Expenses 
Human Resources Expenses 
Public Safety Expenses 
Public Service Expenses 
Public Works Expenses 
Environmental Expenses 
Other Program Expenses 
Capital Outlay 
Principal Debt Service 
Interest Debt Service 
Total Operating Expenses 

Category of CAFR components (continued) 

Sources & Uses  Change in Fund Balances 

Ratios 

NEGLECTED 

NEGLECTED 

NEGLECTED 

These components serve as categories of focus areas in which 
the city invest for maintenance and future development. Bloom-
berg L.P. collected these financial data from numbers of cities in 
the United States, and we can  access data through Bloomberg 
Professional service provided in special Bloomberg Terminal. 

5.  C2ERâ€™s Cost-of-living Index (COLI) in 2014 
Each cluster will have its own regressive model, ultimately al-
lowing higher degree of freedom to  the big picture, to  reduce 
generalization  error.    We  explore  multiple  clustering  algo-
rithms, which are: 

C.  Data Set 

For financial data, we obtained CAFR data from 380 cities in 

California for years between 2004 and 2014. 

For  KPI  data,  we  obtained  crime  rates,  cost  of  living  index, 
health  index,  and  median  income  from  all  cities in  the  United 
States annually, from 2004 up to 2014. 

For demographics data, we obtained 2010 census population 

data of all census-registered cities in the United States.  

To  aggregate  the  data,  we  chose  geoid  primary  index  pro-
vided by United States Census Bureau to establish relationships 
in the rows of data obtained from different data sources. 

D.  Regression Analysis 

First, we attempted to predict the crime index of the City of 
Palo  Alto using its financial data. We  explored five regression 
models: 

1.  Bayesian Linear Regression, 
2.  Neural Network Regression, 
3.  Boosted Decision Tree, 
4.  Linear Regression, and  
5.  Decision Forest Regression.  
Among 20 financial features, we first cleaned the missing data 
by removing features with missing data; it left us with 14 fea-
tures with complete dataset.  

For  each  of  the  five  regression  models,  we  first  trained  the 
model using the all 14 features with complete dataset.  Then, we 
trained the models using just one feature, the public safety ex-
pense, which intuitively, we think is most correlated to crime in-
dex.  Lastly, we used filter-based selection methods to identify 
the features that are most predictive, and trained the models us-
ing the top two  features.  The  five feature scoring method we 
tried are: 

1.  Pearson Correlation (Pearsonâ€™s ğœŒ), 
2.  Mutual Information (MI), 
3.  Spearman Correlation (Spearmanâ€™s ğœŒ), and 
4.  Chi-squared (ğœ’2) Test. 
We  apply  this  method  to  more  cities  as  determined  by  the 
clustering result, and obtain a more generic model trained with 
data belonging to multiple cities instead of a single one. 

E.  Unsupervised Clustering 

It is a possibility  that there are multiple underlying models 
between  financial  budgeting  and  KPIs  for  cities  depending on 
some hidden factors. In reality, cities dissimilar in scale and liv-
ing  standard  require  different  policies  of governance  to  make 
successful progress. To generalize the prediction model, we at-
tempt  to  establish  similarity  clusters  of  cities  in  the  dataset 
based on scale  and living standard, with the following factors 
considered: 

1.  Population census in 2010 
2.  10-year population growth from 2000 to 2010 
3.  Total revenue per capita in 2014 
4.  Total expense per capita in 2014 

1.  K-means clustering, 
2.  K-medoids clustering, 
3.  Agglomerative clustering, and 
4.  Gaussian mixture model. 
We determine the cluster count using â„“2-norm Silhouette 
value as a measure of purity from dissimilarity (higher is bet-
ter): 

 

silhouette(ğ‘¥ğ‘–) =

where: 

â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2 âˆ’ â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2

max{â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2, â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2}

âˆˆ [âˆ’1,1] 

ğ¶(ğ‘¥ğ‘–): Centroid of cluster containing ğ‘¥ğ‘– 
ğ¶â€²(ğ‘¥ğ‘–): Centroid nearest to ğ‘¥ğ‘– satisfying ğ¶(ğ‘¥ğ‘–) â‰  ğ¶â€²(ğ‘¥ğ‘–) 
 
In addition, separately for each algorithm and cluster count 
we remove outlier points from data that induces the algorithm 
to create clusters containing low number of points. With this re-
duced data set, we run each clustering algorithm with 100 rep-
licates  per  cluster  count,  choosing  the  result  that  maximizes 
mean Silhouette value. We then choose the model that maxim-
izes the mean Silhouette value over different cluster counts. The 
pseudo-algorithm for each clustering algorithm is as follows: 

 

def n_replicate = 100 
for k = 2 to sqrt(size(data)): 
  def data_k = data 
  def C_low = {dummy point} 
  while size(C_low) > 0: 
    run clustering on data_k 
    if any cluster has less than min_size points: 
      C_low = join all clusters with size < min_size 
      remove all points in C_low data from data_k 
  end while 
  for r = 1 to n_replicate: 
    def index_kr = result of clustering on data_k 

    def sil_kr = silhouette value of index_r 

    if mean(sil_kr) > mean(sil_k): 
      index_k = index_kr, sil_k = sil_kr 
    end if 
  end for 
end for 
def index = index_k that maximizes sil_k over k 

III. RESULTS 

A.  Baseline Model 

First, we attempted to predict the crime index of the City of 

Palo Alto using its financial data.  

The results of feature scoring in descending order is shown 
on  Figure  1.  To  evaluate  the  models,  10-fold  cross  validation 
was used. The estimated generalization errors of each model in 
terms of root mean squared error (RMSE) are presented in Fig-
ure 2.  Each row represents errors of models using different sets 
of features. For example, the row, Public Safety Expenses, shows 
the errors from just using one feature, Public Safety Expenses; 
the row, Pearson Correlation, shows the errors models using the 

KPI-Driven Predictive ML Models Approach 
Towards Municipal Budgeting Optimization 

Bo Shen 

Pradipta A. B. Hendri 

Kun Shao 

{boshen, dip, kunshao}@stanford.edu 

(CS229 Machine Learning Project Final Report) 

Abstractâ€”  this  project  aims  to  use  machine  learning 
techniques  to  predict  citiesâ€™  Key  Performance  Indicators 
(KPI)  based  on  municipal  governmental  budget  compo-
nents towards segments including education, public safety, 
and  health.    The  project  started  with  building  prediction 
model  for  the  City  of  Palo  Alto  and  then  generalized  the 
model  for  a  cluster  of  cities  that  contains  the  City  of  Palo 
Alto.   The result shows that autoregressive linear models 
can predict Crime Index and Health Index reasonably well.  
By building satisfactory KPI prediction models, this project 
sets a path towards municipal budgeting optimization. 

I. INTRODUCTION 

Key Performance Indicators (KPIs) of a city are a set of met-
rics used to evaluate factors that are crucial to the success of a 
city. Government annual budgets name and prioritize regional 
KPI.  Through  agency  sub-budgets  and  programs,  agency  mis-
sions are turned into programs addressing single or multiple cit-
izen concerns about economic development, education, energy, 
environment,  health,  housing,  shared  infrastructure,  public 
safety and other factors. 

Budgets  reveal  spending  by  a  single  program  in  isolation.  
Given the complexities of urban life, a single KPI (for instance, 
health) can be the function of multiple other elements (such as 
environmental and food pollutants, housing quality, transporta-
tion use, and education). Likewise, strategies of improving any 
given KPI can be ways of budget allocation across multiple agen-
cies. 

The project aims to use machine learning to predict KPI using 
municipal budget data and  set  a path to  optimize a part of  or 
entire budget towards certain KPIs. 

II. METHODOLOGIES 

As an overview, we began with accumulating budgeting and 
KPI data for different cities in the US.   We started with building 
prediction model for  the City  of Palo  Altoâ€™s Crime Index.     We 
then applied unsupervised clustering on demographics data of 
these cities to identify similarity groups and attempted to gen-
eralize the prediction model. The cluster to which Palo Alto be-
longs was chosen as the group to which we generalized our anal-
ysis. 

A.  KPIs 

Cities  and  other  independent  parties  evaluate  the  perfor-

mance using metrics such as the following. 

1.  Crime rate, as a measure of safety 
2.  Proportion of residents self-reporting better than fair or 

poor health, as a measure of health of city residents  

3.  Ratio  of average household income to  cost-of-living in-

dex (COLI), as a measure of affordability 

4.  Ethnicity diversity index, which is a normalized measure 
of ethnicity composition deviation index relative to state-
wide ethnicity composition 

It is the interest of municipal government to develop the nec-
essary  infrastructure and environment to  bring the maximum 
benefit  for  the  inhabitants,  and  KPI-driven  approach is  a  suc-
cinct method to  summarize the  performance of a city  when it 
comes to numerical calculations within a data-driven decision 
support system. 

B.  Budget Components 

Municipalities produce Comprehensive Annual Financial Re-
port (CAFR) that they publish on online and printed media. The 
CAFR segments city financial budgeting as follows. 

Category of CAFR components 

Revenues 

Expenses 

Sales and Use Tax Revenues 
Property Tax Revenues 
Other Tax Revenues 
Charges for Services 
Licenses and Fees 
Intergovernmental Grants 
Investment Earnings 
Miscellaneous Revenues 
Total Revenues 

General Government Expenses 
Human Resources Expenses 
Public Safety Expenses 
Public Service Expenses 
Public Works Expenses 
Environmental Expenses 
Other Program Expenses 
Capital Outlay 
Principal Debt Service 
Interest Debt Service 
Total Operating Expenses 

Category of CAFR components (continued) 

Sources & Uses  Change in Fund Balances 

Ratios 

NEGLECTED 

NEGLECTED 

NEGLECTED 

These components serve as categories of focus areas in which 
the city invest for maintenance and future development. Bloom-
berg L.P. collected these financial data from numbers of cities in 
the United States, and we can  access data through Bloomberg 
Professional service provided in special Bloomberg Terminal. 

5.  C2ERâ€™s Cost-of-living Index (COLI) in 2014 
Each cluster will have its own regressive model, ultimately al-
lowing higher degree of freedom to  the big picture, to  reduce 
generalization  error.    We  explore  multiple  clustering  algo-
rithms, which are: 

C.  Data Set 

For financial data, we obtained CAFR data from 380 cities in 

California for years between 2004 and 2014. 

For  KPI  data,  we  obtained  crime  rates,  cost  of  living  index, 
health  index,  and  median  income  from  all  cities in  the  United 
States annually, from 2004 up to 2014. 

For demographics data, we obtained 2010 census population 

data of all census-registered cities in the United States.  

To  aggregate  the  data,  we  chose  geoid  primary  index  pro-
vided by United States Census Bureau to establish relationships 
in the rows of data obtained from different data sources. 

D.  Regression Analysis 

First, we attempted to predict the crime index of the City of 
Palo  Alto using its financial data. We  explored five regression 
models: 

1.  Bayesian Linear Regression, 
2.  Neural Network Regression, 
3.  Boosted Decision Tree, 
4.  Linear Regression, and  
5.  Decision Forest Regression.  
Among 20 financial features, we first cleaned the missing data 
by removing features with missing data; it left us with 14 fea-
tures with complete dataset.  

For  each  of  the  five  regression  models,  we  first  trained  the 
model using the all 14 features with complete dataset.  Then, we 
trained the models using just one feature, the public safety ex-
pense, which intuitively, we think is most correlated to crime in-
dex.  Lastly, we used filter-based selection methods to identify 
the features that are most predictive, and trained the models us-
ing the top two  features.  The  five feature scoring method we 
tried are: 

1.  Pearson Correlation (Pearsonâ€™s ğœŒ), 
2.  Mutual Information (MI), 
3.  Spearman Correlation (Spearmanâ€™s ğœŒ), and 
4.  Chi-squared (ğœ’2) Test. 
We  apply  this  method  to  more  cities  as  determined  by  the 
clustering result, and obtain a more generic model trained with 
data belonging to multiple cities instead of a single one. 

E.  Unsupervised Clustering 

It is a possibility  that there are multiple underlying models 
between  financial  budgeting  and  KPIs  for  cities  depending on 
some hidden factors. In reality, cities dissimilar in scale and liv-
ing  standard  require  different  policies  of governance  to  make 
successful progress. To generalize the prediction model, we at-
tempt  to  establish  similarity  clusters  of  cities  in  the  dataset 
based on scale  and living standard, with the following factors 
considered: 

1.  Population census in 2010 
2.  10-year population growth from 2000 to 2010 
3.  Total revenue per capita in 2014 
4.  Total expense per capita in 2014 

1.  K-means clustering, 
2.  K-medoids clustering, 
3.  Agglomerative clustering, and 
4.  Gaussian mixture model. 
We determine the cluster count using â„“2-norm Silhouette 
value as a measure of purity from dissimilarity (higher is bet-
ter): 

 

silhouette(ğ‘¥ğ‘–) =

where: 

â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2 âˆ’ â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2

max{â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2, â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2}

âˆˆ [âˆ’1,1] 

ğ¶(ğ‘¥ğ‘–): Centroid of cluster containing ğ‘¥ğ‘– 
ğ¶â€²(ğ‘¥ğ‘–): Centroid nearest to ğ‘¥ğ‘– satisfying ğ¶(ğ‘¥ğ‘–) â‰  ğ¶â€²(ğ‘¥ğ‘–) 
 
In addition, separately for each algorithm and cluster count 
we remove outlier points from data that induces the algorithm 
to create clusters containing low number of points. With this re-
duced data set, we run each clustering algorithm with 100 rep-
licates  per  cluster  count,  choosing  the  result  that  maximizes 
mean Silhouette value. We then choose the model that maxim-
izes the mean Silhouette value over different cluster counts. The 
pseudo-algorithm for each clustering algorithm is as follows: 

 

def n_replicate = 100 
for k = 2 to sqrt(size(data)): 
  def data_k = data 
  def C_low = {dummy point} 
  while size(C_low) > 0: 
    run clustering on data_k 
    if any cluster has less than min_size points: 
      C_low = join all clusters with size < min_size 
      remove all points in C_low data from data_k 
  end while 
  for r = 1 to n_replicate: 
    def index_kr = result of clustering on data_k 

    def sil_kr = silhouette value of index_r 

    if mean(sil_kr) > mean(sil_k): 
      index_k = index_kr, sil_k = sil_kr 
    end if 
  end for 
end for 
def index = index_k that maximizes sil_k over k 

III. RESULTS 

A.  Baseline Model 

First, we attempted to predict the crime index of the City of 

Palo Alto using its financial data.  

The results of feature scoring in descending order is shown 
on  Figure  1.  To  evaluate  the  models,  10-fold  cross  validation 
was used. The estimated generalization errors of each model in 
terms of root mean squared error (RMSE) are presented in Fig-
ure 2.  Each row represents errors of models using different sets 
of features. For example, the row, Public Safety Expenses, shows 
the errors from just using one feature, Public Safety Expenses; 
the row, Pearson Correlation, shows the errors models using the 

top  two  features  selected  by  Pearson  Correlation  Method. 
Among all the models we trained, the linear regression model 
using the public safety expenses alone  was able to predict the 
crime index with the lowest error of 19.80. 
 

shown in Figure 3. Additionally, another criterion is applied for 
a  model  with  given  parameter  to  be  acceptable:  all  cluster 
within the model must have at least one point with Silhouette 
value higher than the model-wide mean Silhouette value. Points 
satisfying this criterion is marked with black circle in Figure 3. 
 

Top 2 features using Ï‡^2 

Top 2 features using 

Spearmanâ€™s Ï 

Top 2 features using MI

Top 2 features using 

Pearsonâ€™s Ï

Public Safety Expenses only

All features

60
Bayesian Linear NN Decision Forest

20

0

40

100

80
Boosted DT

Linear

  
Figure 2â€”Cross-validation RMSE of baseline model. 

Figure 1â€”Feature scoring. 

 

B.  Unsupervised Clustering 

Unsupervised  clustering  was  applied  against  separately  ob-
tained scale and living standard data for 477 cities in California 
as  described  in  Part  E  of  Methodologies.  Unfortunately,  some 
values are found to be missing after merging the factors. Due to 
the  nature  of  unsupervised  clustering,  it  makes  little  sense  to 
apply imputation or surrogate techniques, so we simply remove 
points having one or  more missing factors and were  left with 
364 points. Clustering performance based on Silhouette value is 

Figure 3â€”Clustering algorithms performance comparison. 

 

 
From Figure 3 we can observe that Gaussian mixture model 
quickly degenerates with increasing cluster count, whereas the 
other 3 considered algorithms performs similarly. We note that 
Silhouette value by definition will be high for cluster count of 2 
so long as the algorithm is allowed to converge, due to â„“2-norm 
being used for both clustering and Silhouette, as ğ¶(ğ‘¥ğ‘–) â‰¥ ğ¶â€²(ğ‘¥ğ‘–) 
always in this setting, keeping silhouette(ğ‘¥ğ‘–) â‰¥ 0 for all points. 
With this consideration,  as  well  as  desire  to  lower  the  size  of 
cluster  to  which  Palo  Alto  belong,  we  pick  the  agglomerative 
clustering model pruned to 4 clusters because it maximizes the 
Silhouette value. Figure 4 illustrates how this model clusters the 

KPI-Driven Predictive ML Models Approach 
Towards Municipal Budgeting Optimization 

Bo Shen 

Pradipta A. B. Hendri 

Kun Shao 

{boshen, dip, kunshao}@stanford.edu 

(CS229 Machine Learning Project Final Report) 

Abstractâ€”  this  project  aims  to  use  machine  learning 
techniques  to  predict  citiesâ€™  Key  Performance  Indicators 
(KPI)  based  on  municipal  governmental  budget  compo-
nents towards segments including education, public safety, 
and  health.    The  project  started  with  building  prediction 
model  for  the  City  of  Palo  Alto  and  then  generalized  the 
model  for  a  cluster  of  cities  that  contains  the  City  of  Palo 
Alto.   The result shows that autoregressive linear models 
can predict Crime Index and Health Index reasonably well.  
By building satisfactory KPI prediction models, this project 
sets a path towards municipal budgeting optimization. 

I. INTRODUCTION 

Key Performance Indicators (KPIs) of a city are a set of met-
rics used to evaluate factors that are crucial to the success of a 
city. Government annual budgets name and prioritize regional 
KPI.  Through  agency  sub-budgets  and  programs,  agency  mis-
sions are turned into programs addressing single or multiple cit-
izen concerns about economic development, education, energy, 
environment,  health,  housing,  shared  infrastructure,  public 
safety and other factors. 

Budgets  reveal  spending  by  a  single  program  in  isolation.  
Given the complexities of urban life, a single KPI (for instance, 
health) can be the function of multiple other elements (such as 
environmental and food pollutants, housing quality, transporta-
tion use, and education). Likewise, strategies of improving any 
given KPI can be ways of budget allocation across multiple agen-
cies. 

The project aims to use machine learning to predict KPI using 
municipal budget data and  set  a path to  optimize a part of  or 
entire budget towards certain KPIs. 

II. METHODOLOGIES 

As an overview, we began with accumulating budgeting and 
KPI data for different cities in the US.   We started with building 
prediction model for  the City  of Palo  Altoâ€™s Crime Index.     We 
then applied unsupervised clustering on demographics data of 
these cities to identify similarity groups and attempted to gen-
eralize the prediction model. The cluster to which Palo Alto be-
longs was chosen as the group to which we generalized our anal-
ysis. 

A.  KPIs 

Cities  and  other  independent  parties  evaluate  the  perfor-

mance using metrics such as the following. 

1.  Crime rate, as a measure of safety 
2.  Proportion of residents self-reporting better than fair or 

poor health, as a measure of health of city residents  

3.  Ratio  of average household income to  cost-of-living in-

dex (COLI), as a measure of affordability 

4.  Ethnicity diversity index, which is a normalized measure 
of ethnicity composition deviation index relative to state-
wide ethnicity composition 

It is the interest of municipal government to develop the nec-
essary  infrastructure and environment to  bring the maximum 
benefit  for  the  inhabitants,  and  KPI-driven  approach is  a  suc-
cinct method to  summarize the  performance of a city  when it 
comes to numerical calculations within a data-driven decision 
support system. 

B.  Budget Components 

Municipalities produce Comprehensive Annual Financial Re-
port (CAFR) that they publish on online and printed media. The 
CAFR segments city financial budgeting as follows. 

Category of CAFR components 

Revenues 

Expenses 

Sales and Use Tax Revenues 
Property Tax Revenues 
Other Tax Revenues 
Charges for Services 
Licenses and Fees 
Intergovernmental Grants 
Investment Earnings 
Miscellaneous Revenues 
Total Revenues 

General Government Expenses 
Human Resources Expenses 
Public Safety Expenses 
Public Service Expenses 
Public Works Expenses 
Environmental Expenses 
Other Program Expenses 
Capital Outlay 
Principal Debt Service 
Interest Debt Service 
Total Operating Expenses 

Category of CAFR components (continued) 

Sources & Uses  Change in Fund Balances 

Ratios 

NEGLECTED 

NEGLECTED 

NEGLECTED 

These components serve as categories of focus areas in which 
the city invest for maintenance and future development. Bloom-
berg L.P. collected these financial data from numbers of cities in 
the United States, and we can  access data through Bloomberg 
Professional service provided in special Bloomberg Terminal. 

5.  C2ERâ€™s Cost-of-living Index (COLI) in 2014 
Each cluster will have its own regressive model, ultimately al-
lowing higher degree of freedom to  the big picture, to  reduce 
generalization  error.    We  explore  multiple  clustering  algo-
rithms, which are: 

C.  Data Set 

For financial data, we obtained CAFR data from 380 cities in 

California for years between 2004 and 2014. 

For  KPI  data,  we  obtained  crime  rates,  cost  of  living  index, 
health  index,  and  median  income  from  all  cities in  the  United 
States annually, from 2004 up to 2014. 

For demographics data, we obtained 2010 census population 

data of all census-registered cities in the United States.  

To  aggregate  the  data,  we  chose  geoid  primary  index  pro-
vided by United States Census Bureau to establish relationships 
in the rows of data obtained from different data sources. 

D.  Regression Analysis 

First, we attempted to predict the crime index of the City of 
Palo  Alto using its financial data. We  explored five regression 
models: 

1.  Bayesian Linear Regression, 
2.  Neural Network Regression, 
3.  Boosted Decision Tree, 
4.  Linear Regression, and  
5.  Decision Forest Regression.  
Among 20 financial features, we first cleaned the missing data 
by removing features with missing data; it left us with 14 fea-
tures with complete dataset.  

For  each  of  the  five  regression  models,  we  first  trained  the 
model using the all 14 features with complete dataset.  Then, we 
trained the models using just one feature, the public safety ex-
pense, which intuitively, we think is most correlated to crime in-
dex.  Lastly, we used filter-based selection methods to identify 
the features that are most predictive, and trained the models us-
ing the top two  features.  The  five feature scoring method we 
tried are: 

1.  Pearson Correlation (Pearsonâ€™s ğœŒ), 
2.  Mutual Information (MI), 
3.  Spearman Correlation (Spearmanâ€™s ğœŒ), and 
4.  Chi-squared (ğœ’2) Test. 
We  apply  this  method  to  more  cities  as  determined  by  the 
clustering result, and obtain a more generic model trained with 
data belonging to multiple cities instead of a single one. 

E.  Unsupervised Clustering 

It is a possibility  that there are multiple underlying models 
between  financial  budgeting  and  KPIs  for  cities  depending on 
some hidden factors. In reality, cities dissimilar in scale and liv-
ing  standard  require  different  policies  of governance  to  make 
successful progress. To generalize the prediction model, we at-
tempt  to  establish  similarity  clusters  of  cities  in  the  dataset 
based on scale  and living standard, with the following factors 
considered: 

1.  Population census in 2010 
2.  10-year population growth from 2000 to 2010 
3.  Total revenue per capita in 2014 
4.  Total expense per capita in 2014 

1.  K-means clustering, 
2.  K-medoids clustering, 
3.  Agglomerative clustering, and 
4.  Gaussian mixture model. 
We determine the cluster count using â„“2-norm Silhouette 
value as a measure of purity from dissimilarity (higher is bet-
ter): 

 

silhouette(ğ‘¥ğ‘–) =

where: 

â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2 âˆ’ â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2

max{â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2, â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2}

âˆˆ [âˆ’1,1] 

ğ¶(ğ‘¥ğ‘–): Centroid of cluster containing ğ‘¥ğ‘– 
ğ¶â€²(ğ‘¥ğ‘–): Centroid nearest to ğ‘¥ğ‘– satisfying ğ¶(ğ‘¥ğ‘–) â‰  ğ¶â€²(ğ‘¥ğ‘–) 
 
In addition, separately for each algorithm and cluster count 
we remove outlier points from data that induces the algorithm 
to create clusters containing low number of points. With this re-
duced data set, we run each clustering algorithm with 100 rep-
licates  per  cluster  count,  choosing  the  result  that  maximizes 
mean Silhouette value. We then choose the model that maxim-
izes the mean Silhouette value over different cluster counts. The 
pseudo-algorithm for each clustering algorithm is as follows: 

 

def n_replicate = 100 
for k = 2 to sqrt(size(data)): 
  def data_k = data 
  def C_low = {dummy point} 
  while size(C_low) > 0: 
    run clustering on data_k 
    if any cluster has less than min_size points: 
      C_low = join all clusters with size < min_size 
      remove all points in C_low data from data_k 
  end while 
  for r = 1 to n_replicate: 
    def index_kr = result of clustering on data_k 

    def sil_kr = silhouette value of index_r 

    if mean(sil_kr) > mean(sil_k): 
      index_k = index_kr, sil_k = sil_kr 
    end if 
  end for 
end for 
def index = index_k that maximizes sil_k over k 

III. RESULTS 

A.  Baseline Model 

First, we attempted to predict the crime index of the City of 

Palo Alto using its financial data.  

The results of feature scoring in descending order is shown 
on  Figure  1.  To  evaluate  the  models,  10-fold  cross  validation 
was used. The estimated generalization errors of each model in 
terms of root mean squared error (RMSE) are presented in Fig-
ure 2.  Each row represents errors of models using different sets 
of features. For example, the row, Public Safety Expenses, shows 
the errors from just using one feature, Public Safety Expenses; 
the row, Pearson Correlation, shows the errors models using the 

top  two  features  selected  by  Pearson  Correlation  Method. 
Among all the models we trained, the linear regression model 
using the public safety expenses alone  was able to predict the 
crime index with the lowest error of 19.80. 
 

shown in Figure 3. Additionally, another criterion is applied for 
a  model  with  given  parameter  to  be  acceptable:  all  cluster 
within the model must have at least one point with Silhouette 
value higher than the model-wide mean Silhouette value. Points 
satisfying this criterion is marked with black circle in Figure 3. 
 

Top 2 features using Ï‡^2 

Top 2 features using 

Spearmanâ€™s Ï 

Top 2 features using MI

Top 2 features using 

Pearsonâ€™s Ï

Public Safety Expenses only

All features

60
Bayesian Linear NN Decision Forest

20

0

40

100

80
Boosted DT

Linear

  
Figure 2â€”Cross-validation RMSE of baseline model. 

Figure 1â€”Feature scoring. 

 

B.  Unsupervised Clustering 

Unsupervised  clustering  was  applied  against  separately  ob-
tained scale and living standard data for 477 cities in California 
as  described  in  Part  E  of  Methodologies.  Unfortunately,  some 
values are found to be missing after merging the factors. Due to 
the  nature  of  unsupervised  clustering,  it  makes  little  sense  to 
apply imputation or surrogate techniques, so we simply remove 
points having one or  more missing factors and were  left with 
364 points. Clustering performance based on Silhouette value is 

Figure 3â€”Clustering algorithms performance comparison. 

 

 
From Figure 3 we can observe that Gaussian mixture model 
quickly degenerates with increasing cluster count, whereas the 
other 3 considered algorithms performs similarly. We note that 
Silhouette value by definition will be high for cluster count of 2 
so long as the algorithm is allowed to converge, due to â„“2-norm 
being used for both clustering and Silhouette, as ğ¶(ğ‘¥ğ‘–) â‰¥ ğ¶â€²(ğ‘¥ğ‘–) 
always in this setting, keeping silhouette(ğ‘¥ğ‘–) â‰¥ 0 for all points. 
With this consideration,  as  well  as  desire  to  lower  the  size  of 
cluster  to  which  Palo  Alto  belong,  we  pick  the  agglomerative 
clustering model pruned to 4 clusters because it maximizes the 
Silhouette value. Figure 4 illustrates how this model clusters the 

points, using principal components. We found 225 cities similar 
to Palo Alto based on the factors considered. 

In Figure 5 we see that the cross-validated ğ‘…2 receive little to 
no improvement past the first order of autoregression, so in the 
interest  of  simplicity  and  avoiding  overfitting,  we  opt  for  the 
first order model: 

 

ğ¼ğ‘†(ğ‘¡) = 0.0956 âˆ™ ğ¸ğ‘ƒğ‘†(ğ‘¡) + 0.9410 âˆ™ ğ¼ğ‘†(ğ‘¡ âˆ’ 1) + 4.4689 

where: 

ğ¼ğ‘†(ğ‘¡): Crime index of the year 
ğ¼ğ‘†(ğ‘¡ âˆ’ 1): Crime index of preceding year (autoregressive) 
ğ¸ğ‘ƒğ‘†(ğ‘¡): Public safety expense of the year, in million US$ 
 

Figure 4â€”Agglomerative clustering on PCA, k=4. 

 

 

Based on our baseline model findings in Figure 2, we deter-
mine that the project should be scoped to linear models. To im-
prove the performance of models, we augment stepwise linear 
model construction with autoregressive terms. The significance 
of autoregressive terms is supported by  assumption  that pre-
existing  quality  of  life  in  the  city  affects  the  extent  to  which 
budgeting decision for the year could influence the outcome of 
the development which is incremental in nature.  

C.  Public Safety KPI 

We  applied  linear  model  augmented  with  autoregressive 
terms to the public safety KPI, which is the crime index of cities 
inside cluster containing Palo Alto. The chronological extent of 
our dataset allows for autoregression up to 12th order, and we 
used  10-fold  cross-validated ğ‘…2  as  goodness-of-fit  statistic  of 
models. The result is shown in Figure 5, along with p-values of 
the coefficients involved in the linear model. To evaluate the sig-
nificance of augmented autoregressive terms, we consider only 
the maximum of p-values associated with these terms. 

Shown  also  in  Figure  5  is  the  Akaike  Information  Criteria 
(AIC) of models, corrected to account for finite sample sizes. Alt-
hough AIC typically provides sensible measure to compare mod-
els having varying number of coefficients, in this application we 
observe that the AIC decreases due to the likelihood component 
diminishing in value. This may be caused by the number of train-
ing samples accounted for in AIC calculation decreases as we ex-
pend  the  temporal  limit  of  our  dataset  into  providing  values 
used  for  autoregressive  terms.  Therefore,  we  simply  use  the 
cross-validated ğ‘…2 to choose the model. 

Figure 5â€”Performance of autoregressive linear models 

 

for public safety KPI. 

D.  Health KPI 

We noted from Figure 2 that using all CAFR components in-
creased the validation error of model. For health KPI model, we 
apply stepwise construction of linear model in addition to the 
autoregressive terms similar to public safety KPI model. Step-
wise selection will prevent overfitting due to including all CAFR 
components. 

During model construction, we encountered a lot of missing 
data for CAFR components for a given year. To maximize train-
ing dataset utilization, since the model is linear, we impute miss-
ing  data  with  zeros.  Our  temporal  dataset  enables  us  to  con-
struct up to 9th order autoregression. 

We found, as can be seen in Figure 6, that the autoregressive 
models  perform  poorly  for  models  lower  than  8th  order.  The 
AR(8)  model,  however,  does  not  include  any  of  CAFR  compo-
nents. Therefore, we will pick the AR(9) model: 

 

9

ğ¼ğ»(ğ‘¡) = 0.0020 âˆ™ ğ¸ğ»ğ‘… + âˆ‘{ğ›¼ğ‘ğ¼ğ»(ğ‘¡ âˆ’ ğ‘)}

+ 0.1060 

ğ‘=1

where: 

ğ¼ğ»(ğ‘¡): Health index of the year 
ğ¼ğ‘†(ğ‘¡ âˆ’ ğ‘): Health index of ğ‘ years ago (autoregressive) 
ğ¸ğ»ğ‘…(ğ‘¡): Human resources expense of the year, in million US$ 
ğ›¼ğ‘: Coefficient of p-th autoregressive term 

 

KPI-Driven Predictive ML Models Approach 
Towards Municipal Budgeting Optimization 

Bo Shen 

Pradipta A. B. Hendri 

Kun Shao 

{boshen, dip, kunshao}@stanford.edu 

(CS229 Machine Learning Project Final Report) 

Abstractâ€”  this  project  aims  to  use  machine  learning 
techniques  to  predict  citiesâ€™  Key  Performance  Indicators 
(KPI)  based  on  municipal  governmental  budget  compo-
nents towards segments including education, public safety, 
and  health.    The  project  started  with  building  prediction 
model  for  the  City  of  Palo  Alto  and  then  generalized  the 
model  for  a  cluster  of  cities  that  contains  the  City  of  Palo 
Alto.   The result shows that autoregressive linear models 
can predict Crime Index and Health Index reasonably well.  
By building satisfactory KPI prediction models, this project 
sets a path towards municipal budgeting optimization. 

I. INTRODUCTION 

Key Performance Indicators (KPIs) of a city are a set of met-
rics used to evaluate factors that are crucial to the success of a 
city. Government annual budgets name and prioritize regional 
KPI.  Through  agency  sub-budgets  and  programs,  agency  mis-
sions are turned into programs addressing single or multiple cit-
izen concerns about economic development, education, energy, 
environment,  health,  housing,  shared  infrastructure,  public 
safety and other factors. 

Budgets  reveal  spending  by  a  single  program  in  isolation.  
Given the complexities of urban life, a single KPI (for instance, 
health) can be the function of multiple other elements (such as 
environmental and food pollutants, housing quality, transporta-
tion use, and education). Likewise, strategies of improving any 
given KPI can be ways of budget allocation across multiple agen-
cies. 

The project aims to use machine learning to predict KPI using 
municipal budget data and  set  a path to  optimize a part of  or 
entire budget towards certain KPIs. 

II. METHODOLOGIES 

As an overview, we began with accumulating budgeting and 
KPI data for different cities in the US.   We started with building 
prediction model for  the City  of Palo  Altoâ€™s Crime Index.     We 
then applied unsupervised clustering on demographics data of 
these cities to identify similarity groups and attempted to gen-
eralize the prediction model. The cluster to which Palo Alto be-
longs was chosen as the group to which we generalized our anal-
ysis. 

A.  KPIs 

Cities  and  other  independent  parties  evaluate  the  perfor-

mance using metrics such as the following. 

1.  Crime rate, as a measure of safety 
2.  Proportion of residents self-reporting better than fair or 

poor health, as a measure of health of city residents  

3.  Ratio  of average household income to  cost-of-living in-

dex (COLI), as a measure of affordability 

4.  Ethnicity diversity index, which is a normalized measure 
of ethnicity composition deviation index relative to state-
wide ethnicity composition 

It is the interest of municipal government to develop the nec-
essary  infrastructure and environment to  bring the maximum 
benefit  for  the  inhabitants,  and  KPI-driven  approach is  a  suc-
cinct method to  summarize the  performance of a city  when it 
comes to numerical calculations within a data-driven decision 
support system. 

B.  Budget Components 

Municipalities produce Comprehensive Annual Financial Re-
port (CAFR) that they publish on online and printed media. The 
CAFR segments city financial budgeting as follows. 

Category of CAFR components 

Revenues 

Expenses 

Sales and Use Tax Revenues 
Property Tax Revenues 
Other Tax Revenues 
Charges for Services 
Licenses and Fees 
Intergovernmental Grants 
Investment Earnings 
Miscellaneous Revenues 
Total Revenues 

General Government Expenses 
Human Resources Expenses 
Public Safety Expenses 
Public Service Expenses 
Public Works Expenses 
Environmental Expenses 
Other Program Expenses 
Capital Outlay 
Principal Debt Service 
Interest Debt Service 
Total Operating Expenses 

Category of CAFR components (continued) 

Sources & Uses  Change in Fund Balances 

Ratios 

NEGLECTED 

NEGLECTED 

NEGLECTED 

These components serve as categories of focus areas in which 
the city invest for maintenance and future development. Bloom-
berg L.P. collected these financial data from numbers of cities in 
the United States, and we can  access data through Bloomberg 
Professional service provided in special Bloomberg Terminal. 

5.  C2ERâ€™s Cost-of-living Index (COLI) in 2014 
Each cluster will have its own regressive model, ultimately al-
lowing higher degree of freedom to  the big picture, to  reduce 
generalization  error.    We  explore  multiple  clustering  algo-
rithms, which are: 

C.  Data Set 

For financial data, we obtained CAFR data from 380 cities in 

California for years between 2004 and 2014. 

For  KPI  data,  we  obtained  crime  rates,  cost  of  living  index, 
health  index,  and  median  income  from  all  cities in  the  United 
States annually, from 2004 up to 2014. 

For demographics data, we obtained 2010 census population 

data of all census-registered cities in the United States.  

To  aggregate  the  data,  we  chose  geoid  primary  index  pro-
vided by United States Census Bureau to establish relationships 
in the rows of data obtained from different data sources. 

D.  Regression Analysis 

First, we attempted to predict the crime index of the City of 
Palo  Alto using its financial data. We  explored five regression 
models: 

1.  Bayesian Linear Regression, 
2.  Neural Network Regression, 
3.  Boosted Decision Tree, 
4.  Linear Regression, and  
5.  Decision Forest Regression.  
Among 20 financial features, we first cleaned the missing data 
by removing features with missing data; it left us with 14 fea-
tures with complete dataset.  

For  each  of  the  five  regression  models,  we  first  trained  the 
model using the all 14 features with complete dataset.  Then, we 
trained the models using just one feature, the public safety ex-
pense, which intuitively, we think is most correlated to crime in-
dex.  Lastly, we used filter-based selection methods to identify 
the features that are most predictive, and trained the models us-
ing the top two  features.  The  five feature scoring method we 
tried are: 

1.  Pearson Correlation (Pearsonâ€™s ğœŒ), 
2.  Mutual Information (MI), 
3.  Spearman Correlation (Spearmanâ€™s ğœŒ), and 
4.  Chi-squared (ğœ’2) Test. 
We  apply  this  method  to  more  cities  as  determined  by  the 
clustering result, and obtain a more generic model trained with 
data belonging to multiple cities instead of a single one. 

E.  Unsupervised Clustering 

It is a possibility  that there are multiple underlying models 
between  financial  budgeting  and  KPIs  for  cities  depending on 
some hidden factors. In reality, cities dissimilar in scale and liv-
ing  standard  require  different  policies  of governance  to  make 
successful progress. To generalize the prediction model, we at-
tempt  to  establish  similarity  clusters  of  cities  in  the  dataset 
based on scale  and living standard, with the following factors 
considered: 

1.  Population census in 2010 
2.  10-year population growth from 2000 to 2010 
3.  Total revenue per capita in 2014 
4.  Total expense per capita in 2014 

1.  K-means clustering, 
2.  K-medoids clustering, 
3.  Agglomerative clustering, and 
4.  Gaussian mixture model. 
We determine the cluster count using â„“2-norm Silhouette 
value as a measure of purity from dissimilarity (higher is bet-
ter): 

 

silhouette(ğ‘¥ğ‘–) =

where: 

â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2 âˆ’ â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2

max{â€–ğ‘¥ğ‘– âˆ’ ğ¶â€²(ğ‘¥ğ‘–)â€–2, â€–ğ‘¥ğ‘– âˆ’ ğ¶(ğ‘¥ğ‘–)â€–2}

âˆˆ [âˆ’1,1] 

ğ¶(ğ‘¥ğ‘–): Centroid of cluster containing ğ‘¥ğ‘– 
ğ¶â€²(ğ‘¥ğ‘–): Centroid nearest to ğ‘¥ğ‘– satisfying ğ¶(ğ‘¥ğ‘–) â‰  ğ¶â€²(ğ‘¥ğ‘–) 
 
In addition, separately for each algorithm and cluster count 
we remove outlier points from data that induces the algorithm 
to create clusters containing low number of points. With this re-
duced data set, we run each clustering algorithm with 100 rep-
licates  per  cluster  count,  choosing  the  result  that  maximizes 
mean Silhouette value. We then choose the model that maxim-
izes the mean Silhouette value over different cluster counts. The 
pseudo-algorithm for each clustering algorithm is as follows: 

 

def n_replicate = 100 
for k = 2 to sqrt(size(data)): 
  def data_k = data 
  def C_low = {dummy point} 
  while size(C_low) > 0: 
    run clustering on data_k 
    if any cluster has less than min_size points: 
      C_low = join all clusters with size < min_size 
      remove all points in C_low data from data_k 
  end while 
  for r = 1 to n_replicate: 
    def index_kr = result of clustering on data_k 

    def sil_kr = silhouette value of index_r 

    if mean(sil_kr) > mean(sil_k): 
      index_k = index_kr, sil_k = sil_kr 
    end if 
  end for 
end for 
def index = index_k that maximizes sil_k over k 

III. RESULTS 

A.  Baseline Model 

First, we attempted to predict the crime index of the City of 

Palo Alto using its financial data.  

The results of feature scoring in descending order is shown 
on  Figure  1.  To  evaluate  the  models,  10-fold  cross  validation 
was used. The estimated generalization errors of each model in 
terms of root mean squared error (RMSE) are presented in Fig-
ure 2.  Each row represents errors of models using different sets 
of features. For example, the row, Public Safety Expenses, shows 
the errors from just using one feature, Public Safety Expenses; 
the row, Pearson Correlation, shows the errors models using the 

top  two  features  selected  by  Pearson  Correlation  Method. 
Among all the models we trained, the linear regression model 
using the public safety expenses alone  was able to predict the 
crime index with the lowest error of 19.80. 
 

shown in Figure 3. Additionally, another criterion is applied for 
a  model  with  given  parameter  to  be  acceptable:  all  cluster 
within the model must have at least one point with Silhouette 
value higher than the model-wide mean Silhouette value. Points 
satisfying this criterion is marked with black circle in Figure 3. 
 

Top 2 features using Ï‡^2 

Top 2 features using 

Spearmanâ€™s Ï 

Top 2 features using MI

Top 2 features using 

Pearsonâ€™s Ï

Public Safety Expenses only

All features

60
Bayesian Linear NN Decision Forest

20

0

40

100

80
Boosted DT

Linear

  
Figure 2â€”Cross-validation RMSE of baseline model. 

Figure 1â€”Feature scoring. 

 

B.  Unsupervised Clustering 

Unsupervised  clustering  was  applied  against  separately  ob-
tained scale and living standard data for 477 cities in California 
as  described  in  Part  E  of  Methodologies.  Unfortunately,  some 
values are found to be missing after merging the factors. Due to 
the  nature  of  unsupervised  clustering,  it  makes  little  sense  to 
apply imputation or surrogate techniques, so we simply remove 
points having one or  more missing factors and were  left with 
364 points. Clustering performance based on Silhouette value is 

Figure 3â€”Clustering algorithms performance comparison. 

 

 
From Figure 3 we can observe that Gaussian mixture model 
quickly degenerates with increasing cluster count, whereas the 
other 3 considered algorithms performs similarly. We note that 
Silhouette value by definition will be high for cluster count of 2 
so long as the algorithm is allowed to converge, due to â„“2-norm 
being used for both clustering and Silhouette, as ğ¶(ğ‘¥ğ‘–) â‰¥ ğ¶â€²(ğ‘¥ğ‘–) 
always in this setting, keeping silhouette(ğ‘¥ğ‘–) â‰¥ 0 for all points. 
With this consideration,  as  well  as  desire  to  lower  the  size  of 
cluster  to  which  Palo  Alto  belong,  we  pick  the  agglomerative 
clustering model pruned to 4 clusters because it maximizes the 
Silhouette value. Figure 4 illustrates how this model clusters the 

points, using principal components. We found 225 cities similar 
to Palo Alto based on the factors considered. 

In Figure 5 we see that the cross-validated ğ‘…2 receive little to 
no improvement past the first order of autoregression, so in the 
interest  of  simplicity  and  avoiding  overfitting,  we  opt  for  the 
first order model: 

 

ğ¼ğ‘†(ğ‘¡) = 0.0956 âˆ™ ğ¸ğ‘ƒğ‘†(ğ‘¡) + 0.9410 âˆ™ ğ¼ğ‘†(ğ‘¡ âˆ’ 1) + 4.4689 

where: 

ğ¼ğ‘†(ğ‘¡): Crime index of the year 
ğ¼ğ‘†(ğ‘¡ âˆ’ 1): Crime index of preceding year (autoregressive) 
ğ¸ğ‘ƒğ‘†(ğ‘¡): Public safety expense of the year, in million US$ 
 

Figure 4â€”Agglomerative clustering on PCA, k=4. 

 

 

Based on our baseline model findings in Figure 2, we deter-
mine that the project should be scoped to linear models. To im-
prove the performance of models, we augment stepwise linear 
model construction with autoregressive terms. The significance 
of autoregressive terms is supported by  assumption  that pre-
existing  quality  of  life  in  the  city  affects  the  extent  to  which 
budgeting decision for the year could influence the outcome of 
the development which is incremental in nature.  

C.  Public Safety KPI 

We  applied  linear  model  augmented  with  autoregressive 
terms to the public safety KPI, which is the crime index of cities 
inside cluster containing Palo Alto. The chronological extent of 
our dataset allows for autoregression up to 12th order, and we 
used  10-fold  cross-validated ğ‘…2  as  goodness-of-fit  statistic  of 
models. The result is shown in Figure 5, along with p-values of 
the coefficients involved in the linear model. To evaluate the sig-
nificance of augmented autoregressive terms, we consider only 
the maximum of p-values associated with these terms. 

Shown  also  in  Figure  5  is  the  Akaike  Information  Criteria 
(AIC) of models, corrected to account for finite sample sizes. Alt-
hough AIC typically provides sensible measure to compare mod-
els having varying number of coefficients, in this application we 
observe that the AIC decreases due to the likelihood component 
diminishing in value. This may be caused by the number of train-
ing samples accounted for in AIC calculation decreases as we ex-
pend  the  temporal  limit  of  our  dataset  into  providing  values 
used  for  autoregressive  terms.  Therefore,  we  simply  use  the 
cross-validated ğ‘…2 to choose the model. 

Figure 5â€”Performance of autoregressive linear models 

 

for public safety KPI. 

D.  Health KPI 

We noted from Figure 2 that using all CAFR components in-
creased the validation error of model. For health KPI model, we 
apply stepwise construction of linear model in addition to the 
autoregressive terms similar to public safety KPI model. Step-
wise selection will prevent overfitting due to including all CAFR 
components. 

During model construction, we encountered a lot of missing 
data for CAFR components for a given year. To maximize train-
ing dataset utilization, since the model is linear, we impute miss-
ing  data  with  zeros.  Our  temporal  dataset  enables  us  to  con-
struct up to 9th order autoregression. 

We found, as can be seen in Figure 6, that the autoregressive 
models  perform  poorly  for  models  lower  than  8th  order.  The 
AR(8)  model,  however,  does  not  include  any  of  CAFR  compo-
nents. Therefore, we will pick the AR(9) model: 

 

9

ğ¼ğ»(ğ‘¡) = 0.0020 âˆ™ ğ¸ğ»ğ‘… + âˆ‘{ğ›¼ğ‘ğ¼ğ»(ğ‘¡ âˆ’ ğ‘)}

+ 0.1060 

ğ‘=1

where: 

ğ¼ğ»(ğ‘¡): Health index of the year 
ğ¼ğ‘†(ğ‘¡ âˆ’ ğ‘): Health index of ğ‘ years ago (autoregressive) 
ğ¸ğ»ğ‘…(ğ‘¡): Human resources expense of the year, in million US$ 
ğ›¼ğ‘: Coefficient of p-th autoregressive term 

 

F.  Diversity KPI 

Diversity KPI data, as with that of affordability KPI, was lim-
ited to a single year. The resulting model is again weak without 
any autoregressive terms: 

Estimate  p-value 

 
0.5380  8.6080 âˆ™ 10âˆ’82 
(Intercept) 
Public Safety Expenses 
0.0015  0.0002 
Interest Debt Services  âˆ’0.0928  0.0341 
 
ğ‘› = 223 

10-fold CV ğ‘…2 = 0.0047 

ğ‘…2 = 0.0691 

 

 

 

For this results we also maintain that our proposed method-

ologies may perform well given more temporal data. 

IV. CONCLUSION 

This project showed promising outcome for public safety KPI 
(crime rate) and health KPI (proportion of residents self-report-
ing better than fair or poor health) as shown by the goodness of 
fit of the autoregressive linear models for these KPI. The optimi-
zation of municipal budget  is achievable using the outcome of 
this project, for public safety and health KPI for a cluster of 225 
cities. 

Further works deriving from this project should consider ob-
taining more training data. It is observed from the goodness of 
fit  of  models  for  public  safety  KPI  and  health  KPI  that  linear 
models  without  autoregressive  terms  can  be  dramatically  im-
proved  by  adding  autoregressive  index  values.  We  observed 
that affordability KPI and population diversity KPI models have 
poor  performance  using  only  the  latest  publicly  available  KPI 
values. Obtaining affordability KPI would require us to purchase 
the Cost-of-living Index report for US$750 to enable the level of 
analysis  equivalent  to  that  of  public  safety  and  health,  which 
was cost-prohibitive. Nevertheless, based on the evidence avail-
able to us and given the importance of affordability to the qual-
ity of life, we recommend further works to acquire temporally 
extensive data points for affordability KPI. 

Further works should also consider expanding geographical 
extent of the analysis. Due to Bloomberg Terminal usage limits 
imposed on us, our analysis could only consider financial budg-
eting data from the state of California. 

Lastly, further works should consider augmenting other non-
linear regressive models with autoregressive terms for the final 
models. Due to time and resource limitation, we only considered 
autoregressive linear models. 

V. ACKNOWLEDGEMENTS 

We would like to thank Consulting Professor Bruce Cahan and 
Visiting Scholar Tomasz Golinski for  providing us with city  fi-
nancial data. 

VI. REFERENCES 

Bloomberg L.P. (2015) City Credit Report. Retrieved Nov. 11, 

2015 from Bloomberg database. 

City-data.com, 'City-Data.com - Stats about all US cities', 2015. 
[Online]. Available: http://www.city-data.com/. [Accessed: Oct- 
2015]. 

 

Figure 6â€”Performance of autoregressive linear models 

 

for health KPI. 

E.  Affordability KPI 

Affordability KPI data was limited to a single year, which puts 

autoregression out of reach. The resulting model is weak: 

 
(Intercept) 
Public Safety Expenses  âˆ’1.7796  0.0319 
 
ğ‘› = 223 

Estimate 
675.1712  8.5665 âˆ™ 10âˆ’48 

10-fold CV ğ‘…2 = 0.0020 

ğ‘…2 = 0.0207 

p-value 

 

 

 

However, we also see weak performance in non-autoregres-
sive linear models for public safety and health KPI. The failure 
to obtain a meaningful model for this KPI does not present evi-
dence that would invalidate our proposed methodologies for the 
project. A meaningful model may be obtained with more tem-
poral data. 
 

