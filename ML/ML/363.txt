The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

Xk = UkΣkV T
k where Σk is a diagonal matrix contain-
ing X’s k largest singular values; this hence represents
k components inferred from the original features. Ui,j
then corresponds to the value of new component j at
comment i, while Vi,j corresponds to the weighting of
feature j at old feature i. Higher values roughly cor-
respond to that component being more characteristic
of the comment or feature.

Topic Analysis

To determine the most common topics represented
in the comments, we used the term frequency-inverse
document frequency (tf-idf) scores of each word in a
particular comment as the set of features for that com-
ment.
We applied the SVD algorithm to this set of fea-
tures, which is also known as Latent Semantic Analysis
(LSA) when used in this context.

Results

We chose the number of topics for interpretability of
results, arriving at k = 10 topics (we also attempted
to choose k such that the improvement in reconstruc-
k | levelled oﬀ, producing 25
tion error |X − UkΣkV T
topics, but the diﬀerences between topics were much
more subtle).

Using the notation above, after performing SVD, for
each topic j, the most important words i maximize Vij
and the most representative comments maximize Uij.
For instance, here are the most representative words,
and most representative comment for a selection of
two topics:
Topic 2 - Cable Companies
companies cable comcast
Most important words:
speeds pay consumers charge speed competition net-
ﬂix monopolies monopoly company money dont net
big warner faster lane
Example comment:
”Regarding the proposal to permit
cable companies and other ISPs to charge companies to pro-
vide faster downloads: This is the most ridiculous proposal
I have heard in a long time. The cable companies, eg. Com-
cast and Time Warner are claiming that such fees to com-
panies like Netﬂix would not create a two-tier fast lane-slow
lane internet.”
Topic 3 - Legal terminology
Most important words: net neutrality fcc common ti-
tle rules broadband ii carriers telecommunications pro-
tect reclassify proposed urge support wheeler chair-
man isps carrier public
Example comment: ”Net neutrality is the First Amend-
ment of the Internet, the principle that Internet service
providers (ISPs) treat all data equally. As an Internet user,
net neutrality is vitally important to me. The FCC should

use its Title II authority to protect it.”
Topic 6 - Small Business Equality
Most important words: fast lane lanes small business
businesses slow big open internet pay playing ﬁeld af-
ford level rules innovation create equal traﬃc
Example comment: ”there is no diﬀerence between the
statements ’fast lane’ and ’slow lane’, and ’fast lane’ and
’hyper fast lane’. We’re not stupid. This will only allow
big corporations with money to squeeze out little start up
companies that would have no way to aﬀord to pay for this
hyper fast lane...”
The full list of topics we labelled after analyzing the
examples are as follows: free and open Internet, Amer-
ica government and freedom, cable companies, legal
terminology, innovation and startup encouragement,
ISP proﬁts, small business equality, ISP-consumer re-
lationship, ISP-data treatment, companies controlling
information.

Form letter topics

a set of comments S for topic j, |S|−1(cid:80)

Given the high volume of form letters, one question we
may ask is this: Do form letters talk about diﬀerent
topics than original comments, which are unaﬃliated
with any form letter campaigns? To answer this ques-
tion, we use the topic weights for each comment as
produced above. Consider the average topic weight of
x∈S Uxj. For
each topic, we calculate the average weight over all
the comments, over only the 13 form letter comments,
and over a random sample of 13 comments (as a con-
trol). A bar graph of topic weights per topic is shown
in Figure 1.

From the graph we can see that in particular, form
letters seem to mention topic 3, ”legal terminology”,
a lot more than the average comment (representative
words and comments for this topic are listed above).
This is corroborated by a manual examination of the
form letter comments, which are mostly fairly explicit
references to past legislation and proposed legislative
changes:
”title ii of the communications act of 1934 already grants
you the authority to declare the internet a public utility”
(from the Daily Kos) [3]
”The FCC should use its Title II authority to protect [net
neutrality]” (from Battle for the Net) [4]

Given these results, we may tentatively conclude the
following: while most comments encompass a wider
range of ideas, form letters are speciﬁcally organized
calls for legislative change.

Linguistic analysis

In addition to determining the topic content of the
comments, we also wanted to gain insight into how

2

The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

Xk = UkΣkV T
k where Σk is a diagonal matrix contain-
ing X’s k largest singular values; this hence represents
k components inferred from the original features. Ui,j
then corresponds to the value of new component j at
comment i, while Vi,j corresponds to the weighting of
feature j at old feature i. Higher values roughly cor-
respond to that component being more characteristic
of the comment or feature.

Topic Analysis

To determine the most common topics represented
in the comments, we used the term frequency-inverse
document frequency (tf-idf) scores of each word in a
particular comment as the set of features for that com-
ment.
We applied the SVD algorithm to this set of fea-
tures, which is also known as Latent Semantic Analysis
(LSA) when used in this context.

Results

We chose the number of topics for interpretability of
results, arriving at k = 10 topics (we also attempted
to choose k such that the improvement in reconstruc-
k | levelled oﬀ, producing 25
tion error |X − UkΣkV T
topics, but the diﬀerences between topics were much
more subtle).

Using the notation above, after performing SVD, for
each topic j, the most important words i maximize Vij
and the most representative comments maximize Uij.
For instance, here are the most representative words,
and most representative comment for a selection of
two topics:
Topic 2 - Cable Companies
companies cable comcast
Most important words:
speeds pay consumers charge speed competition net-
ﬂix monopolies monopoly company money dont net
big warner faster lane
Example comment:
”Regarding the proposal to permit
cable companies and other ISPs to charge companies to pro-
vide faster downloads: This is the most ridiculous proposal
I have heard in a long time. The cable companies, eg. Com-
cast and Time Warner are claiming that such fees to com-
panies like Netﬂix would not create a two-tier fast lane-slow
lane internet.”
Topic 3 - Legal terminology
Most important words: net neutrality fcc common ti-
tle rules broadband ii carriers telecommunications pro-
tect reclassify proposed urge support wheeler chair-
man isps carrier public
Example comment: ”Net neutrality is the First Amend-
ment of the Internet, the principle that Internet service
providers (ISPs) treat all data equally. As an Internet user,
net neutrality is vitally important to me. The FCC should

use its Title II authority to protect it.”
Topic 6 - Small Business Equality
Most important words: fast lane lanes small business
businesses slow big open internet pay playing ﬁeld af-
ford level rules innovation create equal traﬃc
Example comment: ”there is no diﬀerence between the
statements ’fast lane’ and ’slow lane’, and ’fast lane’ and
’hyper fast lane’. We’re not stupid. This will only allow
big corporations with money to squeeze out little start up
companies that would have no way to aﬀord to pay for this
hyper fast lane...”
The full list of topics we labelled after analyzing the
examples are as follows: free and open Internet, Amer-
ica government and freedom, cable companies, legal
terminology, innovation and startup encouragement,
ISP proﬁts, small business equality, ISP-consumer re-
lationship, ISP-data treatment, companies controlling
information.

Form letter topics

a set of comments S for topic j, |S|−1(cid:80)

Given the high volume of form letters, one question we
may ask is this: Do form letters talk about diﬀerent
topics than original comments, which are unaﬃliated
with any form letter campaigns? To answer this ques-
tion, we use the topic weights for each comment as
produced above. Consider the average topic weight of
x∈S Uxj. For
each topic, we calculate the average weight over all
the comments, over only the 13 form letter comments,
and over a random sample of 13 comments (as a con-
trol). A bar graph of topic weights per topic is shown
in Figure 1.

From the graph we can see that in particular, form
letters seem to mention topic 3, ”legal terminology”,
a lot more than the average comment (representative
words and comments for this topic are listed above).
This is corroborated by a manual examination of the
form letter comments, which are mostly fairly explicit
references to past legislation and proposed legislative
changes:
”title ii of the communications act of 1934 already grants
you the authority to declare the internet a public utility”
(from the Daily Kos) [3]
”The FCC should use its Title II authority to protect [net
neutrality]” (from Battle for the Net) [4]

Given these results, we may tentatively conclude the
following: while most comments encompass a wider
range of ideas, form letters are speciﬁcally organized
calls for legislative change.

Linguistic analysis

In addition to determining the topic content of the
comments, we also wanted to gain insight into how

2

the comments were written. We hoped to capture dif-
ferences in degree of personal investment, determine
the intended audience and subject for diﬀerent com-
ments, and intensity and politeness of the commenters.

Features

We used features were based on linguistic character-
istics of the comments, attitudes of the writers, and
entities the comments were directed to. We consid-
ered the following features from each document:

% sentences with 1st singular related pronouns
% sentences with 1st plural related pronouns
% sentences with 2nd singular related pronoun
average # words per sentence
# sentences
% sentences with negation (”no”, ”nt”, ”not”)
% sentences with ”must” etc.
% sentences with ”should” etc.
% sentences with ”will” etc.
% sentences with ”may” etc.
% sentences with ”can” etc.
Flesch-Kincaid Reading Ease scores
Mentioning of Chairman Tom Wheeler
Mentioning of swear words
Mentioning of companies ”ATT Warner Verizon

Comcast”
The feature vectors, corresponding to rows of X from
the above notation, were normalized to get a mean of
0 and variance of 1.

Results

Using these features, with k = 5, we found the follow-
ing of comments which were characterized in surpris-
ingly striking and intuitive ways, which we list below.
The full table of components to features is shown in
Figure 2.

1- Personal Worries - Deﬁning Features: High use
of I and negatives, low terminology, no directed audi-
ence:
”i was a computer wizard practically before i could read
without a parent over my shoulder and i think its obvious
why someone who knows computers so well would be so
concerned...”
”dear fcc i use my pc like millions of others do online for
research for diseases or for radio astronomy in conjunc-
tion with volunteer run projects at universities across the
usa those that use the boinc interface, seti@home, ein-
stein@home, rosetta@home, milkyway@home gpugrid etc”
2- Legal References - Deﬁning Features: Low reading
ease, low profanity, lengthy comments:
”forbearance furthers the objective of interpreting law in
light of modern technology and markets without undermin-
ing its core purposes.”

3

”before the federal communications commission washing-
ton dc in the matter of protecting and promoting the open
internet gn docket no. 1428 framework for broadband in-
ternet service gn docket no. 10127 comments of comcast
corporation comcast corporation”
3- Frustrated at Tom Wheeler - Deﬁning Features:
High use of you and profanity, directed at Tom
Wheeler, concise comments:
”mr wheeler i will ﬁrst remind you that you are an employee
of the federal government of the united states of america.
basically you work for us the people.”
”mr wheeler as a paying customer of the internet i ﬁnd
what you are doing oﬀensive and incredibly criminal.
if
you do not back down from this position of destroying net
neutrality i and every one of the computer geeks i know will
demand your resignation.”
4-Dreams and Values - Deﬁning Features: High use of
plural pronouns, can, must; no directed audience
”please consider as this part of our era is economically
hard in so many ways. for many like me who are somewhat
housebound the internet is our library our bank”
”the internet has already greatly changed the way our world
works and for a time this was acceptable. unfortunately
legislation has failed to keep up with the technology and we
have reached a crossroads that could make or break the con-
tinued prosperity and innovation the internet provides.”
5-Experiences and Anecdotes -s Deﬁning Features:
High use of I, low negativity, short comments
”the internet is important to me because as someone who
suﬀers from disabilities due to multiple sclerosis it gives me
back some of my independence that this disease has stripped
from me. i can go online and research treatments to better
make informed decisions.”
”i work for a company that creates comedic videos and puts
them online. its my livelihood. if the internet becomes an
exclusive club myself and many others may be out of a job.”

When we used higher numbers of components, later
components corresponding to small eigenvalues had a
neutral and balanced amount of features, and were not
very helpful in discerning commenter attitudes.

Overall Results

With these two diﬀerent sets of characteristic compo-
nents of our comment set, we wanted to investigate the
relationship between the two. To do this, we created
a matrix M ∈ Rtxc. t is the number of topics, c is the
number of components, Ut is the U vector resulting
from topic modeling and Uc is the U vector resulting
from comment clustering.

M [i, j] =(cid:80)n

k=0 Ut[k, i] ∗ Uc[k, j].

From M , we obtain an other vector M(cid:48), which is nor-
malized such that M(cid:48) = M/max(M ). A large M(cid:48)[i, j]

The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

Xk = UkΣkV T
k where Σk is a diagonal matrix contain-
ing X’s k largest singular values; this hence represents
k components inferred from the original features. Ui,j
then corresponds to the value of new component j at
comment i, while Vi,j corresponds to the weighting of
feature j at old feature i. Higher values roughly cor-
respond to that component being more characteristic
of the comment or feature.

Topic Analysis

To determine the most common topics represented
in the comments, we used the term frequency-inverse
document frequency (tf-idf) scores of each word in a
particular comment as the set of features for that com-
ment.
We applied the SVD algorithm to this set of fea-
tures, which is also known as Latent Semantic Analysis
(LSA) when used in this context.

Results

We chose the number of topics for interpretability of
results, arriving at k = 10 topics (we also attempted
to choose k such that the improvement in reconstruc-
k | levelled oﬀ, producing 25
tion error |X − UkΣkV T
topics, but the diﬀerences between topics were much
more subtle).

Using the notation above, after performing SVD, for
each topic j, the most important words i maximize Vij
and the most representative comments maximize Uij.
For instance, here are the most representative words,
and most representative comment for a selection of
two topics:
Topic 2 - Cable Companies
companies cable comcast
Most important words:
speeds pay consumers charge speed competition net-
ﬂix monopolies monopoly company money dont net
big warner faster lane
Example comment:
”Regarding the proposal to permit
cable companies and other ISPs to charge companies to pro-
vide faster downloads: This is the most ridiculous proposal
I have heard in a long time. The cable companies, eg. Com-
cast and Time Warner are claiming that such fees to com-
panies like Netﬂix would not create a two-tier fast lane-slow
lane internet.”
Topic 3 - Legal terminology
Most important words: net neutrality fcc common ti-
tle rules broadband ii carriers telecommunications pro-
tect reclassify proposed urge support wheeler chair-
man isps carrier public
Example comment: ”Net neutrality is the First Amend-
ment of the Internet, the principle that Internet service
providers (ISPs) treat all data equally. As an Internet user,
net neutrality is vitally important to me. The FCC should

use its Title II authority to protect it.”
Topic 6 - Small Business Equality
Most important words: fast lane lanes small business
businesses slow big open internet pay playing ﬁeld af-
ford level rules innovation create equal traﬃc
Example comment: ”there is no diﬀerence between the
statements ’fast lane’ and ’slow lane’, and ’fast lane’ and
’hyper fast lane’. We’re not stupid. This will only allow
big corporations with money to squeeze out little start up
companies that would have no way to aﬀord to pay for this
hyper fast lane...”
The full list of topics we labelled after analyzing the
examples are as follows: free and open Internet, Amer-
ica government and freedom, cable companies, legal
terminology, innovation and startup encouragement,
ISP proﬁts, small business equality, ISP-consumer re-
lationship, ISP-data treatment, companies controlling
information.

Form letter topics

a set of comments S for topic j, |S|−1(cid:80)

Given the high volume of form letters, one question we
may ask is this: Do form letters talk about diﬀerent
topics than original comments, which are unaﬃliated
with any form letter campaigns? To answer this ques-
tion, we use the topic weights for each comment as
produced above. Consider the average topic weight of
x∈S Uxj. For
each topic, we calculate the average weight over all
the comments, over only the 13 form letter comments,
and over a random sample of 13 comments (as a con-
trol). A bar graph of topic weights per topic is shown
in Figure 1.

From the graph we can see that in particular, form
letters seem to mention topic 3, ”legal terminology”,
a lot more than the average comment (representative
words and comments for this topic are listed above).
This is corroborated by a manual examination of the
form letter comments, which are mostly fairly explicit
references to past legislation and proposed legislative
changes:
”title ii of the communications act of 1934 already grants
you the authority to declare the internet a public utility”
(from the Daily Kos) [3]
”The FCC should use its Title II authority to protect [net
neutrality]” (from Battle for the Net) [4]

Given these results, we may tentatively conclude the
following: while most comments encompass a wider
range of ideas, form letters are speciﬁcally organized
calls for legislative change.

Linguistic analysis

In addition to determining the topic content of the
comments, we also wanted to gain insight into how

2

the comments were written. We hoped to capture dif-
ferences in degree of personal investment, determine
the intended audience and subject for diﬀerent com-
ments, and intensity and politeness of the commenters.

Features

We used features were based on linguistic character-
istics of the comments, attitudes of the writers, and
entities the comments were directed to. We consid-
ered the following features from each document:

% sentences with 1st singular related pronouns
% sentences with 1st plural related pronouns
% sentences with 2nd singular related pronoun
average # words per sentence
# sentences
% sentences with negation (”no”, ”nt”, ”not”)
% sentences with ”must” etc.
% sentences with ”should” etc.
% sentences with ”will” etc.
% sentences with ”may” etc.
% sentences with ”can” etc.
Flesch-Kincaid Reading Ease scores
Mentioning of Chairman Tom Wheeler
Mentioning of swear words
Mentioning of companies ”ATT Warner Verizon

Comcast”
The feature vectors, corresponding to rows of X from
the above notation, were normalized to get a mean of
0 and variance of 1.

Results

Using these features, with k = 5, we found the follow-
ing of comments which were characterized in surpris-
ingly striking and intuitive ways, which we list below.
The full table of components to features is shown in
Figure 2.

1- Personal Worries - Deﬁning Features: High use
of I and negatives, low terminology, no directed audi-
ence:
”i was a computer wizard practically before i could read
without a parent over my shoulder and i think its obvious
why someone who knows computers so well would be so
concerned...”
”dear fcc i use my pc like millions of others do online for
research for diseases or for radio astronomy in conjunc-
tion with volunteer run projects at universities across the
usa those that use the boinc interface, seti@home, ein-
stein@home, rosetta@home, milkyway@home gpugrid etc”
2- Legal References - Deﬁning Features: Low reading
ease, low profanity, lengthy comments:
”forbearance furthers the objective of interpreting law in
light of modern technology and markets without undermin-
ing its core purposes.”

3

”before the federal communications commission washing-
ton dc in the matter of protecting and promoting the open
internet gn docket no. 1428 framework for broadband in-
ternet service gn docket no. 10127 comments of comcast
corporation comcast corporation”
3- Frustrated at Tom Wheeler - Deﬁning Features:
High use of you and profanity, directed at Tom
Wheeler, concise comments:
”mr wheeler i will ﬁrst remind you that you are an employee
of the federal government of the united states of america.
basically you work for us the people.”
”mr wheeler as a paying customer of the internet i ﬁnd
what you are doing oﬀensive and incredibly criminal.
if
you do not back down from this position of destroying net
neutrality i and every one of the computer geeks i know will
demand your resignation.”
4-Dreams and Values - Deﬁning Features: High use of
plural pronouns, can, must; no directed audience
”please consider as this part of our era is economically
hard in so many ways. for many like me who are somewhat
housebound the internet is our library our bank”
”the internet has already greatly changed the way our world
works and for a time this was acceptable. unfortunately
legislation has failed to keep up with the technology and we
have reached a crossroads that could make or break the con-
tinued prosperity and innovation the internet provides.”
5-Experiences and Anecdotes -s Deﬁning Features:
High use of I, low negativity, short comments
”the internet is important to me because as someone who
suﬀers from disabilities due to multiple sclerosis it gives me
back some of my independence that this disease has stripped
from me. i can go online and research treatments to better
make informed decisions.”
”i work for a company that creates comedic videos and puts
them online. its my livelihood. if the internet becomes an
exclusive club myself and many others may be out of a job.”

When we used higher numbers of components, later
components corresponding to small eigenvalues had a
neutral and balanced amount of features, and were not
very helpful in discerning commenter attitudes.

Overall Results

With these two diﬀerent sets of characteristic compo-
nents of our comment set, we wanted to investigate the
relationship between the two. To do this, we created
a matrix M ∈ Rtxc. t is the number of topics, c is the
number of components, Ut is the U vector resulting
from topic modeling and Uc is the U vector resulting
from comment clustering.

M [i, j] =(cid:80)n

k=0 Ut[k, i] ∗ Uc[k, j].

From M , we obtain an other vector M(cid:48), which is nor-
malized such that M(cid:48) = M/max(M ). A large M(cid:48)[i, j]

value indicates high overlap between topic i and com-
ponent j. A heatmap of these weightings is shown
in Figure 3. We found that each component-vector
pairing, which we call comment buckets, matched a
characteristic portrait of a commenter.
The correspondence of the topics and components
was reasonable. The most crowded comments buckets
were:
1 - Personal worries - Innovation and startup en-
couragement. Most people in this bucket either are,
or particularly concerned about small business and
startup owners:
”i am a small businessman. the inter-
net is critical my success. consigning me to a slow lane of
the internet might do serious damage to the success of my
business. also as a private individual i believe the internet
serves as a public good”
2 - Frustrated at Tom Wheeler - Equality for small
business. The second most crowded bucket contains
most of the comments with swearwords: ”if you dumb
asses pass this law taxes will have to go up to pay for schools
and because some schools wont be able to aﬀord it so the
education levels of schools will decrease... and facebook will
die out and many stocks will drop and die aﬀecting the
stock market for many stockholders. with that all aside you
will piss oﬀ millions for literally no reason”
3 - Frustrated at Tom Wheeler - Government, Amer-
ica, Freedom. This bucket was much less profane, and
used patriotic references and national values exten-
sively:
”mr wheeler and fcc members i grow increasingly
concerned with your attempts to ram an anticonsumer net
neutrality bill through the process. we know what you are
doing. you may feel inclined to bow to the corporate inﬂu-
ences”
4 - Legal References - ISPs Data Treatment. Contain-
ing relatively higher levels of rigor, this bucket shows
that people who are worried about monopolization of
data had the most eloquent comments:
”isps need
to be reclassiﬁed as title ii common carriers allowing this
proceeding to go through would allow isps to charge people
extra fees to carry traﬃc from any online business that they
want if a company depends heavily or entirely on internet
traﬃc the isp could refuse to allow web pages to load in
under a minute”
5 - Experiences and Anecdotes - Innovation and
startup encouragement. This bucket held an inter-
estingly high number of comments from people who
were very worried about their proﬁts or lifestyles, but
did not have a very clear understanding of the case:
”i am an artist. how can i succeed in an internet that fa-
vors already built giants. who will be able to ﬁnd me in a
segregated cyberspace. i will no longer be able to ﬁnd end-
less inspiration and utilize the internet the way i do now”

One bucket that we were surprised was the low cor-
relation of use of legal terminology and legal references

component. This may be the case because the legal
references bucket had the length and rigor of the com-
ment as a strong characteristic, and personal worries
captured a lot of comments that were well informed
and used terminology, but were short or included col-
loquialisms.

We found signiﬁcant correlation between the legal
reference comments, and the dreams and values com-
ments in terms of subjects they tackled, even though
their level of rigor is was distinctive. Large companies
controlling information was repeatedly mentioned in
personal worries, even though it is rarely mentioned
by legal reference documents. Comments with high
profanity were also simplest. Government and Amer-
ican values were rarely referred to in personal worries
or experiences, but were very common on comments at
Tom Wheeler, legal references and dreams and values.
Most of the garbage data that was unusually long,
literary or complicated, such as the full text of The
Great Gatsby or LCD screen instructions, were also
contained in the legal references cluster.

Future Work

There are several directions in which we could expand
our work from this paper. Looking further into our
data set, we should be able to extract more informa-
tion on how modiﬁcations to form letters correspond
to the topics and comment characteristics that we have
found. In our current dataset, which contains a frac-
tion of the original comments, there were not enough
form letters with original content added on to draw
any conclusions.
We could also investigate the mapping additional fea-
tures such as gender and location of the commenter or
time of comment to the topics and characterizations
we’ve identiﬁed. Triggers of high numbers of similar
comment submissions can be deduced, which can be
both in forms of celebrity or website encouragement,
or response to events. It would be interesting to fur-
ther study the application of similar analysis on a dif-
ferent body of comments, especially on subjects with
multiple aspects and viewpoints. Since the data was
99% supporting net neutrality, the conclusions did not
lead to a meaningful potential classiﬁcation problem.
The topic-component cross analysis can especially be
helpful in debates with non-binary outcomes.

Conclusion

This research project is a ﬁrst attempt at understand-
ing the large and diverse data set that results from an
open comment platform. By clustering similar atti-
tudes, subjects and concerns, common threads can be
found throughout the comments. Using this type of

4

The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

Xk = UkΣkV T
k where Σk is a diagonal matrix contain-
ing X’s k largest singular values; this hence represents
k components inferred from the original features. Ui,j
then corresponds to the value of new component j at
comment i, while Vi,j corresponds to the weighting of
feature j at old feature i. Higher values roughly cor-
respond to that component being more characteristic
of the comment or feature.

Topic Analysis

To determine the most common topics represented
in the comments, we used the term frequency-inverse
document frequency (tf-idf) scores of each word in a
particular comment as the set of features for that com-
ment.
We applied the SVD algorithm to this set of fea-
tures, which is also known as Latent Semantic Analysis
(LSA) when used in this context.

Results

We chose the number of topics for interpretability of
results, arriving at k = 10 topics (we also attempted
to choose k such that the improvement in reconstruc-
k | levelled oﬀ, producing 25
tion error |X − UkΣkV T
topics, but the diﬀerences between topics were much
more subtle).

Using the notation above, after performing SVD, for
each topic j, the most important words i maximize Vij
and the most representative comments maximize Uij.
For instance, here are the most representative words,
and most representative comment for a selection of
two topics:
Topic 2 - Cable Companies
companies cable comcast
Most important words:
speeds pay consumers charge speed competition net-
ﬂix monopolies monopoly company money dont net
big warner faster lane
Example comment:
”Regarding the proposal to permit
cable companies and other ISPs to charge companies to pro-
vide faster downloads: This is the most ridiculous proposal
I have heard in a long time. The cable companies, eg. Com-
cast and Time Warner are claiming that such fees to com-
panies like Netﬂix would not create a two-tier fast lane-slow
lane internet.”
Topic 3 - Legal terminology
Most important words: net neutrality fcc common ti-
tle rules broadband ii carriers telecommunications pro-
tect reclassify proposed urge support wheeler chair-
man isps carrier public
Example comment: ”Net neutrality is the First Amend-
ment of the Internet, the principle that Internet service
providers (ISPs) treat all data equally. As an Internet user,
net neutrality is vitally important to me. The FCC should

use its Title II authority to protect it.”
Topic 6 - Small Business Equality
Most important words: fast lane lanes small business
businesses slow big open internet pay playing ﬁeld af-
ford level rules innovation create equal traﬃc
Example comment: ”there is no diﬀerence between the
statements ’fast lane’ and ’slow lane’, and ’fast lane’ and
’hyper fast lane’. We’re not stupid. This will only allow
big corporations with money to squeeze out little start up
companies that would have no way to aﬀord to pay for this
hyper fast lane...”
The full list of topics we labelled after analyzing the
examples are as follows: free and open Internet, Amer-
ica government and freedom, cable companies, legal
terminology, innovation and startup encouragement,
ISP proﬁts, small business equality, ISP-consumer re-
lationship, ISP-data treatment, companies controlling
information.

Form letter topics

a set of comments S for topic j, |S|−1(cid:80)

Given the high volume of form letters, one question we
may ask is this: Do form letters talk about diﬀerent
topics than original comments, which are unaﬃliated
with any form letter campaigns? To answer this ques-
tion, we use the topic weights for each comment as
produced above. Consider the average topic weight of
x∈S Uxj. For
each topic, we calculate the average weight over all
the comments, over only the 13 form letter comments,
and over a random sample of 13 comments (as a con-
trol). A bar graph of topic weights per topic is shown
in Figure 1.

From the graph we can see that in particular, form
letters seem to mention topic 3, ”legal terminology”,
a lot more than the average comment (representative
words and comments for this topic are listed above).
This is corroborated by a manual examination of the
form letter comments, which are mostly fairly explicit
references to past legislation and proposed legislative
changes:
”title ii of the communications act of 1934 already grants
you the authority to declare the internet a public utility”
(from the Daily Kos) [3]
”The FCC should use its Title II authority to protect [net
neutrality]” (from Battle for the Net) [4]

Given these results, we may tentatively conclude the
following: while most comments encompass a wider
range of ideas, form letters are speciﬁcally organized
calls for legislative change.

Linguistic analysis

In addition to determining the topic content of the
comments, we also wanted to gain insight into how

2

the comments were written. We hoped to capture dif-
ferences in degree of personal investment, determine
the intended audience and subject for diﬀerent com-
ments, and intensity and politeness of the commenters.

Features

We used features were based on linguistic character-
istics of the comments, attitudes of the writers, and
entities the comments were directed to. We consid-
ered the following features from each document:

% sentences with 1st singular related pronouns
% sentences with 1st plural related pronouns
% sentences with 2nd singular related pronoun
average # words per sentence
# sentences
% sentences with negation (”no”, ”nt”, ”not”)
% sentences with ”must” etc.
% sentences with ”should” etc.
% sentences with ”will” etc.
% sentences with ”may” etc.
% sentences with ”can” etc.
Flesch-Kincaid Reading Ease scores
Mentioning of Chairman Tom Wheeler
Mentioning of swear words
Mentioning of companies ”ATT Warner Verizon

Comcast”
The feature vectors, corresponding to rows of X from
the above notation, were normalized to get a mean of
0 and variance of 1.

Results

Using these features, with k = 5, we found the follow-
ing of comments which were characterized in surpris-
ingly striking and intuitive ways, which we list below.
The full table of components to features is shown in
Figure 2.

1- Personal Worries - Deﬁning Features: High use
of I and negatives, low terminology, no directed audi-
ence:
”i was a computer wizard practically before i could read
without a parent over my shoulder and i think its obvious
why someone who knows computers so well would be so
concerned...”
”dear fcc i use my pc like millions of others do online for
research for diseases or for radio astronomy in conjunc-
tion with volunteer run projects at universities across the
usa those that use the boinc interface, seti@home, ein-
stein@home, rosetta@home, milkyway@home gpugrid etc”
2- Legal References - Deﬁning Features: Low reading
ease, low profanity, lengthy comments:
”forbearance furthers the objective of interpreting law in
light of modern technology and markets without undermin-
ing its core purposes.”

3

”before the federal communications commission washing-
ton dc in the matter of protecting and promoting the open
internet gn docket no. 1428 framework for broadband in-
ternet service gn docket no. 10127 comments of comcast
corporation comcast corporation”
3- Frustrated at Tom Wheeler - Deﬁning Features:
High use of you and profanity, directed at Tom
Wheeler, concise comments:
”mr wheeler i will ﬁrst remind you that you are an employee
of the federal government of the united states of america.
basically you work for us the people.”
”mr wheeler as a paying customer of the internet i ﬁnd
what you are doing oﬀensive and incredibly criminal.
if
you do not back down from this position of destroying net
neutrality i and every one of the computer geeks i know will
demand your resignation.”
4-Dreams and Values - Deﬁning Features: High use of
plural pronouns, can, must; no directed audience
”please consider as this part of our era is economically
hard in so many ways. for many like me who are somewhat
housebound the internet is our library our bank”
”the internet has already greatly changed the way our world
works and for a time this was acceptable. unfortunately
legislation has failed to keep up with the technology and we
have reached a crossroads that could make or break the con-
tinued prosperity and innovation the internet provides.”
5-Experiences and Anecdotes -s Deﬁning Features:
High use of I, low negativity, short comments
”the internet is important to me because as someone who
suﬀers from disabilities due to multiple sclerosis it gives me
back some of my independence that this disease has stripped
from me. i can go online and research treatments to better
make informed decisions.”
”i work for a company that creates comedic videos and puts
them online. its my livelihood. if the internet becomes an
exclusive club myself and many others may be out of a job.”

When we used higher numbers of components, later
components corresponding to small eigenvalues had a
neutral and balanced amount of features, and were not
very helpful in discerning commenter attitudes.

Overall Results

With these two diﬀerent sets of characteristic compo-
nents of our comment set, we wanted to investigate the
relationship between the two. To do this, we created
a matrix M ∈ Rtxc. t is the number of topics, c is the
number of components, Ut is the U vector resulting
from topic modeling and Uc is the U vector resulting
from comment clustering.

M [i, j] =(cid:80)n

k=0 Ut[k, i] ∗ Uc[k, j].

From M , we obtain an other vector M(cid:48), which is nor-
malized such that M(cid:48) = M/max(M ). A large M(cid:48)[i, j]

value indicates high overlap between topic i and com-
ponent j. A heatmap of these weightings is shown
in Figure 3. We found that each component-vector
pairing, which we call comment buckets, matched a
characteristic portrait of a commenter.
The correspondence of the topics and components
was reasonable. The most crowded comments buckets
were:
1 - Personal worries - Innovation and startup en-
couragement. Most people in this bucket either are,
or particularly concerned about small business and
startup owners:
”i am a small businessman. the inter-
net is critical my success. consigning me to a slow lane of
the internet might do serious damage to the success of my
business. also as a private individual i believe the internet
serves as a public good”
2 - Frustrated at Tom Wheeler - Equality for small
business. The second most crowded bucket contains
most of the comments with swearwords: ”if you dumb
asses pass this law taxes will have to go up to pay for schools
and because some schools wont be able to aﬀord it so the
education levels of schools will decrease... and facebook will
die out and many stocks will drop and die aﬀecting the
stock market for many stockholders. with that all aside you
will piss oﬀ millions for literally no reason”
3 - Frustrated at Tom Wheeler - Government, Amer-
ica, Freedom. This bucket was much less profane, and
used patriotic references and national values exten-
sively:
”mr wheeler and fcc members i grow increasingly
concerned with your attempts to ram an anticonsumer net
neutrality bill through the process. we know what you are
doing. you may feel inclined to bow to the corporate inﬂu-
ences”
4 - Legal References - ISPs Data Treatment. Contain-
ing relatively higher levels of rigor, this bucket shows
that people who are worried about monopolization of
data had the most eloquent comments:
”isps need
to be reclassiﬁed as title ii common carriers allowing this
proceeding to go through would allow isps to charge people
extra fees to carry traﬃc from any online business that they
want if a company depends heavily or entirely on internet
traﬃc the isp could refuse to allow web pages to load in
under a minute”
5 - Experiences and Anecdotes - Innovation and
startup encouragement. This bucket held an inter-
estingly high number of comments from people who
were very worried about their proﬁts or lifestyles, but
did not have a very clear understanding of the case:
”i am an artist. how can i succeed in an internet that fa-
vors already built giants. who will be able to ﬁnd me in a
segregated cyberspace. i will no longer be able to ﬁnd end-
less inspiration and utilize the internet the way i do now”

One bucket that we were surprised was the low cor-
relation of use of legal terminology and legal references

component. This may be the case because the legal
references bucket had the length and rigor of the com-
ment as a strong characteristic, and personal worries
captured a lot of comments that were well informed
and used terminology, but were short or included col-
loquialisms.

We found signiﬁcant correlation between the legal
reference comments, and the dreams and values com-
ments in terms of subjects they tackled, even though
their level of rigor is was distinctive. Large companies
controlling information was repeatedly mentioned in
personal worries, even though it is rarely mentioned
by legal reference documents. Comments with high
profanity were also simplest. Government and Amer-
ican values were rarely referred to in personal worries
or experiences, but were very common on comments at
Tom Wheeler, legal references and dreams and values.
Most of the garbage data that was unusually long,
literary or complicated, such as the full text of The
Great Gatsby or LCD screen instructions, were also
contained in the legal references cluster.

Future Work

There are several directions in which we could expand
our work from this paper. Looking further into our
data set, we should be able to extract more informa-
tion on how modiﬁcations to form letters correspond
to the topics and comment characteristics that we have
found. In our current dataset, which contains a frac-
tion of the original comments, there were not enough
form letters with original content added on to draw
any conclusions.
We could also investigate the mapping additional fea-
tures such as gender and location of the commenter or
time of comment to the topics and characterizations
we’ve identiﬁed. Triggers of high numbers of similar
comment submissions can be deduced, which can be
both in forms of celebrity or website encouragement,
or response to events. It would be interesting to fur-
ther study the application of similar analysis on a dif-
ferent body of comments, especially on subjects with
multiple aspects and viewpoints. Since the data was
99% supporting net neutrality, the conclusions did not
lead to a meaningful potential classiﬁcation problem.
The topic-component cross analysis can especially be
helpful in debates with non-binary outcomes.

Conclusion

This research project is a ﬁrst attempt at understand-
ing the large and diverse data set that results from an
open comment platform. By clustering similar atti-
tudes, subjects and concerns, common threads can be
found throughout the comments. Using this type of

4

analysis, the voice of public sentiment can be better
understood and taken into consideration for the issue

of net neutrality, and other debates in the future.

Figures

Figure 1: Topic Weights per Topic. For each of the three groups with blue corresponding to all comments, green
corresponding to form letters, and red corresponding to random comments, along with standard error.

Feature
I
We
You
Ave Len
Tot Len
Negative
Must
Should
Will
May
Can
Tom W
Cable
Read Ease
Swear
Means:
Vars:

Comp 1 Comp 2 Comp 3 Comp 4 Comp 5
0.343
0.055
0.008
0.619
0.033
0.452
-0.067
0.012
0.375
0.218
0.298
0.006
0.046
-0.059
-0.052
0.153
0.043

-0.233
0.563
-0.022
0.029
0.195
-0.199
0.271
-0.513
0.170
0.096
0.201
-0.150
-0.302
-0.146
-0.023
-0.004
0.067

0.438
-0.381
-0.153
-0.190
0.086
-0.166
-0.363
-0.250
0.039
0.064
0.081
-0.398
-0.423
-0.153
-0.016
-0.119
0.052

0.082
-0.154
0.353
-0.022
0.508
-0.080
-0.071
-0.157
-0.028
0.016
-0.034
0.377
0.204
-0.508
-0.328
0.054
0.064

0.141
-0.014
0.564
-0.041
-0.423
-0.097
-0.121
-0.354
0.139
0.017
0.046
0.233
-0.120
0.419
0.256
0.043
0.065

Figure 2: This table lists the weighing of diﬀerent features for each component. The ﬁve components correspond
to: Personal Worries, Legal References, Frustrated at Tom Wheeler, Dreams and Values, Experiences
and Anecdotes.

5

The Many Dimensions of Net Neutrality

(and how we reduced them)

Erin Antono, Deger Turan, Justine Zhang

Introduction

In the spirit of democracy, government organizations
often solicit public comments before a major ruling,
ostensibly to incorporate the public’s input into their
ﬁnal decision. The massive scale of comments these
campaigns attract often prohibits manual inspection.
The ability to analyze and understand this large body
of comments computationally therefore allows these
organizations to better understand the public’s ideas
and overall sentiment.
In this paper, we use unsupervised learning techniques
to understand the content of the comments that the
Federal Communications Commission (FCC) has re-
ceived, relating to its upcoming decisions on net neu-
trality.
In particular, we discuss the application of
Singular Value Decomposition (SVD) to extract key
topical and linguistic characteristics of comments. We
ﬁrst use SVD to extract common topics and their rep-
resentative comments and keywords, based on a tf-idf
weighting of each word used. We then use SVD on
a smaller set of linguistic features, and discover ﬁve
types of comments corresponding to the ﬁve top com-
ponents extracted by SVD, which appear to reﬂect
characteristics such as a commenter’s personal invest-
ment in the issue and the other ﬁgures and organiza-
tions present in the comment’s narrative. Finally, we
perform a cross-comparison of the topical and linguis-
tic components.

Data Set

As of September 2014, the FCC has received over 1.1
million comments on the subject of net neutrality, and
has made the full set of comments available to the
public. Before the start of our project, the Sunlight
Foundation had done analysis on the comments, and
made a set of cleaned data available to the public. For
our project, we started with the Sunlight Foundation’s
set of 800,000 comments, which had been stripped of
a large number of garbage comments[1]. To make the
task more manageable, we constrained our analysis to
a random subset of about 80,000 comments.
As was expected for a forum with open public sub-
missions, the net neutrality comments contained large
quantities of form letters submitted from a variety of
sources. The Sunlight Foundation estimates that ap-
proximately 60% of the data consisted of form letters.
This redundancy made analysis more diﬃcult, because
the large number of nearly-identical comments ob-
scured much of the vocabulary and linguistic features

present in the comments which did not originate from
form letter campaigns. Hence we made an eﬀort to
remove these duplicates.

Preprocessing

We used a corpus of the original form letter documents
from the Sunlight Foundation[1] and the nltk sentence
tokenizer[2] to clean our data. We hence detected form
letter content within each comment on a per-sentence
basis, in order to retain original content which a user
had added to a form letter. Finally, the sentences were
normalized by removing punctuation and casing.
After early attempts at topic modeling, we found that
our topic keywords were dominated by names and ad-
dresses; additionally, the most salient keywords of sev-
eral topics all clearly originated from speciﬁc sentences
in the comments which occurred frequently, and were
missed by our intial form letter detection. To account
for this problem, sentences containing irrelevant infor-
mation such as names, addresses, or greetings were re-
moved altogether. We further cleaned the data set by
treating sentences that occurred more than 10 times
as sentences from undetected form letters.
After this ﬁltering, our results were still similarly im-
pacted by the presence of short comments which were
not necessarily from form letters, but were still nearly-
identical to one another as a consequence of their
length. While it may be interesting to study the prop-
agation of such buzzwords as ”net neutrality” and
”level playing ﬁeld” in short comments, we decided to
focus our analysis on comments for which the writer
could have plausibly contributed a meaningful amount
of personal input, as opposed to terse comments which
were basically variants of these buzzwords. As a sim-
ple heuristic, we removed all comments with less than
four sentences. After these steps, our ﬁltered dataset
consisted of around 15,000 comments; among them
there are 13 form letter comments.

Method

We used the Singular Value Decomposition algorithm
(SVD) from scikit-learn [5] to perform dimensional-
ity reduction on our dataset, allowing us to discover
the most salient characteristics of the comments. As
a brief overview of the process, given m comments
and n features, let X ∈ Rm×n be a matrix with Xi,j
= the value of feature j in comment i. Given some
k < n, we produce a low-rank approximation of X,

1

Xk = UkΣkV T
k where Σk is a diagonal matrix contain-
ing X’s k largest singular values; this hence represents
k components inferred from the original features. Ui,j
then corresponds to the value of new component j at
comment i, while Vi,j corresponds to the weighting of
feature j at old feature i. Higher values roughly cor-
respond to that component being more characteristic
of the comment or feature.

Topic Analysis

To determine the most common topics represented
in the comments, we used the term frequency-inverse
document frequency (tf-idf) scores of each word in a
particular comment as the set of features for that com-
ment.
We applied the SVD algorithm to this set of fea-
tures, which is also known as Latent Semantic Analysis
(LSA) when used in this context.

Results

We chose the number of topics for interpretability of
results, arriving at k = 10 topics (we also attempted
to choose k such that the improvement in reconstruc-
k | levelled oﬀ, producing 25
tion error |X − UkΣkV T
topics, but the diﬀerences between topics were much
more subtle).

Using the notation above, after performing SVD, for
each topic j, the most important words i maximize Vij
and the most representative comments maximize Uij.
For instance, here are the most representative words,
and most representative comment for a selection of
two topics:
Topic 2 - Cable Companies
companies cable comcast
Most important words:
speeds pay consumers charge speed competition net-
ﬂix monopolies monopoly company money dont net
big warner faster lane
Example comment:
”Regarding the proposal to permit
cable companies and other ISPs to charge companies to pro-
vide faster downloads: This is the most ridiculous proposal
I have heard in a long time. The cable companies, eg. Com-
cast and Time Warner are claiming that such fees to com-
panies like Netﬂix would not create a two-tier fast lane-slow
lane internet.”
Topic 3 - Legal terminology
Most important words: net neutrality fcc common ti-
tle rules broadband ii carriers telecommunications pro-
tect reclassify proposed urge support wheeler chair-
man isps carrier public
Example comment: ”Net neutrality is the First Amend-
ment of the Internet, the principle that Internet service
providers (ISPs) treat all data equally. As an Internet user,
net neutrality is vitally important to me. The FCC should

use its Title II authority to protect it.”
Topic 6 - Small Business Equality
Most important words: fast lane lanes small business
businesses slow big open internet pay playing ﬁeld af-
ford level rules innovation create equal traﬃc
Example comment: ”there is no diﬀerence between the
statements ’fast lane’ and ’slow lane’, and ’fast lane’ and
’hyper fast lane’. We’re not stupid. This will only allow
big corporations with money to squeeze out little start up
companies that would have no way to aﬀord to pay for this
hyper fast lane...”
The full list of topics we labelled after analyzing the
examples are as follows: free and open Internet, Amer-
ica government and freedom, cable companies, legal
terminology, innovation and startup encouragement,
ISP proﬁts, small business equality, ISP-consumer re-
lationship, ISP-data treatment, companies controlling
information.

Form letter topics

a set of comments S for topic j, |S|−1(cid:80)

Given the high volume of form letters, one question we
may ask is this: Do form letters talk about diﬀerent
topics than original comments, which are unaﬃliated
with any form letter campaigns? To answer this ques-
tion, we use the topic weights for each comment as
produced above. Consider the average topic weight of
x∈S Uxj. For
each topic, we calculate the average weight over all
the comments, over only the 13 form letter comments,
and over a random sample of 13 comments (as a con-
trol). A bar graph of topic weights per topic is shown
in Figure 1.

From the graph we can see that in particular, form
letters seem to mention topic 3, ”legal terminology”,
a lot more than the average comment (representative
words and comments for this topic are listed above).
This is corroborated by a manual examination of the
form letter comments, which are mostly fairly explicit
references to past legislation and proposed legislative
changes:
”title ii of the communications act of 1934 already grants
you the authority to declare the internet a public utility”
(from the Daily Kos) [3]
”The FCC should use its Title II authority to protect [net
neutrality]” (from Battle for the Net) [4]

Given these results, we may tentatively conclude the
following: while most comments encompass a wider
range of ideas, form letters are speciﬁcally organized
calls for legislative change.

Linguistic analysis

In addition to determining the topic content of the
comments, we also wanted to gain insight into how

2

the comments were written. We hoped to capture dif-
ferences in degree of personal investment, determine
the intended audience and subject for diﬀerent com-
ments, and intensity and politeness of the commenters.

Features

We used features were based on linguistic character-
istics of the comments, attitudes of the writers, and
entities the comments were directed to. We consid-
ered the following features from each document:

% sentences with 1st singular related pronouns
% sentences with 1st plural related pronouns
% sentences with 2nd singular related pronoun
average # words per sentence
# sentences
% sentences with negation (”no”, ”nt”, ”not”)
% sentences with ”must” etc.
% sentences with ”should” etc.
% sentences with ”will” etc.
% sentences with ”may” etc.
% sentences with ”can” etc.
Flesch-Kincaid Reading Ease scores
Mentioning of Chairman Tom Wheeler
Mentioning of swear words
Mentioning of companies ”ATT Warner Verizon

Comcast”
The feature vectors, corresponding to rows of X from
the above notation, were normalized to get a mean of
0 and variance of 1.

Results

Using these features, with k = 5, we found the follow-
ing of comments which were characterized in surpris-
ingly striking and intuitive ways, which we list below.
The full table of components to features is shown in
Figure 2.

1- Personal Worries - Deﬁning Features: High use
of I and negatives, low terminology, no directed audi-
ence:
”i was a computer wizard practically before i could read
without a parent over my shoulder and i think its obvious
why someone who knows computers so well would be so
concerned...”
”dear fcc i use my pc like millions of others do online for
research for diseases or for radio astronomy in conjunc-
tion with volunteer run projects at universities across the
usa those that use the boinc interface, seti@home, ein-
stein@home, rosetta@home, milkyway@home gpugrid etc”
2- Legal References - Deﬁning Features: Low reading
ease, low profanity, lengthy comments:
”forbearance furthers the objective of interpreting law in
light of modern technology and markets without undermin-
ing its core purposes.”

3

”before the federal communications commission washing-
ton dc in the matter of protecting and promoting the open
internet gn docket no. 1428 framework for broadband in-
ternet service gn docket no. 10127 comments of comcast
corporation comcast corporation”
3- Frustrated at Tom Wheeler - Deﬁning Features:
High use of you and profanity, directed at Tom
Wheeler, concise comments:
”mr wheeler i will ﬁrst remind you that you are an employee
of the federal government of the united states of america.
basically you work for us the people.”
”mr wheeler as a paying customer of the internet i ﬁnd
what you are doing oﬀensive and incredibly criminal.
if
you do not back down from this position of destroying net
neutrality i and every one of the computer geeks i know will
demand your resignation.”
4-Dreams and Values - Deﬁning Features: High use of
plural pronouns, can, must; no directed audience
”please consider as this part of our era is economically
hard in so many ways. for many like me who are somewhat
housebound the internet is our library our bank”
”the internet has already greatly changed the way our world
works and for a time this was acceptable. unfortunately
legislation has failed to keep up with the technology and we
have reached a crossroads that could make or break the con-
tinued prosperity and innovation the internet provides.”
5-Experiences and Anecdotes -s Deﬁning Features:
High use of I, low negativity, short comments
”the internet is important to me because as someone who
suﬀers from disabilities due to multiple sclerosis it gives me
back some of my independence that this disease has stripped
from me. i can go online and research treatments to better
make informed decisions.”
”i work for a company that creates comedic videos and puts
them online. its my livelihood. if the internet becomes an
exclusive club myself and many others may be out of a job.”

When we used higher numbers of components, later
components corresponding to small eigenvalues had a
neutral and balanced amount of features, and were not
very helpful in discerning commenter attitudes.

Overall Results

With these two diﬀerent sets of characteristic compo-
nents of our comment set, we wanted to investigate the
relationship between the two. To do this, we created
a matrix M ∈ Rtxc. t is the number of topics, c is the
number of components, Ut is the U vector resulting
from topic modeling and Uc is the U vector resulting
from comment clustering.

M [i, j] =(cid:80)n

k=0 Ut[k, i] ∗ Uc[k, j].

From M , we obtain an other vector M(cid:48), which is nor-
malized such that M(cid:48) = M/max(M ). A large M(cid:48)[i, j]

value indicates high overlap between topic i and com-
ponent j. A heatmap of these weightings is shown
in Figure 3. We found that each component-vector
pairing, which we call comment buckets, matched a
characteristic portrait of a commenter.
The correspondence of the topics and components
was reasonable. The most crowded comments buckets
were:
1 - Personal worries - Innovation and startup en-
couragement. Most people in this bucket either are,
or particularly concerned about small business and
startup owners:
”i am a small businessman. the inter-
net is critical my success. consigning me to a slow lane of
the internet might do serious damage to the success of my
business. also as a private individual i believe the internet
serves as a public good”
2 - Frustrated at Tom Wheeler - Equality for small
business. The second most crowded bucket contains
most of the comments with swearwords: ”if you dumb
asses pass this law taxes will have to go up to pay for schools
and because some schools wont be able to aﬀord it so the
education levels of schools will decrease... and facebook will
die out and many stocks will drop and die aﬀecting the
stock market for many stockholders. with that all aside you
will piss oﬀ millions for literally no reason”
3 - Frustrated at Tom Wheeler - Government, Amer-
ica, Freedom. This bucket was much less profane, and
used patriotic references and national values exten-
sively:
”mr wheeler and fcc members i grow increasingly
concerned with your attempts to ram an anticonsumer net
neutrality bill through the process. we know what you are
doing. you may feel inclined to bow to the corporate inﬂu-
ences”
4 - Legal References - ISPs Data Treatment. Contain-
ing relatively higher levels of rigor, this bucket shows
that people who are worried about monopolization of
data had the most eloquent comments:
”isps need
to be reclassiﬁed as title ii common carriers allowing this
proceeding to go through would allow isps to charge people
extra fees to carry traﬃc from any online business that they
want if a company depends heavily or entirely on internet
traﬃc the isp could refuse to allow web pages to load in
under a minute”
5 - Experiences and Anecdotes - Innovation and
startup encouragement. This bucket held an inter-
estingly high number of comments from people who
were very worried about their proﬁts or lifestyles, but
did not have a very clear understanding of the case:
”i am an artist. how can i succeed in an internet that fa-
vors already built giants. who will be able to ﬁnd me in a
segregated cyberspace. i will no longer be able to ﬁnd end-
less inspiration and utilize the internet the way i do now”

One bucket that we were surprised was the low cor-
relation of use of legal terminology and legal references

component. This may be the case because the legal
references bucket had the length and rigor of the com-
ment as a strong characteristic, and personal worries
captured a lot of comments that were well informed
and used terminology, but were short or included col-
loquialisms.

We found signiﬁcant correlation between the legal
reference comments, and the dreams and values com-
ments in terms of subjects they tackled, even though
their level of rigor is was distinctive. Large companies
controlling information was repeatedly mentioned in
personal worries, even though it is rarely mentioned
by legal reference documents. Comments with high
profanity were also simplest. Government and Amer-
ican values were rarely referred to in personal worries
or experiences, but were very common on comments at
Tom Wheeler, legal references and dreams and values.
Most of the garbage data that was unusually long,
literary or complicated, such as the full text of The
Great Gatsby or LCD screen instructions, were also
contained in the legal references cluster.

Future Work

There are several directions in which we could expand
our work from this paper. Looking further into our
data set, we should be able to extract more informa-
tion on how modiﬁcations to form letters correspond
to the topics and comment characteristics that we have
found. In our current dataset, which contains a frac-
tion of the original comments, there were not enough
form letters with original content added on to draw
any conclusions.
We could also investigate the mapping additional fea-
tures such as gender and location of the commenter or
time of comment to the topics and characterizations
we’ve identiﬁed. Triggers of high numbers of similar
comment submissions can be deduced, which can be
both in forms of celebrity or website encouragement,
or response to events. It would be interesting to fur-
ther study the application of similar analysis on a dif-
ferent body of comments, especially on subjects with
multiple aspects and viewpoints. Since the data was
99% supporting net neutrality, the conclusions did not
lead to a meaningful potential classiﬁcation problem.
The topic-component cross analysis can especially be
helpful in debates with non-binary outcomes.

Conclusion

This research project is a ﬁrst attempt at understand-
ing the large and diverse data set that results from an
open comment platform. By clustering similar atti-
tudes, subjects and concerns, common threads can be
found throughout the comments. Using this type of

4

analysis, the voice of public sentiment can be better
understood and taken into consideration for the issue

of net neutrality, and other debates in the future.

Figures

Figure 1: Topic Weights per Topic. For each of the three groups with blue corresponding to all comments, green
corresponding to form letters, and red corresponding to random comments, along with standard error.

Feature
I
We
You
Ave Len
Tot Len
Negative
Must
Should
Will
May
Can
Tom W
Cable
Read Ease
Swear
Means:
Vars:

Comp 1 Comp 2 Comp 3 Comp 4 Comp 5
0.343
0.055
0.008
0.619
0.033
0.452
-0.067
0.012
0.375
0.218
0.298
0.006
0.046
-0.059
-0.052
0.153
0.043

-0.233
0.563
-0.022
0.029
0.195
-0.199
0.271
-0.513
0.170
0.096
0.201
-0.150
-0.302
-0.146
-0.023
-0.004
0.067

0.438
-0.381
-0.153
-0.190
0.086
-0.166
-0.363
-0.250
0.039
0.064
0.081
-0.398
-0.423
-0.153
-0.016
-0.119
0.052

0.082
-0.154
0.353
-0.022
0.508
-0.080
-0.071
-0.157
-0.028
0.016
-0.034
0.377
0.204
-0.508
-0.328
0.054
0.064

0.141
-0.014
0.564
-0.041
-0.423
-0.097
-0.121
-0.354
0.139
0.017
0.046
0.233
-0.120
0.419
0.256
0.043
0.065

Figure 2: This table lists the weighing of diﬀerent features for each component. The ﬁve components correspond
to: Personal Worries, Legal References, Frustrated at Tom Wheeler, Dreams and Values, Experiences
and Anecdotes.

5

Figure 3: Heatmap of Topics and Components. This ﬁgure was generated using plot.ly[6]

References

1. Lannon, Bob, and Andrew Pendleton. ”What Can We Learn from 800,000 Public Comments on the FCC’s Net Neutrality

Plan?” Sunlight Foundation, 2 Sept. 2014. Web. 08 Dec. 2014. http://sunlightfoundation.com/blog/2014/09/02/what-can-we-

learn-from-800000-public-comments-on-the-fccs-net-neutrality-plan/

2. Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. OReilly Media Inc.

3. ”Sign the Petition: Save Net Neutrality, Stop the Dangerous.” Daily Kos. Web. 13 Dec. 2014. https://www.dailykos.com/campaigns/785

4. ”This Is Why Your Internet Is Slow. And It’ll Get Worse. Unless You Take 1 Min to Do This, Now.” Battle For The Net.

Team@ﬁghtforthefuture.org. Web. 13 Dec. 2014. https://www.battleforthenet.com/ 5. Pedregosa et al., Scikit-learn: Machine

Learning in Python,, JMLR 12, pp. 2825-2830, 2011. http://scikit-learn.org/stable/modules/decomposition.html

6. ”Heatmap Made by Eantono — Plotly.” Heatmap Made by Eantono @ Plotly. Plot.ly at https://github.com/plotly, 13 Dec.

2014. Web. 13 Dec. 2014. https://plot.ly/ eantono/28

6

