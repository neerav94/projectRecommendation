Algorithmic Trading Strategy Based

On Massive Data Mining

Haoming Li, Zhijun Yang and Tianlun Li

Stanford University

Abstract

We believe that there is useful information hiding behind the noisy and massive data that can provide
us insight into the ﬁnancial markets. Our goal in this project is to ﬁnd a strategy to select proﬁtable
U.S stocks everyday by mining the public data. To achieve this we build models that predict the daily
return of a stock from a set of features. These features are constructed based on quoted and external data
that is available before the prediction date. When considering machine learning models we consider both
regression and classiﬁcation approaches and several supervised learning algorithms are implemented. In
order to catch the dynamical nature of the ﬁnancial market, we carefully design out-sample testing and
cross validation procedures to ensure that our historical test results are reasonable and is achievable in
the real market. Finally, we construct stock portfolios based on our forecast models and illustrate the
performance of these portfolios to show that our strategy works indeed.

I.

Introduction

How can we discover stocks that will

rise in the future? The general answer
is to gather as much relevant and non-
trivial information as possible. One possible
way to get such information is mining the huge
amount of ﬁnancial and Internet data that can-
not be easily understood. This data allows us
to deﬁne various features for each individual
stock. For example, we can distinguish dif-
ferent stocks by their historical performance,
trading volume or sensitivity to external eco-
nomical and ﬁnancial variables. Then we can
use machine learning models to discover the
underlying relation between these features and
actual performance of stocks. Finally, we can
select those stocks that are predicted to have
the highest returns.

The report is organized as follows. In part
2 we mainly discuss what data we are using
and how we collected and processed the data.
In part 3 we introduce our methodology of
constructing features. Part 4 gives the machine
learning models that we are implementing and
the procedures of dynamically training and
testing. Part 5 gives the results and the perfor-

mance of our daily selected portfolio as well as
some discussions and analysis on the results
we get. In Part 6 we draw the summary.

II. Data description

We collected daily trading data of 2666 U.S
stocks trading (or once traded) at NYSE or
NASDAQ from 2000-01-01 to 2014-11-10. This
dataset includes each day’s open price, close
price, highest price, lowest price and trading
volume of every stock. Data is collected from a
free online database named Quandl.

Meanwhile, we also collected data that is
not directly related to each stock but may con-
tain additional information for forecasting pur-
poses. These include the daily quotes of 5
commodity future contracts (gold, crude oil,
nature gas, corn, cotton), 2 foreign currencies
(EUR, JPY) and 1 interest rate (10-year treasury
rate), all from 2000-01-01 to 2014-11-10. The
aggregate size of all data ﬁles is 1.11 GB.

1

Algorithmic Trading Strategy Based

On Massive Data Mining

Haoming Li, Zhijun Yang and Tianlun Li

Stanford University

Abstract

We believe that there is useful information hiding behind the noisy and massive data that can provide
us insight into the ﬁnancial markets. Our goal in this project is to ﬁnd a strategy to select proﬁtable
U.S stocks everyday by mining the public data. To achieve this we build models that predict the daily
return of a stock from a set of features. These features are constructed based on quoted and external data
that is available before the prediction date. When considering machine learning models we consider both
regression and classiﬁcation approaches and several supervised learning algorithms are implemented. In
order to catch the dynamical nature of the ﬁnancial market, we carefully design out-sample testing and
cross validation procedures to ensure that our historical test results are reasonable and is achievable in
the real market. Finally, we construct stock portfolios based on our forecast models and illustrate the
performance of these portfolios to show that our strategy works indeed.

I.

Introduction

How can we discover stocks that will

rise in the future? The general answer
is to gather as much relevant and non-
trivial information as possible. One possible
way to get such information is mining the huge
amount of ﬁnancial and Internet data that can-
not be easily understood. This data allows us
to deﬁne various features for each individual
stock. For example, we can distinguish dif-
ferent stocks by their historical performance,
trading volume or sensitivity to external eco-
nomical and ﬁnancial variables. Then we can
use machine learning models to discover the
underlying relation between these features and
actual performance of stocks. Finally, we can
select those stocks that are predicted to have
the highest returns.

The report is organized as follows. In part
2 we mainly discuss what data we are using
and how we collected and processed the data.
In part 3 we introduce our methodology of
constructing features. Part 4 gives the machine
learning models that we are implementing and
the procedures of dynamically training and
testing. Part 5 gives the results and the perfor-

mance of our daily selected portfolio as well as
some discussions and analysis on the results
we get. In Part 6 we draw the summary.

II. Data description

We collected daily trading data of 2666 U.S
stocks trading (or once traded) at NYSE or
NASDAQ from 2000-01-01 to 2014-11-10. This
dataset includes each day’s open price, close
price, highest price, lowest price and trading
volume of every stock. Data is collected from a
free online database named Quandl.

Meanwhile, we also collected data that is
not directly related to each stock but may con-
tain additional information for forecasting pur-
poses. These include the daily quotes of 5
commodity future contracts (gold, crude oil,
nature gas, corn, cotton), 2 foreign currencies
(EUR, JPY) and 1 interest rate (10-year treasury
rate), all from 2000-01-01 to 2014-11-10. The
aggregate size of all data ﬁles is 1.11 GB.

1

III. Targets and Features

Construction

As our goal is to predict the daily return of
each stock, then we naturally deﬁne our target
as stock i’s daily return on day t for all i and t:

Targeti,t =

ClosePricei,t
OpenPricei,t

− 1

(1)

Note that we can also focus only on the direc-
tion in spite of the amplitude. Another way of
deﬁning or targets is:

(cid:18) ClosePricei,t

OpenPricei,t

(cid:19)

− 1

(2)

Target(cid:48)

i,t = sign

For the ﬁrst deﬁnition we have a regression
problem and for the second we have a classiﬁ-
cation problem. Both of these two setups will
be tried.

And then we have to construct features that
help distinguish (or say, deﬁne) each stock ev-
ery day. These features should be relevant to
the performance and should be available be-
fore the trading day.
It is well known that
stock performance is correlated with dozens
of things and our model will only employ a
relative small amount of features in this paper
for simplicity.

The features we constructed can be divided
into two categories. The ﬁrst category, which
is named as direct features, contains some
variables that are constructed by explicit (and
lagged) market data of stocks, e.g., open, close,
high, low, etc. The other category is named as
indirect features and concerns about the infor-
mation carried by external factors. That is, we
construct one feature for each external variable
to reﬂect how a speciﬁc stock can be affected
at a certain day when the external variable
changes. Now we will have a more detailed
discussion on how we construct the features by
category:

Direct Features:
Based on our raw data, we constructed 4

direct features:

RETi,t =

ClosePricei,t
OpenPricei,t

− 1 = Targeti,t−1

(3)

(4)

(5)

(cid:19)

HLi,t =

HighPricei,t
LowPricei,t

VOLi,t = ln (TradingVolumei,t−1)

(cid:18) TradingVolumei,t−1

TradingVolumei,t−2

VOLCHNGi,t = ln

(6)
These four features are properly lagged so
that can be computed. And these are all rele-
vant since they measure some trends or relative
strength of each stock.

Indirect Features:
The intuition of constructing indirect fea-
tures corresponding to some external economic
indices is to compute the ‘sensitivity’ of each
stock’s return to these indices and multiply
this sensitivity by the latest indices values. As
mentioned above we have data of 8 external
indices (5 commodity futures, 2 foreign curren-
cies and 1 interest rate). For index j, we deﬁne
the corresponding feature for stock i at day t
as:

EXTRN_ji,t = β_ji,t × indexjt−1

(7)

Where:
(c, β_1i,t,· · · , β_8i,t)T = argminβ(cid:107)Xi,tβ − yi,t(cid:107)2
(8)
Where:

index_1t−2

index_8t−2

 1

:
1

Xi,t =



· · ·
...
· · ·

:

index_1t−T−1

 Targeti,t−1

:

Targeti,t−T



yi,t =

:

index_8t−T−1
(9)

(10)

Here T is an arbitrary window period parame-
ter to compute sensitivity. Intuitively, these 8
indirect features describe the relative change
of stock i’th possible price change at time t
with respect to the change of index j at time t-1.
Since everything deﬁned here is lagged, the
values of these 8 indirect features are available.
Thus we construct 12 features for stocks.
Cross-sectional averages of these features are
shown as follows:

2

Algorithmic Trading Strategy Based

On Massive Data Mining

Haoming Li, Zhijun Yang and Tianlun Li

Stanford University

Abstract

We believe that there is useful information hiding behind the noisy and massive data that can provide
us insight into the ﬁnancial markets. Our goal in this project is to ﬁnd a strategy to select proﬁtable
U.S stocks everyday by mining the public data. To achieve this we build models that predict the daily
return of a stock from a set of features. These features are constructed based on quoted and external data
that is available before the prediction date. When considering machine learning models we consider both
regression and classiﬁcation approaches and several supervised learning algorithms are implemented. In
order to catch the dynamical nature of the ﬁnancial market, we carefully design out-sample testing and
cross validation procedures to ensure that our historical test results are reasonable and is achievable in
the real market. Finally, we construct stock portfolios based on our forecast models and illustrate the
performance of these portfolios to show that our strategy works indeed.

I.

Introduction

How can we discover stocks that will

rise in the future? The general answer
is to gather as much relevant and non-
trivial information as possible. One possible
way to get such information is mining the huge
amount of ﬁnancial and Internet data that can-
not be easily understood. This data allows us
to deﬁne various features for each individual
stock. For example, we can distinguish dif-
ferent stocks by their historical performance,
trading volume or sensitivity to external eco-
nomical and ﬁnancial variables. Then we can
use machine learning models to discover the
underlying relation between these features and
actual performance of stocks. Finally, we can
select those stocks that are predicted to have
the highest returns.

The report is organized as follows. In part
2 we mainly discuss what data we are using
and how we collected and processed the data.
In part 3 we introduce our methodology of
constructing features. Part 4 gives the machine
learning models that we are implementing and
the procedures of dynamically training and
testing. Part 5 gives the results and the perfor-

mance of our daily selected portfolio as well as
some discussions and analysis on the results
we get. In Part 6 we draw the summary.

II. Data description

We collected daily trading data of 2666 U.S
stocks trading (or once traded) at NYSE or
NASDAQ from 2000-01-01 to 2014-11-10. This
dataset includes each day’s open price, close
price, highest price, lowest price and trading
volume of every stock. Data is collected from a
free online database named Quandl.

Meanwhile, we also collected data that is
not directly related to each stock but may con-
tain additional information for forecasting pur-
poses. These include the daily quotes of 5
commodity future contracts (gold, crude oil,
nature gas, corn, cotton), 2 foreign currencies
(EUR, JPY) and 1 interest rate (10-year treasury
rate), all from 2000-01-01 to 2014-11-10. The
aggregate size of all data ﬁles is 1.11 GB.

1

III. Targets and Features

Construction

As our goal is to predict the daily return of
each stock, then we naturally deﬁne our target
as stock i’s daily return on day t for all i and t:

Targeti,t =

ClosePricei,t
OpenPricei,t

− 1

(1)

Note that we can also focus only on the direc-
tion in spite of the amplitude. Another way of
deﬁning or targets is:

(cid:18) ClosePricei,t

OpenPricei,t

(cid:19)

− 1

(2)

Target(cid:48)

i,t = sign

For the ﬁrst deﬁnition we have a regression
problem and for the second we have a classiﬁ-
cation problem. Both of these two setups will
be tried.

And then we have to construct features that
help distinguish (or say, deﬁne) each stock ev-
ery day. These features should be relevant to
the performance and should be available be-
fore the trading day.
It is well known that
stock performance is correlated with dozens
of things and our model will only employ a
relative small amount of features in this paper
for simplicity.

The features we constructed can be divided
into two categories. The ﬁrst category, which
is named as direct features, contains some
variables that are constructed by explicit (and
lagged) market data of stocks, e.g., open, close,
high, low, etc. The other category is named as
indirect features and concerns about the infor-
mation carried by external factors. That is, we
construct one feature for each external variable
to reﬂect how a speciﬁc stock can be affected
at a certain day when the external variable
changes. Now we will have a more detailed
discussion on how we construct the features by
category:

Direct Features:
Based on our raw data, we constructed 4

direct features:

RETi,t =

ClosePricei,t
OpenPricei,t

− 1 = Targeti,t−1

(3)

(4)

(5)

(cid:19)

HLi,t =

HighPricei,t
LowPricei,t

VOLi,t = ln (TradingVolumei,t−1)

(cid:18) TradingVolumei,t−1

TradingVolumei,t−2

VOLCHNGi,t = ln

(6)
These four features are properly lagged so
that can be computed. And these are all rele-
vant since they measure some trends or relative
strength of each stock.

Indirect Features:
The intuition of constructing indirect fea-
tures corresponding to some external economic
indices is to compute the ‘sensitivity’ of each
stock’s return to these indices and multiply
this sensitivity by the latest indices values. As
mentioned above we have data of 8 external
indices (5 commodity futures, 2 foreign curren-
cies and 1 interest rate). For index j, we deﬁne
the corresponding feature for stock i at day t
as:

EXTRN_ji,t = β_ji,t × indexjt−1

(7)

Where:
(c, β_1i,t,· · · , β_8i,t)T = argminβ(cid:107)Xi,tβ − yi,t(cid:107)2
(8)
Where:

index_1t−2

index_8t−2

 1

:
1

Xi,t =



· · ·
...
· · ·

:

index_1t−T−1

 Targeti,t−1

:

Targeti,t−T



yi,t =

:

index_8t−T−1
(9)

(10)

Here T is an arbitrary window period parame-
ter to compute sensitivity. Intuitively, these 8
indirect features describe the relative change
of stock i’th possible price change at time t
with respect to the change of index j at time t-1.
Since everything deﬁned here is lagged, the
values of these 8 indirect features are available.
Thus we construct 12 features for stocks.
Cross-sectional averages of these features are
shown as follows:

2

Figure 1: The upper ﬁgure indicates the cross-sectional averages of direct features, including RET, HL, VOL,
VOLCHNG. The lower ﬁgure indicates the cross-sectional averages of indirect features,including gold,
crude oil, nature gas, corn, cotton, USDvsEUR, USDvsJPY and Treasury

IV. Learning Algorithms

Implementation

Now that we have speciﬁed our targets and fea-
tures, implementing speciﬁc machine learning
algorithm is important.

As we have speciﬁed two ways of deﬁning
targets (numerical or categorical), we have two
representations of predicting the performance
of stocks: classiﬁcation and regression. In the
classiﬁcation set-up we try to predict the trend
of the stock in a speciﬁc day. Besides, we pre-
dict the exact return of a stock in regression
set-up. For simplicity we ﬁrst try linear models:
logistic regression as the classiﬁcation model
and linear regression as the regression model.
Then we implement SVM models (classiﬁer
and regression) to explore possible non-linear
regularities utilizing kernels. Before feeding
into models we also normalize and centralize
our features to mean 0 and standard deviation
1. However our model is dynamic rather than
ﬁxed, depending on the date at which a return
is to be predicted. Speciﬁcally, our procedure

of training and testing models are as follows:

1. Specify a training window parameter W

2. To predict the performance of stocks
on the date Ti, use the sample during
Ti − 1, Ti − 2, Ti − 3,· · · , Ti − W as the
training set to train models.

After we generated predictions for every
day we should measure how good our predic-
tions are. We can compute every day’s cor-
rection rate in the classiﬁcation models and
the mean square root error in the regression
models but then it would then be abstruse to
compare cross these two categories. We there-
fore give a more practical and visualizable way
of measuring performance: testing the perfor-
mance of stocks selected by our models. The
methodology is as follows:

1. Specify a portfolio size (number of stocks

to be picked) N

2. Every day choose N stocks according to
the predictions generate by the models.

3

Algorithmic Trading Strategy Based

On Massive Data Mining

Haoming Li, Zhijun Yang and Tianlun Li

Stanford University

Abstract

We believe that there is useful information hiding behind the noisy and massive data that can provide
us insight into the ﬁnancial markets. Our goal in this project is to ﬁnd a strategy to select proﬁtable
U.S stocks everyday by mining the public data. To achieve this we build models that predict the daily
return of a stock from a set of features. These features are constructed based on quoted and external data
that is available before the prediction date. When considering machine learning models we consider both
regression and classiﬁcation approaches and several supervised learning algorithms are implemented. In
order to catch the dynamical nature of the ﬁnancial market, we carefully design out-sample testing and
cross validation procedures to ensure that our historical test results are reasonable and is achievable in
the real market. Finally, we construct stock portfolios based on our forecast models and illustrate the
performance of these portfolios to show that our strategy works indeed.

I.

Introduction

How can we discover stocks that will

rise in the future? The general answer
is to gather as much relevant and non-
trivial information as possible. One possible
way to get such information is mining the huge
amount of ﬁnancial and Internet data that can-
not be easily understood. This data allows us
to deﬁne various features for each individual
stock. For example, we can distinguish dif-
ferent stocks by their historical performance,
trading volume or sensitivity to external eco-
nomical and ﬁnancial variables. Then we can
use machine learning models to discover the
underlying relation between these features and
actual performance of stocks. Finally, we can
select those stocks that are predicted to have
the highest returns.

The report is organized as follows. In part
2 we mainly discuss what data we are using
and how we collected and processed the data.
In part 3 we introduce our methodology of
constructing features. Part 4 gives the machine
learning models that we are implementing and
the procedures of dynamically training and
testing. Part 5 gives the results and the perfor-

mance of our daily selected portfolio as well as
some discussions and analysis on the results
we get. In Part 6 we draw the summary.

II. Data description

We collected daily trading data of 2666 U.S
stocks trading (or once traded) at NYSE or
NASDAQ from 2000-01-01 to 2014-11-10. This
dataset includes each day’s open price, close
price, highest price, lowest price and trading
volume of every stock. Data is collected from a
free online database named Quandl.

Meanwhile, we also collected data that is
not directly related to each stock but may con-
tain additional information for forecasting pur-
poses. These include the daily quotes of 5
commodity future contracts (gold, crude oil,
nature gas, corn, cotton), 2 foreign currencies
(EUR, JPY) and 1 interest rate (10-year treasury
rate), all from 2000-01-01 to 2014-11-10. The
aggregate size of all data ﬁles is 1.11 GB.

1

III. Targets and Features

Construction

As our goal is to predict the daily return of
each stock, then we naturally deﬁne our target
as stock i’s daily return on day t for all i and t:

Targeti,t =

ClosePricei,t
OpenPricei,t

− 1

(1)

Note that we can also focus only on the direc-
tion in spite of the amplitude. Another way of
deﬁning or targets is:

(cid:18) ClosePricei,t

OpenPricei,t

(cid:19)

− 1

(2)

Target(cid:48)

i,t = sign

For the ﬁrst deﬁnition we have a regression
problem and for the second we have a classiﬁ-
cation problem. Both of these two setups will
be tried.

And then we have to construct features that
help distinguish (or say, deﬁne) each stock ev-
ery day. These features should be relevant to
the performance and should be available be-
fore the trading day.
It is well known that
stock performance is correlated with dozens
of things and our model will only employ a
relative small amount of features in this paper
for simplicity.

The features we constructed can be divided
into two categories. The ﬁrst category, which
is named as direct features, contains some
variables that are constructed by explicit (and
lagged) market data of stocks, e.g., open, close,
high, low, etc. The other category is named as
indirect features and concerns about the infor-
mation carried by external factors. That is, we
construct one feature for each external variable
to reﬂect how a speciﬁc stock can be affected
at a certain day when the external variable
changes. Now we will have a more detailed
discussion on how we construct the features by
category:

Direct Features:
Based on our raw data, we constructed 4

direct features:

RETi,t =

ClosePricei,t
OpenPricei,t

− 1 = Targeti,t−1

(3)

(4)

(5)

(cid:19)

HLi,t =

HighPricei,t
LowPricei,t

VOLi,t = ln (TradingVolumei,t−1)

(cid:18) TradingVolumei,t−1

TradingVolumei,t−2

VOLCHNGi,t = ln

(6)
These four features are properly lagged so
that can be computed. And these are all rele-
vant since they measure some trends or relative
strength of each stock.

Indirect Features:
The intuition of constructing indirect fea-
tures corresponding to some external economic
indices is to compute the ‘sensitivity’ of each
stock’s return to these indices and multiply
this sensitivity by the latest indices values. As
mentioned above we have data of 8 external
indices (5 commodity futures, 2 foreign curren-
cies and 1 interest rate). For index j, we deﬁne
the corresponding feature for stock i at day t
as:

EXTRN_ji,t = β_ji,t × indexjt−1

(7)

Where:
(c, β_1i,t,· · · , β_8i,t)T = argminβ(cid:107)Xi,tβ − yi,t(cid:107)2
(8)
Where:

index_1t−2

index_8t−2

 1

:
1

Xi,t =



· · ·
...
· · ·

:

index_1t−T−1

 Targeti,t−1

:

Targeti,t−T



yi,t =

:

index_8t−T−1
(9)

(10)

Here T is an arbitrary window period parame-
ter to compute sensitivity. Intuitively, these 8
indirect features describe the relative change
of stock i’th possible price change at time t
with respect to the change of index j at time t-1.
Since everything deﬁned here is lagged, the
values of these 8 indirect features are available.
Thus we construct 12 features for stocks.
Cross-sectional averages of these features are
shown as follows:

2

Figure 1: The upper ﬁgure indicates the cross-sectional averages of direct features, including RET, HL, VOL,
VOLCHNG. The lower ﬁgure indicates the cross-sectional averages of indirect features,including gold,
crude oil, nature gas, corn, cotton, USDvsEUR, USDvsJPY and Treasury

IV. Learning Algorithms

Implementation

Now that we have speciﬁed our targets and fea-
tures, implementing speciﬁc machine learning
algorithm is important.

As we have speciﬁed two ways of deﬁning
targets (numerical or categorical), we have two
representations of predicting the performance
of stocks: classiﬁcation and regression. In the
classiﬁcation set-up we try to predict the trend
of the stock in a speciﬁc day. Besides, we pre-
dict the exact return of a stock in regression
set-up. For simplicity we ﬁrst try linear models:
logistic regression as the classiﬁcation model
and linear regression as the regression model.
Then we implement SVM models (classiﬁer
and regression) to explore possible non-linear
regularities utilizing kernels. Before feeding
into models we also normalize and centralize
our features to mean 0 and standard deviation
1. However our model is dynamic rather than
ﬁxed, depending on the date at which a return
is to be predicted. Speciﬁcally, our procedure

of training and testing models are as follows:

1. Specify a training window parameter W

2. To predict the performance of stocks
on the date Ti, use the sample during
Ti − 1, Ti − 2, Ti − 3,· · · , Ti − W as the
training set to train models.

After we generated predictions for every
day we should measure how good our predic-
tions are. We can compute every day’s cor-
rection rate in the classiﬁcation models and
the mean square root error in the regression
models but then it would then be abstruse to
compare cross these two categories. We there-
fore give a more practical and visualizable way
of measuring performance: testing the perfor-
mance of stocks selected by our models. The
methodology is as follows:

1. Specify a portfolio size (number of stocks

to be picked) N

2. Every day choose N stocks according to
the predictions generate by the models.

3

For regression model we simply choose
the N stocks that are predicted to have
the highest return, and for classiﬁcation
models we choose N stocks that are best
classiﬁed, i.e., with the largest scores in
the classiﬁcation

3. Compute the actual return of every day’s
stock basket. Compare this time series to
the market index such as S&P 500. Fur-
thermore we can denote one speciﬁc day
as ‘successful’ if the portfolio we selected
has greater return than the market index
and as ‘unsuccessful’ if that didn’t hap-
pen. Then we can compute the successful
rate for each model:

SR =

N o f succes f ul days

N o f total days

(11)

Then we compare different models and
present the model with the best successful rate.

Results see Figure 2 and Figure 3

V. Discussions and Analysis

The linear models behave well. Actually from
the portfolio return graphs we can see that lin-
ear classiﬁcation model and linear regression
model give similar results here. The regression
approach and classiﬁcation approach both can
capture the underlying regularities.

The supporting vector machines don’t be-
have well enough. One possible reason is that
for these extremely noisy data linear simple
models can behave better. SVM classiﬁer’s per-
formance is especially bad. One possible rea-
son is that the ‘conﬁdence’of the classiﬁcation,
or say decision function that we are sorting as
an indicator of potential success doesn’t make
much sense in the non-linear case. Using more
data to train each day’s model may improve the
performance of SVM, but the computational
cost will increase signiﬁcantly since we retrain
our model for each trading day.

Another interesting question to think is
whether our models behave stably over time.
From the graph we ﬁnd that the 2 linear mod-
els behave relatively stably before the end of
2008. To quantify this we compute SR every
80 days and plot these time series showed in
Figure 4

VI. Conclusion

To conclude: we derived an approach to predict
daily returns of U.S stocks based on their trad-
ing data and external ﬁnancial indices. Our lin-
ear models work well in both regression frame-
work and classiﬁcation framework. The best
model turns out to be linear classiﬁer: logistic
regression. It gives 56.65% successful rate and
2000% cumulative return over 14 years. How-
ever as time pass by the models tend to behave
less stably especially after 2008.

In the future we can try to ﬁnd methods
that give more stable predictions. From the per-
spective of machine learning we can try mixing
different models our train models with more
data every day. From the perspective of in-
vestment we can make predictions on ‘alphas’
rather than returns. Also we can try to get
more information from text data. News and
social networks can be excellent information
resources for predicting stocks returns.

References

[Abu-Mostafa and Atiya, 1996] Abu-Mostafa,
Y. S., & Atiya, A. F. (1996). Introduction to
ﬁnancial forecasting. Applied Intelligence.,
6(3):205-213.

[Smola and Schölkopf, 2004 ] Smola, A. J., &
Schölkopf, B. (2004). A tutorial on support
vector regression Statistics and computing.,
14(3): 199-222.

4

Algorithmic Trading Strategy Based

On Massive Data Mining

Haoming Li, Zhijun Yang and Tianlun Li

Stanford University

Abstract

We believe that there is useful information hiding behind the noisy and massive data that can provide
us insight into the ﬁnancial markets. Our goal in this project is to ﬁnd a strategy to select proﬁtable
U.S stocks everyday by mining the public data. To achieve this we build models that predict the daily
return of a stock from a set of features. These features are constructed based on quoted and external data
that is available before the prediction date. When considering machine learning models we consider both
regression and classiﬁcation approaches and several supervised learning algorithms are implemented. In
order to catch the dynamical nature of the ﬁnancial market, we carefully design out-sample testing and
cross validation procedures to ensure that our historical test results are reasonable and is achievable in
the real market. Finally, we construct stock portfolios based on our forecast models and illustrate the
performance of these portfolios to show that our strategy works indeed.

I.

Introduction

How can we discover stocks that will

rise in the future? The general answer
is to gather as much relevant and non-
trivial information as possible. One possible
way to get such information is mining the huge
amount of ﬁnancial and Internet data that can-
not be easily understood. This data allows us
to deﬁne various features for each individual
stock. For example, we can distinguish dif-
ferent stocks by their historical performance,
trading volume or sensitivity to external eco-
nomical and ﬁnancial variables. Then we can
use machine learning models to discover the
underlying relation between these features and
actual performance of stocks. Finally, we can
select those stocks that are predicted to have
the highest returns.

The report is organized as follows. In part
2 we mainly discuss what data we are using
and how we collected and processed the data.
In part 3 we introduce our methodology of
constructing features. Part 4 gives the machine
learning models that we are implementing and
the procedures of dynamically training and
testing. Part 5 gives the results and the perfor-

mance of our daily selected portfolio as well as
some discussions and analysis on the results
we get. In Part 6 we draw the summary.

II. Data description

We collected daily trading data of 2666 U.S
stocks trading (or once traded) at NYSE or
NASDAQ from 2000-01-01 to 2014-11-10. This
dataset includes each day’s open price, close
price, highest price, lowest price and trading
volume of every stock. Data is collected from a
free online database named Quandl.

Meanwhile, we also collected data that is
not directly related to each stock but may con-
tain additional information for forecasting pur-
poses. These include the daily quotes of 5
commodity future contracts (gold, crude oil,
nature gas, corn, cotton), 2 foreign currencies
(EUR, JPY) and 1 interest rate (10-year treasury
rate), all from 2000-01-01 to 2014-11-10. The
aggregate size of all data ﬁles is 1.11 GB.

1

III. Targets and Features

Construction

As our goal is to predict the daily return of
each stock, then we naturally deﬁne our target
as stock i’s daily return on day t for all i and t:

Targeti,t =

ClosePricei,t
OpenPricei,t

− 1

(1)

Note that we can also focus only on the direc-
tion in spite of the amplitude. Another way of
deﬁning or targets is:

(cid:18) ClosePricei,t

OpenPricei,t

(cid:19)

− 1

(2)

Target(cid:48)

i,t = sign

For the ﬁrst deﬁnition we have a regression
problem and for the second we have a classiﬁ-
cation problem. Both of these two setups will
be tried.

And then we have to construct features that
help distinguish (or say, deﬁne) each stock ev-
ery day. These features should be relevant to
the performance and should be available be-
fore the trading day.
It is well known that
stock performance is correlated with dozens
of things and our model will only employ a
relative small amount of features in this paper
for simplicity.

The features we constructed can be divided
into two categories. The ﬁrst category, which
is named as direct features, contains some
variables that are constructed by explicit (and
lagged) market data of stocks, e.g., open, close,
high, low, etc. The other category is named as
indirect features and concerns about the infor-
mation carried by external factors. That is, we
construct one feature for each external variable
to reﬂect how a speciﬁc stock can be affected
at a certain day when the external variable
changes. Now we will have a more detailed
discussion on how we construct the features by
category:

Direct Features:
Based on our raw data, we constructed 4

direct features:

RETi,t =

ClosePricei,t
OpenPricei,t

− 1 = Targeti,t−1

(3)

(4)

(5)

(cid:19)

HLi,t =

HighPricei,t
LowPricei,t

VOLi,t = ln (TradingVolumei,t−1)

(cid:18) TradingVolumei,t−1

TradingVolumei,t−2

VOLCHNGi,t = ln

(6)
These four features are properly lagged so
that can be computed. And these are all rele-
vant since they measure some trends or relative
strength of each stock.

Indirect Features:
The intuition of constructing indirect fea-
tures corresponding to some external economic
indices is to compute the ‘sensitivity’ of each
stock’s return to these indices and multiply
this sensitivity by the latest indices values. As
mentioned above we have data of 8 external
indices (5 commodity futures, 2 foreign curren-
cies and 1 interest rate). For index j, we deﬁne
the corresponding feature for stock i at day t
as:

EXTRN_ji,t = β_ji,t × indexjt−1

(7)

Where:
(c, β_1i,t,· · · , β_8i,t)T = argminβ(cid:107)Xi,tβ − yi,t(cid:107)2
(8)
Where:

index_1t−2

index_8t−2

 1

:
1

Xi,t =



· · ·
...
· · ·

:

index_1t−T−1

 Targeti,t−1

:

Targeti,t−T



yi,t =

:

index_8t−T−1
(9)

(10)

Here T is an arbitrary window period parame-
ter to compute sensitivity. Intuitively, these 8
indirect features describe the relative change
of stock i’th possible price change at time t
with respect to the change of index j at time t-1.
Since everything deﬁned here is lagged, the
values of these 8 indirect features are available.
Thus we construct 12 features for stocks.
Cross-sectional averages of these features are
shown as follows:

2

Figure 1: The upper ﬁgure indicates the cross-sectional averages of direct features, including RET, HL, VOL,
VOLCHNG. The lower ﬁgure indicates the cross-sectional averages of indirect features,including gold,
crude oil, nature gas, corn, cotton, USDvsEUR, USDvsJPY and Treasury

IV. Learning Algorithms

Implementation

Now that we have speciﬁed our targets and fea-
tures, implementing speciﬁc machine learning
algorithm is important.

As we have speciﬁed two ways of deﬁning
targets (numerical or categorical), we have two
representations of predicting the performance
of stocks: classiﬁcation and regression. In the
classiﬁcation set-up we try to predict the trend
of the stock in a speciﬁc day. Besides, we pre-
dict the exact return of a stock in regression
set-up. For simplicity we ﬁrst try linear models:
logistic regression as the classiﬁcation model
and linear regression as the regression model.
Then we implement SVM models (classiﬁer
and regression) to explore possible non-linear
regularities utilizing kernels. Before feeding
into models we also normalize and centralize
our features to mean 0 and standard deviation
1. However our model is dynamic rather than
ﬁxed, depending on the date at which a return
is to be predicted. Speciﬁcally, our procedure

of training and testing models are as follows:

1. Specify a training window parameter W

2. To predict the performance of stocks
on the date Ti, use the sample during
Ti − 1, Ti − 2, Ti − 3,· · · , Ti − W as the
training set to train models.

After we generated predictions for every
day we should measure how good our predic-
tions are. We can compute every day’s cor-
rection rate in the classiﬁcation models and
the mean square root error in the regression
models but then it would then be abstruse to
compare cross these two categories. We there-
fore give a more practical and visualizable way
of measuring performance: testing the perfor-
mance of stocks selected by our models. The
methodology is as follows:

1. Specify a portfolio size (number of stocks

to be picked) N

2. Every day choose N stocks according to
the predictions generate by the models.

3

For regression model we simply choose
the N stocks that are predicted to have
the highest return, and for classiﬁcation
models we choose N stocks that are best
classiﬁed, i.e., with the largest scores in
the classiﬁcation

3. Compute the actual return of every day’s
stock basket. Compare this time series to
the market index such as S&P 500. Fur-
thermore we can denote one speciﬁc day
as ‘successful’ if the portfolio we selected
has greater return than the market index
and as ‘unsuccessful’ if that didn’t hap-
pen. Then we can compute the successful
rate for each model:

SR =

N o f succes f ul days

N o f total days

(11)

Then we compare different models and
present the model with the best successful rate.

Results see Figure 2 and Figure 3

V. Discussions and Analysis

The linear models behave well. Actually from
the portfolio return graphs we can see that lin-
ear classiﬁcation model and linear regression
model give similar results here. The regression
approach and classiﬁcation approach both can
capture the underlying regularities.

The supporting vector machines don’t be-
have well enough. One possible reason is that
for these extremely noisy data linear simple
models can behave better. SVM classiﬁer’s per-
formance is especially bad. One possible rea-
son is that the ‘conﬁdence’of the classiﬁcation,
or say decision function that we are sorting as
an indicator of potential success doesn’t make
much sense in the non-linear case. Using more
data to train each day’s model may improve the
performance of SVM, but the computational
cost will increase signiﬁcantly since we retrain
our model for each trading day.

Another interesting question to think is
whether our models behave stably over time.
From the graph we ﬁnd that the 2 linear mod-
els behave relatively stably before the end of
2008. To quantify this we compute SR every
80 days and plot these time series showed in
Figure 4

VI. Conclusion

To conclude: we derived an approach to predict
daily returns of U.S stocks based on their trad-
ing data and external ﬁnancial indices. Our lin-
ear models work well in both regression frame-
work and classiﬁcation framework. The best
model turns out to be linear classiﬁer: logistic
regression. It gives 56.65% successful rate and
2000% cumulative return over 14 years. How-
ever as time pass by the models tend to behave
less stably especially after 2008.

In the future we can try to ﬁnd methods
that give more stable predictions. From the per-
spective of machine learning we can try mixing
different models our train models with more
data every day. From the perspective of in-
vestment we can make predictions on ‘alphas’
rather than returns. Also we can try to get
more information from text data. News and
social networks can be excellent information
resources for predicting stocks returns.

References

[Abu-Mostafa and Atiya, 1996] Abu-Mostafa,
Y. S., & Atiya, A. F. (1996). Introduction to
ﬁnancial forecasting. Applied Intelligence.,
6(3):205-213.

[Smola and Schölkopf, 2004 ] Smola, A. J., &
Schölkopf, B. (2004). A tutorial on support
vector regression Statistics and computing.,
14(3): 199-222.

4

Figure 2: left ﬁgure is the result of Logistic Regression modelIn the implementation we specify our window parameter
W=5 and portfolio size N = 100. We ﬁrst implement linear models. The logistic regression gives SR =
56.65%. The cumulative return of stocks selected by this model. The right ﬁgure shows linear regression
model giving SR = 55.82%. The cumulative return of the portfolio selected.As we can see that for linear
models, both classiﬁcation setup and regression setup behave well. $1 invested in 2000 became about $20 in
2014 if we have continually implemented the trades suggested by these 2 models. This success indicates that
our approach did get information from the data we collected.

Figure 3: The left is SVM. We use Gaussian Kernel and since the ﬁnancial data is highly noised we set the parameter
C as 0.85. Surprisingly SVM give worse results than linear models. For SVM classiﬁer we have: SR =
49.56%. The return of selected portfolio. The rightis SVM regression we get SR = 53.18%.After we adjusted
the window parameter W and the regularization parameter C this doesn’t improve much.

Figure 4: It can be shown that all models tend to behave less well as time goes by especially after 2008. We believe that

from that time daily stock prices change depend on more factors than we have recovered.

5

