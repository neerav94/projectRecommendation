 1

Whats Your Type? Personalized Prediction of 

Facial Attractiveness

Sam Crognale, Computer Science, Danish Shabbir Electrical Engineering

 

INTRODUCTION 

I.
  Attempts to obtain a universal model of facial beauty by 
the  way  of  symmetry,  golden  ratios,  and  measured 
placement of various facial features fall short in explaining 
the varied attraction that is actually witnessed in the world. 
In this investigation, we devise an application to give a user 
some insight about their ‘type’ as users swipe yes or no on a 
large dataset of images 
  There  is  a  wealth  of  interesting  literature  attempting  to 
map the psychophysics of attraction. For example, Johnston 
and Franklin (1993) use a genetic algorithm which evolves a 
“most  beautiful”  female  face  according  to  interactive  user 
selections. They sought to  mimic the way humans filter for 
features they find the most attractive.  
  Our approach builds on Kagian et. al (2007), where it was 
shown that feature selection and training procedure with the 
original geometric features instead of the eigenfeatures fails 
to  produce  good  predictors  due  to  the  strong  correlations 
between the original geometric features.  
  The  input  to  our  algorithm  is  a  dataset  of  face  images. 
Each  image  in  the  dataset  is  labelled  with  a  positive  or  a 
negative rating from a given user — positive rating implies 
that the user finds the face attractive. Features are extracted 
from  these  images  using  NMF  (Non  Negative  Matrix 
Factorization) and then a Naive Bayes classifier is employed 
to  predict  whether  this  particular  user  will  rate  an  unseen 
image as attractive or not. 

II.

DATASET AND FEATURES 

We obtained access to the 10K Adult Faces Dataset  [3]— a 
large  and  comprehensive  image  dataset  of  10,  168  face 
photographs representative of the adult U.S population. The 
dataset was created using a random name generator on 1990 
U.S.  Census  name  distribution,  for  each  name  several 

 Labelling 

A.
In  order  to  figure  out  a  user’s 
type,  we  require  the  user  to  go 
through  a  large  number  of  face 
images, labelling each image as it 
attracts  them  subjectively.  We 
created a web interface with Flask  
that  serves  images  from  the 
database  and  records  the  user’s 
associated {yes}/{no} preference. 
At most we could get the users to 
label up to 2000 - 3000 images in 
this way. 

 

 
B. Preprocessing 
We obtained a training set of images from the 10K dataset 
by cropping or padding the images as required so that they 
are  uniformly  sized.  Once  grayscaled,  each  image  is 
normalized by subtracting from the mean.  

III.

METHODS 

A. Eigenfaces 
It is possible find an information rich encoding of a face 
image  that  best  captures  the  significant  local  /  global 
“features”  of  the  face,  albeit  these  features  do  not 
necessarily  correspond  to  usual  facial  features  like  the 
eyes, nose, lips, hair and so on. Such encoding can be 
found by capturing the variation in a collection of face 
images which is then using it to find a low dimensional 
representation  of  each  face.  Mathematically  this 
translates  to  finding  the  principle  components  of  a 
distribution of faces in the dataset which is achieved by 

publicly available colored photos were scraped from Google 
Image search. 

finding eigenvectors of the covariance matrix of the set 
of face images where each image is treated as a point in 
a high dimensional space. 

These  eigenvectors  characterize  the  variation  between 
faces the faces in the 10K dataset. It follows that each 
individual face in the 10K dataset can be reconstructed 
as a linear combination of these eigenfaces. 

!
 
 
 1

Whats Your Type? Personalized Prediction of 

Facial Attractiveness

Sam Crognale, Computer Science, Danish Shabbir Electrical Engineering

 

INTRODUCTION 

I.
  Attempts to obtain a universal model of facial beauty by 
the  way  of  symmetry,  golden  ratios,  and  measured 
placement of various facial features fall short in explaining 
the varied attraction that is actually witnessed in the world. 
In this investigation, we devise an application to give a user 
some insight about their ‘type’ as users swipe yes or no on a 
large dataset of images 
  There  is  a  wealth  of  interesting  literature  attempting  to 
map the psychophysics of attraction. For example, Johnston 
and Franklin (1993) use a genetic algorithm which evolves a 
“most  beautiful”  female  face  according  to  interactive  user 
selections. They sought to  mimic the way humans filter for 
features they find the most attractive.  
  Our approach builds on Kagian et. al (2007), where it was 
shown that feature selection and training procedure with the 
original geometric features instead of the eigenfeatures fails 
to  produce  good  predictors  due  to  the  strong  correlations 
between the original geometric features.  
  The  input  to  our  algorithm  is  a  dataset  of  face  images. 
Each  image  in  the  dataset  is  labelled  with  a  positive  or  a 
negative rating from a given user — positive rating implies 
that the user finds the face attractive. Features are extracted 
from  these  images  using  NMF  (Non  Negative  Matrix 
Factorization) and then a Naive Bayes classifier is employed 
to  predict  whether  this  particular  user  will  rate  an  unseen 
image as attractive or not. 

II.

DATASET AND FEATURES 

We obtained access to the 10K Adult Faces Dataset  [3]— a 
large  and  comprehensive  image  dataset  of  10,  168  face 
photographs representative of the adult U.S population. The 
dataset was created using a random name generator on 1990 
U.S.  Census  name  distribution,  for  each  name  several 

 Labelling 

A.
In  order  to  figure  out  a  user’s 
type,  we  require  the  user  to  go 
through  a  large  number  of  face 
images, labelling each image as it 
attracts  them  subjectively.  We 
created a web interface with Flask  
that  serves  images  from  the 
database  and  records  the  user’s 
associated {yes}/{no} preference. 
At most we could get the users to 
label up to 2000 - 3000 images in 
this way. 

 

 
B. Preprocessing 
We obtained a training set of images from the 10K dataset 
by cropping or padding the images as required so that they 
are  uniformly  sized.  Once  grayscaled,  each  image  is 
normalized by subtracting from the mean.  

III.

METHODS 

A. Eigenfaces 
It is possible find an information rich encoding of a face 
image  that  best  captures  the  significant  local  /  global 
“features”  of  the  face,  albeit  these  features  do  not 
necessarily  correspond  to  usual  facial  features  like  the 
eyes, nose, lips, hair and so on. Such encoding can be 
found by capturing the variation in a collection of face 
images which is then using it to find a low dimensional 
representation  of  each  face.  Mathematically  this 
translates  to  finding  the  principle  components  of  a 
distribution of faces in the dataset which is achieved by 

publicly available colored photos were scraped from Google 
Image search. 

finding eigenvectors of the covariance matrix of the set 
of face images where each image is treated as a point in 
a high dimensional space. 

These  eigenvectors  characterize  the  variation  between 
faces the faces in the 10K dataset. It follows that each 
individual face in the 10K dataset can be reconstructed 
as a linear combination of these eigenfaces. 

!
 
 
B. Non-Negative Matrix Factorization (NMF) 

NMF takes a matrix X, where xi,j  is the i-th element of the j-
th image in the dataset. NMF decomposes X = ZH. The lines 
of matrix  can be considered as a basis images and the 
vector h_j as the corresponding weight vector. The NMF 
imposes non-negative constraints in both the elements of Z 
and of H. Thus only non-subtractive combinations are 
allowed, this corresponds with better features as images 
don’t cancel each other out.  

B. Gaussian Naive Bayes with NMF 

Features were generated using 1000 faces from the data 
base, The classiﬁer was trained on 2000 ratings and tested 
on 1000 ratings.  We found that using top 25 non-negative 
eigenvectors yields 77% accuracy on predicting unattractive 
faces and 37% accuracy on attractive faces. The table below 
shows how the classiﬁer performance shifts with the number 
of eigenfaces used.

 2

The NMF implementation in scikit-learn finds a 
decomposition of X into W and H, by optimizing for the 
squared Frobenius norm.  

First 50 sparse components found with NMFactorization 

of images in the 10K Adult Faces Dataset: 

C. Prediction 
1. k-nn 
To  predict  whether  a  given  user  will  like  a  previously 
unseen  face,  we  find  a  labelled  face  image  with  the 
encoding  closest  to  the  face  in  question.  It  is  then 
possible  to  predict  whether  the  user  will  like  this  face 
given  how  they  rated  its  nearest  neighbors.  These  K-
nearest  neighbors  are  found  using  euclidean  and 
mahalanobis distance. 
2. Gaussian Naive Bayes 
In this approach, the continuous values associated with 
each feature are modeled as a Gaussian distribution and 
a (naive) independence is assumed between the features.  

IV.

A. k-NN with Eigenfaces 

RESULTS 

This  method  succeeds  96%  of  the  time  in  identifying 
unattractive  faces  but  only  shows  3%  accuracy  on 
recommending faces that a user may find attractive. This 
result  makes  sense  given  the  structure  of  this  data, 
where the average user in our study only rated 3.4% of 
the images as attractive, so most of the image points are 
negatively rated. 

0/1 correspond with negative and positive ratings 
respectively.

CONCLUSIONS AND FUTURE WORK 

V.
Reconstructed images that represents the ideal ‘type’ for our 
users given how they labelled the many varied faces on our 
data set. The image is generated by taking a mean of all the 
weights associated with faces that the user rated positively. 

Attraction is subtle and difficult to verbalize, yet patterns in 
attraction can be found as users swipe through tens of 
images every day on the dating apps that have cropped up. 
These dating services could improve the user experience 
considerably by making use of this information. Our 
investigation shows that it is feasible to recognize such 
patterns particularly in that we mimic the constrained binary 
input a user might offer to an app like Tinder. 
There are many directions this work can take in the future, 
more obviously we would like to leverage demographic 
labels in a dataset so that users can choose a target age range 
and gender when labelling images. This way we can hope to 
have more positively rated image points that the algorithm 
can learn from. Having a prior distribution on features that 
demonstrably indicate health could improve the prediction 
step.  

!
 
 
 
 
 1

Whats Your Type? Personalized Prediction of 

Facial Attractiveness

Sam Crognale, Computer Science, Danish Shabbir Electrical Engineering

 

INTRODUCTION 

I.
  Attempts to obtain a universal model of facial beauty by 
the  way  of  symmetry,  golden  ratios,  and  measured 
placement of various facial features fall short in explaining 
the varied attraction that is actually witnessed in the world. 
In this investigation, we devise an application to give a user 
some insight about their ‘type’ as users swipe yes or no on a 
large dataset of images 
  There  is  a  wealth  of  interesting  literature  attempting  to 
map the psychophysics of attraction. For example, Johnston 
and Franklin (1993) use a genetic algorithm which evolves a 
“most  beautiful”  female  face  according  to  interactive  user 
selections. They sought to  mimic the way humans filter for 
features they find the most attractive.  
  Our approach builds on Kagian et. al (2007), where it was 
shown that feature selection and training procedure with the 
original geometric features instead of the eigenfeatures fails 
to  produce  good  predictors  due  to  the  strong  correlations 
between the original geometric features.  
  The  input  to  our  algorithm  is  a  dataset  of  face  images. 
Each  image  in  the  dataset  is  labelled  with  a  positive  or  a 
negative rating from a given user — positive rating implies 
that the user finds the face attractive. Features are extracted 
from  these  images  using  NMF  (Non  Negative  Matrix 
Factorization) and then a Naive Bayes classifier is employed 
to  predict  whether  this  particular  user  will  rate  an  unseen 
image as attractive or not. 

II.

DATASET AND FEATURES 

We obtained access to the 10K Adult Faces Dataset  [3]— a 
large  and  comprehensive  image  dataset  of  10,  168  face 
photographs representative of the adult U.S population. The 
dataset was created using a random name generator on 1990 
U.S.  Census  name  distribution,  for  each  name  several 

 Labelling 

A.
In  order  to  figure  out  a  user’s 
type,  we  require  the  user  to  go 
through  a  large  number  of  face 
images, labelling each image as it 
attracts  them  subjectively.  We 
created a web interface with Flask  
that  serves  images  from  the 
database  and  records  the  user’s 
associated {yes}/{no} preference. 
At most we could get the users to 
label up to 2000 - 3000 images in 
this way. 

 

 
B. Preprocessing 
We obtained a training set of images from the 10K dataset 
by cropping or padding the images as required so that they 
are  uniformly  sized.  Once  grayscaled,  each  image  is 
normalized by subtracting from the mean.  

III.

METHODS 

A. Eigenfaces 
It is possible find an information rich encoding of a face 
image  that  best  captures  the  significant  local  /  global 
“features”  of  the  face,  albeit  these  features  do  not 
necessarily  correspond  to  usual  facial  features  like  the 
eyes, nose, lips, hair and so on. Such encoding can be 
found by capturing the variation in a collection of face 
images which is then using it to find a low dimensional 
representation  of  each  face.  Mathematically  this 
translates  to  finding  the  principle  components  of  a 
distribution of faces in the dataset which is achieved by 

publicly available colored photos were scraped from Google 
Image search. 

finding eigenvectors of the covariance matrix of the set 
of face images where each image is treated as a point in 
a high dimensional space. 

These  eigenvectors  characterize  the  variation  between 
faces the faces in the 10K dataset. It follows that each 
individual face in the 10K dataset can be reconstructed 
as a linear combination of these eigenfaces. 

!
 
 
B. Non-Negative Matrix Factorization (NMF) 

NMF takes a matrix X, where xi,j  is the i-th element of the j-
th image in the dataset. NMF decomposes X = ZH. The lines 
of matrix  can be considered as a basis images and the 
vector h_j as the corresponding weight vector. The NMF 
imposes non-negative constraints in both the elements of Z 
and of H. Thus only non-subtractive combinations are 
allowed, this corresponds with better features as images 
don’t cancel each other out.  

B. Gaussian Naive Bayes with NMF 

Features were generated using 1000 faces from the data 
base, The classiﬁer was trained on 2000 ratings and tested 
on 1000 ratings.  We found that using top 25 non-negative 
eigenvectors yields 77% accuracy on predicting unattractive 
faces and 37% accuracy on attractive faces. The table below 
shows how the classiﬁer performance shifts with the number 
of eigenfaces used.

 2

The NMF implementation in scikit-learn finds a 
decomposition of X into W and H, by optimizing for the 
squared Frobenius norm.  

First 50 sparse components found with NMFactorization 

of images in the 10K Adult Faces Dataset: 

C. Prediction 
1. k-nn 
To  predict  whether  a  given  user  will  like  a  previously 
unseen  face,  we  find  a  labelled  face  image  with  the 
encoding  closest  to  the  face  in  question.  It  is  then 
possible  to  predict  whether  the  user  will  like  this  face 
given  how  they  rated  its  nearest  neighbors.  These  K-
nearest  neighbors  are  found  using  euclidean  and 
mahalanobis distance. 
2. Gaussian Naive Bayes 
In this approach, the continuous values associated with 
each feature are modeled as a Gaussian distribution and 
a (naive) independence is assumed between the features.  

IV.

A. k-NN with Eigenfaces 

RESULTS 

This  method  succeeds  96%  of  the  time  in  identifying 
unattractive  faces  but  only  shows  3%  accuracy  on 
recommending faces that a user may find attractive. This 
result  makes  sense  given  the  structure  of  this  data, 
where the average user in our study only rated 3.4% of 
the images as attractive, so most of the image points are 
negatively rated. 

0/1 correspond with negative and positive ratings 
respectively.

CONCLUSIONS AND FUTURE WORK 

V.
Reconstructed images that represents the ideal ‘type’ for our 
users given how they labelled the many varied faces on our 
data set. The image is generated by taking a mean of all the 
weights associated with faces that the user rated positively. 

Attraction is subtle and difficult to verbalize, yet patterns in 
attraction can be found as users swipe through tens of 
images every day on the dating apps that have cropped up. 
These dating services could improve the user experience 
considerably by making use of this information. Our 
investigation shows that it is feasible to recognize such 
patterns particularly in that we mimic the constrained binary 
input a user might offer to an app like Tinder. 
There are many directions this work can take in the future, 
more obviously we would like to leverage demographic 
labels in a dataset so that users can choose a target age range 
and gender when labelling images. This way we can hope to 
have more positively rated image points that the algorithm 
can learn from. Having a prior distribution on features that 
demonstrably indicate health could improve the prediction 
step.  

!
 
 
 
 
REFERENCES 

 3

1. A.  Kagian,  G.  Dror,  T.  Leyvand,  D.  Cohen-Or,  and  E.  Ruppin.  A 
humanlike  predictor  of  facial  attractiveness.  In  Advances  in  Neural 
Information Processing Systems, 2007 

2. Johnston,  V.  S.,  &  Franklin,  M.  (1993).  Is  beauty  in  the  eye  of  the 

beholder? Ethology and Sociobiology, 14, 183–199. 

3. Bainbridge,  W.A.,  Isola,  P.,  &  Oliva,  A.  (2013).  The  intrinsic 
memorability  of  face  images.  Journal  of  Experimental  Psychology: 
General. Journal of Experimental Psychology: General, 142(4) 

4. M.  Turk  and A.  Pentland,  “Face  Recognition  Using  Eigenfaces,”Proc. 
IEEE  Conf.  on  Computer  Vision  and  Pattern  Recognition,  1991,  pp. 
586-591. 

5. M.  Turk  and A.  Pentland,  “Eigenfaces  for  Recognition,”  J.  Cognitive 

Neuroscience, vol. 3, no. 1, 1991 

6. Scikit-learn:  Machine  Learning  in  Python,  Pedregosa  et  al.,  JMLR  12, 

pp. 2825-2830, 2011 

!
