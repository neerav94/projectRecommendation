Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

we can then apply our model to our testing sample
to classify each as benign or malignant by choosing the
prior condition that gives the higher probability.

III.ii Ensemble Methods I: Random Forests

The Random Forest classiﬁer creates many decision
trees from bootstrap replicates of the original dataset.
In the case of RF, when building each decision tree for
its respective bootstrap sample, each time a split in
the tree is considered, a random subset of predictors
√
is used to create said split.
In this case, a subset of
p predictors (13 features out of 173) was used from
the original feature space. This technique effectively
decorrelates each of the constructed decision trees to
reduce overﬁtting. A tuning parameter B determines
the number of trees to construct. After B trees are
constructed, the trees are averaged in order to create
the ﬁnal model:

ˆf (x) =

1
B

B∑

b=1

ˆf ∗b(x)

Because each tree is created out of a random sampling
of the training data, the Random Forest is robust to
overﬁtting despite very large values for B. Thus, in
practice we use a sufﬁciently large B for the error rate to
have settled. For a given test observation, the predicted
value is chosen based on the most commonly occurring
class among the B predictions.

III.iii Ensemble Methods II: Boosting

Boosting is also an ensemble method for classiﬁcation.
It differs from the RF method in that each tree in the
constructed forest is not independent from the last, and
each tree is ﬁt on a modiﬁed version on the original
dataset (versus a bootstrap sample). Each boosted tree
is ﬁt to the residuals from the model rather than the
response. This tree is then added into the ﬁtted function
to update the residuals. Boosted trees tend to be quite
small (depths of 1 or 2 are typically used in practice).
By ﬁtting these small trees to the residuals, Boosting
improves the ﬁt in areas where the previous iteration of
the model did not perform well. Boosting involves three
tuning parameters: number of trees B (although the
Boosted trees are not independent as in RF, overﬁtting
tends to occur slowly if at all, such that we can also
choose large values for B); shrinkage parameter λ which
controls how quickly the Boosted model learns; and
interaction depth d:

1. Set ˆf (x) = 0, ri = yi for all i in the training set.

Figure 1: Overview of techniques used

Each was then evaluated on classiﬁcation accuracy on a
held-out test set of 55 samples (out of the original 367)
4. These methods were chosen based on literature re-
views (see references) which indicated that they would
perform well on our dataset given the following factors:
(1) Large feature space relative to number of observa-
tions, (2) Previous literature using these methods and
classiﬁers applied to gene expression data. We build
on the existing literature through our feature selection
methods, and through the methods used for tuning
our ﬁnal models. In particular, we hope to emulate the
results of the Alexander et. al. study of benign thyroid
nodules with indeterminate cytology.

III.i Baseline Model: Naive Bayes

Our baseline model is a Naive Bayes classiﬁer imple-
mented in MATLAB trained via splitting up the data
set into training and test sets and using the entire set
of 173 genes (as per the preceding literature) and their
gene expression values as our feature set.

For this particular model, in order to tame the num-
ber of parameters, we make a strong assumption where
all features are conditionally independent given the
response for that sample (malignant or benign). We
experiment with different training set sizes (60-140 sam-
ples) where we calculate all parameters relevant for our
model, incorporating Laplace smoothing in the process
(i.e., add 1 to the numerator and the number of genes
to the denominator for each parameter). By using a
multinomial model where the overall probability of a
message is given by:

p(y)

p(xi|y)

173∏

i=1

4One sample was corrupted and removed from the dataset

2. for b = 1, 2, ...B repeat 3-5:

2

Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

we can then apply our model to our testing sample
to classify each as benign or malignant by choosing the
prior condition that gives the higher probability.

III.ii Ensemble Methods I: Random Forests

The Random Forest classiﬁer creates many decision
trees from bootstrap replicates of the original dataset.
In the case of RF, when building each decision tree for
its respective bootstrap sample, each time a split in
the tree is considered, a random subset of predictors
√
is used to create said split.
In this case, a subset of
p predictors (13 features out of 173) was used from
the original feature space. This technique effectively
decorrelates each of the constructed decision trees to
reduce overﬁtting. A tuning parameter B determines
the number of trees to construct. After B trees are
constructed, the trees are averaged in order to create
the ﬁnal model:

ˆf (x) =

1
B

B∑

b=1

ˆf ∗b(x)

Because each tree is created out of a random sampling
of the training data, the Random Forest is robust to
overﬁtting despite very large values for B. Thus, in
practice we use a sufﬁciently large B for the error rate to
have settled. For a given test observation, the predicted
value is chosen based on the most commonly occurring
class among the B predictions.

III.iii Ensemble Methods II: Boosting

Boosting is also an ensemble method for classiﬁcation.
It differs from the RF method in that each tree in the
constructed forest is not independent from the last, and
each tree is ﬁt on a modiﬁed version on the original
dataset (versus a bootstrap sample). Each boosted tree
is ﬁt to the residuals from the model rather than the
response. This tree is then added into the ﬁtted function
to update the residuals. Boosted trees tend to be quite
small (depths of 1 or 2 are typically used in practice).
By ﬁtting these small trees to the residuals, Boosting
improves the ﬁt in areas where the previous iteration of
the model did not perform well. Boosting involves three
tuning parameters: number of trees B (although the
Boosted trees are not independent as in RF, overﬁtting
tends to occur slowly if at all, such that we can also
choose large values for B); shrinkage parameter λ which
controls how quickly the Boosted model learns; and
interaction depth d:

1. Set ˆf (x) = 0, ri = yi for all i in the training set.

Figure 1: Overview of techniques used

Each was then evaluated on classiﬁcation accuracy on a
held-out test set of 55 samples (out of the original 367)
4. These methods were chosen based on literature re-
views (see references) which indicated that they would
perform well on our dataset given the following factors:
(1) Large feature space relative to number of observa-
tions, (2) Previous literature using these methods and
classiﬁers applied to gene expression data. We build
on the existing literature through our feature selection
methods, and through the methods used for tuning
our ﬁnal models. In particular, we hope to emulate the
results of the Alexander et. al. study of benign thyroid
nodules with indeterminate cytology.

III.i Baseline Model: Naive Bayes

Our baseline model is a Naive Bayes classiﬁer imple-
mented in MATLAB trained via splitting up the data
set into training and test sets and using the entire set
of 173 genes (as per the preceding literature) and their
gene expression values as our feature set.

For this particular model, in order to tame the num-
ber of parameters, we make a strong assumption where
all features are conditionally independent given the
response for that sample (malignant or benign). We
experiment with different training set sizes (60-140 sam-
ples) where we calculate all parameters relevant for our
model, incorporating Laplace smoothing in the process
(i.e., add 1 to the numerator and the number of genes
to the denominator for each parameter). By using a
multinomial model where the overall probability of a
message is given by:

p(y)

p(xi|y)

173∏

i=1

4One sample was corrupted and removed from the dataset

2. for b = 1, 2, ...B repeat 3-5:

2

3. Fit a tree ˆf b with d splits (d + 1 terminal nodes) to

the training data (X, r).

4. Update ˆf by adding a shrunken version of the new

tree ˆf (x) ← ˆf (x) + λ ˆf b(x).

5. Update the residuals ri ← ri − λ ˆf b(xi)
6. Output boosted model,

ˆf (x) =

B∑

b=1

λ ˆf b(x)

We tuned these parameters using 10-fold cross vali-

dation on our test set via R’s caret package.

III.iv Linear Kernel SVM

The linear kernel SVM is a parametric method con-
structed by identifying observations to deﬁne the classi-
ﬁcation boundary (these observations are called support
vectors). Several SVM models were implemented using
different kernels, although the linear kernel performed
best. The cost parameter C was chosen using 10-fold
cross validation.

III.v Neural Network

For this algorithm, one "neuron" takes an input vector of
features and is fed through a weight vector with some
bias. Usually one neuron is not enough to produce an
accurate model of our training set, so we have a layer
of neurons wherein every single feature for a different
sample is fed into multiple neurons. This results in our
argument equal to the weight matrix W multiplied by
the input feature vector x. A bias vector b is then added
on. Within the hidden layer of neurons, a sigmoid
function takes the result from the previous computation
and computes a value that is between 0 and 1. For
model selection, we measure results using classiﬁcation
error on the held-out test set, as well as cross entropy:

C = − 1
n

∑
x

y ln a + (1 − y) ln(1 − a)

Weights and bias values are updated with each sim-
ulation until the cross-entropy of the overall model
reaches a very small value ideally as close to 0 as possi-
ble.

The number of neurons in the hidden layer and the
regluarization parameter λ were chosen using 10-fold
cross validation on the training set using R’s caret pack-
age.

Neural networks usually apply sigmoid transfer func-
tions in the hidden layers. Sigmoid functions are useful
for differentiating inputs especially when they are either
very large or small since these are the regions when the

Figure 2: Tuning RF+NN hidden layer using 10-fold CV

slope approaches zero. However, this characteristic is
problematic when using gradient descent to train a mul-
tilayer network with sigmoid functions since they may
not produce large changes in the weights and biases
when attempting to ﬁnd their respective optimal values.
In order to circumvent this problem, back propagation
training algorithms are used where only the sign of
the derivative is used to determine the direction of the
weight update. I.e., if the weight continues to change in
the same direction (e.g. negative) for several iterations,
the magnitude of the weight change will be increased
(Rumelhart).

III.vi Feature Selection using Random Forests

We were able to reduce the feature space by an order of
magnitude via variable selection using the RF variable
importance plots (see ﬁg. 3). For the best Boosting
model, we were able to reduce the feature space by two
orders of magnitude. Several studies (see references)
show that RF serves as an effective feature selection
method for both SVMs and Neural Networks. Variable
importance is calculated based on classiﬁcation error
rate on the held-out test set:

E = 1 − max
k

( ˆpmk)

and Gini index:

G =

K∑

k=1

ˆpmk(1 − ˆpmk)

which is a measure of total variance across the K
classes. (Note that mathematically, the Gini index and
cross-entropy metrics are quite similar).

Backward stepwise selection (BSS) using the top 30
variables based on the RF variable importance measures

3

Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

we can then apply our model to our testing sample
to classify each as benign or malignant by choosing the
prior condition that gives the higher probability.

III.ii Ensemble Methods I: Random Forests

The Random Forest classiﬁer creates many decision
trees from bootstrap replicates of the original dataset.
In the case of RF, when building each decision tree for
its respective bootstrap sample, each time a split in
the tree is considered, a random subset of predictors
√
is used to create said split.
In this case, a subset of
p predictors (13 features out of 173) was used from
the original feature space. This technique effectively
decorrelates each of the constructed decision trees to
reduce overﬁtting. A tuning parameter B determines
the number of trees to construct. After B trees are
constructed, the trees are averaged in order to create
the ﬁnal model:

ˆf (x) =

1
B

B∑

b=1

ˆf ∗b(x)

Because each tree is created out of a random sampling
of the training data, the Random Forest is robust to
overﬁtting despite very large values for B. Thus, in
practice we use a sufﬁciently large B for the error rate to
have settled. For a given test observation, the predicted
value is chosen based on the most commonly occurring
class among the B predictions.

III.iii Ensemble Methods II: Boosting

Boosting is also an ensemble method for classiﬁcation.
It differs from the RF method in that each tree in the
constructed forest is not independent from the last, and
each tree is ﬁt on a modiﬁed version on the original
dataset (versus a bootstrap sample). Each boosted tree
is ﬁt to the residuals from the model rather than the
response. This tree is then added into the ﬁtted function
to update the residuals. Boosted trees tend to be quite
small (depths of 1 or 2 are typically used in practice).
By ﬁtting these small trees to the residuals, Boosting
improves the ﬁt in areas where the previous iteration of
the model did not perform well. Boosting involves three
tuning parameters: number of trees B (although the
Boosted trees are not independent as in RF, overﬁtting
tends to occur slowly if at all, such that we can also
choose large values for B); shrinkage parameter λ which
controls how quickly the Boosted model learns; and
interaction depth d:

1. Set ˆf (x) = 0, ri = yi for all i in the training set.

Figure 1: Overview of techniques used

Each was then evaluated on classiﬁcation accuracy on a
held-out test set of 55 samples (out of the original 367)
4. These methods were chosen based on literature re-
views (see references) which indicated that they would
perform well on our dataset given the following factors:
(1) Large feature space relative to number of observa-
tions, (2) Previous literature using these methods and
classiﬁers applied to gene expression data. We build
on the existing literature through our feature selection
methods, and through the methods used for tuning
our ﬁnal models. In particular, we hope to emulate the
results of the Alexander et. al. study of benign thyroid
nodules with indeterminate cytology.

III.i Baseline Model: Naive Bayes

Our baseline model is a Naive Bayes classiﬁer imple-
mented in MATLAB trained via splitting up the data
set into training and test sets and using the entire set
of 173 genes (as per the preceding literature) and their
gene expression values as our feature set.

For this particular model, in order to tame the num-
ber of parameters, we make a strong assumption where
all features are conditionally independent given the
response for that sample (malignant or benign). We
experiment with different training set sizes (60-140 sam-
ples) where we calculate all parameters relevant for our
model, incorporating Laplace smoothing in the process
(i.e., add 1 to the numerator and the number of genes
to the denominator for each parameter). By using a
multinomial model where the overall probability of a
message is given by:

p(y)

p(xi|y)

173∏

i=1

4One sample was corrupted and removed from the dataset

2. for b = 1, 2, ...B repeat 3-5:

2

3. Fit a tree ˆf b with d splits (d + 1 terminal nodes) to

the training data (X, r).

4. Update ˆf by adding a shrunken version of the new

tree ˆf (x) ← ˆf (x) + λ ˆf b(x).

5. Update the residuals ri ← ri − λ ˆf b(xi)
6. Output boosted model,

ˆf (x) =

B∑

b=1

λ ˆf b(x)

We tuned these parameters using 10-fold cross vali-

dation on our test set via R’s caret package.

III.iv Linear Kernel SVM

The linear kernel SVM is a parametric method con-
structed by identifying observations to deﬁne the classi-
ﬁcation boundary (these observations are called support
vectors). Several SVM models were implemented using
different kernels, although the linear kernel performed
best. The cost parameter C was chosen using 10-fold
cross validation.

III.v Neural Network

For this algorithm, one "neuron" takes an input vector of
features and is fed through a weight vector with some
bias. Usually one neuron is not enough to produce an
accurate model of our training set, so we have a layer
of neurons wherein every single feature for a different
sample is fed into multiple neurons. This results in our
argument equal to the weight matrix W multiplied by
the input feature vector x. A bias vector b is then added
on. Within the hidden layer of neurons, a sigmoid
function takes the result from the previous computation
and computes a value that is between 0 and 1. For
model selection, we measure results using classiﬁcation
error on the held-out test set, as well as cross entropy:

C = − 1
n

∑
x

y ln a + (1 − y) ln(1 − a)

Weights and bias values are updated with each sim-
ulation until the cross-entropy of the overall model
reaches a very small value ideally as close to 0 as possi-
ble.

The number of neurons in the hidden layer and the
regluarization parameter λ were chosen using 10-fold
cross validation on the training set using R’s caret pack-
age.

Neural networks usually apply sigmoid transfer func-
tions in the hidden layers. Sigmoid functions are useful
for differentiating inputs especially when they are either
very large or small since these are the regions when the

Figure 2: Tuning RF+NN hidden layer using 10-fold CV

slope approaches zero. However, this characteristic is
problematic when using gradient descent to train a mul-
tilayer network with sigmoid functions since they may
not produce large changes in the weights and biases
when attempting to ﬁnd their respective optimal values.
In order to circumvent this problem, back propagation
training algorithms are used where only the sign of
the derivative is used to determine the direction of the
weight update. I.e., if the weight continues to change in
the same direction (e.g. negative) for several iterations,
the magnitude of the weight change will be increased
(Rumelhart).

III.vi Feature Selection using Random Forests

We were able to reduce the feature space by an order of
magnitude via variable selection using the RF variable
importance plots (see ﬁg. 3). For the best Boosting
model, we were able to reduce the feature space by two
orders of magnitude. Several studies (see references)
show that RF serves as an effective feature selection
method for both SVMs and Neural Networks. Variable
importance is calculated based on classiﬁcation error
rate on the held-out test set:

E = 1 − max
k

( ˆpmk)

and Gini index:

G =

K∑

k=1

ˆpmk(1 − ˆpmk)

which is a measure of total variance across the K
classes. (Note that mathematically, the Gini index and
cross-entropy metrics are quite similar).

Backward stepwise selection (BSS) using the top 30
variables based on the RF variable importance measures

3

were used to construct the ﬁnal SVM and NN models.
Variable selection using BSS also signiﬁcantly improved
the performance of both the RF and Boosting models.
This indicates a large amount of noise in the data set.

We opted for feature selection instead of dimension-
ality reduction techniques such as PCA in order to ﬁnd
speciﬁc genes that were correlated with the response.
Reducing the feature space in this manner reduces over-
head and computational complexity. In addition, iden-
tifying particular genes correlated with thyroid cancer
could prove useful for further studies.

Figure 3: Most signiﬁcant variables according to RF

Figure 4: Linear kernel SVM on test data using V101 and
V96 as predictors, as selected by RF

IV Results and Discussion

Out of the models implemented, RF+NN proved to
be the most effective with an accuracy of 89% on the
held-out test set.

Method
NB
RF
Boosting
BSS+RF
BSS+Boosting
SVM
NN
RF+SVM
RF+NN

Acc.
0.76
0.76
0.78
0.78
0.81
0.80
0.76
0.81
0.89

Sn.
0.87
0.87
0.90
0.90
0.90
0.97
0.83
0.93
0.88

Spc. PPV NPV
0.80
0.64
0.80
0.64
0.64
0.84
0.84
0.64
0.86
0.72
0.93
0.60
0.68
0.77
0.89
0.68
0.91
0.84

0.74
0.74
0.75
0.75
0.79
0.74
0.76
0.78
0.93

Figure 5: Results showing accuracy, sensitivity, speciﬁcity,
positive predictive value, and negative predictive value on the
test set for each method used

That variable selection improved each model indi-
cates that the raw models were heavily overﬁtting the
test data. In particular, the small sample size and large
feature set size (relative to sample size) made it difﬁcult
to train our models without incurring variance vis-a-vis
the test set.
For all algorithms tested, classiﬁcation error on the
held-out test set was minimized using ≤ 10 predictors.
These correspond to 10 genes from the original dataset
provided by the NCBI. Using a smaller set of predictors
reduces variance of the model and increases model
interpretability. From a clinical standpoint, there is a
real-world cost difference incurred by collecting a larger
number of gene expression data (both in terms of time
and money), we deem this a signiﬁcant result that could
be useful in further studies exploring the correlation
between speciﬁc gene expressions and the presence of
thyroid cancer.

The ROC curve for RF+NN (ﬁg. 6) shows true posi-
tive rate versus false positive rate, or equivalently, sensi-
tivity versus 1-speciﬁcity, for different thresholds of the
classiﬁer output. This curve indicates that overall our
model is able to accurately classify most of our samples,
however produced false positives for samples that were
classiﬁed as malignant when in fact they were benign.
The Neural Network model calculates the cross-
entropy of each set of data for every run (ﬁg. 7). Here
it stops running on the twelfth run as the validation-set
cross-entropy reaches a minimum value at that point.
All subsequent runs check to validate this result.

From the results, our Neural Network model pro-
duced the most accurate results out of all classiﬁers
tested (see ﬁg. 8):

4

Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

we can then apply our model to our testing sample
to classify each as benign or malignant by choosing the
prior condition that gives the higher probability.

III.ii Ensemble Methods I: Random Forests

The Random Forest classiﬁer creates many decision
trees from bootstrap replicates of the original dataset.
In the case of RF, when building each decision tree for
its respective bootstrap sample, each time a split in
the tree is considered, a random subset of predictors
√
is used to create said split.
In this case, a subset of
p predictors (13 features out of 173) was used from
the original feature space. This technique effectively
decorrelates each of the constructed decision trees to
reduce overﬁtting. A tuning parameter B determines
the number of trees to construct. After B trees are
constructed, the trees are averaged in order to create
the ﬁnal model:

ˆf (x) =

1
B

B∑

b=1

ˆf ∗b(x)

Because each tree is created out of a random sampling
of the training data, the Random Forest is robust to
overﬁtting despite very large values for B. Thus, in
practice we use a sufﬁciently large B for the error rate to
have settled. For a given test observation, the predicted
value is chosen based on the most commonly occurring
class among the B predictions.

III.iii Ensemble Methods II: Boosting

Boosting is also an ensemble method for classiﬁcation.
It differs from the RF method in that each tree in the
constructed forest is not independent from the last, and
each tree is ﬁt on a modiﬁed version on the original
dataset (versus a bootstrap sample). Each boosted tree
is ﬁt to the residuals from the model rather than the
response. This tree is then added into the ﬁtted function
to update the residuals. Boosted trees tend to be quite
small (depths of 1 or 2 are typically used in practice).
By ﬁtting these small trees to the residuals, Boosting
improves the ﬁt in areas where the previous iteration of
the model did not perform well. Boosting involves three
tuning parameters: number of trees B (although the
Boosted trees are not independent as in RF, overﬁtting
tends to occur slowly if at all, such that we can also
choose large values for B); shrinkage parameter λ which
controls how quickly the Boosted model learns; and
interaction depth d:

1. Set ˆf (x) = 0, ri = yi for all i in the training set.

Figure 1: Overview of techniques used

Each was then evaluated on classiﬁcation accuracy on a
held-out test set of 55 samples (out of the original 367)
4. These methods were chosen based on literature re-
views (see references) which indicated that they would
perform well on our dataset given the following factors:
(1) Large feature space relative to number of observa-
tions, (2) Previous literature using these methods and
classiﬁers applied to gene expression data. We build
on the existing literature through our feature selection
methods, and through the methods used for tuning
our ﬁnal models. In particular, we hope to emulate the
results of the Alexander et. al. study of benign thyroid
nodules with indeterminate cytology.

III.i Baseline Model: Naive Bayes

Our baseline model is a Naive Bayes classiﬁer imple-
mented in MATLAB trained via splitting up the data
set into training and test sets and using the entire set
of 173 genes (as per the preceding literature) and their
gene expression values as our feature set.

For this particular model, in order to tame the num-
ber of parameters, we make a strong assumption where
all features are conditionally independent given the
response for that sample (malignant or benign). We
experiment with different training set sizes (60-140 sam-
ples) where we calculate all parameters relevant for our
model, incorporating Laplace smoothing in the process
(i.e., add 1 to the numerator and the number of genes
to the denominator for each parameter). By using a
multinomial model where the overall probability of a
message is given by:

p(y)

p(xi|y)

173∏

i=1

4One sample was corrupted and removed from the dataset

2. for b = 1, 2, ...B repeat 3-5:

2

3. Fit a tree ˆf b with d splits (d + 1 terminal nodes) to

the training data (X, r).

4. Update ˆf by adding a shrunken version of the new

tree ˆf (x) ← ˆf (x) + λ ˆf b(x).

5. Update the residuals ri ← ri − λ ˆf b(xi)
6. Output boosted model,

ˆf (x) =

B∑

b=1

λ ˆf b(x)

We tuned these parameters using 10-fold cross vali-

dation on our test set via R’s caret package.

III.iv Linear Kernel SVM

The linear kernel SVM is a parametric method con-
structed by identifying observations to deﬁne the classi-
ﬁcation boundary (these observations are called support
vectors). Several SVM models were implemented using
different kernels, although the linear kernel performed
best. The cost parameter C was chosen using 10-fold
cross validation.

III.v Neural Network

For this algorithm, one "neuron" takes an input vector of
features and is fed through a weight vector with some
bias. Usually one neuron is not enough to produce an
accurate model of our training set, so we have a layer
of neurons wherein every single feature for a different
sample is fed into multiple neurons. This results in our
argument equal to the weight matrix W multiplied by
the input feature vector x. A bias vector b is then added
on. Within the hidden layer of neurons, a sigmoid
function takes the result from the previous computation
and computes a value that is between 0 and 1. For
model selection, we measure results using classiﬁcation
error on the held-out test set, as well as cross entropy:

C = − 1
n

∑
x

y ln a + (1 − y) ln(1 − a)

Weights and bias values are updated with each sim-
ulation until the cross-entropy of the overall model
reaches a very small value ideally as close to 0 as possi-
ble.

The number of neurons in the hidden layer and the
regluarization parameter λ were chosen using 10-fold
cross validation on the training set using R’s caret pack-
age.

Neural networks usually apply sigmoid transfer func-
tions in the hidden layers. Sigmoid functions are useful
for differentiating inputs especially when they are either
very large or small since these are the regions when the

Figure 2: Tuning RF+NN hidden layer using 10-fold CV

slope approaches zero. However, this characteristic is
problematic when using gradient descent to train a mul-
tilayer network with sigmoid functions since they may
not produce large changes in the weights and biases
when attempting to ﬁnd their respective optimal values.
In order to circumvent this problem, back propagation
training algorithms are used where only the sign of
the derivative is used to determine the direction of the
weight update. I.e., if the weight continues to change in
the same direction (e.g. negative) for several iterations,
the magnitude of the weight change will be increased
(Rumelhart).

III.vi Feature Selection using Random Forests

We were able to reduce the feature space by an order of
magnitude via variable selection using the RF variable
importance plots (see ﬁg. 3). For the best Boosting
model, we were able to reduce the feature space by two
orders of magnitude. Several studies (see references)
show that RF serves as an effective feature selection
method for both SVMs and Neural Networks. Variable
importance is calculated based on classiﬁcation error
rate on the held-out test set:

E = 1 − max
k

( ˆpmk)

and Gini index:

G =

K∑

k=1

ˆpmk(1 − ˆpmk)

which is a measure of total variance across the K
classes. (Note that mathematically, the Gini index and
cross-entropy metrics are quite similar).

Backward stepwise selection (BSS) using the top 30
variables based on the RF variable importance measures

3

were used to construct the ﬁnal SVM and NN models.
Variable selection using BSS also signiﬁcantly improved
the performance of both the RF and Boosting models.
This indicates a large amount of noise in the data set.

We opted for feature selection instead of dimension-
ality reduction techniques such as PCA in order to ﬁnd
speciﬁc genes that were correlated with the response.
Reducing the feature space in this manner reduces over-
head and computational complexity. In addition, iden-
tifying particular genes correlated with thyroid cancer
could prove useful for further studies.

Figure 3: Most signiﬁcant variables according to RF

Figure 4: Linear kernel SVM on test data using V101 and
V96 as predictors, as selected by RF

IV Results and Discussion

Out of the models implemented, RF+NN proved to
be the most effective with an accuracy of 89% on the
held-out test set.

Method
NB
RF
Boosting
BSS+RF
BSS+Boosting
SVM
NN
RF+SVM
RF+NN

Acc.
0.76
0.76
0.78
0.78
0.81
0.80
0.76
0.81
0.89

Sn.
0.87
0.87
0.90
0.90
0.90
0.97
0.83
0.93
0.88

Spc. PPV NPV
0.80
0.64
0.80
0.64
0.64
0.84
0.84
0.64
0.86
0.72
0.93
0.60
0.68
0.77
0.89
0.68
0.91
0.84

0.74
0.74
0.75
0.75
0.79
0.74
0.76
0.78
0.93

Figure 5: Results showing accuracy, sensitivity, speciﬁcity,
positive predictive value, and negative predictive value on the
test set for each method used

That variable selection improved each model indi-
cates that the raw models were heavily overﬁtting the
test data. In particular, the small sample size and large
feature set size (relative to sample size) made it difﬁcult
to train our models without incurring variance vis-a-vis
the test set.
For all algorithms tested, classiﬁcation error on the
held-out test set was minimized using ≤ 10 predictors.
These correspond to 10 genes from the original dataset
provided by the NCBI. Using a smaller set of predictors
reduces variance of the model and increases model
interpretability. From a clinical standpoint, there is a
real-world cost difference incurred by collecting a larger
number of gene expression data (both in terms of time
and money), we deem this a signiﬁcant result that could
be useful in further studies exploring the correlation
between speciﬁc gene expressions and the presence of
thyroid cancer.

The ROC curve for RF+NN (ﬁg. 6) shows true posi-
tive rate versus false positive rate, or equivalently, sensi-
tivity versus 1-speciﬁcity, for different thresholds of the
classiﬁer output. This curve indicates that overall our
model is able to accurately classify most of our samples,
however produced false positives for samples that were
classiﬁed as malignant when in fact they were benign.
The Neural Network model calculates the cross-
entropy of each set of data for every run (ﬁg. 7). Here
it stops running on the twelfth run as the validation-set
cross-entropy reaches a minimum value at that point.
All subsequent runs check to validate this result.

From the results, our Neural Network model pro-
duced the most accurate results out of all classiﬁers
tested (see ﬁg. 8):

4

avoid any learning slowdown. The rate at which both
the weights and biases learn is controlled ultimately by
the error in the output, which seems like an appropri-
ate way to determine the best model for our data set;
(2) Neural Networks take correlations between features
into account when producing its model. By having the
Neural Network make use of â ˘AIJfeature learning,â ˘A˙I
the model we are able to produce becomes much more
versatile. Of course, we can see that we are still produc-
ing mismatches. Part of this may be explained by the
fact that the data can be noisy and taking into account
the original feature set size of 173.

Figure 6: ROC curve of RF+NN on the held-out test set

V Conclusion

The dataset collected from the NCBI consisted of mostly
indeterminate results (265 out of 367 samples). Our
sample size was also smaller than that used in the ref-
erenced literature (Alexander et. al.). Despite these
constraints, the performance of our best performing
model has an overall classiﬁcation accuracy comparable
to published results. This further validates the use of
RF as a feature selection method to complement SVM
and Neural Networks for applications in analysing gene
expression and cancer data, as well as machine learning
classiﬁers in analysing biomedical data in general. Fur-
ther we we able to produce these comparable results
using a feature set an order of magnitude smaller than
that of the original dataset. This translates to identify-
ing speciﬁc genes that are correlated with predicting
thyroid cancer, and in particular, could aid further stud-
ies in validating this result by reducing cost of collection
of these gene expression data, as well as reducing com-
putational complexity in producing results.

VI Acknowledgements

The authors would like to thank Professor Olivier
Gevaert for his guidance and for providing the orig-
inal dataset, as well as Professor Andrew Ng and the
CS 229 teaching team for their guidance.

VII References

1. Alexander EK, Kennedy GC, Baloch ZW, Cibas ES, Chu-
dova D,Diggans J, et al. Preoperative Diagnosis of Benign
Thyroid Nodules with Indeterminate Cytology. N Engl J
Med. 2012; 367:705-715.

2. Ghanem, Muhammad, Yair Levy, and Haggi Mazeh.
"Preoperative Diagnosis of Benign Thyroid Nodules with
Intermediate Cytology." Gland Surgery 1.2 (2012): 89-91.
PMC.

5

Figure 7: Training RF + NN

Figure 8: Confusion Matrix for RF + NN on held-out test set

We believe that this may be due to two factors: (1)
Using the cross-entropy expression, we were able to

Machine Learning Classiﬁer for Preoperative Diagnosis of Benign

Thyroid Nodules

Blanca Villanueva, Joshua Yoon
{ villanue, jyyoon } @stanford.edu

Abstract

Diagnosis of a thyroid nodule is the most common endocrine problem in the United States. Approximately 15-30% of thyroid
nodules evaluated by via the most common method, ﬁne-needle aspiration biopsies (FNABs), are indeterminate. Individuals with
cytologically indeterminate thyroid nodules are often referred for diagnostic surgery. These surgical consultations can be costly,
dangerous, and in most cases leave patients requiring levothyroxine replacement therapy for life. Most of these indeterminate
nodules prove to be benign. This project aims to provide individuals a means to avoid surgery by building upon existing machine
learning techniques for preoperative diagnosis of thyroid nodules. In order to be successful our classiﬁer should yield results
comparable to the current benchmarks of 90% sensitivity, 95% negative predictive value. Our best result was achieved using a
combination of Random Forests and Neural Networks, which yielded 89% accuracy, 88% sensitivity, and 84% negative predictive
value for a held-out test set. This result was achieved using a feature set an order of magnitude smaller than the original feature
space.
Introduction

I

Diagnosis of a thyroid nodule is the most common en-
docrine problem in the United States1. Up to 8% of
adult females and 2% of adult males have thyroid nod-
ules detectable by physical examination, and approx-
imately 30% of adult women have nodules detectable
by ultrasound. Although thyroid nodules are common
and usually benign, they prove to be cancerous in 5-15%
of cases. A ﬁne-needle aspiration biopsy (FNABs) is the
diagnostic tool of choice for thyroid nodule evaluation
as the technique has shown to be safe and effective at
producing accurate results. However, 15-30% of these
biopsies yield an indeterminate result. Patients with
indeterminate FNAB reults are usually referred for diag-
nostic surgery. Most individuals with thyroid nodules
larger than 1cm in diameter are referred for surgical
consultation. These individuals are exposed to a 2-10%
risk of serious surgical complications, and many indi-
viduals who undergo the procedure will require lifelong
levothyroxine replacement therapy thereafter. 60-70%
of thyroid cancers bear at least one known genetic mu-
tation, and several classiﬁers based on gene expression
data have shown promise (see references). Thus, this
study aims to reduce the number of individuals who
undergo diagnostic surgery due to indeterminate FNAB
results by implementing a machine learning classiﬁer
for preoperative diagnosis of benign thyroid nodules.

II Data

The data were collected from a study conducted by sci-
entists from multiple centres over 19 months 2; the data

1Ferry, Robert, Jr. "Thyroid Nodule." MedicineNet. N.p., n.d.
2Departments of Medicine (E.K.A.) and Pathology (E.S.C.),
Brigham and Women’s Hospital and Harvard Medical School, Boston;

set itself consists of 367 FNAB specimens (47 benign,
55 malignant, and 265 indeterminate). Each of these
biopsies contains gene expression data on 173 genes.
Each of these gene expression data is represented as a
numerical value in the data set. We imported this data
from the National Center for Biotechnology Informa-
tion (NCBI) Gene Expression Omnibus (GEO) website
3. Individual CEL ﬁles for each sample were unzipped
from a TAR ﬁle and were then extracted, reformatted,
and then saved in a convenient matrix format using the
getgeodata MATLAB function. We represented each
sample via a feature vector with its length equal to the
number of genes that were examined with every ele-
ment corresponding to its respective gene expression
value.

III Methods and Related Work

Several classiﬁcation algorithms, both parametric and
non-parametric were tested on the dataset: Naive Bayes
(which has been shown to outperform Logistic Regres-
sion on smaller datasets); ensemble methods: Random
forests, Boosting; linear kernel SVM; and Neural Net-
works. Each of these methods was trained on the same
random subset of 311 samples (out of the original 367).

Veracyte, South San Francisco, CA (G.C.K., D.C., J.D., L.F., P.S.W.,
J.I.W., R.B.L.); the Departments of Pathology (Z.W.B., V.A.L.) and
Medicine (S.J.M.), Perelman School of Medicine, University of Penn-
sylvania, Philadelphia; the Department of Medicine, Ohio State Uni-
versity College of Medicine, Columbus (R.T.K.); the Department of
Pathology, University of Washington School of Medicine, Seattle
(S.S.R.); Centro Diagnostico Italiano, Milan (J.R.); the Department
of Surgery, University of Cincinnati College of Medicine, Cincinnati
(D.L.S.); the Department of Surgery, Johns Hopkins University School
of Medicine, Baltimore (M.A.Z.); and the Department of Medicine,
University of Colorado School of Medicine, Aurora (B.R.H.).

3http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?

acc=GSE34289

1

we can then apply our model to our testing sample
to classify each as benign or malignant by choosing the
prior condition that gives the higher probability.

III.ii Ensemble Methods I: Random Forests

The Random Forest classiﬁer creates many decision
trees from bootstrap replicates of the original dataset.
In the case of RF, when building each decision tree for
its respective bootstrap sample, each time a split in
the tree is considered, a random subset of predictors
√
is used to create said split.
In this case, a subset of
p predictors (13 features out of 173) was used from
the original feature space. This technique effectively
decorrelates each of the constructed decision trees to
reduce overﬁtting. A tuning parameter B determines
the number of trees to construct. After B trees are
constructed, the trees are averaged in order to create
the ﬁnal model:

ˆf (x) =

1
B

B∑

b=1

ˆf ∗b(x)

Because each tree is created out of a random sampling
of the training data, the Random Forest is robust to
overﬁtting despite very large values for B. Thus, in
practice we use a sufﬁciently large B for the error rate to
have settled. For a given test observation, the predicted
value is chosen based on the most commonly occurring
class among the B predictions.

III.iii Ensemble Methods II: Boosting

Boosting is also an ensemble method for classiﬁcation.
It differs from the RF method in that each tree in the
constructed forest is not independent from the last, and
each tree is ﬁt on a modiﬁed version on the original
dataset (versus a bootstrap sample). Each boosted tree
is ﬁt to the residuals from the model rather than the
response. This tree is then added into the ﬁtted function
to update the residuals. Boosted trees tend to be quite
small (depths of 1 or 2 are typically used in practice).
By ﬁtting these small trees to the residuals, Boosting
improves the ﬁt in areas where the previous iteration of
the model did not perform well. Boosting involves three
tuning parameters: number of trees B (although the
Boosted trees are not independent as in RF, overﬁtting
tends to occur slowly if at all, such that we can also
choose large values for B); shrinkage parameter λ which
controls how quickly the Boosted model learns; and
interaction depth d:

1. Set ˆf (x) = 0, ri = yi for all i in the training set.

Figure 1: Overview of techniques used

Each was then evaluated on classiﬁcation accuracy on a
held-out test set of 55 samples (out of the original 367)
4. These methods were chosen based on literature re-
views (see references) which indicated that they would
perform well on our dataset given the following factors:
(1) Large feature space relative to number of observa-
tions, (2) Previous literature using these methods and
classiﬁers applied to gene expression data. We build
on the existing literature through our feature selection
methods, and through the methods used for tuning
our ﬁnal models. In particular, we hope to emulate the
results of the Alexander et. al. study of benign thyroid
nodules with indeterminate cytology.

III.i Baseline Model: Naive Bayes

Our baseline model is a Naive Bayes classiﬁer imple-
mented in MATLAB trained via splitting up the data
set into training and test sets and using the entire set
of 173 genes (as per the preceding literature) and their
gene expression values as our feature set.

For this particular model, in order to tame the num-
ber of parameters, we make a strong assumption where
all features are conditionally independent given the
response for that sample (malignant or benign). We
experiment with different training set sizes (60-140 sam-
ples) where we calculate all parameters relevant for our
model, incorporating Laplace smoothing in the process
(i.e., add 1 to the numerator and the number of genes
to the denominator for each parameter). By using a
multinomial model where the overall probability of a
message is given by:

p(y)

p(xi|y)

173∏

i=1

4One sample was corrupted and removed from the dataset

2. for b = 1, 2, ...B repeat 3-5:

2

3. Fit a tree ˆf b with d splits (d + 1 terminal nodes) to

the training data (X, r).

4. Update ˆf by adding a shrunken version of the new

tree ˆf (x) ← ˆf (x) + λ ˆf b(x).

5. Update the residuals ri ← ri − λ ˆf b(xi)
6. Output boosted model,

ˆf (x) =

B∑

b=1

λ ˆf b(x)

We tuned these parameters using 10-fold cross vali-

dation on our test set via R’s caret package.

III.iv Linear Kernel SVM

The linear kernel SVM is a parametric method con-
structed by identifying observations to deﬁne the classi-
ﬁcation boundary (these observations are called support
vectors). Several SVM models were implemented using
different kernels, although the linear kernel performed
best. The cost parameter C was chosen using 10-fold
cross validation.

III.v Neural Network

For this algorithm, one "neuron" takes an input vector of
features and is fed through a weight vector with some
bias. Usually one neuron is not enough to produce an
accurate model of our training set, so we have a layer
of neurons wherein every single feature for a different
sample is fed into multiple neurons. This results in our
argument equal to the weight matrix W multiplied by
the input feature vector x. A bias vector b is then added
on. Within the hidden layer of neurons, a sigmoid
function takes the result from the previous computation
and computes a value that is between 0 and 1. For
model selection, we measure results using classiﬁcation
error on the held-out test set, as well as cross entropy:

C = − 1
n

∑
x

y ln a + (1 − y) ln(1 − a)

Weights and bias values are updated with each sim-
ulation until the cross-entropy of the overall model
reaches a very small value ideally as close to 0 as possi-
ble.

The number of neurons in the hidden layer and the
regluarization parameter λ were chosen using 10-fold
cross validation on the training set using R’s caret pack-
age.

Neural networks usually apply sigmoid transfer func-
tions in the hidden layers. Sigmoid functions are useful
for differentiating inputs especially when they are either
very large or small since these are the regions when the

Figure 2: Tuning RF+NN hidden layer using 10-fold CV

slope approaches zero. However, this characteristic is
problematic when using gradient descent to train a mul-
tilayer network with sigmoid functions since they may
not produce large changes in the weights and biases
when attempting to ﬁnd their respective optimal values.
In order to circumvent this problem, back propagation
training algorithms are used where only the sign of
the derivative is used to determine the direction of the
weight update. I.e., if the weight continues to change in
the same direction (e.g. negative) for several iterations,
the magnitude of the weight change will be increased
(Rumelhart).

III.vi Feature Selection using Random Forests

We were able to reduce the feature space by an order of
magnitude via variable selection using the RF variable
importance plots (see ﬁg. 3). For the best Boosting
model, we were able to reduce the feature space by two
orders of magnitude. Several studies (see references)
show that RF serves as an effective feature selection
method for both SVMs and Neural Networks. Variable
importance is calculated based on classiﬁcation error
rate on the held-out test set:

E = 1 − max
k

( ˆpmk)

and Gini index:

G =

K∑

k=1

ˆpmk(1 − ˆpmk)

which is a measure of total variance across the K
classes. (Note that mathematically, the Gini index and
cross-entropy metrics are quite similar).

Backward stepwise selection (BSS) using the top 30
variables based on the RF variable importance measures

3

were used to construct the ﬁnal SVM and NN models.
Variable selection using BSS also signiﬁcantly improved
the performance of both the RF and Boosting models.
This indicates a large amount of noise in the data set.

We opted for feature selection instead of dimension-
ality reduction techniques such as PCA in order to ﬁnd
speciﬁc genes that were correlated with the response.
Reducing the feature space in this manner reduces over-
head and computational complexity. In addition, iden-
tifying particular genes correlated with thyroid cancer
could prove useful for further studies.

Figure 3: Most signiﬁcant variables according to RF

Figure 4: Linear kernel SVM on test data using V101 and
V96 as predictors, as selected by RF

IV Results and Discussion

Out of the models implemented, RF+NN proved to
be the most effective with an accuracy of 89% on the
held-out test set.

Method
NB
RF
Boosting
BSS+RF
BSS+Boosting
SVM
NN
RF+SVM
RF+NN

Acc.
0.76
0.76
0.78
0.78
0.81
0.80
0.76
0.81
0.89

Sn.
0.87
0.87
0.90
0.90
0.90
0.97
0.83
0.93
0.88

Spc. PPV NPV
0.80
0.64
0.80
0.64
0.64
0.84
0.84
0.64
0.86
0.72
0.93
0.60
0.68
0.77
0.89
0.68
0.91
0.84

0.74
0.74
0.75
0.75
0.79
0.74
0.76
0.78
0.93

Figure 5: Results showing accuracy, sensitivity, speciﬁcity,
positive predictive value, and negative predictive value on the
test set for each method used

That variable selection improved each model indi-
cates that the raw models were heavily overﬁtting the
test data. In particular, the small sample size and large
feature set size (relative to sample size) made it difﬁcult
to train our models without incurring variance vis-a-vis
the test set.
For all algorithms tested, classiﬁcation error on the
held-out test set was minimized using ≤ 10 predictors.
These correspond to 10 genes from the original dataset
provided by the NCBI. Using a smaller set of predictors
reduces variance of the model and increases model
interpretability. From a clinical standpoint, there is a
real-world cost difference incurred by collecting a larger
number of gene expression data (both in terms of time
and money), we deem this a signiﬁcant result that could
be useful in further studies exploring the correlation
between speciﬁc gene expressions and the presence of
thyroid cancer.

The ROC curve for RF+NN (ﬁg. 6) shows true posi-
tive rate versus false positive rate, or equivalently, sensi-
tivity versus 1-speciﬁcity, for different thresholds of the
classiﬁer output. This curve indicates that overall our
model is able to accurately classify most of our samples,
however produced false positives for samples that were
classiﬁed as malignant when in fact they were benign.
The Neural Network model calculates the cross-
entropy of each set of data for every run (ﬁg. 7). Here
it stops running on the twelfth run as the validation-set
cross-entropy reaches a minimum value at that point.
All subsequent runs check to validate this result.

From the results, our Neural Network model pro-
duced the most accurate results out of all classiﬁers
tested (see ﬁg. 8):

4

avoid any learning slowdown. The rate at which both
the weights and biases learn is controlled ultimately by
the error in the output, which seems like an appropri-
ate way to determine the best model for our data set;
(2) Neural Networks take correlations between features
into account when producing its model. By having the
Neural Network make use of â ˘AIJfeature learning,â ˘A˙I
the model we are able to produce becomes much more
versatile. Of course, we can see that we are still produc-
ing mismatches. Part of this may be explained by the
fact that the data can be noisy and taking into account
the original feature set size of 173.

Figure 6: ROC curve of RF+NN on the held-out test set

V Conclusion

The dataset collected from the NCBI consisted of mostly
indeterminate results (265 out of 367 samples). Our
sample size was also smaller than that used in the ref-
erenced literature (Alexander et. al.). Despite these
constraints, the performance of our best performing
model has an overall classiﬁcation accuracy comparable
to published results. This further validates the use of
RF as a feature selection method to complement SVM
and Neural Networks for applications in analysing gene
expression and cancer data, as well as machine learning
classiﬁers in analysing biomedical data in general. Fur-
ther we we able to produce these comparable results
using a feature set an order of magnitude smaller than
that of the original dataset. This translates to identify-
ing speciﬁc genes that are correlated with predicting
thyroid cancer, and in particular, could aid further stud-
ies in validating this result by reducing cost of collection
of these gene expression data, as well as reducing com-
putational complexity in producing results.

VI Acknowledgements

The authors would like to thank Professor Olivier
Gevaert for his guidance and for providing the orig-
inal dataset, as well as Professor Andrew Ng and the
CS 229 teaching team for their guidance.

VII References

1. Alexander EK, Kennedy GC, Baloch ZW, Cibas ES, Chu-
dova D,Diggans J, et al. Preoperative Diagnosis of Benign
Thyroid Nodules with Indeterminate Cytology. N Engl J
Med. 2012; 367:705-715.

2. Ghanem, Muhammad, Yair Levy, and Haggi Mazeh.
"Preoperative Diagnosis of Benign Thyroid Nodules with
Intermediate Cytology." Gland Surgery 1.2 (2012): 89-91.
PMC.

5

Figure 7: Training RF + NN

Figure 8: Confusion Matrix for RF + NN on held-out test set

We believe that this may be due to two factors: (1)
Using the cross-entropy expression, we were able to

3. Chen, Yi-Wei, and Chih-Jen Lin.

"Combining SVMs
with Various Feature Selection Strategies." Feature
Extraction: Foundations and Applications (Studies
in Fuzziness and Soft Computing) (2006):
315-24.
Web. <https://www.csie.ntu.edu.tw/ cjlin/papers/ fea-
tures.pdf>.

4. Li, Wenjuan and Meng, Yuxin. "Improving the Perfor-
mance of Neural Networks with Random Forest in De-
tecting Network Intrusions". Proceedings of the 10th
International Conference on Advances in Neural Net-
works - Volume Part II. 2013. Springer-Verlag: Dalian,
China.

5. Rumelhart,

D.E.,

Hinton,

G.E., Williams,
back-
533-536
<http://www.nature.com/nature/journal/

representations
Nature

by
323,

Learning

R.J.
propagating
(1986).
v323/n6088/pdf/323533a0.pdf>.

errors.

6

