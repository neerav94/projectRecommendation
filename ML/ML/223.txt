Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

Chun-Che Peng
Mohammad Lakis
Jan Wei Pan

Abstract

Sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions. Nonetheless, the human compre-
hension system can often spot a sarcastic senti-
ment, and reason about what makes it so. Re-
cent advances in natural language sentence gen-
eration research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases. However, ac-
curacy and robustness of results are often af-
fected by untruthful sentiments that are of sar-
casm nature and this is often left untreated. Sar-
casm detection is a very important process to
ﬁlter out noisy data (in this case, sarcastic sen-
tences) from training data inputs, which can be
used for natural language sentence generation.
In this paper, we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by Mathieu Cliche
of www.thesarcasmdetector.com and improving
upon it. By analyzing the strengths and weak-
nesses of the baseline model, we strive to develop
one that will achieve better results.

1. Introduction
1.1. Motivation

Analysis on social media has attracted much interest in the
research areas of NLP over the past decade (Pt´aˇcek et al.,
2014).
In fact, on June 5, 2014, the BBC reported that
the U.S. Secret Service was looking for a software sys-
tem that could detect sarcasm in social media data (BBC,
2014). Misinterpreting irony and sarcasm represents a big
challenge. However, although sarcasm detection in text is a
daunting task, it is an important chapter in the advancement
of artiﬁcial intelligence.
This paper investigates the possibility of classifying sar-

Writeup for Stanford CS 229 Machine Learning Final Project.
Copyright 2015 by the author(s).

CHUNCHE@STANFORD.EDU
MJLAKIS@STANFORD.EDU
JWPAN@STANFORD.EDU

casm in text reliability and identiﬁes typical textual fea-
tures from Twitter that are important for sarcasm in the pro-
cess. As there is only a weak boundary in meaning between
irony, sarcasm and satire (Reyes et al., 2013), the usage of
the term sarcasm in this paper refers to the general concept.

1.2. Statement of Problem

Sarcasm sentences can be used almost in all topics. They
can take variable grammatical structures. Also, to under-
stand sarcasm, one has to know the context of the sentence.
For instance, the sentence ”I love being rich” is not sarcas-
tic by itself. However, if you know that the speaker is poor,
you will decide that this is a sarcastic sentence. Therefore,
to detect sarcasm, you have to have prior knowledge about
the subject or sarcasm, which might not always be avail-
able. For our approach, we will not attempt to start from
scratch. Rather, we will leverage the work done by Math-
ieu Cliche of www.thesarcasmdetector.com and build upon
it. As a baseline for our project we will replicate some re-
sults from Cliches work. Our goal is to develop a machine
learning algorithm that will achieve better results.
In his work, Cliche gathered tweets from Twitter labeled
with #sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments (i.e. start very
positively but end very negatively). He also adds other fea-
tures such as n-grams and topics. He then trains an SVM
and compares it with other classiﬁcation algorithms such
as Nave Bayes. His results show that using an SVM on
the engineered features yields better results from previous
work (Cliche, 2014).
In the following section, we will conduct error analysis to
pinpoint areas for improvement.

2. Related Works
Sarcasm is a challenging problem in the ﬁeld of sentiment
analysis for a wide range of languages. For example, Lu-
nando and Purwarianti presented their sarcasm detection
classiﬁers, including a Naive Bayes classiﬁer and a Sup-
port Vector Machine, for analyzing Indonesian Social me-
dia, using features of negativity and number of interjec-

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

Chun-Che Peng
Mohammad Lakis
Jan Wei Pan

Abstract

Sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions. Nonetheless, the human compre-
hension system can often spot a sarcastic senti-
ment, and reason about what makes it so. Re-
cent advances in natural language sentence gen-
eration research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases. However, ac-
curacy and robustness of results are often af-
fected by untruthful sentiments that are of sar-
casm nature and this is often left untreated. Sar-
casm detection is a very important process to
ﬁlter out noisy data (in this case, sarcastic sen-
tences) from training data inputs, which can be
used for natural language sentence generation.
In this paper, we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by Mathieu Cliche
of www.thesarcasmdetector.com and improving
upon it. By analyzing the strengths and weak-
nesses of the baseline model, we strive to develop
one that will achieve better results.

1. Introduction
1.1. Motivation

Analysis on social media has attracted much interest in the
research areas of NLP over the past decade (Pt´aˇcek et al.,
2014).
In fact, on June 5, 2014, the BBC reported that
the U.S. Secret Service was looking for a software sys-
tem that could detect sarcasm in social media data (BBC,
2014). Misinterpreting irony and sarcasm represents a big
challenge. However, although sarcasm detection in text is a
daunting task, it is an important chapter in the advancement
of artiﬁcial intelligence.
This paper investigates the possibility of classifying sar-

Writeup for Stanford CS 229 Machine Learning Final Project.
Copyright 2015 by the author(s).

CHUNCHE@STANFORD.EDU
MJLAKIS@STANFORD.EDU
JWPAN@STANFORD.EDU

casm in text reliability and identiﬁes typical textual fea-
tures from Twitter that are important for sarcasm in the pro-
cess. As there is only a weak boundary in meaning between
irony, sarcasm and satire (Reyes et al., 2013), the usage of
the term sarcasm in this paper refers to the general concept.

1.2. Statement of Problem

Sarcasm sentences can be used almost in all topics. They
can take variable grammatical structures. Also, to under-
stand sarcasm, one has to know the context of the sentence.
For instance, the sentence ”I love being rich” is not sarcas-
tic by itself. However, if you know that the speaker is poor,
you will decide that this is a sarcastic sentence. Therefore,
to detect sarcasm, you have to have prior knowledge about
the subject or sarcasm, which might not always be avail-
able. For our approach, we will not attempt to start from
scratch. Rather, we will leverage the work done by Math-
ieu Cliche of www.thesarcasmdetector.com and build upon
it. As a baseline for our project we will replicate some re-
sults from Cliches work. Our goal is to develop a machine
learning algorithm that will achieve better results.
In his work, Cliche gathered tweets from Twitter labeled
with #sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments (i.e. start very
positively but end very negatively). He also adds other fea-
tures such as n-grams and topics. He then trains an SVM
and compares it with other classiﬁcation algorithms such
as Nave Bayes. His results show that using an SVM on
the engineered features yields better results from previous
work (Cliche, 2014).
In the following section, we will conduct error analysis to
pinpoint areas for improvement.

2. Related Works
Sarcasm is a challenging problem in the ﬁeld of sentiment
analysis for a wide range of languages. For example, Lu-
nando and Purwarianti presented their sarcasm detection
classiﬁers, including a Naive Bayes classiﬁer and a Sup-
port Vector Machine, for analyzing Indonesian Social me-
dia, using features of negativity and number of interjec-

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

tion words. Their aim of using negativity feature was to
catch the global sentiment value, and the interjection fea-
ture was to represent the lexical phenomena of the text mes-
sage. Their intents were however challenged, because it
was shown that negativity features were not useful as many
sarcasm texts that they analyzed had no global topic, and
thus making the text topic is not widely known. Also, there
was quite a lot of text with personal message that could
only be analyzed if the reader has prior knowledge about
the context or writer (Lunando & Purwarianti, 2013).
Gathering data to be categorized as sarcastic and non-
sarcastic is a challenge in of itself. Fortunately, Twitter
has proved itself to be a valuable tool for whole variety
of natural language processing investigations. The idea of
using #sarcasm as a way of gathering positive data points
from Twitter is not new as evident by the research done by
(Liebrecht et al., 2013). The authors made use of Balanced
Winnow and achieved an accuracy of 75%.

3. Dataset and Features
3.1. Baseline Model Description

The baseline model uses a support vector machine (SVM)
as implemented by the LinearSVC function from scikit-
learn, a popular open source machine learning library in
Python. Aside from a value of 0.1 for the penalty param-
eter C, all other conﬁguration options are left as default.
Features are extracted from the raw Twitter data to create
training examples that are fed into the SVM to create a hy-
pothesis model. Although much of the machine learning
implemented is already provided by a third party tool, ef-
fort is still necessary for feature engineering.
The tweets were collected over a span of several months
in 2014. The sanitation processed included removing all
the hashtags, non ASCII characters, and http links. In ad-
dition, each tweet is tokenized, stemmed, and uncapital-
ized through the use of the Python NLTK library. For each
tweet, features that are hypothesized to be crucial to sar-
casm detection are extracted. The features fall broadly into
5 categories: n-grams, sentiments, parts of speeches, capi-
talizations, and topics.

3.2. Baseline Features

N-grams: Individual tokens (i.e. unigrams) and bigrams
are placed into a binary feature dictionary. Bigrams are ex-
tracted using the same library and are deﬁned as pairs of
words that typically go together. Examples include artiﬁ-
cial intelligence, peanut butter, etc.
Sentiments: A tweet is broken up into two and three parts.
Sentiment scores are calculated using two libraries (Senti-
WordNet and TextBlob). Positive and negative sentiment

scores are collected for the overall tweet as well as each in-
dividual part. Furthermore, the contrast between the parts
are inserted into the features.
Parts of Speech: The parts of speech in each tweet are
counted and inserted into the features.
Capitalizations: A binary ﬂag indicating whether the tweet
contains at least 4 tokens that start with a capitalization is
inserted into the features.
Topics: The python library gensim which implements topic
modeling using latent Dirichlet allocation (LDA) is used to
learn the topics. The collection of topics for each tweet is
then inserted into the features.

4. Methods and Analysis
4.1. Analysis of Baseline Model

Initial analysis of the baseline model quickly reveals that
the testing error far exceeds the training error. In fact, the
training error is virtually non-existent! A value of 0.1 is
initially used for the penalty parameter C in the SVM. Since
the parameter is a measure of how much one wants to avoid
misclassifying each training example, smaller values of C
(0.01, and 0.001) are then used.

Figure 1. Training and testing error percentages for various values
of the penalty parameter C.

Despite trying different values of C, it appears that the test-
ing error can be improved only slightly. The testing error
remains at around 30%. Nonetheless, the best results are
obtained for C= 0.01. The large gap between training and
testing error suggests that the model is suffering from high
variance.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

Chun-Che Peng
Mohammad Lakis
Jan Wei Pan

Abstract

Sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions. Nonetheless, the human compre-
hension system can often spot a sarcastic senti-
ment, and reason about what makes it so. Re-
cent advances in natural language sentence gen-
eration research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases. However, ac-
curacy and robustness of results are often af-
fected by untruthful sentiments that are of sar-
casm nature and this is often left untreated. Sar-
casm detection is a very important process to
ﬁlter out noisy data (in this case, sarcastic sen-
tences) from training data inputs, which can be
used for natural language sentence generation.
In this paper, we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by Mathieu Cliche
of www.thesarcasmdetector.com and improving
upon it. By analyzing the strengths and weak-
nesses of the baseline model, we strive to develop
one that will achieve better results.

1. Introduction
1.1. Motivation

Analysis on social media has attracted much interest in the
research areas of NLP over the past decade (Pt´aˇcek et al.,
2014).
In fact, on June 5, 2014, the BBC reported that
the U.S. Secret Service was looking for a software sys-
tem that could detect sarcasm in social media data (BBC,
2014). Misinterpreting irony and sarcasm represents a big
challenge. However, although sarcasm detection in text is a
daunting task, it is an important chapter in the advancement
of artiﬁcial intelligence.
This paper investigates the possibility of classifying sar-

Writeup for Stanford CS 229 Machine Learning Final Project.
Copyright 2015 by the author(s).

CHUNCHE@STANFORD.EDU
MJLAKIS@STANFORD.EDU
JWPAN@STANFORD.EDU

casm in text reliability and identiﬁes typical textual fea-
tures from Twitter that are important for sarcasm in the pro-
cess. As there is only a weak boundary in meaning between
irony, sarcasm and satire (Reyes et al., 2013), the usage of
the term sarcasm in this paper refers to the general concept.

1.2. Statement of Problem

Sarcasm sentences can be used almost in all topics. They
can take variable grammatical structures. Also, to under-
stand sarcasm, one has to know the context of the sentence.
For instance, the sentence ”I love being rich” is not sarcas-
tic by itself. However, if you know that the speaker is poor,
you will decide that this is a sarcastic sentence. Therefore,
to detect sarcasm, you have to have prior knowledge about
the subject or sarcasm, which might not always be avail-
able. For our approach, we will not attempt to start from
scratch. Rather, we will leverage the work done by Math-
ieu Cliche of www.thesarcasmdetector.com and build upon
it. As a baseline for our project we will replicate some re-
sults from Cliches work. Our goal is to develop a machine
learning algorithm that will achieve better results.
In his work, Cliche gathered tweets from Twitter labeled
with #sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments (i.e. start very
positively but end very negatively). He also adds other fea-
tures such as n-grams and topics. He then trains an SVM
and compares it with other classiﬁcation algorithms such
as Nave Bayes. His results show that using an SVM on
the engineered features yields better results from previous
work (Cliche, 2014).
In the following section, we will conduct error analysis to
pinpoint areas for improvement.

2. Related Works
Sarcasm is a challenging problem in the ﬁeld of sentiment
analysis for a wide range of languages. For example, Lu-
nando and Purwarianti presented their sarcasm detection
classiﬁers, including a Naive Bayes classiﬁer and a Sup-
port Vector Machine, for analyzing Indonesian Social me-
dia, using features of negativity and number of interjec-

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

tion words. Their aim of using negativity feature was to
catch the global sentiment value, and the interjection fea-
ture was to represent the lexical phenomena of the text mes-
sage. Their intents were however challenged, because it
was shown that negativity features were not useful as many
sarcasm texts that they analyzed had no global topic, and
thus making the text topic is not widely known. Also, there
was quite a lot of text with personal message that could
only be analyzed if the reader has prior knowledge about
the context or writer (Lunando & Purwarianti, 2013).
Gathering data to be categorized as sarcastic and non-
sarcastic is a challenge in of itself. Fortunately, Twitter
has proved itself to be a valuable tool for whole variety
of natural language processing investigations. The idea of
using #sarcasm as a way of gathering positive data points
from Twitter is not new as evident by the research done by
(Liebrecht et al., 2013). The authors made use of Balanced
Winnow and achieved an accuracy of 75%.

3. Dataset and Features
3.1. Baseline Model Description

The baseline model uses a support vector machine (SVM)
as implemented by the LinearSVC function from scikit-
learn, a popular open source machine learning library in
Python. Aside from a value of 0.1 for the penalty param-
eter C, all other conﬁguration options are left as default.
Features are extracted from the raw Twitter data to create
training examples that are fed into the SVM to create a hy-
pothesis model. Although much of the machine learning
implemented is already provided by a third party tool, ef-
fort is still necessary for feature engineering.
The tweets were collected over a span of several months
in 2014. The sanitation processed included removing all
the hashtags, non ASCII characters, and http links. In ad-
dition, each tweet is tokenized, stemmed, and uncapital-
ized through the use of the Python NLTK library. For each
tweet, features that are hypothesized to be crucial to sar-
casm detection are extracted. The features fall broadly into
5 categories: n-grams, sentiments, parts of speeches, capi-
talizations, and topics.

3.2. Baseline Features

N-grams: Individual tokens (i.e. unigrams) and bigrams
are placed into a binary feature dictionary. Bigrams are ex-
tracted using the same library and are deﬁned as pairs of
words that typically go together. Examples include artiﬁ-
cial intelligence, peanut butter, etc.
Sentiments: A tweet is broken up into two and three parts.
Sentiment scores are calculated using two libraries (Senti-
WordNet and TextBlob). Positive and negative sentiment

scores are collected for the overall tweet as well as each in-
dividual part. Furthermore, the contrast between the parts
are inserted into the features.
Parts of Speech: The parts of speech in each tweet are
counted and inserted into the features.
Capitalizations: A binary ﬂag indicating whether the tweet
contains at least 4 tokens that start with a capitalization is
inserted into the features.
Topics: The python library gensim which implements topic
modeling using latent Dirichlet allocation (LDA) is used to
learn the topics. The collection of topics for each tweet is
then inserted into the features.

4. Methods and Analysis
4.1. Analysis of Baseline Model

Initial analysis of the baseline model quickly reveals that
the testing error far exceeds the training error. In fact, the
training error is virtually non-existent! A value of 0.1 is
initially used for the penalty parameter C in the SVM. Since
the parameter is a measure of how much one wants to avoid
misclassifying each training example, smaller values of C
(0.01, and 0.001) are then used.

Figure 1. Training and testing error percentages for various values
of the penalty parameter C.

Despite trying different values of C, it appears that the test-
ing error can be improved only slightly. The testing error
remains at around 30%. Nonetheless, the best results are
obtained for C= 0.01. The large gap between training and
testing error suggests that the model is suffering from high
variance.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

4.2. Targeted Areas for Improvement

The high testing error of the model at hand implies that we
are ﬁtting noise. This problem could be caused by the fact
that we have a high dimensional feature space. Another
possibility is that there are features that are not relevant for
detecting sarcasm. In both cases, we think it is important
to reduce the dimension of feature space and use relevant
features. For instance, the beneﬁt of adding some features
such as bigrams, sentiments and topics is not clear. Bi-
grams might have the same effect as unigrams. Also, we
should test whether adding sentiments improves our classi-
ﬁcation by a signiﬁcant factor. While it is true that some
sarcastic sentences have words with negative sentiments
and others with positive sentiments, many other sentences
do not have this property. Thus, adding this feature might
not be useful. Also, non-sarcastic sentences can still have
both positive and negative sentiments. We also think that
ﬁnding the sentiments in each training example takes a lot
of time. For each training example, we have to look for
the sentiment of each word in a dictionary, which takes a
lot of time. We also want to investigate the topics that are
added. Topic modeling using LDA might be returning sim-
ilar words as the unigrams of the training example, and we
might end up getting redundant information. However, we
think that categorizing the training examples into a set of
topics can be useful in a different way than it is used. In-
stead of adding topics as a separate feature, we might split
our classiﬁer to n-classiﬁers, where n is the number of top-
ics in the training set. In other words, we build a classiﬁer
for each topic. Consider for instance the following topics,
soccer and unemployment. Words used in sentences about
soccer are different from those used in sentences about un-
employment. Therefore, the unigrams that are used to de-
tect spam in soccer topic will be very different from the un-
igrams used to detect sarcasm in unemployment. So what
we get is a set of classiﬁers with much lower feature space.
To analyze the classiﬁcation problem that we have, we start
by training a simple Naive Bayes classiﬁer. Based on the
error analysis from this classiﬁer, we tried other classiﬁers
such as one class SVM and a binary SVM with different
features and a non-linear kernel (Gaussian kernel).

4.3. Model Improvement Methods

4.3.1. NAIVE BAYES

We ﬁrst created a multinomial Naive Bayes classiﬁer to
train and test the datasets that were previously collected by
Clich. During the pre-processing, we performed an auto-
mated tagging of 25,278 datasets as sarcastic and 117,842
datasets as non-sarcastic, based on the labels from Clichs
datasets. Then, we randomly selected 70% of the data for
training, and 30% of the data for testing purposes. After
that, we constructed a term frequency-inverse document

frequency (TF-IDF) vector, and then fed it into a multino-
mial Naive Bayes classiﬁer using the ”TﬁdfVectorizer” and
”naive bayes” modules from NLTK toolkit (scikit-learn,
2014). The results are discussed in Section 5.

4.3.2. ONE CLASS SVM

We noticed that the sarcastic data has a lot of ambiguous
sentences. Without the knowledge of the subject of a sen-
tence, we expect it to be non-sarcastic. On the other hand,
the non-sarcastic data sample is clean and clear. Also, we
have around 110,000 non-sarcastic example compared to
25,000 sarcastic example. This motivated us to rely more
on non-sarcastic data. So we decided to use one class SVM
as described in (Sch¨olkoph et al., 2000) and (Manevitz &
Yousef, 2001). Our one class SVM will be trained only on
non-sarcastic data. Hence, we can think of sarcasm detec-
tion as Novelty detection (Sch¨olkoph et al., 2000; scikit-
learn, 2014). This means we are trying to detect sarcasm
by measuring how similar it is to the training set. For one
class SVM, we want to solve the following optimization
problem:

n(cid:88)

ξi − ρ

i=1

i = 1, ..., n

i = 1, ..., n

min
ω,ξ,ρ

1
2

(cid:107)ω(cid:107)2 +

1
νn

subject to :

ω.φ(cid:0)xi

(cid:1) ≥ ρ − ξi;

ρ ≥ 0;

With the decision function being:

f(cid:0)x(cid:1) = sgn(ω.φ(cid:0)xi

(cid:1) − ρ)

(1)

In our implementation, we used a Gaussian kernel with dif-
ferent values of σ.
Therefore, the decision function becomes:

f(cid:0)x(cid:1) = sgn(ω.K(cid:0)xi, x(cid:1) − ρ)

(2)

Where, according to (scikit-learn, 2014), ν represents an
upper bound on the fraction of training errors, and a lower
bound of fraction of support vectors. We implemented one
class SVM with a feature vector formed of unigrams and
bigrams. We discuss the results in section 6.

4.3.3. GAUSSIAN KERNEL

It’s possible that the dataset is not linearly separable and
so using a Gaussian kernel instead of a linear kernel in the
SVM might be a better approach. We use the SVC function
(RBF kernel) from the same Python library scikit-learn. In
addition to the penalty parameter C, there’s the paramter
gamma which deﬁnes how far the inﬂuence of a single
training example reaches. Through repeated trials of vary-
ing both pamaters, we ﬁnd that the values for C and gamma

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

Chun-Che Peng
Mohammad Lakis
Jan Wei Pan

Abstract

Sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions. Nonetheless, the human compre-
hension system can often spot a sarcastic senti-
ment, and reason about what makes it so. Re-
cent advances in natural language sentence gen-
eration research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases. However, ac-
curacy and robustness of results are often af-
fected by untruthful sentiments that are of sar-
casm nature and this is often left untreated. Sar-
casm detection is a very important process to
ﬁlter out noisy data (in this case, sarcastic sen-
tences) from training data inputs, which can be
used for natural language sentence generation.
In this paper, we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by Mathieu Cliche
of www.thesarcasmdetector.com and improving
upon it. By analyzing the strengths and weak-
nesses of the baseline model, we strive to develop
one that will achieve better results.

1. Introduction
1.1. Motivation

Analysis on social media has attracted much interest in the
research areas of NLP over the past decade (Pt´aˇcek et al.,
2014).
In fact, on June 5, 2014, the BBC reported that
the U.S. Secret Service was looking for a software sys-
tem that could detect sarcasm in social media data (BBC,
2014). Misinterpreting irony and sarcasm represents a big
challenge. However, although sarcasm detection in text is a
daunting task, it is an important chapter in the advancement
of artiﬁcial intelligence.
This paper investigates the possibility of classifying sar-

Writeup for Stanford CS 229 Machine Learning Final Project.
Copyright 2015 by the author(s).

CHUNCHE@STANFORD.EDU
MJLAKIS@STANFORD.EDU
JWPAN@STANFORD.EDU

casm in text reliability and identiﬁes typical textual fea-
tures from Twitter that are important for sarcasm in the pro-
cess. As there is only a weak boundary in meaning between
irony, sarcasm and satire (Reyes et al., 2013), the usage of
the term sarcasm in this paper refers to the general concept.

1.2. Statement of Problem

Sarcasm sentences can be used almost in all topics. They
can take variable grammatical structures. Also, to under-
stand sarcasm, one has to know the context of the sentence.
For instance, the sentence ”I love being rich” is not sarcas-
tic by itself. However, if you know that the speaker is poor,
you will decide that this is a sarcastic sentence. Therefore,
to detect sarcasm, you have to have prior knowledge about
the subject or sarcasm, which might not always be avail-
able. For our approach, we will not attempt to start from
scratch. Rather, we will leverage the work done by Math-
ieu Cliche of www.thesarcasmdetector.com and build upon
it. As a baseline for our project we will replicate some re-
sults from Cliches work. Our goal is to develop a machine
learning algorithm that will achieve better results.
In his work, Cliche gathered tweets from Twitter labeled
with #sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments (i.e. start very
positively but end very negatively). He also adds other fea-
tures such as n-grams and topics. He then trains an SVM
and compares it with other classiﬁcation algorithms such
as Nave Bayes. His results show that using an SVM on
the engineered features yields better results from previous
work (Cliche, 2014).
In the following section, we will conduct error analysis to
pinpoint areas for improvement.

2. Related Works
Sarcasm is a challenging problem in the ﬁeld of sentiment
analysis for a wide range of languages. For example, Lu-
nando and Purwarianti presented their sarcasm detection
classiﬁers, including a Naive Bayes classiﬁer and a Sup-
port Vector Machine, for analyzing Indonesian Social me-
dia, using features of negativity and number of interjec-

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

tion words. Their aim of using negativity feature was to
catch the global sentiment value, and the interjection fea-
ture was to represent the lexical phenomena of the text mes-
sage. Their intents were however challenged, because it
was shown that negativity features were not useful as many
sarcasm texts that they analyzed had no global topic, and
thus making the text topic is not widely known. Also, there
was quite a lot of text with personal message that could
only be analyzed if the reader has prior knowledge about
the context or writer (Lunando & Purwarianti, 2013).
Gathering data to be categorized as sarcastic and non-
sarcastic is a challenge in of itself. Fortunately, Twitter
has proved itself to be a valuable tool for whole variety
of natural language processing investigations. The idea of
using #sarcasm as a way of gathering positive data points
from Twitter is not new as evident by the research done by
(Liebrecht et al., 2013). The authors made use of Balanced
Winnow and achieved an accuracy of 75%.

3. Dataset and Features
3.1. Baseline Model Description

The baseline model uses a support vector machine (SVM)
as implemented by the LinearSVC function from scikit-
learn, a popular open source machine learning library in
Python. Aside from a value of 0.1 for the penalty param-
eter C, all other conﬁguration options are left as default.
Features are extracted from the raw Twitter data to create
training examples that are fed into the SVM to create a hy-
pothesis model. Although much of the machine learning
implemented is already provided by a third party tool, ef-
fort is still necessary for feature engineering.
The tweets were collected over a span of several months
in 2014. The sanitation processed included removing all
the hashtags, non ASCII characters, and http links. In ad-
dition, each tweet is tokenized, stemmed, and uncapital-
ized through the use of the Python NLTK library. For each
tweet, features that are hypothesized to be crucial to sar-
casm detection are extracted. The features fall broadly into
5 categories: n-grams, sentiments, parts of speeches, capi-
talizations, and topics.

3.2. Baseline Features

N-grams: Individual tokens (i.e. unigrams) and bigrams
are placed into a binary feature dictionary. Bigrams are ex-
tracted using the same library and are deﬁned as pairs of
words that typically go together. Examples include artiﬁ-
cial intelligence, peanut butter, etc.
Sentiments: A tweet is broken up into two and three parts.
Sentiment scores are calculated using two libraries (Senti-
WordNet and TextBlob). Positive and negative sentiment

scores are collected for the overall tweet as well as each in-
dividual part. Furthermore, the contrast between the parts
are inserted into the features.
Parts of Speech: The parts of speech in each tweet are
counted and inserted into the features.
Capitalizations: A binary ﬂag indicating whether the tweet
contains at least 4 tokens that start with a capitalization is
inserted into the features.
Topics: The python library gensim which implements topic
modeling using latent Dirichlet allocation (LDA) is used to
learn the topics. The collection of topics for each tweet is
then inserted into the features.

4. Methods and Analysis
4.1. Analysis of Baseline Model

Initial analysis of the baseline model quickly reveals that
the testing error far exceeds the training error. In fact, the
training error is virtually non-existent! A value of 0.1 is
initially used for the penalty parameter C in the SVM. Since
the parameter is a measure of how much one wants to avoid
misclassifying each training example, smaller values of C
(0.01, and 0.001) are then used.

Figure 1. Training and testing error percentages for various values
of the penalty parameter C.

Despite trying different values of C, it appears that the test-
ing error can be improved only slightly. The testing error
remains at around 30%. Nonetheless, the best results are
obtained for C= 0.01. The large gap between training and
testing error suggests that the model is suffering from high
variance.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

4.2. Targeted Areas for Improvement

The high testing error of the model at hand implies that we
are ﬁtting noise. This problem could be caused by the fact
that we have a high dimensional feature space. Another
possibility is that there are features that are not relevant for
detecting sarcasm. In both cases, we think it is important
to reduce the dimension of feature space and use relevant
features. For instance, the beneﬁt of adding some features
such as bigrams, sentiments and topics is not clear. Bi-
grams might have the same effect as unigrams. Also, we
should test whether adding sentiments improves our classi-
ﬁcation by a signiﬁcant factor. While it is true that some
sarcastic sentences have words with negative sentiments
and others with positive sentiments, many other sentences
do not have this property. Thus, adding this feature might
not be useful. Also, non-sarcastic sentences can still have
both positive and negative sentiments. We also think that
ﬁnding the sentiments in each training example takes a lot
of time. For each training example, we have to look for
the sentiment of each word in a dictionary, which takes a
lot of time. We also want to investigate the topics that are
added. Topic modeling using LDA might be returning sim-
ilar words as the unigrams of the training example, and we
might end up getting redundant information. However, we
think that categorizing the training examples into a set of
topics can be useful in a different way than it is used. In-
stead of adding topics as a separate feature, we might split
our classiﬁer to n-classiﬁers, where n is the number of top-
ics in the training set. In other words, we build a classiﬁer
for each topic. Consider for instance the following topics,
soccer and unemployment. Words used in sentences about
soccer are different from those used in sentences about un-
employment. Therefore, the unigrams that are used to de-
tect spam in soccer topic will be very different from the un-
igrams used to detect sarcasm in unemployment. So what
we get is a set of classiﬁers with much lower feature space.
To analyze the classiﬁcation problem that we have, we start
by training a simple Naive Bayes classiﬁer. Based on the
error analysis from this classiﬁer, we tried other classiﬁers
such as one class SVM and a binary SVM with different
features and a non-linear kernel (Gaussian kernel).

4.3. Model Improvement Methods

4.3.1. NAIVE BAYES

We ﬁrst created a multinomial Naive Bayes classiﬁer to
train and test the datasets that were previously collected by
Clich. During the pre-processing, we performed an auto-
mated tagging of 25,278 datasets as sarcastic and 117,842
datasets as non-sarcastic, based on the labels from Clichs
datasets. Then, we randomly selected 70% of the data for
training, and 30% of the data for testing purposes. After
that, we constructed a term frequency-inverse document

frequency (TF-IDF) vector, and then fed it into a multino-
mial Naive Bayes classiﬁer using the ”TﬁdfVectorizer” and
”naive bayes” modules from NLTK toolkit (scikit-learn,
2014). The results are discussed in Section 5.

4.3.2. ONE CLASS SVM

We noticed that the sarcastic data has a lot of ambiguous
sentences. Without the knowledge of the subject of a sen-
tence, we expect it to be non-sarcastic. On the other hand,
the non-sarcastic data sample is clean and clear. Also, we
have around 110,000 non-sarcastic example compared to
25,000 sarcastic example. This motivated us to rely more
on non-sarcastic data. So we decided to use one class SVM
as described in (Sch¨olkoph et al., 2000) and (Manevitz &
Yousef, 2001). Our one class SVM will be trained only on
non-sarcastic data. Hence, we can think of sarcasm detec-
tion as Novelty detection (Sch¨olkoph et al., 2000; scikit-
learn, 2014). This means we are trying to detect sarcasm
by measuring how similar it is to the training set. For one
class SVM, we want to solve the following optimization
problem:

n(cid:88)

ξi − ρ

i=1

i = 1, ..., n

i = 1, ..., n

min
ω,ξ,ρ

1
2

(cid:107)ω(cid:107)2 +

1
νn

subject to :

ω.φ(cid:0)xi

(cid:1) ≥ ρ − ξi;

ρ ≥ 0;

With the decision function being:

f(cid:0)x(cid:1) = sgn(ω.φ(cid:0)xi

(cid:1) − ρ)

(1)

In our implementation, we used a Gaussian kernel with dif-
ferent values of σ.
Therefore, the decision function becomes:

f(cid:0)x(cid:1) = sgn(ω.K(cid:0)xi, x(cid:1) − ρ)

(2)

Where, according to (scikit-learn, 2014), ν represents an
upper bound on the fraction of training errors, and a lower
bound of fraction of support vectors. We implemented one
class SVM with a feature vector formed of unigrams and
bigrams. We discuss the results in section 6.

4.3.3. GAUSSIAN KERNEL

It’s possible that the dataset is not linearly separable and
so using a Gaussian kernel instead of a linear kernel in the
SVM might be a better approach. We use the SVC function
(RBF kernel) from the same Python library scikit-learn. In
addition to the penalty parameter C, there’s the paramter
gamma which deﬁnes how far the inﬂuence of a single
training example reaches. Through repeated trials of vary-
ing both pamaters, we ﬁnd that the values for C and gamma

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

that lead to the best results are 0.6 and 1 respectively. We
also investigate the choices of the features by conducting
leave-one-out of each feature type to see the effect. The
results are discussed in section 5.

5. Results and Discussion
5.1. Naive Bayes

Our Nave Bayes classiﬁer was built and the classiﬁcation
performance was also compared, all using the scikit-learn
package for python. We use the following confusion matrix
to visualize the classiﬁcation accuracy based on the training
data.

Positive

(Predicted)

Negative
(Predicted)

Accuracy

25180

19141

60

99.76%

6137

24.28%

62.02%

Positive
(Actual)
Negative
(Actual)
Overall

Table above shows, of the 25240 patterns that are sar-
castic, 25180 were correctly predicted Sarcastic while 60
were incorrectly predicted as Non-Sarcastic (Accuracy of
99.76%). Similarly, of the 25278 patterns that are non-
sarcastic, 24.28% was reported to be correctly predicted
Non-Sarcastic. The overall accuracy of the classiﬁer for
predicting both classes given this dataset was evaluated
achieving 62.02%.
To avoid the effect of large class imbalance, i.e. model
prediction becomes biased to the majority class for all pre-
dictions and still achieve high classiﬁcation accuracy, the
following additional measures were applied based on the
training data.

Non-Sarcastic

Sarcastic
Overall

Precision Recall
100%
24%
62%

57%
99%
78%

F1 Score

72%
39%
56%

data, so we used a small value of ν = 0.1 (and hence set an
upper bound of 0.1 training error). Our settings produced
a testing accuracy of 90% on non-sarcastic data. How-
ever, only 10% of the sarcastic data was classiﬁer correctly.
Overall, this would translate to 50% classiﬁcation accuracy,
which is not satisfying. We tried to make a tighter bound by
setting ν to 0.01. This resulted in better detection of non-
sarcastic sentences (99%), but with much less detection of
sarcastic sentences (only 0.2%). While these results overall
average to 50%, we are still unable to detect sarcasm. The
results are summarized in the table below.

ν
0.1
0.01
0.5

σ
0.1
0.01
0.5

Accuracy
Total Negative
50%
50%
51%

90%
99%
36%

Positive

10%
0.2%
67%

The main observation is the following: if we detect non-
sarcasm with very high accuracy, we will not be able to
detect any sarcastic example (i.e, our classiﬁer will always
decide that the test example is non-sarcasm). If we relax
the bound on non-sarcasm, the error on positive (sarcas-
tic) examples will slightly decrease, but will signiﬁcantly
increase on negative (non-sarcastic) examples.
As we have formulated our classiﬁcation as a novelty de-
tection problem, it seems that there is very high similar-
ity between sarcasm and non-sarcasm based on our feature
space of unigrams and bigrams. We think that our labeled
data can be visualized as in ﬁgure 2 below, which is a rep-
resentation of a linearly inseparable data. This tells us, that
using only unigrams and bigrams is not useful for detecting
sarcasm. To be able to do so, we have to engineer new fea-
tures that distinguish between sarcasm and non-sarcasm;
i.e. make them separable.

The precision rate in the table above shows that there is
a larger number of false positives (57%) in non-sarcastic
sentences than the sarcastic sentences (99%). Nave Bayes
also classiﬁes more false negatives in sarcastic sentences
than the non-sarcastic ones, as suggested by the reported re-
call values. Using the reported Precision and Recall values,
the classiﬁer demonstrates higher F1 Score in non-sarcastic
sentences than the sarcastic ones.

5.2. One Class SVM

We built a one class SVM using scikit-learn package for
python. We want to set a tight bound on the non-sarcastic

5.3. Gaussian kernel

The leave-one-out approached yielded very similar results
regardless of the feature type that was left out. This sug-
gests that no feature is more important than the other. In
addition, we re-ran the model without sentiment analysis
scores using a Gaussian kernel on the full dataset and ob-
tained a testing accuracy of 82.2% and but a training accu-
racy of over 99%. While it shows signs of the same high
variance error as the baseline model, the Gaussian kernel
approach shows potential for being better than the base-
line. However, it does appear that the baseline approach
achieved better results for smaller sizes of the dataset.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

Chun-Che Peng
Mohammad Lakis
Jan Wei Pan

Abstract

Sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions. Nonetheless, the human compre-
hension system can often spot a sarcastic senti-
ment, and reason about what makes it so. Re-
cent advances in natural language sentence gen-
eration research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases. However, ac-
curacy and robustness of results are often af-
fected by untruthful sentiments that are of sar-
casm nature and this is often left untreated. Sar-
casm detection is a very important process to
ﬁlter out noisy data (in this case, sarcastic sen-
tences) from training data inputs, which can be
used for natural language sentence generation.
In this paper, we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by Mathieu Cliche
of www.thesarcasmdetector.com and improving
upon it. By analyzing the strengths and weak-
nesses of the baseline model, we strive to develop
one that will achieve better results.

1. Introduction
1.1. Motivation

Analysis on social media has attracted much interest in the
research areas of NLP over the past decade (Pt´aˇcek et al.,
2014).
In fact, on June 5, 2014, the BBC reported that
the U.S. Secret Service was looking for a software sys-
tem that could detect sarcasm in social media data (BBC,
2014). Misinterpreting irony and sarcasm represents a big
challenge. However, although sarcasm detection in text is a
daunting task, it is an important chapter in the advancement
of artiﬁcial intelligence.
This paper investigates the possibility of classifying sar-

Writeup for Stanford CS 229 Machine Learning Final Project.
Copyright 2015 by the author(s).

CHUNCHE@STANFORD.EDU
MJLAKIS@STANFORD.EDU
JWPAN@STANFORD.EDU

casm in text reliability and identiﬁes typical textual fea-
tures from Twitter that are important for sarcasm in the pro-
cess. As there is only a weak boundary in meaning between
irony, sarcasm and satire (Reyes et al., 2013), the usage of
the term sarcasm in this paper refers to the general concept.

1.2. Statement of Problem

Sarcasm sentences can be used almost in all topics. They
can take variable grammatical structures. Also, to under-
stand sarcasm, one has to know the context of the sentence.
For instance, the sentence ”I love being rich” is not sarcas-
tic by itself. However, if you know that the speaker is poor,
you will decide that this is a sarcastic sentence. Therefore,
to detect sarcasm, you have to have prior knowledge about
the subject or sarcasm, which might not always be avail-
able. For our approach, we will not attempt to start from
scratch. Rather, we will leverage the work done by Math-
ieu Cliche of www.thesarcasmdetector.com and build upon
it. As a baseline for our project we will replicate some re-
sults from Cliches work. Our goal is to develop a machine
learning algorithm that will achieve better results.
In his work, Cliche gathered tweets from Twitter labeled
with #sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments (i.e. start very
positively but end very negatively). He also adds other fea-
tures such as n-grams and topics. He then trains an SVM
and compares it with other classiﬁcation algorithms such
as Nave Bayes. His results show that using an SVM on
the engineered features yields better results from previous
work (Cliche, 2014).
In the following section, we will conduct error analysis to
pinpoint areas for improvement.

2. Related Works
Sarcasm is a challenging problem in the ﬁeld of sentiment
analysis for a wide range of languages. For example, Lu-
nando and Purwarianti presented their sarcasm detection
classiﬁers, including a Naive Bayes classiﬁer and a Sup-
port Vector Machine, for analyzing Indonesian Social me-
dia, using features of negativity and number of interjec-

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

tion words. Their aim of using negativity feature was to
catch the global sentiment value, and the interjection fea-
ture was to represent the lexical phenomena of the text mes-
sage. Their intents were however challenged, because it
was shown that negativity features were not useful as many
sarcasm texts that they analyzed had no global topic, and
thus making the text topic is not widely known. Also, there
was quite a lot of text with personal message that could
only be analyzed if the reader has prior knowledge about
the context or writer (Lunando & Purwarianti, 2013).
Gathering data to be categorized as sarcastic and non-
sarcastic is a challenge in of itself. Fortunately, Twitter
has proved itself to be a valuable tool for whole variety
of natural language processing investigations. The idea of
using #sarcasm as a way of gathering positive data points
from Twitter is not new as evident by the research done by
(Liebrecht et al., 2013). The authors made use of Balanced
Winnow and achieved an accuracy of 75%.

3. Dataset and Features
3.1. Baseline Model Description

The baseline model uses a support vector machine (SVM)
as implemented by the LinearSVC function from scikit-
learn, a popular open source machine learning library in
Python. Aside from a value of 0.1 for the penalty param-
eter C, all other conﬁguration options are left as default.
Features are extracted from the raw Twitter data to create
training examples that are fed into the SVM to create a hy-
pothesis model. Although much of the machine learning
implemented is already provided by a third party tool, ef-
fort is still necessary for feature engineering.
The tweets were collected over a span of several months
in 2014. The sanitation processed included removing all
the hashtags, non ASCII characters, and http links. In ad-
dition, each tweet is tokenized, stemmed, and uncapital-
ized through the use of the Python NLTK library. For each
tweet, features that are hypothesized to be crucial to sar-
casm detection are extracted. The features fall broadly into
5 categories: n-grams, sentiments, parts of speeches, capi-
talizations, and topics.

3.2. Baseline Features

N-grams: Individual tokens (i.e. unigrams) and bigrams
are placed into a binary feature dictionary. Bigrams are ex-
tracted using the same library and are deﬁned as pairs of
words that typically go together. Examples include artiﬁ-
cial intelligence, peanut butter, etc.
Sentiments: A tweet is broken up into two and three parts.
Sentiment scores are calculated using two libraries (Senti-
WordNet and TextBlob). Positive and negative sentiment

scores are collected for the overall tweet as well as each in-
dividual part. Furthermore, the contrast between the parts
are inserted into the features.
Parts of Speech: The parts of speech in each tweet are
counted and inserted into the features.
Capitalizations: A binary ﬂag indicating whether the tweet
contains at least 4 tokens that start with a capitalization is
inserted into the features.
Topics: The python library gensim which implements topic
modeling using latent Dirichlet allocation (LDA) is used to
learn the topics. The collection of topics for each tweet is
then inserted into the features.

4. Methods and Analysis
4.1. Analysis of Baseline Model

Initial analysis of the baseline model quickly reveals that
the testing error far exceeds the training error. In fact, the
training error is virtually non-existent! A value of 0.1 is
initially used for the penalty parameter C in the SVM. Since
the parameter is a measure of how much one wants to avoid
misclassifying each training example, smaller values of C
(0.01, and 0.001) are then used.

Figure 1. Training and testing error percentages for various values
of the penalty parameter C.

Despite trying different values of C, it appears that the test-
ing error can be improved only slightly. The testing error
remains at around 30%. Nonetheless, the best results are
obtained for C= 0.01. The large gap between training and
testing error suggests that the model is suffering from high
variance.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

4.2. Targeted Areas for Improvement

The high testing error of the model at hand implies that we
are ﬁtting noise. This problem could be caused by the fact
that we have a high dimensional feature space. Another
possibility is that there are features that are not relevant for
detecting sarcasm. In both cases, we think it is important
to reduce the dimension of feature space and use relevant
features. For instance, the beneﬁt of adding some features
such as bigrams, sentiments and topics is not clear. Bi-
grams might have the same effect as unigrams. Also, we
should test whether adding sentiments improves our classi-
ﬁcation by a signiﬁcant factor. While it is true that some
sarcastic sentences have words with negative sentiments
and others with positive sentiments, many other sentences
do not have this property. Thus, adding this feature might
not be useful. Also, non-sarcastic sentences can still have
both positive and negative sentiments. We also think that
ﬁnding the sentiments in each training example takes a lot
of time. For each training example, we have to look for
the sentiment of each word in a dictionary, which takes a
lot of time. We also want to investigate the topics that are
added. Topic modeling using LDA might be returning sim-
ilar words as the unigrams of the training example, and we
might end up getting redundant information. However, we
think that categorizing the training examples into a set of
topics can be useful in a different way than it is used. In-
stead of adding topics as a separate feature, we might split
our classiﬁer to n-classiﬁers, where n is the number of top-
ics in the training set. In other words, we build a classiﬁer
for each topic. Consider for instance the following topics,
soccer and unemployment. Words used in sentences about
soccer are different from those used in sentences about un-
employment. Therefore, the unigrams that are used to de-
tect spam in soccer topic will be very different from the un-
igrams used to detect sarcasm in unemployment. So what
we get is a set of classiﬁers with much lower feature space.
To analyze the classiﬁcation problem that we have, we start
by training a simple Naive Bayes classiﬁer. Based on the
error analysis from this classiﬁer, we tried other classiﬁers
such as one class SVM and a binary SVM with different
features and a non-linear kernel (Gaussian kernel).

4.3. Model Improvement Methods

4.3.1. NAIVE BAYES

We ﬁrst created a multinomial Naive Bayes classiﬁer to
train and test the datasets that were previously collected by
Clich. During the pre-processing, we performed an auto-
mated tagging of 25,278 datasets as sarcastic and 117,842
datasets as non-sarcastic, based on the labels from Clichs
datasets. Then, we randomly selected 70% of the data for
training, and 30% of the data for testing purposes. After
that, we constructed a term frequency-inverse document

frequency (TF-IDF) vector, and then fed it into a multino-
mial Naive Bayes classiﬁer using the ”TﬁdfVectorizer” and
”naive bayes” modules from NLTK toolkit (scikit-learn,
2014). The results are discussed in Section 5.

4.3.2. ONE CLASS SVM

We noticed that the sarcastic data has a lot of ambiguous
sentences. Without the knowledge of the subject of a sen-
tence, we expect it to be non-sarcastic. On the other hand,
the non-sarcastic data sample is clean and clear. Also, we
have around 110,000 non-sarcastic example compared to
25,000 sarcastic example. This motivated us to rely more
on non-sarcastic data. So we decided to use one class SVM
as described in (Sch¨olkoph et al., 2000) and (Manevitz &
Yousef, 2001). Our one class SVM will be trained only on
non-sarcastic data. Hence, we can think of sarcasm detec-
tion as Novelty detection (Sch¨olkoph et al., 2000; scikit-
learn, 2014). This means we are trying to detect sarcasm
by measuring how similar it is to the training set. For one
class SVM, we want to solve the following optimization
problem:

n(cid:88)

ξi − ρ

i=1

i = 1, ..., n

i = 1, ..., n

min
ω,ξ,ρ

1
2

(cid:107)ω(cid:107)2 +

1
νn

subject to :

ω.φ(cid:0)xi

(cid:1) ≥ ρ − ξi;

ρ ≥ 0;

With the decision function being:

f(cid:0)x(cid:1) = sgn(ω.φ(cid:0)xi

(cid:1) − ρ)

(1)

In our implementation, we used a Gaussian kernel with dif-
ferent values of σ.
Therefore, the decision function becomes:

f(cid:0)x(cid:1) = sgn(ω.K(cid:0)xi, x(cid:1) − ρ)

(2)

Where, according to (scikit-learn, 2014), ν represents an
upper bound on the fraction of training errors, and a lower
bound of fraction of support vectors. We implemented one
class SVM with a feature vector formed of unigrams and
bigrams. We discuss the results in section 6.

4.3.3. GAUSSIAN KERNEL

It’s possible that the dataset is not linearly separable and
so using a Gaussian kernel instead of a linear kernel in the
SVM might be a better approach. We use the SVC function
(RBF kernel) from the same Python library scikit-learn. In
addition to the penalty parameter C, there’s the paramter
gamma which deﬁnes how far the inﬂuence of a single
training example reaches. Through repeated trials of vary-
ing both pamaters, we ﬁnd that the values for C and gamma

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

that lead to the best results are 0.6 and 1 respectively. We
also investigate the choices of the features by conducting
leave-one-out of each feature type to see the effect. The
results are discussed in section 5.

5. Results and Discussion
5.1. Naive Bayes

Our Nave Bayes classiﬁer was built and the classiﬁcation
performance was also compared, all using the scikit-learn
package for python. We use the following confusion matrix
to visualize the classiﬁcation accuracy based on the training
data.

Positive

(Predicted)

Negative
(Predicted)

Accuracy

25180

19141

60

99.76%

6137

24.28%

62.02%

Positive
(Actual)
Negative
(Actual)
Overall

Table above shows, of the 25240 patterns that are sar-
castic, 25180 were correctly predicted Sarcastic while 60
were incorrectly predicted as Non-Sarcastic (Accuracy of
99.76%). Similarly, of the 25278 patterns that are non-
sarcastic, 24.28% was reported to be correctly predicted
Non-Sarcastic. The overall accuracy of the classiﬁer for
predicting both classes given this dataset was evaluated
achieving 62.02%.
To avoid the effect of large class imbalance, i.e. model
prediction becomes biased to the majority class for all pre-
dictions and still achieve high classiﬁcation accuracy, the
following additional measures were applied based on the
training data.

Non-Sarcastic

Sarcastic
Overall

Precision Recall
100%
24%
62%

57%
99%
78%

F1 Score

72%
39%
56%

data, so we used a small value of ν = 0.1 (and hence set an
upper bound of 0.1 training error). Our settings produced
a testing accuracy of 90% on non-sarcastic data. How-
ever, only 10% of the sarcastic data was classiﬁer correctly.
Overall, this would translate to 50% classiﬁcation accuracy,
which is not satisfying. We tried to make a tighter bound by
setting ν to 0.01. This resulted in better detection of non-
sarcastic sentences (99%), but with much less detection of
sarcastic sentences (only 0.2%). While these results overall
average to 50%, we are still unable to detect sarcasm. The
results are summarized in the table below.

ν
0.1
0.01
0.5

σ
0.1
0.01
0.5

Accuracy
Total Negative
50%
50%
51%

90%
99%
36%

Positive

10%
0.2%
67%

The main observation is the following: if we detect non-
sarcasm with very high accuracy, we will not be able to
detect any sarcastic example (i.e, our classiﬁer will always
decide that the test example is non-sarcasm). If we relax
the bound on non-sarcasm, the error on positive (sarcas-
tic) examples will slightly decrease, but will signiﬁcantly
increase on negative (non-sarcastic) examples.
As we have formulated our classiﬁcation as a novelty de-
tection problem, it seems that there is very high similar-
ity between sarcasm and non-sarcasm based on our feature
space of unigrams and bigrams. We think that our labeled
data can be visualized as in ﬁgure 2 below, which is a rep-
resentation of a linearly inseparable data. This tells us, that
using only unigrams and bigrams is not useful for detecting
sarcasm. To be able to do so, we have to engineer new fea-
tures that distinguish between sarcasm and non-sarcasm;
i.e. make them separable.

The precision rate in the table above shows that there is
a larger number of false positives (57%) in non-sarcastic
sentences than the sarcastic sentences (99%). Nave Bayes
also classiﬁes more false negatives in sarcastic sentences
than the non-sarcastic ones, as suggested by the reported re-
call values. Using the reported Precision and Recall values,
the classiﬁer demonstrates higher F1 Score in non-sarcastic
sentences than the sarcastic ones.

5.2. One Class SVM

We built a one class SVM using scikit-learn package for
python. We want to set a tight bound on the non-sarcastic

5.3. Gaussian kernel

The leave-one-out approached yielded very similar results
regardless of the feature type that was left out. This sug-
gests that no feature is more important than the other. In
addition, we re-ran the model without sentiment analysis
scores using a Gaussian kernel on the full dataset and ob-
tained a testing accuracy of 82.2% and but a training accu-
racy of over 99%. While it shows signs of the same high
variance error as the baseline model, the Gaussian kernel
approach shows potential for being better than the base-
line. However, it does appear that the baseline approach
achieved better results for smaller sizes of the dataset.

Detecting Sarcasm in Text: An Obvious Solution to a Trivial Problem

References
BBC. Us secret service seeks twitter sarcasm detec-
tor, 2014. URL http://www.bbc.com/news/
technology-27711109.

Cliche, M. The sarcasm detector, 2014. URL http://

www.thesarcasmdetector.com/about/.

Liebrecht, C., Kunneman, F., and van den Bosch, A. The
perfect solution for detecting sarcasm in tweets #not.
In Proceedings of the 4th Workshop on Computational
Approaches to Subjectivity, Sentiment and Social Media
Analysis, pp. 29–37, 2013.

Lunando, E. and Purwarianti, A. Indonesian social media
sentiment analysis with sarcasm detection. In 2013 In-
ternational Conference on Advanced Computer Science
and Information Systems (ICACSIS), 2013.

Manevitz, L. M. and Yousef, M. One-class svms for doc-
ument classiﬁcation. Journal of Machine Learning Re-
search, pp. 139–154, 2001.

Pt´aˇcek, T., Habernal, I., and Hong, J. Sarcasm detection on
czech and english twitter. In The 25th International Con-
ference on Computational Linguistics (COLING 2014),
2014.

Reyes, A., Rosso, P., and Veale, T. A multidimensional
approach for detecting irony in twitter. Language Re-
sources and Evaluation, 47(1):239–268, 2013.

Sch¨olkoph, B., Platt, J. C., Shawe-Taylor, J., Smola, A. J.,
and Williamson, R. C. Estimating the support of a high-
dimensional distribution. Technical report, Microsoft
Research, 2000.

scikit-learn.

Support fector machines, 2014.
http://scikit-learn.org/stable/
modules/svm.html.

URL

Figure 2. A simple visualization of our data

6. Conclusion and Future Work
As mentioned in section 4.1, sarcasm can be found in wide
variety of topics. Therefore, if we want to build a classi-
ﬁer that detects sarcasm in all topics, we need to sample
much larger data. Also, as we saw in section 5.2, the use of
unigrams and bigrams alone is not sufﬁcient. Finding new
features relevant to sarcasm is a critical step for improving
sarcasm detection. More investigation on the binary SVM
is warranted.
The poorer results obtained using Naive Bayes were not
completely unexpected. We expect to see that some sort
of contextual clues (feature types such as sentiment con-
trast, order of words, etc.) to play a big role in the sarcastic
nature of a sentence. As implemented, the Naive Bayes ap-
proach does not take any of that into account. We did ﬁnd
agreement between Naive Bayes and one-class SVM. Both
of them misclassify most of the sarcastic data.
We also see that the accuracy greatly depend on a mixture
of feature types. Unigrams and bigrams alone are insufﬁ-
cient in designing an accurate classiﬁer. When combined
with other types such as topic modeling, the accuracy is
greatly increased.
The importance of feature engineering (relative to simply
obtaining more data points) can’t be over-emphasied. We
believe it is where most of the effort should be placed in
order for sarcasm detection to be successful. In the end, we
found more questions than answers but that in of itself is a
small step in the right direction.

