1  Abstract	  

2 

Introduction	  

Predict	  seizures	  in	  intracranial	  EEG	  recordings	  
Linyu	  He	  (linyu90@stanford.edu)	  and	  Lingbin	  Li	  (lingbin@stanford.edu)	  

	  
This	  project	  aims	  to	  predict	  seizures	  in	  intracranial	  electroencephalography	  (iEEG)	  recordings	  using	  four	  algorithms.	  The	  data	  are	  a	  series	  of	  10-­‐
minute	  iEEG	  clips	  labeled	  “preictal	  (positive)”	  for	  data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Our	  
goal	  is	  to	  distinguish	  between	  the	  two	  states.	  The	  major	  challenge	  is	  that	  the	  data	  are	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  positive	  examples	  is	  less	  
than	  10%	  of	  that	  of	  negative	  examples.	  Our	  work	  is	  to	  make	  modifications	  to	  each	  of	  the	  four	  models	  and	  analyze	  the	  corresponding	  performance	  
gain.	  	  
Spontaneous	  seizures	  are	  the	  typical	  symptom	  of	  epilepsy,	  which	  is	  a	  common	  but	  refractory	  neurological	  disorder	  that	  afflicts	  nearly	  1%	  of	  the	  
world’s	  population.	  Anticonvulsant	  medications	  are	  administered	  to	  many	  patients	  at	  high	  doses	  to	  prevent	  seizures,	  but	  their	  effectiveness	  is	  
limited	  and	  patients	  often	  suffer	  their	  side	  effects.	  Even	  for	  patients	  whose	  epilepsy-­‐causing	  brain	  tissue	  is	  removed	  via	  surgery,	  spontaneous	  
seizures	  still	  persist.	  Due	  to	  the	  seemingly	  unpredictable	  occurrence	  of	  seizures,	  patients	  with	  epilepsy	  experience	  constant	  anxiety	  [1].	  
This	  project	  aims	  to	  make	  it	  possible	  that	  devices	  designed	  to	  monitor	  patients’	  brain	  activity	  can	  warn	  them	  of	  impeding	  seizures	  so	  that	  patients	  
are	  able	  to	  take	  appropriate	  precautions.	  It	  is	  also	  helpful	  to	  reduce	  overall	  side	  effects	  caused	  by	  anticonvulsant	  medications	  taken	  by	  these	  
patients.	  By	  providing	  them	  with	  devices	  with	  the	  ability	  to	  predict	  an	  impending	  seizure,	  anticonvulsant	  medications	  could	  be	  administered	  only	  
when	  necessary,	  thus	  lowering	  the	  doses	  given	  to	  patients.	  
Multiple	  researches	  support	  the	  notion	  that	  the	  occurrence	  of	  seizures	  is	  not	  random.	  According	  to	  evidence	  shown	  by	  related	  researches,	  for	  
patients	  with	  epilepsy,	  the	  temporal	  dynamics	  of	  brain	  activity	  can	  be	  classified	  into	  4	  states:	  interictal	  (between	  seizures),	  preictal	  (prior	  to	  
seizures),	  ictal	  (seizure)	  and	  postictal	  (after	  seizures).	  The	  brain	  activity	  of	  each	  state	  can	  be	  recorded	  by	  iEEG	  [1].	  Our	  goal	  is	  to	  employ	  machine	  
learning	  techniques	  to	  learn	  from	  iEEG	  data	  the	  characteristics	  of	  preictal	  states	  and	  then	  distinguish	  these	  states	  from	  the	  interictal	  states.	  After	  
one	  preictal	  state	  is	  identified,	  a	  warning	  should	  be	  sent	  to	  the	  patient	  to	  prepare	  him	  or	  her	  for	  an	  impending	  seizure.	  
Kaggle	  provides	  iEEG	  data	  collected	  from	  canine	  subjects.	  The	  data	  of	  each	  subject	  is	  organized	  into	  10-­‐minute	  clips	  labeled	  “preictal	  (positive)”	  for	  
data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Each	  clip	  contains	  16	  channels	  of	  iEEG	  data	  where	  
each	  channel	  corresponds	  to	  one	  electrode	  implanted	  in	  the	  subject’s	  brain.	  For	  each	  training	  example	  𝑥(!),𝑦(!),	  𝑦(!)	  is	  the	  label	  and	  𝑥(!)	  is	  a	  clip	  in	  
which	  each	  row	  corresponds	  to	  one	  channel	  and	  each	  column	  corresponds	  to	  iEEG	  readings	  at	  one	  sampling	  time	  point.	  
Since	  seizures	  in	  most	  patients	  are	  associated	  with	  a	  stereotypic	  EEG	  discharge	  with	  characteristic	  spectral	  pattern,	  we	  employed	  the	  following	  
feature	  extraction	  procedure	  [2]:	  
Apply	  fast	  Fourier	  transform	  to	  each	  channel	  in	  a	  clip	  and	  divide	  the	  resulting	  power	  spectrum	  into	  6	  bands:	  delta	  (0.1	  –	  4	  Hz),	  theta	  (4	  –	  8	  Hz),	  
alpha	  (8	  –	  12	  Hz),	  beta	  (12	  –	  30	  Hz),	  low-­‐gamma	  (30	  –	  70	  Hz),	  and	  high-­‐gamma	  (70	  –	  180	  Hz).	  In	  each	  band,	  sum	  the	  power	  over	  all	  band	  
frequencies	  to	  produce	  a	  power-­‐in-­‐band	  (PIB)	  feature.	  Therefore,	  6	  features	  are	  obtained	  in	  each	  channel	  and	  96	  features	  are	  obtained	  in	  one	  clip.	  
The	  procedure	  above	  is	  also	  illustrated	  in	  Fig	  1,	  where	  𝑝(𝑓)	  is	  the	  power	  spectrum.	  
Channel	  1	  
Channel	  2	  
…	  …	  …	  Channel	  16	  
There	  are	  3939	  examples	  in	  total,	  in	  which	  3674	  are	  negative	  and	  265	  are	  positive.	  For	  each	  time	  of	  cross	  validation,	  we	  randomly	  pick	  70%	  of	  the	  
negative	  examples	  and	  70%	  of	  the	  positive	  examples	  for	  training	  and	  use	  the	  rest	  for	  testing.	  This	  process	  is	  repeated	  for	  100	  times	  to	  calculate	  the	  
average	  evaluation.	  
	  
1	  

delta	  (0.1	  –	  4Hz):	  ∑
𝑝(𝑓)
	  
!!!!.!
theta	  (4	  –	  8Hz):	  ∑
𝑝(𝑓)
	  
!!!!
alpha	  (8	  –	  12Hz):	  ∑
	  
𝑝(𝑓)
!"!!!
beta	  (12	  –	  30Hz):	  ∑
	  
𝑝(𝑓)
!"!!!"
low-­‐gamma	  (30	  –	  70Hz):	  ∑
𝑝(𝑓)
	  
!"!!!"
high-­‐gamma	  (70	  –	  180Hz):	  ∑
𝑝(𝑓)
	  
!"#!!!"

Fig.	  1	  Feature	  Extraction	  using	  FFT	  

3  Data	  and	  Feature	  Extraction	  

FFT	  

4  Cross	  Validation	  

1  Abstract	  

2 

Introduction	  

Predict	  seizures	  in	  intracranial	  EEG	  recordings	  
Linyu	  He	  (linyu90@stanford.edu)	  and	  Lingbin	  Li	  (lingbin@stanford.edu)	  

	  
This	  project	  aims	  to	  predict	  seizures	  in	  intracranial	  electroencephalography	  (iEEG)	  recordings	  using	  four	  algorithms.	  The	  data	  are	  a	  series	  of	  10-­‐
minute	  iEEG	  clips	  labeled	  “preictal	  (positive)”	  for	  data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Our	  
goal	  is	  to	  distinguish	  between	  the	  two	  states.	  The	  major	  challenge	  is	  that	  the	  data	  are	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  positive	  examples	  is	  less	  
than	  10%	  of	  that	  of	  negative	  examples.	  Our	  work	  is	  to	  make	  modifications	  to	  each	  of	  the	  four	  models	  and	  analyze	  the	  corresponding	  performance	  
gain.	  	  
Spontaneous	  seizures	  are	  the	  typical	  symptom	  of	  epilepsy,	  which	  is	  a	  common	  but	  refractory	  neurological	  disorder	  that	  afflicts	  nearly	  1%	  of	  the	  
world’s	  population.	  Anticonvulsant	  medications	  are	  administered	  to	  many	  patients	  at	  high	  doses	  to	  prevent	  seizures,	  but	  their	  effectiveness	  is	  
limited	  and	  patients	  often	  suffer	  their	  side	  effects.	  Even	  for	  patients	  whose	  epilepsy-­‐causing	  brain	  tissue	  is	  removed	  via	  surgery,	  spontaneous	  
seizures	  still	  persist.	  Due	  to	  the	  seemingly	  unpredictable	  occurrence	  of	  seizures,	  patients	  with	  epilepsy	  experience	  constant	  anxiety	  [1].	  
This	  project	  aims	  to	  make	  it	  possible	  that	  devices	  designed	  to	  monitor	  patients’	  brain	  activity	  can	  warn	  them	  of	  impeding	  seizures	  so	  that	  patients	  
are	  able	  to	  take	  appropriate	  precautions.	  It	  is	  also	  helpful	  to	  reduce	  overall	  side	  effects	  caused	  by	  anticonvulsant	  medications	  taken	  by	  these	  
patients.	  By	  providing	  them	  with	  devices	  with	  the	  ability	  to	  predict	  an	  impending	  seizure,	  anticonvulsant	  medications	  could	  be	  administered	  only	  
when	  necessary,	  thus	  lowering	  the	  doses	  given	  to	  patients.	  
Multiple	  researches	  support	  the	  notion	  that	  the	  occurrence	  of	  seizures	  is	  not	  random.	  According	  to	  evidence	  shown	  by	  related	  researches,	  for	  
patients	  with	  epilepsy,	  the	  temporal	  dynamics	  of	  brain	  activity	  can	  be	  classified	  into	  4	  states:	  interictal	  (between	  seizures),	  preictal	  (prior	  to	  
seizures),	  ictal	  (seizure)	  and	  postictal	  (after	  seizures).	  The	  brain	  activity	  of	  each	  state	  can	  be	  recorded	  by	  iEEG	  [1].	  Our	  goal	  is	  to	  employ	  machine	  
learning	  techniques	  to	  learn	  from	  iEEG	  data	  the	  characteristics	  of	  preictal	  states	  and	  then	  distinguish	  these	  states	  from	  the	  interictal	  states.	  After	  
one	  preictal	  state	  is	  identified,	  a	  warning	  should	  be	  sent	  to	  the	  patient	  to	  prepare	  him	  or	  her	  for	  an	  impending	  seizure.	  
Kaggle	  provides	  iEEG	  data	  collected	  from	  canine	  subjects.	  The	  data	  of	  each	  subject	  is	  organized	  into	  10-­‐minute	  clips	  labeled	  “preictal	  (positive)”	  for	  
data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Each	  clip	  contains	  16	  channels	  of	  iEEG	  data	  where	  
each	  channel	  corresponds	  to	  one	  electrode	  implanted	  in	  the	  subject’s	  brain.	  For	  each	  training	  example	  𝑥(!),𝑦(!),	  𝑦(!)	  is	  the	  label	  and	  𝑥(!)	  is	  a	  clip	  in	  
which	  each	  row	  corresponds	  to	  one	  channel	  and	  each	  column	  corresponds	  to	  iEEG	  readings	  at	  one	  sampling	  time	  point.	  
Since	  seizures	  in	  most	  patients	  are	  associated	  with	  a	  stereotypic	  EEG	  discharge	  with	  characteristic	  spectral	  pattern,	  we	  employed	  the	  following	  
feature	  extraction	  procedure	  [2]:	  
Apply	  fast	  Fourier	  transform	  to	  each	  channel	  in	  a	  clip	  and	  divide	  the	  resulting	  power	  spectrum	  into	  6	  bands:	  delta	  (0.1	  –	  4	  Hz),	  theta	  (4	  –	  8	  Hz),	  
alpha	  (8	  –	  12	  Hz),	  beta	  (12	  –	  30	  Hz),	  low-­‐gamma	  (30	  –	  70	  Hz),	  and	  high-­‐gamma	  (70	  –	  180	  Hz).	  In	  each	  band,	  sum	  the	  power	  over	  all	  band	  
frequencies	  to	  produce	  a	  power-­‐in-­‐band	  (PIB)	  feature.	  Therefore,	  6	  features	  are	  obtained	  in	  each	  channel	  and	  96	  features	  are	  obtained	  in	  one	  clip.	  
The	  procedure	  above	  is	  also	  illustrated	  in	  Fig	  1,	  where	  𝑝(𝑓)	  is	  the	  power	  spectrum.	  
Channel	  1	  
Channel	  2	  
…	  …	  …	  Channel	  16	  
There	  are	  3939	  examples	  in	  total,	  in	  which	  3674	  are	  negative	  and	  265	  are	  positive.	  For	  each	  time	  of	  cross	  validation,	  we	  randomly	  pick	  70%	  of	  the	  
negative	  examples	  and	  70%	  of	  the	  positive	  examples	  for	  training	  and	  use	  the	  rest	  for	  testing.	  This	  process	  is	  repeated	  for	  100	  times	  to	  calculate	  the	  
average	  evaluation.	  
	  
1	  

delta	  (0.1	  –	  4Hz):	  ∑
𝑝(𝑓)
	  
!!!!.!
theta	  (4	  –	  8Hz):	  ∑
𝑝(𝑓)
	  
!!!!
alpha	  (8	  –	  12Hz):	  ∑
	  
𝑝(𝑓)
!"!!!
beta	  (12	  –	  30Hz):	  ∑
	  
𝑝(𝑓)
!"!!!"
low-­‐gamma	  (30	  –	  70Hz):	  ∑
𝑝(𝑓)
	  
!"!!!"
high-­‐gamma	  (70	  –	  180Hz):	  ∑
𝑝(𝑓)
	  
!"#!!!"

Fig.	  1	  Feature	  Extraction	  using	  FFT	  

3  Data	  and	  Feature	  Extraction	  

FFT	  

4  Cross	  Validation	  

Name	  

Definition	  

5 

Besides	  the	  training	  error	  and	  the	  testing	  error,	  the	  following	  values	  are	  adopted	  to	  evaluate	  the	  performance	  of	  each	  model	  since	  the	  data	  are	  
highly	  imbalanced.	  
	  

Table	  1.	  Values	  chosen	  to	  evaluate	  the	  performance	  

Learning	  Algorithms	  

Accuracy	  (ACC)	  
Positive	  Predictive	  Rate(PPV)/Precision	  
True	  Positive	  Rate	  (TPR)/Recall	  
False	  Negative	  Rate	  (FNR)/Miss	  Rate	  
False	  Positive	  Rate	  (FPR)/Fall-­‐out	  

𝑇𝑃+𝑇𝑁
𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁	  
𝑇𝑃
𝑇𝑃+𝐹𝑃	  
𝑇𝑃
𝑇𝑃+𝐹𝑁	  
𝐹𝑁𝑇𝑃+𝐹𝑁	  
𝐹𝑃
𝐹𝑃+𝑇𝑁	  
	  In	  Table	  1,	  𝑇𝑃,	  𝑇𝑁,	  𝐹𝑃	  and	  𝐹𝑁	  are	  the	  number	  of	  true	  positives,	  true	  negatives,	  false	  positives	  and	  false	  negatives,	  respectively.	  Finally,	  the	  receiver	  
operating	  characteristic	  (ROC)	  curves	  and	  precision-­‐recall	  curves	  will	  be	  plotted	  based	  on	  values	  in	  the	  table	  above.	  
In	  out	  attempt	  to	  seek	  a	  solution,	  three	  models	  covered	  in	  CS	  229	  were	  first	  adopted,	  which	  are	  logistic	  regression,	  naïve	  Bayes	  classifiers	  and	  
support	  vector	  machines	  (SVMs).	  Later,	  we	  employed	  a	  model	  inherited	  from	  communication	  systems,	  which	  makes	  a	  prediction	  based	  on	  
correlation	  coefficients	  between	  the	  test	  example	  and	  all	  training	  examples.	  Modifications	  are	  made	  to	  each	  model	  to	  improve	  their	  performance	  on	  
an	  imbalanced	  data	  set.	  In	  the	  following	  discussion,	  we	  use	  𝑥(!),𝑦(!)	  to	  denote	  each	  training	  example	  where	  𝑥(!)∈𝑅!"	  is	  the	  set	  of	  features	  and	  
𝑦(!)∈ 0,1	  is	  a	  label	  (0	  corresponds	  to	  a	  negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label.	  In	  SVMs,	  𝑦(!)∈ −1,1	  where	  -­‐1	  corresponds	  to	  a	  
negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label).	  We	  use	  𝑋	  to	  denote	  a	  query	  point	  (test	  example)	  and	  𝑌	  to	  denote	  the	  label	  predicted	  by	  a	  
model.	  
!!!!!!!	  where	  𝜃	  is	  the	  parameter.	  The	  probability	  of	  𝑌=1	  conditioned	  on	  𝑋	  and	  parameterized	  by	  
In	  logistic	  regression,	  the	  hypothesis	  is	  ℎ!𝑥 =
!
𝜃	  is	  𝑃𝑌=1|𝑋,𝜃 =ℎ!𝑋.	  
Usually,	  the	  prediction	  that	  𝑌=1	  is	  made	  if	  ℎ!𝑋 ≥0.5.	  Since	  the	  data	  set	  is	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  negative	  examples	  is	  much	  
larger	  than	  that	  of	  positive	  ones,	  we	  consider	  it	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  examples	  than	  to	  have	  a	  few	  false	  positives.	  
Therefore,	  the	  decision	  threshold	  of	  ℎ!𝑋	  can	  be	  less	  than	  0.5,	  which	  makes	  it	  more	  likely	  to	  classify	  a	  test	  example	  as	  positive.	  We	  set	  the	  decision	  
threshold	  to	  be	  𝜂	  where	  𝜂∈  [0,0.5]	  and	  plot	  the	  cross	  validation	  results	  when	  choosing	  different	  values	  of	  𝜂,	  which	  is	  shown	  in	  Fig.	  2.	  

5.1 

Logistic	  Regression	  

Fig.	  2	  The	  relation	  between	  the	  decision	  threshold	  𝜂	  and	  accuracy,	  recall	  and	  precision	  of	  the	  logistic	  regression	  model	  
	  It	  can	  be	  seen	  in	  Fig.	  2	  that	  when	  𝜂=0.5,	  both	  accuracy	  and	  precision	  are	  high,	  but	  the	  recall	  is	  not	  satisfactory.	  When	  𝜂=0,	  we	  achieve	  the	  
maximum	  recall	  but	  the	  accuracy	  and	  precision	  are	  very	  low.	  So	  a	  trade-­‐off	  has	  to	  be	  made	  between	  recall	  and	  precision/accuracy	  by	  choosing	  an	  
appropriate	  value	  of	  𝜂.	  For	  example,	  if	  𝜂=0.04,	  both	  accuracy	  and	  recall	  are	  high	  and	  close	  to	  each	  other,	  meaning	  the	  accuracy	  for	  classifying	  all	  
test	  examples	  and	  the	  one	  for	  classifying	  positive	  test	  examples	  are	  close.	  The	  low	  precision	  when	  𝜂=0.04	  is	  caused	  by	  the	  increased	  number	  of	  
false	  positives,	  which	  is	  acceptable	  to	  some	  extent	  since	  false	  positives	  are	  less	  important	  than	  true	  positives	  in	  seizure	  prediction.	  
	  

2	  

1  Abstract	  

2 

Introduction	  

Predict	  seizures	  in	  intracranial	  EEG	  recordings	  
Linyu	  He	  (linyu90@stanford.edu)	  and	  Lingbin	  Li	  (lingbin@stanford.edu)	  

	  
This	  project	  aims	  to	  predict	  seizures	  in	  intracranial	  electroencephalography	  (iEEG)	  recordings	  using	  four	  algorithms.	  The	  data	  are	  a	  series	  of	  10-­‐
minute	  iEEG	  clips	  labeled	  “preictal	  (positive)”	  for	  data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Our	  
goal	  is	  to	  distinguish	  between	  the	  two	  states.	  The	  major	  challenge	  is	  that	  the	  data	  are	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  positive	  examples	  is	  less	  
than	  10%	  of	  that	  of	  negative	  examples.	  Our	  work	  is	  to	  make	  modifications	  to	  each	  of	  the	  four	  models	  and	  analyze	  the	  corresponding	  performance	  
gain.	  	  
Spontaneous	  seizures	  are	  the	  typical	  symptom	  of	  epilepsy,	  which	  is	  a	  common	  but	  refractory	  neurological	  disorder	  that	  afflicts	  nearly	  1%	  of	  the	  
world’s	  population.	  Anticonvulsant	  medications	  are	  administered	  to	  many	  patients	  at	  high	  doses	  to	  prevent	  seizures,	  but	  their	  effectiveness	  is	  
limited	  and	  patients	  often	  suffer	  their	  side	  effects.	  Even	  for	  patients	  whose	  epilepsy-­‐causing	  brain	  tissue	  is	  removed	  via	  surgery,	  spontaneous	  
seizures	  still	  persist.	  Due	  to	  the	  seemingly	  unpredictable	  occurrence	  of	  seizures,	  patients	  with	  epilepsy	  experience	  constant	  anxiety	  [1].	  
This	  project	  aims	  to	  make	  it	  possible	  that	  devices	  designed	  to	  monitor	  patients’	  brain	  activity	  can	  warn	  them	  of	  impeding	  seizures	  so	  that	  patients	  
are	  able	  to	  take	  appropriate	  precautions.	  It	  is	  also	  helpful	  to	  reduce	  overall	  side	  effects	  caused	  by	  anticonvulsant	  medications	  taken	  by	  these	  
patients.	  By	  providing	  them	  with	  devices	  with	  the	  ability	  to	  predict	  an	  impending	  seizure,	  anticonvulsant	  medications	  could	  be	  administered	  only	  
when	  necessary,	  thus	  lowering	  the	  doses	  given	  to	  patients.	  
Multiple	  researches	  support	  the	  notion	  that	  the	  occurrence	  of	  seizures	  is	  not	  random.	  According	  to	  evidence	  shown	  by	  related	  researches,	  for	  
patients	  with	  epilepsy,	  the	  temporal	  dynamics	  of	  brain	  activity	  can	  be	  classified	  into	  4	  states:	  interictal	  (between	  seizures),	  preictal	  (prior	  to	  
seizures),	  ictal	  (seizure)	  and	  postictal	  (after	  seizures).	  The	  brain	  activity	  of	  each	  state	  can	  be	  recorded	  by	  iEEG	  [1].	  Our	  goal	  is	  to	  employ	  machine	  
learning	  techniques	  to	  learn	  from	  iEEG	  data	  the	  characteristics	  of	  preictal	  states	  and	  then	  distinguish	  these	  states	  from	  the	  interictal	  states.	  After	  
one	  preictal	  state	  is	  identified,	  a	  warning	  should	  be	  sent	  to	  the	  patient	  to	  prepare	  him	  or	  her	  for	  an	  impending	  seizure.	  
Kaggle	  provides	  iEEG	  data	  collected	  from	  canine	  subjects.	  The	  data	  of	  each	  subject	  is	  organized	  into	  10-­‐minute	  clips	  labeled	  “preictal	  (positive)”	  for	  
data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Each	  clip	  contains	  16	  channels	  of	  iEEG	  data	  where	  
each	  channel	  corresponds	  to	  one	  electrode	  implanted	  in	  the	  subject’s	  brain.	  For	  each	  training	  example	  𝑥(!),𝑦(!),	  𝑦(!)	  is	  the	  label	  and	  𝑥(!)	  is	  a	  clip	  in	  
which	  each	  row	  corresponds	  to	  one	  channel	  and	  each	  column	  corresponds	  to	  iEEG	  readings	  at	  one	  sampling	  time	  point.	  
Since	  seizures	  in	  most	  patients	  are	  associated	  with	  a	  stereotypic	  EEG	  discharge	  with	  characteristic	  spectral	  pattern,	  we	  employed	  the	  following	  
feature	  extraction	  procedure	  [2]:	  
Apply	  fast	  Fourier	  transform	  to	  each	  channel	  in	  a	  clip	  and	  divide	  the	  resulting	  power	  spectrum	  into	  6	  bands:	  delta	  (0.1	  –	  4	  Hz),	  theta	  (4	  –	  8	  Hz),	  
alpha	  (8	  –	  12	  Hz),	  beta	  (12	  –	  30	  Hz),	  low-­‐gamma	  (30	  –	  70	  Hz),	  and	  high-­‐gamma	  (70	  –	  180	  Hz).	  In	  each	  band,	  sum	  the	  power	  over	  all	  band	  
frequencies	  to	  produce	  a	  power-­‐in-­‐band	  (PIB)	  feature.	  Therefore,	  6	  features	  are	  obtained	  in	  each	  channel	  and	  96	  features	  are	  obtained	  in	  one	  clip.	  
The	  procedure	  above	  is	  also	  illustrated	  in	  Fig	  1,	  where	  𝑝(𝑓)	  is	  the	  power	  spectrum.	  
Channel	  1	  
Channel	  2	  
…	  …	  …	  Channel	  16	  
There	  are	  3939	  examples	  in	  total,	  in	  which	  3674	  are	  negative	  and	  265	  are	  positive.	  For	  each	  time	  of	  cross	  validation,	  we	  randomly	  pick	  70%	  of	  the	  
negative	  examples	  and	  70%	  of	  the	  positive	  examples	  for	  training	  and	  use	  the	  rest	  for	  testing.	  This	  process	  is	  repeated	  for	  100	  times	  to	  calculate	  the	  
average	  evaluation.	  
	  
1	  

delta	  (0.1	  –	  4Hz):	  ∑
𝑝(𝑓)
	  
!!!!.!
theta	  (4	  –	  8Hz):	  ∑
𝑝(𝑓)
	  
!!!!
alpha	  (8	  –	  12Hz):	  ∑
	  
𝑝(𝑓)
!"!!!
beta	  (12	  –	  30Hz):	  ∑
	  
𝑝(𝑓)
!"!!!"
low-­‐gamma	  (30	  –	  70Hz):	  ∑
𝑝(𝑓)
	  
!"!!!"
high-­‐gamma	  (70	  –	  180Hz):	  ∑
𝑝(𝑓)
	  
!"#!!!"

Fig.	  1	  Feature	  Extraction	  using	  FFT	  

3  Data	  and	  Feature	  Extraction	  

FFT	  

4  Cross	  Validation	  

Name	  

Definition	  

5 

Besides	  the	  training	  error	  and	  the	  testing	  error,	  the	  following	  values	  are	  adopted	  to	  evaluate	  the	  performance	  of	  each	  model	  since	  the	  data	  are	  
highly	  imbalanced.	  
	  

Table	  1.	  Values	  chosen	  to	  evaluate	  the	  performance	  

Learning	  Algorithms	  

Accuracy	  (ACC)	  
Positive	  Predictive	  Rate(PPV)/Precision	  
True	  Positive	  Rate	  (TPR)/Recall	  
False	  Negative	  Rate	  (FNR)/Miss	  Rate	  
False	  Positive	  Rate	  (FPR)/Fall-­‐out	  

𝑇𝑃+𝑇𝑁
𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁	  
𝑇𝑃
𝑇𝑃+𝐹𝑃	  
𝑇𝑃
𝑇𝑃+𝐹𝑁	  
𝐹𝑁𝑇𝑃+𝐹𝑁	  
𝐹𝑃
𝐹𝑃+𝑇𝑁	  
	  In	  Table	  1,	  𝑇𝑃,	  𝑇𝑁,	  𝐹𝑃	  and	  𝐹𝑁	  are	  the	  number	  of	  true	  positives,	  true	  negatives,	  false	  positives	  and	  false	  negatives,	  respectively.	  Finally,	  the	  receiver	  
operating	  characteristic	  (ROC)	  curves	  and	  precision-­‐recall	  curves	  will	  be	  plotted	  based	  on	  values	  in	  the	  table	  above.	  
In	  out	  attempt	  to	  seek	  a	  solution,	  three	  models	  covered	  in	  CS	  229	  were	  first	  adopted,	  which	  are	  logistic	  regression,	  naïve	  Bayes	  classifiers	  and	  
support	  vector	  machines	  (SVMs).	  Later,	  we	  employed	  a	  model	  inherited	  from	  communication	  systems,	  which	  makes	  a	  prediction	  based	  on	  
correlation	  coefficients	  between	  the	  test	  example	  and	  all	  training	  examples.	  Modifications	  are	  made	  to	  each	  model	  to	  improve	  their	  performance	  on	  
an	  imbalanced	  data	  set.	  In	  the	  following	  discussion,	  we	  use	  𝑥(!),𝑦(!)	  to	  denote	  each	  training	  example	  where	  𝑥(!)∈𝑅!"	  is	  the	  set	  of	  features	  and	  
𝑦(!)∈ 0,1	  is	  a	  label	  (0	  corresponds	  to	  a	  negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label.	  In	  SVMs,	  𝑦(!)∈ −1,1	  where	  -­‐1	  corresponds	  to	  a	  
negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label).	  We	  use	  𝑋	  to	  denote	  a	  query	  point	  (test	  example)	  and	  𝑌	  to	  denote	  the	  label	  predicted	  by	  a	  
model.	  
!!!!!!!	  where	  𝜃	  is	  the	  parameter.	  The	  probability	  of	  𝑌=1	  conditioned	  on	  𝑋	  and	  parameterized	  by	  
In	  logistic	  regression,	  the	  hypothesis	  is	  ℎ!𝑥 =
!
𝜃	  is	  𝑃𝑌=1|𝑋,𝜃 =ℎ!𝑋.	  
Usually,	  the	  prediction	  that	  𝑌=1	  is	  made	  if	  ℎ!𝑋 ≥0.5.	  Since	  the	  data	  set	  is	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  negative	  examples	  is	  much	  
larger	  than	  that	  of	  positive	  ones,	  we	  consider	  it	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  examples	  than	  to	  have	  a	  few	  false	  positives.	  
Therefore,	  the	  decision	  threshold	  of	  ℎ!𝑋	  can	  be	  less	  than	  0.5,	  which	  makes	  it	  more	  likely	  to	  classify	  a	  test	  example	  as	  positive.	  We	  set	  the	  decision	  
threshold	  to	  be	  𝜂	  where	  𝜂∈  [0,0.5]	  and	  plot	  the	  cross	  validation	  results	  when	  choosing	  different	  values	  of	  𝜂,	  which	  is	  shown	  in	  Fig.	  2.	  

5.1 

Logistic	  Regression	  

Fig.	  2	  The	  relation	  between	  the	  decision	  threshold	  𝜂	  and	  accuracy,	  recall	  and	  precision	  of	  the	  logistic	  regression	  model	  
	  It	  can	  be	  seen	  in	  Fig.	  2	  that	  when	  𝜂=0.5,	  both	  accuracy	  and	  precision	  are	  high,	  but	  the	  recall	  is	  not	  satisfactory.	  When	  𝜂=0,	  we	  achieve	  the	  
maximum	  recall	  but	  the	  accuracy	  and	  precision	  are	  very	  low.	  So	  a	  trade-­‐off	  has	  to	  be	  made	  between	  recall	  and	  precision/accuracy	  by	  choosing	  an	  
appropriate	  value	  of	  𝜂.	  For	  example,	  if	  𝜂=0.04,	  both	  accuracy	  and	  recall	  are	  high	  and	  close	  to	  each	  other,	  meaning	  the	  accuracy	  for	  classifying	  all	  
test	  examples	  and	  the	  one	  for	  classifying	  positive	  test	  examples	  are	  close.	  The	  low	  precision	  when	  𝜂=0.04	  is	  caused	  by	  the	  increased	  number	  of	  
false	  positives,	  which	  is	  acceptable	  to	  some	  extent	  since	  false	  positives	  are	  less	  important	  than	  true	  positives	  in	  seizure	  prediction.	  
	  

2	  

5.2 

Naïve	  Bayes	  

The	  multinomial	  distribution	  is	  used	  to	  model	  the	  features	  of	  each	  iEEG	  clip.	  Since	  the	  value	  of	  each	  feature	  is	  continuous,	  we	  first	  discretize	  the	  
values	  into	  𝑁	  groups	  where	  𝑁=!!"#! ,	  𝑉!"#	  is	  the	  maximum	  value	  of	  the	  features	  of	  all	  clips	  and	  𝐺	  is	  the	  group	  size.	  Similar	  to	  the	  modification	  made	  
to	  logistic	  regression,	  a	  test	  example	  is	  labeled	  “1”	  if	  𝑄𝑃𝑌=1|𝑋 ≥𝑃𝑌=0|𝑋	  where	  𝑄	  is	  a	  positive	  constant	  specified	  to	  overcome	  the	  
imbalanced	  data	  when	  making	  predictions.	  Fig.	  3	  indicates	  that	  the	  naïve	  Bayesian	  model	  cannot	  make	  satisfactory	  predictions	  no	  matter	  what	  the	  
value	  of	  𝑄	  is.	  

Fig.	  3	  The	  relation	  between	  𝑄	  and	  accuracy,	  recall	  and	  precision	  of	  the	  naïve	  Bayesian	  model	  	  

5.3 

Support	  Vector	  Machine	  (SVM)	  

In	  the	  𝑙!-­‐regularized	  SVM,	  the	  hypothesis	  is	  ℎ!,!𝑥 =𝑤!𝑥+𝑏	  where	  parameters	  𝑤	  and	  𝑏	  are	  obtained	  by	  solving	  the	  primal	  optimization	  problem	  
whose	  objective	  is	  min!,!!! 𝑤 !+𝐶
	  is	  the	  cost	  term.	  Since	  it	  is	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  
examples	  than	  to	  have	  a	  few	  false	  positives,	  the	  2-­‐cost-­‐sensitive	  SVM	  (2C-­‐SVM)	  [3]	  is	  adopted	  in	  which	  two	  different	  costs	  are	  assigned	  to	  negative	  
and	  positive	  examples,	  respectively.	  In	  2C-­‐SVM,	  the	  objective	  of	  the	  primal	  optimization	  problem	  is	  min!,!!! 𝑤 !+𝐶!
	  where	  
𝐶=𝐶!+𝐶!	  is	  a	  trade	  off	  between	  the	  classification	  margin	  and	  misclassified	  or	  non-­‐separable	  examples	  and	  the	  cost	  factor	  𝑅=!!!!	  is	  the	  ratio	  of	  
costs	  between	  positive	  and	  negative	  examples.	  We	  employ	  the	  LIBSVM	  library	  [4]	  as	  our	  2C-­‐SVM	  implementation.	  

𝜉!
!∈!! +𝐶!

,	  where	  𝐶

𝜉!!!!!

𝜉!!!!!

𝜉!

!∈!!

Fig.	  4	  The	  relation	  between	  𝐶,	  𝑅	  and	  accuracy,	  recall	  and	  precision	  of	  the	  2C-­‐SVM	  model	  

	  Different	  values	  of	  𝐶>0	  and	  𝑅≥1	  are	  chosen	  and	  the	  corresponding	  results	  of	  accuracy,	  recall	  and	  precision	  are	  shown	  in	  Fig.	  4.	  Satisfactory	  
accuracy	  and	  recall	  can	  be	  achieved	  when	  (𝐶,𝑅)	  is	  chosen	  as	  10!!,10!,	  10!!,10!	  or	  10!!,10!,	  etc.	  
We	  derived	  the	  correlation	  decision	  model	  from	  a	  few	  concepts	  in	  communication	  systems.	  The	  previous	  three	  models	  discard	  the	  training	  set	  after	  
a	  hypothesis	  is	  built.	  However,	  in	  correlation	  decision,	  we	  do	  not	  use	  training	  examples	  to	  build	  a	  hypothesis	  and	  we	  keep	  the	  entire	  training	  set.	  

Correlation	  Decision	  

5.4 

	  

	  

3	  

1  Abstract	  

2 

Introduction	  

Predict	  seizures	  in	  intracranial	  EEG	  recordings	  
Linyu	  He	  (linyu90@stanford.edu)	  and	  Lingbin	  Li	  (lingbin@stanford.edu)	  

	  
This	  project	  aims	  to	  predict	  seizures	  in	  intracranial	  electroencephalography	  (iEEG)	  recordings	  using	  four	  algorithms.	  The	  data	  are	  a	  series	  of	  10-­‐
minute	  iEEG	  clips	  labeled	  “preictal	  (positive)”	  for	  data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Our	  
goal	  is	  to	  distinguish	  between	  the	  two	  states.	  The	  major	  challenge	  is	  that	  the	  data	  are	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  positive	  examples	  is	  less	  
than	  10%	  of	  that	  of	  negative	  examples.	  Our	  work	  is	  to	  make	  modifications	  to	  each	  of	  the	  four	  models	  and	  analyze	  the	  corresponding	  performance	  
gain.	  	  
Spontaneous	  seizures	  are	  the	  typical	  symptom	  of	  epilepsy,	  which	  is	  a	  common	  but	  refractory	  neurological	  disorder	  that	  afflicts	  nearly	  1%	  of	  the	  
world’s	  population.	  Anticonvulsant	  medications	  are	  administered	  to	  many	  patients	  at	  high	  doses	  to	  prevent	  seizures,	  but	  their	  effectiveness	  is	  
limited	  and	  patients	  often	  suffer	  their	  side	  effects.	  Even	  for	  patients	  whose	  epilepsy-­‐causing	  brain	  tissue	  is	  removed	  via	  surgery,	  spontaneous	  
seizures	  still	  persist.	  Due	  to	  the	  seemingly	  unpredictable	  occurrence	  of	  seizures,	  patients	  with	  epilepsy	  experience	  constant	  anxiety	  [1].	  
This	  project	  aims	  to	  make	  it	  possible	  that	  devices	  designed	  to	  monitor	  patients’	  brain	  activity	  can	  warn	  them	  of	  impeding	  seizures	  so	  that	  patients	  
are	  able	  to	  take	  appropriate	  precautions.	  It	  is	  also	  helpful	  to	  reduce	  overall	  side	  effects	  caused	  by	  anticonvulsant	  medications	  taken	  by	  these	  
patients.	  By	  providing	  them	  with	  devices	  with	  the	  ability	  to	  predict	  an	  impending	  seizure,	  anticonvulsant	  medications	  could	  be	  administered	  only	  
when	  necessary,	  thus	  lowering	  the	  doses	  given	  to	  patients.	  
Multiple	  researches	  support	  the	  notion	  that	  the	  occurrence	  of	  seizures	  is	  not	  random.	  According	  to	  evidence	  shown	  by	  related	  researches,	  for	  
patients	  with	  epilepsy,	  the	  temporal	  dynamics	  of	  brain	  activity	  can	  be	  classified	  into	  4	  states:	  interictal	  (between	  seizures),	  preictal	  (prior	  to	  
seizures),	  ictal	  (seizure)	  and	  postictal	  (after	  seizures).	  The	  brain	  activity	  of	  each	  state	  can	  be	  recorded	  by	  iEEG	  [1].	  Our	  goal	  is	  to	  employ	  machine	  
learning	  techniques	  to	  learn	  from	  iEEG	  data	  the	  characteristics	  of	  preictal	  states	  and	  then	  distinguish	  these	  states	  from	  the	  interictal	  states.	  After	  
one	  preictal	  state	  is	  identified,	  a	  warning	  should	  be	  sent	  to	  the	  patient	  to	  prepare	  him	  or	  her	  for	  an	  impending	  seizure.	  
Kaggle	  provides	  iEEG	  data	  collected	  from	  canine	  subjects.	  The	  data	  of	  each	  subject	  is	  organized	  into	  10-­‐minute	  clips	  labeled	  “preictal	  (positive)”	  for	  
data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Each	  clip	  contains	  16	  channels	  of	  iEEG	  data	  where	  
each	  channel	  corresponds	  to	  one	  electrode	  implanted	  in	  the	  subject’s	  brain.	  For	  each	  training	  example	  𝑥(!),𝑦(!),	  𝑦(!)	  is	  the	  label	  and	  𝑥(!)	  is	  a	  clip	  in	  
which	  each	  row	  corresponds	  to	  one	  channel	  and	  each	  column	  corresponds	  to	  iEEG	  readings	  at	  one	  sampling	  time	  point.	  
Since	  seizures	  in	  most	  patients	  are	  associated	  with	  a	  stereotypic	  EEG	  discharge	  with	  characteristic	  spectral	  pattern,	  we	  employed	  the	  following	  
feature	  extraction	  procedure	  [2]:	  
Apply	  fast	  Fourier	  transform	  to	  each	  channel	  in	  a	  clip	  and	  divide	  the	  resulting	  power	  spectrum	  into	  6	  bands:	  delta	  (0.1	  –	  4	  Hz),	  theta	  (4	  –	  8	  Hz),	  
alpha	  (8	  –	  12	  Hz),	  beta	  (12	  –	  30	  Hz),	  low-­‐gamma	  (30	  –	  70	  Hz),	  and	  high-­‐gamma	  (70	  –	  180	  Hz).	  In	  each	  band,	  sum	  the	  power	  over	  all	  band	  
frequencies	  to	  produce	  a	  power-­‐in-­‐band	  (PIB)	  feature.	  Therefore,	  6	  features	  are	  obtained	  in	  each	  channel	  and	  96	  features	  are	  obtained	  in	  one	  clip.	  
The	  procedure	  above	  is	  also	  illustrated	  in	  Fig	  1,	  where	  𝑝(𝑓)	  is	  the	  power	  spectrum.	  
Channel	  1	  
Channel	  2	  
…	  …	  …	  Channel	  16	  
There	  are	  3939	  examples	  in	  total,	  in	  which	  3674	  are	  negative	  and	  265	  are	  positive.	  For	  each	  time	  of	  cross	  validation,	  we	  randomly	  pick	  70%	  of	  the	  
negative	  examples	  and	  70%	  of	  the	  positive	  examples	  for	  training	  and	  use	  the	  rest	  for	  testing.	  This	  process	  is	  repeated	  for	  100	  times	  to	  calculate	  the	  
average	  evaluation.	  
	  
1	  

delta	  (0.1	  –	  4Hz):	  ∑
𝑝(𝑓)
	  
!!!!.!
theta	  (4	  –	  8Hz):	  ∑
𝑝(𝑓)
	  
!!!!
alpha	  (8	  –	  12Hz):	  ∑
	  
𝑝(𝑓)
!"!!!
beta	  (12	  –	  30Hz):	  ∑
	  
𝑝(𝑓)
!"!!!"
low-­‐gamma	  (30	  –	  70Hz):	  ∑
𝑝(𝑓)
	  
!"!!!"
high-­‐gamma	  (70	  –	  180Hz):	  ∑
𝑝(𝑓)
	  
!"#!!!"

Fig.	  1	  Feature	  Extraction	  using	  FFT	  

3  Data	  and	  Feature	  Extraction	  

FFT	  

4  Cross	  Validation	  

Name	  

Definition	  

5 

Besides	  the	  training	  error	  and	  the	  testing	  error,	  the	  following	  values	  are	  adopted	  to	  evaluate	  the	  performance	  of	  each	  model	  since	  the	  data	  are	  
highly	  imbalanced.	  
	  

Table	  1.	  Values	  chosen	  to	  evaluate	  the	  performance	  

Learning	  Algorithms	  

Accuracy	  (ACC)	  
Positive	  Predictive	  Rate(PPV)/Precision	  
True	  Positive	  Rate	  (TPR)/Recall	  
False	  Negative	  Rate	  (FNR)/Miss	  Rate	  
False	  Positive	  Rate	  (FPR)/Fall-­‐out	  

𝑇𝑃+𝑇𝑁
𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁	  
𝑇𝑃
𝑇𝑃+𝐹𝑃	  
𝑇𝑃
𝑇𝑃+𝐹𝑁	  
𝐹𝑁𝑇𝑃+𝐹𝑁	  
𝐹𝑃
𝐹𝑃+𝑇𝑁	  
	  In	  Table	  1,	  𝑇𝑃,	  𝑇𝑁,	  𝐹𝑃	  and	  𝐹𝑁	  are	  the	  number	  of	  true	  positives,	  true	  negatives,	  false	  positives	  and	  false	  negatives,	  respectively.	  Finally,	  the	  receiver	  
operating	  characteristic	  (ROC)	  curves	  and	  precision-­‐recall	  curves	  will	  be	  plotted	  based	  on	  values	  in	  the	  table	  above.	  
In	  out	  attempt	  to	  seek	  a	  solution,	  three	  models	  covered	  in	  CS	  229	  were	  first	  adopted,	  which	  are	  logistic	  regression,	  naïve	  Bayes	  classifiers	  and	  
support	  vector	  machines	  (SVMs).	  Later,	  we	  employed	  a	  model	  inherited	  from	  communication	  systems,	  which	  makes	  a	  prediction	  based	  on	  
correlation	  coefficients	  between	  the	  test	  example	  and	  all	  training	  examples.	  Modifications	  are	  made	  to	  each	  model	  to	  improve	  their	  performance	  on	  
an	  imbalanced	  data	  set.	  In	  the	  following	  discussion,	  we	  use	  𝑥(!),𝑦(!)	  to	  denote	  each	  training	  example	  where	  𝑥(!)∈𝑅!"	  is	  the	  set	  of	  features	  and	  
𝑦(!)∈ 0,1	  is	  a	  label	  (0	  corresponds	  to	  a	  negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label.	  In	  SVMs,	  𝑦(!)∈ −1,1	  where	  -­‐1	  corresponds	  to	  a	  
negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label).	  We	  use	  𝑋	  to	  denote	  a	  query	  point	  (test	  example)	  and	  𝑌	  to	  denote	  the	  label	  predicted	  by	  a	  
model.	  
!!!!!!!	  where	  𝜃	  is	  the	  parameter.	  The	  probability	  of	  𝑌=1	  conditioned	  on	  𝑋	  and	  parameterized	  by	  
In	  logistic	  regression,	  the	  hypothesis	  is	  ℎ!𝑥 =
!
𝜃	  is	  𝑃𝑌=1|𝑋,𝜃 =ℎ!𝑋.	  
Usually,	  the	  prediction	  that	  𝑌=1	  is	  made	  if	  ℎ!𝑋 ≥0.5.	  Since	  the	  data	  set	  is	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  negative	  examples	  is	  much	  
larger	  than	  that	  of	  positive	  ones,	  we	  consider	  it	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  examples	  than	  to	  have	  a	  few	  false	  positives.	  
Therefore,	  the	  decision	  threshold	  of	  ℎ!𝑋	  can	  be	  less	  than	  0.5,	  which	  makes	  it	  more	  likely	  to	  classify	  a	  test	  example	  as	  positive.	  We	  set	  the	  decision	  
threshold	  to	  be	  𝜂	  where	  𝜂∈  [0,0.5]	  and	  plot	  the	  cross	  validation	  results	  when	  choosing	  different	  values	  of	  𝜂,	  which	  is	  shown	  in	  Fig.	  2.	  

5.1 

Logistic	  Regression	  

Fig.	  2	  The	  relation	  between	  the	  decision	  threshold	  𝜂	  and	  accuracy,	  recall	  and	  precision	  of	  the	  logistic	  regression	  model	  
	  It	  can	  be	  seen	  in	  Fig.	  2	  that	  when	  𝜂=0.5,	  both	  accuracy	  and	  precision	  are	  high,	  but	  the	  recall	  is	  not	  satisfactory.	  When	  𝜂=0,	  we	  achieve	  the	  
maximum	  recall	  but	  the	  accuracy	  and	  precision	  are	  very	  low.	  So	  a	  trade-­‐off	  has	  to	  be	  made	  between	  recall	  and	  precision/accuracy	  by	  choosing	  an	  
appropriate	  value	  of	  𝜂.	  For	  example,	  if	  𝜂=0.04,	  both	  accuracy	  and	  recall	  are	  high	  and	  close	  to	  each	  other,	  meaning	  the	  accuracy	  for	  classifying	  all	  
test	  examples	  and	  the	  one	  for	  classifying	  positive	  test	  examples	  are	  close.	  The	  low	  precision	  when	  𝜂=0.04	  is	  caused	  by	  the	  increased	  number	  of	  
false	  positives,	  which	  is	  acceptable	  to	  some	  extent	  since	  false	  positives	  are	  less	  important	  than	  true	  positives	  in	  seizure	  prediction.	  
	  

2	  

5.2 

Naïve	  Bayes	  

The	  multinomial	  distribution	  is	  used	  to	  model	  the	  features	  of	  each	  iEEG	  clip.	  Since	  the	  value	  of	  each	  feature	  is	  continuous,	  we	  first	  discretize	  the	  
values	  into	  𝑁	  groups	  where	  𝑁=!!"#! ,	  𝑉!"#	  is	  the	  maximum	  value	  of	  the	  features	  of	  all	  clips	  and	  𝐺	  is	  the	  group	  size.	  Similar	  to	  the	  modification	  made	  
to	  logistic	  regression,	  a	  test	  example	  is	  labeled	  “1”	  if	  𝑄𝑃𝑌=1|𝑋 ≥𝑃𝑌=0|𝑋	  where	  𝑄	  is	  a	  positive	  constant	  specified	  to	  overcome	  the	  
imbalanced	  data	  when	  making	  predictions.	  Fig.	  3	  indicates	  that	  the	  naïve	  Bayesian	  model	  cannot	  make	  satisfactory	  predictions	  no	  matter	  what	  the	  
value	  of	  𝑄	  is.	  

Fig.	  3	  The	  relation	  between	  𝑄	  and	  accuracy,	  recall	  and	  precision	  of	  the	  naïve	  Bayesian	  model	  	  

5.3 

Support	  Vector	  Machine	  (SVM)	  

In	  the	  𝑙!-­‐regularized	  SVM,	  the	  hypothesis	  is	  ℎ!,!𝑥 =𝑤!𝑥+𝑏	  where	  parameters	  𝑤	  and	  𝑏	  are	  obtained	  by	  solving	  the	  primal	  optimization	  problem	  
whose	  objective	  is	  min!,!!! 𝑤 !+𝐶
	  is	  the	  cost	  term.	  Since	  it	  is	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  
examples	  than	  to	  have	  a	  few	  false	  positives,	  the	  2-­‐cost-­‐sensitive	  SVM	  (2C-­‐SVM)	  [3]	  is	  adopted	  in	  which	  two	  different	  costs	  are	  assigned	  to	  negative	  
and	  positive	  examples,	  respectively.	  In	  2C-­‐SVM,	  the	  objective	  of	  the	  primal	  optimization	  problem	  is	  min!,!!! 𝑤 !+𝐶!
	  where	  
𝐶=𝐶!+𝐶!	  is	  a	  trade	  off	  between	  the	  classification	  margin	  and	  misclassified	  or	  non-­‐separable	  examples	  and	  the	  cost	  factor	  𝑅=!!!!	  is	  the	  ratio	  of	  
costs	  between	  positive	  and	  negative	  examples.	  We	  employ	  the	  LIBSVM	  library	  [4]	  as	  our	  2C-­‐SVM	  implementation.	  

𝜉!
!∈!! +𝐶!

,	  where	  𝐶

𝜉!!!!!

𝜉!!!!!

𝜉!

!∈!!

Fig.	  4	  The	  relation	  between	  𝐶,	  𝑅	  and	  accuracy,	  recall	  and	  precision	  of	  the	  2C-­‐SVM	  model	  

	  Different	  values	  of	  𝐶>0	  and	  𝑅≥1	  are	  chosen	  and	  the	  corresponding	  results	  of	  accuracy,	  recall	  and	  precision	  are	  shown	  in	  Fig.	  4.	  Satisfactory	  
accuracy	  and	  recall	  can	  be	  achieved	  when	  (𝐶,𝑅)	  is	  chosen	  as	  10!!,10!,	  10!!,10!	  or	  10!!,10!,	  etc.	  
We	  derived	  the	  correlation	  decision	  model	  from	  a	  few	  concepts	  in	  communication	  systems.	  The	  previous	  three	  models	  discard	  the	  training	  set	  after	  
a	  hypothesis	  is	  built.	  However,	  in	  correlation	  decision,	  we	  do	  not	  use	  training	  examples	  to	  build	  a	  hypothesis	  and	  we	  keep	  the	  entire	  training	  set.	  

Correlation	  Decision	  

5.4 

	  

	  

3	  

Consider	   a	   given	   query	   point	  𝑋.	   Calculate	  
its	   correlation	   with	   each	   training	   example	   and	   assign	   a	   score	   to	   each	   of	   them:	  
𝑆𝑐𝑜𝑟𝑒𝑖 =𝑐𝑜𝑟𝑟𝑋,𝑋(!),∀𝑖=1,2…  𝑚.	  Find	  the	  training	  example	  with	  the	  maximum	  score:	  𝑖∗=𝑎𝑟𝑔𝑚𝑎𝑥  𝑆𝑐𝑜𝑟𝑒  (𝑖).	  Since	  𝑋(!∗)	  is	  the	  training	  
example	  that	  the	  query	  point	  is	  most	  similar	  to,	  we	  can	  make	  a	  prediction	  that	  𝑌=𝑌(!∗).	  
In	  order	  to	  classify	  more	  positive	  examples	  correctly,	  in	  other	  words,	  to	  output	  more	  positives,	  we	  increase	  the	  scores	  for	  positive	  training	  
examples	  by	  a	  factor	  𝛾≥0,	  namely,	  𝑆𝑐𝑜𝑟𝑒∶=  𝑆𝑐𝑜𝑟𝑒×(1+𝛾)	  for	  all	  positive	  training	  examples.	  	  

ACC	  

Recall	  

5.5 

Others	  

0.5η=
0.04
η=

Decision	  	  
Parameters	  

6  Results	  and	  Discussion	  

Fig.	  5	  The	  relation	  between	  𝛾	  and	  accuracy,	  recall	  and	  precision	  of	  the	  correlation	  decision	  model	  	  
We	  also	  tried	  extracting	  features	  using	  PCA	  and	  ICA,	  using	  different	  kernels	  (such	  as	  the	  Gaussian	  kernel	  and	  the	  sigmoid	  kernel)	  in	  SVMs,	  and	  
capturing	  non-­‐linear	  behaviors	  of	  features	  (such	  as	  log𝑥,	   𝑥	  and	  𝑥!).	  But	  we	  didn’t	  achieve	  improvement	  in	  performance.	  
Table	  2	  shows	  the	  results	  of	  the	  models	  discussed	  above,	  where	  for	  each	  model,	  the	  results	  before	  and	  after	  our	  modification	  to	  these	  models	  are	  
compared.	  For	  each	  modified	  model	  except	  naïve	  Bayes,	  the	  decision	  parameters	  that	  achieve	  an	  acceptable	  performance	  are	  shown.	  Among	  all	  
chosen	  models,	  logistic	  regression	  with	  a	  threshold	  of	  0.04	  works	  best,	  in	  whose	  results	  both	  accuracy	  and	  recall	  are	  close	  to	  90%.	  
	  
67%	  
34%	  
NAN	  
8%	  
55%	  
24%	  
66%	  
28%	  

Logistic	  Regression	  
Naïve	  Bayes	  
2C-­‐SVM	  
Correlation	  Decision	  
	  Fig.	  6	  shows	  the	  ROC	  curve	  and	  the	  precision-­‐recall	  curve	  of	  each	  model.	  The	  area	  under	  curve	  (AUC)	  is	  calculated	  by	  using	  the	  trapezoidal	  areas	  
created	  between	  each	  point	  [5].	  It	  can	  be	  seen	  that	  logistic	  regression	  outperforms	  others	  since	  its	  AUCs	  for	  ROC	  and	  precision-­‐recall	  curves	  are	  the	  
highest.	  	  Correlation	  decision	  model	  also	  provides	  high	  AUCs	  for	  both	  kinds	  of	  curves,	  which	  indicates	  its	  performance	  is	  close	  to	  that	  of	  logistic	  
regression.	  	  
Seizure	  prediction	  is	  usually	  performed	  in	  real	  time.	  Table	  3	  gives	  the	  comparison	  of	  average	  runtime	  for	  different	  models.	  The	  test	  is	  performed	  on	  
the	  same	  PC	  with	  a	  2.2GHz	  CPU.	  It	  can	  be	  seen	  that	  logistic	  regression	  consumes	  the	  least	  time.	  Since	  it	  also	  has	  the	  highest	  prediction	  performance,	  
it	  is	  the	  most	  cost-­‐efficient	  algorithm	  in	  this	  situation.	  Although	  the	  performance	  of	  the	  correlation	  decision	  model	  is	  as	  good	  as	  that	  of	  logistic	  
	  
4	  

	  
1Q = 	  
Linear	  
Kernel;	  
1C = 	  
1R = 	  
Linear	  
Kernel;	  
	  
	  
0γ = 	  

96%	  
88%	  
93%	  
53%	  
94%	  
80%	  
95%	  
85%	  

71%	  
88%	  
0	  
54%	  
67%	  
85%	  
62%	  
85%	  

Precision	  

FPR	  

FNR	  

Error	  

Training	  	  

Test	  	  
Error	  

Table	  2.	  Performance	  results	  of	  different	  models	  
0.0262	  
0.0046	  
0.0567	  
0.1257	  
0	  
0.0685	  
0.1993	  
0.4697	  
0.0018	  
0.0412	  
0.2034	  
0.0387	  
0.0244	  
-­‐	  
0.1521	  
-­‐	  

0.0443	  
0.1255	  
0.0691	  
0.4688	  
0.0610	  
0.1994	  
0.0489	  
0.1502	  

0.2871	  
0.1232	  
1	  
0.4565	  
0.3273	  
0.1453	  
0.3780	  
0.1341	  

7010Q =

C
=
R =

−

410
210

γ =

0.0125

Model	  

	  
	  

	  

1  Abstract	  

2 

Introduction	  

Predict	  seizures	  in	  intracranial	  EEG	  recordings	  
Linyu	  He	  (linyu90@stanford.edu)	  and	  Lingbin	  Li	  (lingbin@stanford.edu)	  

	  
This	  project	  aims	  to	  predict	  seizures	  in	  intracranial	  electroencephalography	  (iEEG)	  recordings	  using	  four	  algorithms.	  The	  data	  are	  a	  series	  of	  10-­‐
minute	  iEEG	  clips	  labeled	  “preictal	  (positive)”	  for	  data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Our	  
goal	  is	  to	  distinguish	  between	  the	  two	  states.	  The	  major	  challenge	  is	  that	  the	  data	  are	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  positive	  examples	  is	  less	  
than	  10%	  of	  that	  of	  negative	  examples.	  Our	  work	  is	  to	  make	  modifications	  to	  each	  of	  the	  four	  models	  and	  analyze	  the	  corresponding	  performance	  
gain.	  	  
Spontaneous	  seizures	  are	  the	  typical	  symptom	  of	  epilepsy,	  which	  is	  a	  common	  but	  refractory	  neurological	  disorder	  that	  afflicts	  nearly	  1%	  of	  the	  
world’s	  population.	  Anticonvulsant	  medications	  are	  administered	  to	  many	  patients	  at	  high	  doses	  to	  prevent	  seizures,	  but	  their	  effectiveness	  is	  
limited	  and	  patients	  often	  suffer	  their	  side	  effects.	  Even	  for	  patients	  whose	  epilepsy-­‐causing	  brain	  tissue	  is	  removed	  via	  surgery,	  spontaneous	  
seizures	  still	  persist.	  Due	  to	  the	  seemingly	  unpredictable	  occurrence	  of	  seizures,	  patients	  with	  epilepsy	  experience	  constant	  anxiety	  [1].	  
This	  project	  aims	  to	  make	  it	  possible	  that	  devices	  designed	  to	  monitor	  patients’	  brain	  activity	  can	  warn	  them	  of	  impeding	  seizures	  so	  that	  patients	  
are	  able	  to	  take	  appropriate	  precautions.	  It	  is	  also	  helpful	  to	  reduce	  overall	  side	  effects	  caused	  by	  anticonvulsant	  medications	  taken	  by	  these	  
patients.	  By	  providing	  them	  with	  devices	  with	  the	  ability	  to	  predict	  an	  impending	  seizure,	  anticonvulsant	  medications	  could	  be	  administered	  only	  
when	  necessary,	  thus	  lowering	  the	  doses	  given	  to	  patients.	  
Multiple	  researches	  support	  the	  notion	  that	  the	  occurrence	  of	  seizures	  is	  not	  random.	  According	  to	  evidence	  shown	  by	  related	  researches,	  for	  
patients	  with	  epilepsy,	  the	  temporal	  dynamics	  of	  brain	  activity	  can	  be	  classified	  into	  4	  states:	  interictal	  (between	  seizures),	  preictal	  (prior	  to	  
seizures),	  ictal	  (seizure)	  and	  postictal	  (after	  seizures).	  The	  brain	  activity	  of	  each	  state	  can	  be	  recorded	  by	  iEEG	  [1].	  Our	  goal	  is	  to	  employ	  machine	  
learning	  techniques	  to	  learn	  from	  iEEG	  data	  the	  characteristics	  of	  preictal	  states	  and	  then	  distinguish	  these	  states	  from	  the	  interictal	  states.	  After	  
one	  preictal	  state	  is	  identified,	  a	  warning	  should	  be	  sent	  to	  the	  patient	  to	  prepare	  him	  or	  her	  for	  an	  impending	  seizure.	  
Kaggle	  provides	  iEEG	  data	  collected	  from	  canine	  subjects.	  The	  data	  of	  each	  subject	  is	  organized	  into	  10-­‐minute	  clips	  labeled	  “preictal	  (positive)”	  for	  
data	  recorded	  prior	  to	  seizures	  or	  “interictal	  (negative)”	  for	  data	  recorded	  between	  seizures.	  Each	  clip	  contains	  16	  channels	  of	  iEEG	  data	  where	  
each	  channel	  corresponds	  to	  one	  electrode	  implanted	  in	  the	  subject’s	  brain.	  For	  each	  training	  example	  𝑥(!),𝑦(!),	  𝑦(!)	  is	  the	  label	  and	  𝑥(!)	  is	  a	  clip	  in	  
which	  each	  row	  corresponds	  to	  one	  channel	  and	  each	  column	  corresponds	  to	  iEEG	  readings	  at	  one	  sampling	  time	  point.	  
Since	  seizures	  in	  most	  patients	  are	  associated	  with	  a	  stereotypic	  EEG	  discharge	  with	  characteristic	  spectral	  pattern,	  we	  employed	  the	  following	  
feature	  extraction	  procedure	  [2]:	  
Apply	  fast	  Fourier	  transform	  to	  each	  channel	  in	  a	  clip	  and	  divide	  the	  resulting	  power	  spectrum	  into	  6	  bands:	  delta	  (0.1	  –	  4	  Hz),	  theta	  (4	  –	  8	  Hz),	  
alpha	  (8	  –	  12	  Hz),	  beta	  (12	  –	  30	  Hz),	  low-­‐gamma	  (30	  –	  70	  Hz),	  and	  high-­‐gamma	  (70	  –	  180	  Hz).	  In	  each	  band,	  sum	  the	  power	  over	  all	  band	  
frequencies	  to	  produce	  a	  power-­‐in-­‐band	  (PIB)	  feature.	  Therefore,	  6	  features	  are	  obtained	  in	  each	  channel	  and	  96	  features	  are	  obtained	  in	  one	  clip.	  
The	  procedure	  above	  is	  also	  illustrated	  in	  Fig	  1,	  where	  𝑝(𝑓)	  is	  the	  power	  spectrum.	  
Channel	  1	  
Channel	  2	  
…	  …	  …	  Channel	  16	  
There	  are	  3939	  examples	  in	  total,	  in	  which	  3674	  are	  negative	  and	  265	  are	  positive.	  For	  each	  time	  of	  cross	  validation,	  we	  randomly	  pick	  70%	  of	  the	  
negative	  examples	  and	  70%	  of	  the	  positive	  examples	  for	  training	  and	  use	  the	  rest	  for	  testing.	  This	  process	  is	  repeated	  for	  100	  times	  to	  calculate	  the	  
average	  evaluation.	  
	  
1	  

delta	  (0.1	  –	  4Hz):	  ∑
𝑝(𝑓)
	  
!!!!.!
theta	  (4	  –	  8Hz):	  ∑
𝑝(𝑓)
	  
!!!!
alpha	  (8	  –	  12Hz):	  ∑
	  
𝑝(𝑓)
!"!!!
beta	  (12	  –	  30Hz):	  ∑
	  
𝑝(𝑓)
!"!!!"
low-­‐gamma	  (30	  –	  70Hz):	  ∑
𝑝(𝑓)
	  
!"!!!"
high-­‐gamma	  (70	  –	  180Hz):	  ∑
𝑝(𝑓)
	  
!"#!!!"

Fig.	  1	  Feature	  Extraction	  using	  FFT	  

3  Data	  and	  Feature	  Extraction	  

FFT	  

4  Cross	  Validation	  

Name	  

Definition	  

5 

Besides	  the	  training	  error	  and	  the	  testing	  error,	  the	  following	  values	  are	  adopted	  to	  evaluate	  the	  performance	  of	  each	  model	  since	  the	  data	  are	  
highly	  imbalanced.	  
	  

Table	  1.	  Values	  chosen	  to	  evaluate	  the	  performance	  

Learning	  Algorithms	  

Accuracy	  (ACC)	  
Positive	  Predictive	  Rate(PPV)/Precision	  
True	  Positive	  Rate	  (TPR)/Recall	  
False	  Negative	  Rate	  (FNR)/Miss	  Rate	  
False	  Positive	  Rate	  (FPR)/Fall-­‐out	  

𝑇𝑃+𝑇𝑁
𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁	  
𝑇𝑃
𝑇𝑃+𝐹𝑃	  
𝑇𝑃
𝑇𝑃+𝐹𝑁	  
𝐹𝑁𝑇𝑃+𝐹𝑁	  
𝐹𝑃
𝐹𝑃+𝑇𝑁	  
	  In	  Table	  1,	  𝑇𝑃,	  𝑇𝑁,	  𝐹𝑃	  and	  𝐹𝑁	  are	  the	  number	  of	  true	  positives,	  true	  negatives,	  false	  positives	  and	  false	  negatives,	  respectively.	  Finally,	  the	  receiver	  
operating	  characteristic	  (ROC)	  curves	  and	  precision-­‐recall	  curves	  will	  be	  plotted	  based	  on	  values	  in	  the	  table	  above.	  
In	  out	  attempt	  to	  seek	  a	  solution,	  three	  models	  covered	  in	  CS	  229	  were	  first	  adopted,	  which	  are	  logistic	  regression,	  naïve	  Bayes	  classifiers	  and	  
support	  vector	  machines	  (SVMs).	  Later,	  we	  employed	  a	  model	  inherited	  from	  communication	  systems,	  which	  makes	  a	  prediction	  based	  on	  
correlation	  coefficients	  between	  the	  test	  example	  and	  all	  training	  examples.	  Modifications	  are	  made	  to	  each	  model	  to	  improve	  their	  performance	  on	  
an	  imbalanced	  data	  set.	  In	  the	  following	  discussion,	  we	  use	  𝑥(!),𝑦(!)	  to	  denote	  each	  training	  example	  where	  𝑥(!)∈𝑅!"	  is	  the	  set	  of	  features	  and	  
𝑦(!)∈ 0,1	  is	  a	  label	  (0	  corresponds	  to	  a	  negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label.	  In	  SVMs,	  𝑦(!)∈ −1,1	  where	  -­‐1	  corresponds	  to	  a	  
negative	  label	  and	  1	  corresponds	  to	  a	  positive	  label).	  We	  use	  𝑋	  to	  denote	  a	  query	  point	  (test	  example)	  and	  𝑌	  to	  denote	  the	  label	  predicted	  by	  a	  
model.	  
!!!!!!!	  where	  𝜃	  is	  the	  parameter.	  The	  probability	  of	  𝑌=1	  conditioned	  on	  𝑋	  and	  parameterized	  by	  
In	  logistic	  regression,	  the	  hypothesis	  is	  ℎ!𝑥 =
!
𝜃	  is	  𝑃𝑌=1|𝑋,𝜃 =ℎ!𝑋.	  
Usually,	  the	  prediction	  that	  𝑌=1	  is	  made	  if	  ℎ!𝑋 ≥0.5.	  Since	  the	  data	  set	  is	  highly	  imbalanced,	  i.e.,	  the	  number	  of	  negative	  examples	  is	  much	  
larger	  than	  that	  of	  positive	  ones,	  we	  consider	  it	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  examples	  than	  to	  have	  a	  few	  false	  positives.	  
Therefore,	  the	  decision	  threshold	  of	  ℎ!𝑋	  can	  be	  less	  than	  0.5,	  which	  makes	  it	  more	  likely	  to	  classify	  a	  test	  example	  as	  positive.	  We	  set	  the	  decision	  
threshold	  to	  be	  𝜂	  where	  𝜂∈  [0,0.5]	  and	  plot	  the	  cross	  validation	  results	  when	  choosing	  different	  values	  of	  𝜂,	  which	  is	  shown	  in	  Fig.	  2.	  

5.1 

Logistic	  Regression	  

Fig.	  2	  The	  relation	  between	  the	  decision	  threshold	  𝜂	  and	  accuracy,	  recall	  and	  precision	  of	  the	  logistic	  regression	  model	  
	  It	  can	  be	  seen	  in	  Fig.	  2	  that	  when	  𝜂=0.5,	  both	  accuracy	  and	  precision	  are	  high,	  but	  the	  recall	  is	  not	  satisfactory.	  When	  𝜂=0,	  we	  achieve	  the	  
maximum	  recall	  but	  the	  accuracy	  and	  precision	  are	  very	  low.	  So	  a	  trade-­‐off	  has	  to	  be	  made	  between	  recall	  and	  precision/accuracy	  by	  choosing	  an	  
appropriate	  value	  of	  𝜂.	  For	  example,	  if	  𝜂=0.04,	  both	  accuracy	  and	  recall	  are	  high	  and	  close	  to	  each	  other,	  meaning	  the	  accuracy	  for	  classifying	  all	  
test	  examples	  and	  the	  one	  for	  classifying	  positive	  test	  examples	  are	  close.	  The	  low	  precision	  when	  𝜂=0.04	  is	  caused	  by	  the	  increased	  number	  of	  
false	  positives,	  which	  is	  acceptable	  to	  some	  extent	  since	  false	  positives	  are	  less	  important	  than	  true	  positives	  in	  seizure	  prediction.	  
	  

2	  

5.2 

Naïve	  Bayes	  

The	  multinomial	  distribution	  is	  used	  to	  model	  the	  features	  of	  each	  iEEG	  clip.	  Since	  the	  value	  of	  each	  feature	  is	  continuous,	  we	  first	  discretize	  the	  
values	  into	  𝑁	  groups	  where	  𝑁=!!"#! ,	  𝑉!"#	  is	  the	  maximum	  value	  of	  the	  features	  of	  all	  clips	  and	  𝐺	  is	  the	  group	  size.	  Similar	  to	  the	  modification	  made	  
to	  logistic	  regression,	  a	  test	  example	  is	  labeled	  “1”	  if	  𝑄𝑃𝑌=1|𝑋 ≥𝑃𝑌=0|𝑋	  where	  𝑄	  is	  a	  positive	  constant	  specified	  to	  overcome	  the	  
imbalanced	  data	  when	  making	  predictions.	  Fig.	  3	  indicates	  that	  the	  naïve	  Bayesian	  model	  cannot	  make	  satisfactory	  predictions	  no	  matter	  what	  the	  
value	  of	  𝑄	  is.	  

Fig.	  3	  The	  relation	  between	  𝑄	  and	  accuracy,	  recall	  and	  precision	  of	  the	  naïve	  Bayesian	  model	  	  

5.3 

Support	  Vector	  Machine	  (SVM)	  

In	  the	  𝑙!-­‐regularized	  SVM,	  the	  hypothesis	  is	  ℎ!,!𝑥 =𝑤!𝑥+𝑏	  where	  parameters	  𝑤	  and	  𝑏	  are	  obtained	  by	  solving	  the	  primal	  optimization	  problem	  
whose	  objective	  is	  min!,!!! 𝑤 !+𝐶
	  is	  the	  cost	  term.	  Since	  it	  is	  more	  important	  to	  correctly	  classify	  more	  positive	  test	  
examples	  than	  to	  have	  a	  few	  false	  positives,	  the	  2-­‐cost-­‐sensitive	  SVM	  (2C-­‐SVM)	  [3]	  is	  adopted	  in	  which	  two	  different	  costs	  are	  assigned	  to	  negative	  
and	  positive	  examples,	  respectively.	  In	  2C-­‐SVM,	  the	  objective	  of	  the	  primal	  optimization	  problem	  is	  min!,!!! 𝑤 !+𝐶!
	  where	  
𝐶=𝐶!+𝐶!	  is	  a	  trade	  off	  between	  the	  classification	  margin	  and	  misclassified	  or	  non-­‐separable	  examples	  and	  the	  cost	  factor	  𝑅=!!!!	  is	  the	  ratio	  of	  
costs	  between	  positive	  and	  negative	  examples.	  We	  employ	  the	  LIBSVM	  library	  [4]	  as	  our	  2C-­‐SVM	  implementation.	  

𝜉!
!∈!! +𝐶!

,	  where	  𝐶

𝜉!!!!!

𝜉!!!!!

𝜉!

!∈!!

Fig.	  4	  The	  relation	  between	  𝐶,	  𝑅	  and	  accuracy,	  recall	  and	  precision	  of	  the	  2C-­‐SVM	  model	  

	  Different	  values	  of	  𝐶>0	  and	  𝑅≥1	  are	  chosen	  and	  the	  corresponding	  results	  of	  accuracy,	  recall	  and	  precision	  are	  shown	  in	  Fig.	  4.	  Satisfactory	  
accuracy	  and	  recall	  can	  be	  achieved	  when	  (𝐶,𝑅)	  is	  chosen	  as	  10!!,10!,	  10!!,10!	  or	  10!!,10!,	  etc.	  
We	  derived	  the	  correlation	  decision	  model	  from	  a	  few	  concepts	  in	  communication	  systems.	  The	  previous	  three	  models	  discard	  the	  training	  set	  after	  
a	  hypothesis	  is	  built.	  However,	  in	  correlation	  decision,	  we	  do	  not	  use	  training	  examples	  to	  build	  a	  hypothesis	  and	  we	  keep	  the	  entire	  training	  set.	  

Correlation	  Decision	  

5.4 

	  

	  

3	  

Consider	   a	   given	   query	   point	  𝑋.	   Calculate	  
its	   correlation	   with	   each	   training	   example	   and	   assign	   a	   score	   to	   each	   of	   them:	  
𝑆𝑐𝑜𝑟𝑒𝑖 =𝑐𝑜𝑟𝑟𝑋,𝑋(!),∀𝑖=1,2…  𝑚.	  Find	  the	  training	  example	  with	  the	  maximum	  score:	  𝑖∗=𝑎𝑟𝑔𝑚𝑎𝑥  𝑆𝑐𝑜𝑟𝑒  (𝑖).	  Since	  𝑋(!∗)	  is	  the	  training	  
example	  that	  the	  query	  point	  is	  most	  similar	  to,	  we	  can	  make	  a	  prediction	  that	  𝑌=𝑌(!∗).	  
In	  order	  to	  classify	  more	  positive	  examples	  correctly,	  in	  other	  words,	  to	  output	  more	  positives,	  we	  increase	  the	  scores	  for	  positive	  training	  
examples	  by	  a	  factor	  𝛾≥0,	  namely,	  𝑆𝑐𝑜𝑟𝑒∶=  𝑆𝑐𝑜𝑟𝑒×(1+𝛾)	  for	  all	  positive	  training	  examples.	  	  

ACC	  

Recall	  

5.5 

Others	  

0.5η=
0.04
η=

Decision	  	  
Parameters	  

6  Results	  and	  Discussion	  

Fig.	  5	  The	  relation	  between	  𝛾	  and	  accuracy,	  recall	  and	  precision	  of	  the	  correlation	  decision	  model	  	  
We	  also	  tried	  extracting	  features	  using	  PCA	  and	  ICA,	  using	  different	  kernels	  (such	  as	  the	  Gaussian	  kernel	  and	  the	  sigmoid	  kernel)	  in	  SVMs,	  and	  
capturing	  non-­‐linear	  behaviors	  of	  features	  (such	  as	  log𝑥,	   𝑥	  and	  𝑥!).	  But	  we	  didn’t	  achieve	  improvement	  in	  performance.	  
Table	  2	  shows	  the	  results	  of	  the	  models	  discussed	  above,	  where	  for	  each	  model,	  the	  results	  before	  and	  after	  our	  modification	  to	  these	  models	  are	  
compared.	  For	  each	  modified	  model	  except	  naïve	  Bayes,	  the	  decision	  parameters	  that	  achieve	  an	  acceptable	  performance	  are	  shown.	  Among	  all	  
chosen	  models,	  logistic	  regression	  with	  a	  threshold	  of	  0.04	  works	  best,	  in	  whose	  results	  both	  accuracy	  and	  recall	  are	  close	  to	  90%.	  
	  
67%	  
34%	  
NAN	  
8%	  
55%	  
24%	  
66%	  
28%	  

Logistic	  Regression	  
Naïve	  Bayes	  
2C-­‐SVM	  
Correlation	  Decision	  
	  Fig.	  6	  shows	  the	  ROC	  curve	  and	  the	  precision-­‐recall	  curve	  of	  each	  model.	  The	  area	  under	  curve	  (AUC)	  is	  calculated	  by	  using	  the	  trapezoidal	  areas	  
created	  between	  each	  point	  [5].	  It	  can	  be	  seen	  that	  logistic	  regression	  outperforms	  others	  since	  its	  AUCs	  for	  ROC	  and	  precision-­‐recall	  curves	  are	  the	  
highest.	  	  Correlation	  decision	  model	  also	  provides	  high	  AUCs	  for	  both	  kinds	  of	  curves,	  which	  indicates	  its	  performance	  is	  close	  to	  that	  of	  logistic	  
regression.	  	  
Seizure	  prediction	  is	  usually	  performed	  in	  real	  time.	  Table	  3	  gives	  the	  comparison	  of	  average	  runtime	  for	  different	  models.	  The	  test	  is	  performed	  on	  
the	  same	  PC	  with	  a	  2.2GHz	  CPU.	  It	  can	  be	  seen	  that	  logistic	  regression	  consumes	  the	  least	  time.	  Since	  it	  also	  has	  the	  highest	  prediction	  performance,	  
it	  is	  the	  most	  cost-­‐efficient	  algorithm	  in	  this	  situation.	  Although	  the	  performance	  of	  the	  correlation	  decision	  model	  is	  as	  good	  as	  that	  of	  logistic	  
	  
4	  

	  
1Q = 	  
Linear	  
Kernel;	  
1C = 	  
1R = 	  
Linear	  
Kernel;	  
	  
	  
0γ = 	  

96%	  
88%	  
93%	  
53%	  
94%	  
80%	  
95%	  
85%	  

71%	  
88%	  
0	  
54%	  
67%	  
85%	  
62%	  
85%	  

Precision	  

FPR	  

FNR	  

Error	  

Training	  	  

Test	  	  
Error	  

Table	  2.	  Performance	  results	  of	  different	  models	  
0.0262	  
0.0046	  
0.0567	  
0.1257	  
0	  
0.0685	  
0.1993	  
0.4697	  
0.0018	  
0.0412	  
0.2034	  
0.0387	  
0.0244	  
-­‐	  
0.1521	  
-­‐	  

0.0443	  
0.1255	  
0.0691	  
0.4688	  
0.0610	  
0.1994	  
0.0489	  
0.1502	  

0.2871	  
0.1232	  
1	  
0.4565	  
0.3273	  
0.1453	  
0.3780	  
0.1341	  

7010Q =

C
=
R =

−

410
210

γ =

0.0125

Model	  

	  
	  

	  

regression,	  it	  runs	  much	  more	  slowly,	  since	  it	  has	  to	  keep	  track	  of	  all	  training	  examples	  during	  the	  prediction	  process.	  Therefore,	  we	  consider	  
logistic	  regression	  with	  threshold	  modification	  as	  the	  best	  model	  in	  this	  project.	  

Model	  

η=

0.04

C

410

−

=

R =

210

Runtime	  (in	  seconds)	  

Naïve	  Bayes	  
(
)	  
0.488759	  

7010Q =

7  Conclusions	  and	  Future	  Work	  

Fig.	  6	  	  The	  ROC	  curve	  and	  precision-­‐recall	  curve	  of	  each	  model	  
2C-­‐SVM	  
Logistic	  Regression	  
(
)	  
,
0.267448	  
0.432028	  

	  
	  
Table	  3.	  The	  average	  runtime	  of	  different	  models	  (#	  of	  training	  examples	  :	  2758,	  #	  of	  test	  examples	  :	  1182)	  
Correlation	  Decision	  
(
)	  
12.8690	  
	  The	  major	  challenge	  of	  this	  project	  is	  the	  imbalanced	  data.	  What	  we’ve	  done	  so	  far	  is	  to	  sacrifice	  false	  positive	  rate	  to	  achieve	  a	  low	  false	  negative	  
rate	  because	  a	  false	  negative	  is	  far	  more	  dangerous	  than	  a	  false	  positive	  in	  seizure	  prediction.	  The	  current	  results	  are	  within	  our	  expectations	  but	  
they	  are	  not	  good	  enough	  since	  we	  believe	  the	  information	  extracted	  from	  the	  limited	  number	  of	  positive	  examples	  is	  not	  enough	  to	  perfectly	  
distinguish	  between	  the	  two	  classes.	  
Three	  supervised	  learning	  models	  covered	  in	  CS229	  and	  one	  model	  inherited	  from	  communication	  systems	  are	  employed	  in	  this	  project	  to	  predict	  
the	  occurrence	  of	  seizures.	  Modifications	  are	  made	  to	  these	  models	  to	  deal	  with	  the	  highly	  imbalanced	  data.	  Among	  the	  four	  models,	  logistic	  
regression	  outperforms	  others,	  which	  obtains	  the	  highest	  AUCs	  for	  ROC	  and	  precision-­‐recall	  curves.	  Meanwhile,	  when	  choosing	  the	  decision	  
parameter	  properly,	  both	  accuracy	  and	  recall	  of	  logistic	  regression	  are	  close	  to	  90%.	  
An	  important	  method	  to	  deal	  with	  imbalanced	  bits	  “0”	  and	  “1”	  in	  wireless	  communication	  is	  to	  code	  “0”	  into	  “01”	  and	  “1”	  into	  “10”	  so	  that	  the	  
numbers	  of	  both	  classes	  become	  balanced.	  We’ve	  been	  trying	  to	  apply	  similar	  ideas	  to	  the	  project,	  but	  have	  yet	  got	  a	  satisfying	  result.	  So	  the	  
exploration	  will	  be	  continued	  to	  seek	  better	  solutions.	  
Also,	  instead	  of	  using	  a	  single	  model	  to	  build	  a	  classifier,	  attempts	  can	  be	  made	  to	  combine	  the	  predictions	  of	  different	  models	  and	  develop	  
strategies	  to	  make	  a	  final	  decision.	  Models	  involved	  in	  the	  combination	  may	  differ	  in	  their	  feature	  extraction	  process	  since	  it	  is	  possible	  to	  develop	  
for	  each	  model	  the	  features	  that	  best	  fit	  the	  model.	  
[1]	  Kaggle	  Inc.	  (2014)	  Kaggle:	  The	  Home	  of	  Data	  Science.	  [Online].	  http://www.kaggle.com/c/seizure-­‐prediction	  
[2]	  J.	  Jeffry	  Howbert	  et	  al.,	  "Forecasting	  seizures	  in	  dogs	  with	  naturally	  occurring	  epilepsy,"	  PloS	  one,	  vol.	  9,	  no.	  1,	  p.	  e81920,	  2014.	  
[3]	  Yun	  Park,	  Lan	  Luo,	  Keshab	  K.	  Parhi,	  and	  Theoden	  Netoff,	  "Seizure	  prediction	  with	  spectral	  power	  of	  EEG	  using	  cost-­‐sensitive	  support	  vector	  
machines.,"	  Epilepsia	  52,	  no.	  10,	  pp.	  1761-­‐1770,	  2011.	  
[4]	  Chih-­‐Chung	  
[Online].	  
Vector	   Machines.	  
Support	  
(2014)	  
Lin.	  
Chih-­‐Jen	  
http://www.csie.ntu.edu.tw/~cjlin/libsvm/	  
[5]	  Jesse	  Davis	  and	  Mark	  Goadrich,	  "The	  relationship	  between	  Precision-­‐Recall	  and	  ROC	  curves,"	  in	  Proceedings	  of	  the	  23rd	  international	  conference	  
on	  Machine	  learning,	  2006,	  pp.	  233-­‐240.	  
	  
	  

8  References	  

LIBSVM	  

Library	  

Chang	  

and	  

-­‐-­‐	  

A	  

for	  

(

)	  

γ =

0.0125

5	  

