Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Figure 2: The features used as inputs to the classiﬁer .

Figure 3: The histogram of collected UTXO lifespans with two regions magniﬁed.

listed in ﬁgure 2. The feature set consists of information pertaining to the individual beginning
transactions, and information about the bitcoin market statistics on the day of creation.

We dummy coded the weekday with the reference day being Sunday. This created 6 new
binary features, where each feature dictates whether the transaction occurred on a particular day.
Sunday, the reference day, is represented by these 6 features being 0. The UNIX time of beginning
transaction corresponded to the number of hours that occurred since the Epoch time, Thursday, 1
January, 1970. The 11th feature, transaction volume on creation date, corresponds to to the total
number of unique Bitcoin transactions that occurred on the day of creation. The ﬁnal three features
are the three 2nd order polynomial parameters that ﬁt the last week’s USD to BTC conversion
rate.

3 Methods
As shown in ﬁgure 3, the tail of the UTXO Lifespan distribution is extremely long. As such,
regression might lead to prediction errors that are large enough to remove their useful meaning.

2

Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Figure 2: The features used as inputs to the classiﬁer .

Figure 3: The histogram of collected UTXO lifespans with two regions magniﬁed.

listed in ﬁgure 2. The feature set consists of information pertaining to the individual beginning
transactions, and information about the bitcoin market statistics on the day of creation.

We dummy coded the weekday with the reference day being Sunday. This created 6 new
binary features, where each feature dictates whether the transaction occurred on a particular day.
Sunday, the reference day, is represented by these 6 features being 0. The UNIX time of beginning
transaction corresponded to the number of hours that occurred since the Epoch time, Thursday, 1
January, 1970. The 11th feature, transaction volume on creation date, corresponds to to the total
number of unique Bitcoin transactions that occurred on the day of creation. The ﬁnal three features
are the three 2nd order polynomial parameters that ﬁt the last week’s USD to BTC conversion
rate.

3 Methods
As shown in ﬁgure 3, the tail of the UTXO Lifespan distribution is extremely long. As such,
regression might lead to prediction errors that are large enough to remove their useful meaning.

2

Figure 4: The maximum likelihood distribution ﬁts for each of the six (cid:96)1 penalty clusters.

Classiﬁcation into a ﬁnite set of lifespan bins (deﬁned by ranges of time) clariﬁes this issue and
provides more intuitive results. The trick, however, is to deﬁne useful, data-dependent time ranges.
Hardcoding these based on eyeballing the distribution seemed meaningless so we chose to instead
split the full domain into ten equal-probability ranges.

Two methods of doing this are either (1) entirely empirically or (2) based on a ﬁtted distribution.
The former case is simply a matter of sorting the lifespan dataset and splitting it into ten equally
sized groups. The latter requires more processing. Understanding that the data should show signs
of a Laplace or exponential distribution based the standard application of those distributions, the
ﬁrst step was to cluster the lifespan set using k-median ((cid:96)1 penalty function) clustering. From
there, we ﬁtted either a Normal, Laplace, or Exponential (whichever was most likely) distribution
to each cluster using maximum likelihood estimation and then formed a global distribution as a
weighted sum.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 m 10 m 31 m 80 m 3 h 7 h 1 d 3 d 2 wk ∞
10
10

10

10

10

10

10

10

10

10

Table 1: Table of subdomain boundaries and the distribution of datapoints within subdomains for empiri-
cally calculated subdomains.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 h 4 h 6.5 h 9.5 h 12.5 h 17.5 h 1 d 1.5 d 2 wk ∞
10
44

16

8

5

7

2

2

3

3

Table 2: Table of subdomain boundaries and the distribution of datapoints within subdomains for subdo-
mains from a ﬁtted distribution.

Tables 1 and 2 describe the ten subdomains with raw data and the ﬁtted distribution respec-
tively. Table 2 reveals that the ﬁtted distribution does not suﬃciently capture the heavy weighting

3

501001502000.020.040.060.080.10.12Maximum Likelihood Distribution for Each Cluster2004006008001000120014000.0050.010.0150.020.02511.5×1042468101214×10-41.522.533.5×1040.511.52×10-3020004000012345678×10-3050001000000.511.522.5×10-3Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Figure 2: The features used as inputs to the classiﬁer .

Figure 3: The histogram of collected UTXO lifespans with two regions magniﬁed.

listed in ﬁgure 2. The feature set consists of information pertaining to the individual beginning
transactions, and information about the bitcoin market statistics on the day of creation.

We dummy coded the weekday with the reference day being Sunday. This created 6 new
binary features, where each feature dictates whether the transaction occurred on a particular day.
Sunday, the reference day, is represented by these 6 features being 0. The UNIX time of beginning
transaction corresponded to the number of hours that occurred since the Epoch time, Thursday, 1
January, 1970. The 11th feature, transaction volume on creation date, corresponds to to the total
number of unique Bitcoin transactions that occurred on the day of creation. The ﬁnal three features
are the three 2nd order polynomial parameters that ﬁt the last week’s USD to BTC conversion
rate.

3 Methods
As shown in ﬁgure 3, the tail of the UTXO Lifespan distribution is extremely long. As such,
regression might lead to prediction errors that are large enough to remove their useful meaning.

2

Figure 4: The maximum likelihood distribution ﬁts for each of the six (cid:96)1 penalty clusters.

Classiﬁcation into a ﬁnite set of lifespan bins (deﬁned by ranges of time) clariﬁes this issue and
provides more intuitive results. The trick, however, is to deﬁne useful, data-dependent time ranges.
Hardcoding these based on eyeballing the distribution seemed meaningless so we chose to instead
split the full domain into ten equal-probability ranges.

Two methods of doing this are either (1) entirely empirically or (2) based on a ﬁtted distribution.
The former case is simply a matter of sorting the lifespan dataset and splitting it into ten equally
sized groups. The latter requires more processing. Understanding that the data should show signs
of a Laplace or exponential distribution based the standard application of those distributions, the
ﬁrst step was to cluster the lifespan set using k-median ((cid:96)1 penalty function) clustering. From
there, we ﬁtted either a Normal, Laplace, or Exponential (whichever was most likely) distribution
to each cluster using maximum likelihood estimation and then formed a global distribution as a
weighted sum.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 m 10 m 31 m 80 m 3 h 7 h 1 d 3 d 2 wk ∞
10
10

10

10

10

10

10

10

10

10

Table 1: Table of subdomain boundaries and the distribution of datapoints within subdomains for empiri-
cally calculated subdomains.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 h 4 h 6.5 h 9.5 h 12.5 h 17.5 h 1 d 1.5 d 2 wk ∞
10
44

16

8

5

7

2

2

3

3

Table 2: Table of subdomain boundaries and the distribution of datapoints within subdomains for subdo-
mains from a ﬁtted distribution.

Tables 1 and 2 describe the ten subdomains with raw data and the ﬁtted distribution respec-
tively. Table 2 reveals that the ﬁtted distribution does not suﬃciently capture the heavy weighting

3

501001502000.020.040.060.080.10.12Maximum Likelihood Distribution for Each Cluster2004006008001000120014000.0050.010.0150.020.02511.5×1042468101214×10-41.522.533.5×1040.511.52×10-3020004000012345678×10-3050001000000.511.522.5×10-3Figure 5: Classiﬁer performance vs γ and C. One region of the broader heatmap is magniﬁed for higher
granularity.

towards 0 since 44% of the data is falling into what we hoped was a 10% probability domain.
Keeping in mind that the goal of this subdomain split is to ﬁnd a meaningful set of lables, the
choice between the two options is up to which domains seem more meaningful to a future user. We
created two classiﬁers – one for each label set.

We used two diﬀerent classiﬁcation algorithms: SVM with a (Gaussian) radial basis kernel and

softmax regression. The SVM optimization problem is as follows [3, 4, 5]:

m(cid:88)

||w||2 + C

1
2

min
γ,w,b
s.t.y(i)(wT x(i) + b) ≥ 1 − ξi,

i=1

ξi

ξi ≥ 0,

i = 1, ..., m

(cid:16)−(cid:107)x−z(cid:107)2

(cid:17)

i = 1, ..., m

. This kernel function implicitly moves the
With the kernel function K(x, z) = exp
feature set to a high dimensional space where the optimal margin between classes is larger and
better ﬁt by a linear equation than in the original, low dimentional space.

2σ2

Softmax regression is a GLM that can be run on a multinomial dataset. In class we saw that if we
eηi(cid:80)k
dummy coded our labels (with one being a reference label), then we could express the multinomial
distribution as a member of the exponential family. The softmax function, φi =
j=1 eηj , where
η is the natural parameter and k is the number of labels, is found to describe the conditional
distribution of y given x :

p(y = i|x; θ) =

eηi(cid:80)k

j=1 eηj

i x(cid:80)k

eθT
j=1 eθT
j x

=

With this conditional probablity we are able to estimate the probablity of a certain feature set
falling into each category, i.

4 Results
SVM with a radial kernel performed signiﬁcantly better than any other tested alternative so this
section highlights only those results on the empirically decided equal-probability labels. The pa-
rameters γ and C changed the predication accuracy as they varied so ﬁgure 5 highlights the process

4

Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Figure 2: The features used as inputs to the classiﬁer .

Figure 3: The histogram of collected UTXO lifespans with two regions magniﬁed.

listed in ﬁgure 2. The feature set consists of information pertaining to the individual beginning
transactions, and information about the bitcoin market statistics on the day of creation.

We dummy coded the weekday with the reference day being Sunday. This created 6 new
binary features, where each feature dictates whether the transaction occurred on a particular day.
Sunday, the reference day, is represented by these 6 features being 0. The UNIX time of beginning
transaction corresponded to the number of hours that occurred since the Epoch time, Thursday, 1
January, 1970. The 11th feature, transaction volume on creation date, corresponds to to the total
number of unique Bitcoin transactions that occurred on the day of creation. The ﬁnal three features
are the three 2nd order polynomial parameters that ﬁt the last week’s USD to BTC conversion
rate.

3 Methods
As shown in ﬁgure 3, the tail of the UTXO Lifespan distribution is extremely long. As such,
regression might lead to prediction errors that are large enough to remove their useful meaning.

2

Figure 4: The maximum likelihood distribution ﬁts for each of the six (cid:96)1 penalty clusters.

Classiﬁcation into a ﬁnite set of lifespan bins (deﬁned by ranges of time) clariﬁes this issue and
provides more intuitive results. The trick, however, is to deﬁne useful, data-dependent time ranges.
Hardcoding these based on eyeballing the distribution seemed meaningless so we chose to instead
split the full domain into ten equal-probability ranges.

Two methods of doing this are either (1) entirely empirically or (2) based on a ﬁtted distribution.
The former case is simply a matter of sorting the lifespan dataset and splitting it into ten equally
sized groups. The latter requires more processing. Understanding that the data should show signs
of a Laplace or exponential distribution based the standard application of those distributions, the
ﬁrst step was to cluster the lifespan set using k-median ((cid:96)1 penalty function) clustering. From
there, we ﬁtted either a Normal, Laplace, or Exponential (whichever was most likely) distribution
to each cluster using maximum likelihood estimation and then formed a global distribution as a
weighted sum.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 m 10 m 31 m 80 m 3 h 7 h 1 d 3 d 2 wk ∞
10
10

10

10

10

10

10

10

10

10

Table 1: Table of subdomain boundaries and the distribution of datapoints within subdomains for empiri-
cally calculated subdomains.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 h 4 h 6.5 h 9.5 h 12.5 h 17.5 h 1 d 1.5 d 2 wk ∞
10
44

16

8

5

7

2

2

3

3

Table 2: Table of subdomain boundaries and the distribution of datapoints within subdomains for subdo-
mains from a ﬁtted distribution.

Tables 1 and 2 describe the ten subdomains with raw data and the ﬁtted distribution respec-
tively. Table 2 reveals that the ﬁtted distribution does not suﬃciently capture the heavy weighting

3

501001502000.020.040.060.080.10.12Maximum Likelihood Distribution for Each Cluster2004006008001000120014000.0050.010.0150.020.02511.5×1042468101214×10-41.522.533.5×1040.511.52×10-3020004000012345678×10-3050001000000.511.522.5×10-3Figure 5: Classiﬁer performance vs γ and C. One region of the broader heatmap is magniﬁed for higher
granularity.

towards 0 since 44% of the data is falling into what we hoped was a 10% probability domain.
Keeping in mind that the goal of this subdomain split is to ﬁnd a meaningful set of lables, the
choice between the two options is up to which domains seem more meaningful to a future user. We
created two classiﬁers – one for each label set.

We used two diﬀerent classiﬁcation algorithms: SVM with a (Gaussian) radial basis kernel and

softmax regression. The SVM optimization problem is as follows [3, 4, 5]:

m(cid:88)

||w||2 + C

1
2

min
γ,w,b
s.t.y(i)(wT x(i) + b) ≥ 1 − ξi,

i=1

ξi

ξi ≥ 0,

i = 1, ..., m

(cid:16)−(cid:107)x−z(cid:107)2

(cid:17)

i = 1, ..., m

. This kernel function implicitly moves the
With the kernel function K(x, z) = exp
feature set to a high dimensional space where the optimal margin between classes is larger and
better ﬁt by a linear equation than in the original, low dimentional space.

2σ2

Softmax regression is a GLM that can be run on a multinomial dataset. In class we saw that if we
eηi(cid:80)k
dummy coded our labels (with one being a reference label), then we could express the multinomial
distribution as a member of the exponential family. The softmax function, φi =
j=1 eηj , where
η is the natural parameter and k is the number of labels, is found to describe the conditional
distribution of y given x :

p(y = i|x; θ) =

eηi(cid:80)k

j=1 eηj

i x(cid:80)k

eθT
j=1 eθT
j x

=

With this conditional probablity we are able to estimate the probablity of a certain feature set
falling into each category, i.

4 Results
SVM with a radial kernel performed signiﬁcantly better than any other tested alternative so this
section highlights only those results on the empirically decided equal-probability labels. The pa-
rameters γ and C changed the predication accuracy as they varied so ﬁgure 5 highlights the process

4

Figure 6: The accuracy of the SVM classiﬁer using empirical labels with the sequential addition of features
and the training/test error vs dataset size.

of ﬁrst training and 5-fold validating on a rough range of the two, then zooming in for ﬁner changes
to ﬁnd an ideal pair of values at γ = 1.9 × 10−6 and C = 4.2 × 106.

Figure 6 shows the training and test error with respect to training set size with the peak γ
and C pair as well as the eﬀect of each feature on prediction accuracy as the features are added
in one by one. Since space is scarce, suﬃce to say we have corresponding plots of ﬁgures 5 and 6
for the ﬁtted-distribution-deﬁned equal probability labels. The baseline accuracy (i.e. predicting
label 1 every time) is 44% while the peak accuracy with all features present is about 95%. Using
other classiﬁers – softmax regression, linear SVM kernel, 3rd degree polynomial SVM kernel, and
sigmoid SVM kernel – we had prediction accuracies 43%, 35%, 34%, and 9% respectively.

5 Conclusion & Future Work

It would be interesting to study the stationarity (or lack-there-of) of the UTXO Lifespan distribu-
tion (i.e. are typical spending habits varying over Bitcoin history?) Such information might help
with ﬁnding a better ﬁtting underlying distribution that would be more robust than relying on
equal-probability binning of raw data. Similarly, attempting to model the underlying distribution
as a mixture of Laplace distributions might make more sense than ﬁtting a set of adjacent clusters
with individual distributions. We started down that path and would like to acknowledge Junjie
Qin’s help but we were unable to bring it to a useful state. It would also be worth see how many
equal-probability bins we can meaningfully classify into (the more the better). Finally, two inter-
esting follow up projects would be to use this prediction tool to create expected volatility plots of
the Bitcoin market or pairing this predictor with de-anonymizing tools to form individual spending
models for clustered entities on the blockchain.

5

Bitcoin UTXO Lifespan Prediction

Robert Konrad & Stephen Pinto

December 11, 2015

1 Background & Motivation

The Bitcoin crypto currency [1, 2] is the most widely used and highly valued digital currency in
existence. Every day sees thousands of transactions added to the blockchain. The blockchain is a
global, agreed-upon ledger of every transaction that has ever occured and is continually extended
as a single linked list. Each transaction in the blockchain, say Alice paying Bob 10 BTC, has one or
more transaction outputs (TXO) which serve as sums of spendable BTC. These unspent sums are
called Unspent Transaction Outputs (UTXO). They remain UTXOs until the owner (Bob in our
example) redeems them to pay someone else (at which time they are referred to as spent TXOs).
This project seeks to predict how long a TXO will remain unspent. More formally, given
some information about the beginning transaction which created the UTXO and some information
about the Bitcoin market on the day of its creation, this project predicts which of ten broad time
scales the UTXO lifespan will fall into. This predictor could inform broader applications such as
anomaly/fraud detection, trade volume and volatility prediction, and the modelling of individual
spending habit. The Bitcoin industry is worth billions of dollars and growing rapidly. Possible
insights into the previosly mentioned topics would be of use to any number of ﬁnancial institutions
involved in the future of cryptocurrencies.

2 Dataset & Features

One of the (many) blockchain explorers, Blockchain.info, has a public API exposing data about
individual transactions as well as general Bitcoin market statistics. A python script queried
Blockchain.info at a polite rate to gather 13146 training samples and then exported the data to a
Matlab readable format. A Matlab script then curated the data into a matrix with the features

Figure 1: Illustrated Explanation of a UTXO. An arbitrary amount of time may pass before Bob spends
his UTXO.

1

Figure 2: The features used as inputs to the classiﬁer .

Figure 3: The histogram of collected UTXO lifespans with two regions magniﬁed.

listed in ﬁgure 2. The feature set consists of information pertaining to the individual beginning
transactions, and information about the bitcoin market statistics on the day of creation.

We dummy coded the weekday with the reference day being Sunday. This created 6 new
binary features, where each feature dictates whether the transaction occurred on a particular day.
Sunday, the reference day, is represented by these 6 features being 0. The UNIX time of beginning
transaction corresponded to the number of hours that occurred since the Epoch time, Thursday, 1
January, 1970. The 11th feature, transaction volume on creation date, corresponds to to the total
number of unique Bitcoin transactions that occurred on the day of creation. The ﬁnal three features
are the three 2nd order polynomial parameters that ﬁt the last week’s USD to BTC conversion
rate.

3 Methods
As shown in ﬁgure 3, the tail of the UTXO Lifespan distribution is extremely long. As such,
regression might lead to prediction errors that are large enough to remove their useful meaning.

2

Figure 4: The maximum likelihood distribution ﬁts for each of the six (cid:96)1 penalty clusters.

Classiﬁcation into a ﬁnite set of lifespan bins (deﬁned by ranges of time) clariﬁes this issue and
provides more intuitive results. The trick, however, is to deﬁne useful, data-dependent time ranges.
Hardcoding these based on eyeballing the distribution seemed meaningless so we chose to instead
split the full domain into ten equal-probability ranges.

Two methods of doing this are either (1) entirely empirically or (2) based on a ﬁtted distribution.
The former case is simply a matter of sorting the lifespan dataset and splitting it into ten equally
sized groups. The latter requires more processing. Understanding that the data should show signs
of a Laplace or exponential distribution based the standard application of those distributions, the
ﬁrst step was to cluster the lifespan set using k-median ((cid:96)1 penalty function) clustering. From
there, we ﬁtted either a Normal, Laplace, or Exponential (whichever was most likely) distribution
to each cluster using maximum likelihood estimation and then formed a global distribution as a
weighted sum.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 m 10 m 31 m 80 m 3 h 7 h 1 d 3 d 2 wk ∞
10
10

10

10

10

10

10

10

10

10

Table 1: Table of subdomain boundaries and the distribution of datapoints within subdomains for empiri-
cally calculated subdomains.

Upper Bound of Subdomain
% of Dataset in Subdomain

2 h 4 h 6.5 h 9.5 h 12.5 h 17.5 h 1 d 1.5 d 2 wk ∞
10
44

16

8

5

7

2

2

3

3

Table 2: Table of subdomain boundaries and the distribution of datapoints within subdomains for subdo-
mains from a ﬁtted distribution.

Tables 1 and 2 describe the ten subdomains with raw data and the ﬁtted distribution respec-
tively. Table 2 reveals that the ﬁtted distribution does not suﬃciently capture the heavy weighting

3

501001502000.020.040.060.080.10.12Maximum Likelihood Distribution for Each Cluster2004006008001000120014000.0050.010.0150.020.02511.5×1042468101214×10-41.522.533.5×1040.511.52×10-3020004000012345678×10-3050001000000.511.522.5×10-3Figure 5: Classiﬁer performance vs γ and C. One region of the broader heatmap is magniﬁed for higher
granularity.

towards 0 since 44% of the data is falling into what we hoped was a 10% probability domain.
Keeping in mind that the goal of this subdomain split is to ﬁnd a meaningful set of lables, the
choice between the two options is up to which domains seem more meaningful to a future user. We
created two classiﬁers – one for each label set.

We used two diﬀerent classiﬁcation algorithms: SVM with a (Gaussian) radial basis kernel and

softmax regression. The SVM optimization problem is as follows [3, 4, 5]:

m(cid:88)

||w||2 + C

1
2

min
γ,w,b
s.t.y(i)(wT x(i) + b) ≥ 1 − ξi,

i=1

ξi

ξi ≥ 0,

i = 1, ..., m

(cid:16)−(cid:107)x−z(cid:107)2

(cid:17)

i = 1, ..., m

. This kernel function implicitly moves the
With the kernel function K(x, z) = exp
feature set to a high dimensional space where the optimal margin between classes is larger and
better ﬁt by a linear equation than in the original, low dimentional space.

2σ2

Softmax regression is a GLM that can be run on a multinomial dataset. In class we saw that if we
eηi(cid:80)k
dummy coded our labels (with one being a reference label), then we could express the multinomial
distribution as a member of the exponential family. The softmax function, φi =
j=1 eηj , where
η is the natural parameter and k is the number of labels, is found to describe the conditional
distribution of y given x :

p(y = i|x; θ) =

eηi(cid:80)k

j=1 eηj

i x(cid:80)k

eθT
j=1 eθT
j x

=

With this conditional probablity we are able to estimate the probablity of a certain feature set
falling into each category, i.

4 Results
SVM with a radial kernel performed signiﬁcantly better than any other tested alternative so this
section highlights only those results on the empirically decided equal-probability labels. The pa-
rameters γ and C changed the predication accuracy as they varied so ﬁgure 5 highlights the process

4

Figure 6: The accuracy of the SVM classiﬁer using empirical labels with the sequential addition of features
and the training/test error vs dataset size.

of ﬁrst training and 5-fold validating on a rough range of the two, then zooming in for ﬁner changes
to ﬁnd an ideal pair of values at γ = 1.9 × 10−6 and C = 4.2 × 106.

Figure 6 shows the training and test error with respect to training set size with the peak γ
and C pair as well as the eﬀect of each feature on prediction accuracy as the features are added
in one by one. Since space is scarce, suﬃce to say we have corresponding plots of ﬁgures 5 and 6
for the ﬁtted-distribution-deﬁned equal probability labels. The baseline accuracy (i.e. predicting
label 1 every time) is 44% while the peak accuracy with all features present is about 95%. Using
other classiﬁers – softmax regression, linear SVM kernel, 3rd degree polynomial SVM kernel, and
sigmoid SVM kernel – we had prediction accuracies 43%, 35%, 34%, and 9% respectively.

5 Conclusion & Future Work

It would be interesting to study the stationarity (or lack-there-of) of the UTXO Lifespan distribu-
tion (i.e. are typical spending habits varying over Bitcoin history?) Such information might help
with ﬁnding a better ﬁtting underlying distribution that would be more robust than relying on
equal-probability binning of raw data. Similarly, attempting to model the underlying distribution
as a mixture of Laplace distributions might make more sense than ﬁtting a set of adjacent clusters
with individual distributions. We started down that path and would like to acknowledge Junjie
Qin’s help but we were unable to bring it to a useful state. It would also be worth see how many
equal-probability bins we can meaningfully classify into (the more the better). Finally, two inter-
esting follow up projects would be to use this prediction tool to create expected volatility plots of
the Bitcoin market or pairing this predictor with de-anonymizing tools to form individual spending
models for clustered entities on the blockchain.

5

References

[1] S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” 2008.

[2] E. F. A. M. S. G. Arvind Narayanan, Joseph Bonneau, Bitcoin and Cryptocurrency Technologies.

2015.

[3] A. Ng, CS 229 Lecture Notes. 2015.

[4] C. wei Hsu, C. chung Chang, and C. jen Lin, “A practical guide to support vector classiﬁcation,”

2010.

[5] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2004.

6

