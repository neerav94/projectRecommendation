Seizure Prediction from

Intracranial EEG Recordings

Alex Fu, Spencer Gibbs, and Yuqi Liu

1

ternational Epilepsy Electrophysiology Portal
(www.ieeg.org) and hosted by Kaggle.com.

The competition provides iEEG datasets for
ﬁve dogs and two human subjects, each di-
vided into preictal training examples, interictal
training examples, and test examples. Each ex-
ample contains data collected by 15 electrodes
over a span of 10 minutes, with a sampling
frequency of 400Hz; therefore, each example
has a 15 x 240,000 matrix with voltage record-
ings of the 15 electrodes. Essentially, we have
3.6 million predictor variables for each data
set, with 480 data sets available for just one
of the subjects. The total amount of available
data, when uncompressed, is 99.3 Gb. With
such high dimensional data, our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability.
3 METHODS

W E ﬁrst applied feature selection tech-

niques and chose 3 summary statistics
as features, then applied logistic regression and
SVM for sample classiﬁcation.

!

1 INTRODUCTION

S EIZURE forecasting systems hold promise

for improving the quality of life for pa-
tients with epilepsy. One proposed forecasting
method relies on continuous intracranial elec-
troencephalography (iEEG) recording to look
for telltale feature sets in EEG data that suggest
imminent seizure threats. In order for EEG
–based seizure forecasting systems to work
effectively, computational algorithms must re-
liably identify periods of increased probability
of seizure occurrence. If a reasonably well-
performing algorithm could be implemented
to identify those periods, then it is possible
to warn patients only before seizures, enabling
them to live a close to normal life.

Recent research has shown that EEG signals
can be classiﬁed in four unique categories:
interictal (between seizures), preictal (immedi-
ately prior to seizure), ictal (during seizure)
and postictal (after seizure). In this project, we
applied machine learning algorithms to iden-
tify potential seizure occurrence using training
datasets collected from both dog and human
subjects. Speciﬁcally, we aimed to differentiate
between data collected during preictal and in-
terictal states, and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy.

Based on the results of the initial learning
algorithms used, we decided to run aditional
algorithms on the most promising features, in-
cluding dimension reduction using PCA anal-
ysis and support vector machines on the pre-
processed data.

2 DATA OVERVIEW

T HE data used in this project is provided

by the American Epilepsy Seizure Predic-
tion Contest, which is sponsored by the In-

3.1 Feature Extraction
We start with visually analyzing the raw data
to gain insights of the EEG signal characteris-
tics. A few initial features we looked at includ-
ing mean, variance, extreme values, period,

Seizure Prediction from

Intracranial EEG Recordings

Alex Fu, Spencer Gibbs, and Yuqi Liu

1

ternational Epilepsy Electrophysiology Portal
(www.ieeg.org) and hosted by Kaggle.com.

The competition provides iEEG datasets for
ﬁve dogs and two human subjects, each di-
vided into preictal training examples, interictal
training examples, and test examples. Each ex-
ample contains data collected by 15 electrodes
over a span of 10 minutes, with a sampling
frequency of 400Hz; therefore, each example
has a 15 x 240,000 matrix with voltage record-
ings of the 15 electrodes. Essentially, we have
3.6 million predictor variables for each data
set, with 480 data sets available for just one
of the subjects. The total amount of available
data, when uncompressed, is 99.3 Gb. With
such high dimensional data, our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability.
3 METHODS

W E ﬁrst applied feature selection tech-

niques and chose 3 summary statistics
as features, then applied logistic regression and
SVM for sample classiﬁcation.

!

1 INTRODUCTION

S EIZURE forecasting systems hold promise

for improving the quality of life for pa-
tients with epilepsy. One proposed forecasting
method relies on continuous intracranial elec-
troencephalography (iEEG) recording to look
for telltale feature sets in EEG data that suggest
imminent seizure threats. In order for EEG
–based seizure forecasting systems to work
effectively, computational algorithms must re-
liably identify periods of increased probability
of seizure occurrence. If a reasonably well-
performing algorithm could be implemented
to identify those periods, then it is possible
to warn patients only before seizures, enabling
them to live a close to normal life.

Recent research has shown that EEG signals
can be classiﬁed in four unique categories:
interictal (between seizures), preictal (immedi-
ately prior to seizure), ictal (during seizure)
and postictal (after seizure). In this project, we
applied machine learning algorithms to iden-
tify potential seizure occurrence using training
datasets collected from both dog and human
subjects. Speciﬁcally, we aimed to differentiate
between data collected during preictal and in-
terictal states, and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy.

Based on the results of the initial learning
algorithms used, we decided to run aditional
algorithms on the most promising features, in-
cluding dimension reduction using PCA anal-
ysis and support vector machines on the pre-
processed data.

2 DATA OVERVIEW

T HE data used in this project is provided

by the American Epilepsy Seizure Predic-
tion Contest, which is sponsored by the In-

3.1 Feature Extraction
We start with visually analyzing the raw data
to gain insights of the EEG signal characteris-
tics. A few initial features we looked at includ-
ing mean, variance, extreme values, period,

2

Let the sequence x(n) be a preprocessed
and fused input signal, then the instantaneous
energy is given by x(n)2. Considering that a
sliding window is used, the energy of the signal
becomes the average power over the window
mathematically deﬁned as

nN(cid:88)

E[n] =

1
N

x(i)2

i=(n−1)N +1

Fig. 1. Extreme value-related feature. Shows
30 positive (i.e. preictal) (blue) and 30 negative
(red) training examples. The x-axis denotes the
number of examples. For every example, we
compute the number of EEG values that fall
within the 10th to 90th percentile range of all
15 electrodes. From the diagram we can see
the blue labeled positive training examples in
general have lower deviations of extreme values
from the mean.

and spectral energy distribution derived from
Fourier transformations. For example, ﬁgure 1
shows an extreme value related feature and
how value of that feature differs among pos-
itive and negative training examples.

Based on these ﬁrst observations and pre-
vious research in literature, we decided to
use a two-step approach for feature extraction.
We ﬁrst extracted ﬁrst-level features from the
raw data, then extracted second-level features
from ﬁrst-level features, and ﬁnally trained the
model and based predictions using the second-
level features.

3.1.1 First-level features
We implemented several ﬁrst-level features, in-
cluding curve length, energy, spectral entropy,
and energy of wavelet packets. The result is
that the signal energy best differentiates be-
tween positive and negative samples while
maintaining the information of the original raw
data. A detailed implementation is as follow-
ing.

where N is the size of the sliding window
expressed in number of points, range from 1
to 15; n is the discrete time index, range from
1 to 239766 in our data samples.

3.1.2 Second-level features
To generate prediction indicators we extracted
20 different second-level features from the ﬁrst-
level features for each sample. These included
sample minimum, maximum, median, mean,
variance, standard deviation, skewness, kurto-
sis, slope, geometric mean, trapez, sum and
derivative. Some of these features did not nec-
essarily give good results initially, but we keep
them in the list for developing the objective
feature vector.

3.2 Feature Selection
We started with the ﬁlters and wrappers
method for feature selection, and ﬁnalized with
the minimum Redundancy Maximum Rele-
vance (mRMR) algorithm (Ding and Peng,
2005). The algorithm ranks a set of features
minimizing the redundancy among the subset
of features while maximizing the relevance of
the features. It ﬁrst runs an F-test as a relevance
measure, and then a computation of the Pear-
son’s correlation as a redundancy measure. Af-
ter selecting the ﬁrst feature, it iterates through
the rest of the features and ranks them based
on mRMR score.

(cid:88)

j∈S

1
|S|

{F (i, s) − (

mRM Rscore = max
i∈ΩS

|c(i, j)|)}
(1)
Using this method, we select 4 features: norm
of variance, variance of variance, kurtosis, and
skewness.

Seizure Prediction from

Intracranial EEG Recordings

Alex Fu, Spencer Gibbs, and Yuqi Liu

1

ternational Epilepsy Electrophysiology Portal
(www.ieeg.org) and hosted by Kaggle.com.

The competition provides iEEG datasets for
ﬁve dogs and two human subjects, each di-
vided into preictal training examples, interictal
training examples, and test examples. Each ex-
ample contains data collected by 15 electrodes
over a span of 10 minutes, with a sampling
frequency of 400Hz; therefore, each example
has a 15 x 240,000 matrix with voltage record-
ings of the 15 electrodes. Essentially, we have
3.6 million predictor variables for each data
set, with 480 data sets available for just one
of the subjects. The total amount of available
data, when uncompressed, is 99.3 Gb. With
such high dimensional data, our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability.
3 METHODS

W E ﬁrst applied feature selection tech-

niques and chose 3 summary statistics
as features, then applied logistic regression and
SVM for sample classiﬁcation.

!

1 INTRODUCTION

S EIZURE forecasting systems hold promise

for improving the quality of life for pa-
tients with epilepsy. One proposed forecasting
method relies on continuous intracranial elec-
troencephalography (iEEG) recording to look
for telltale feature sets in EEG data that suggest
imminent seizure threats. In order for EEG
–based seizure forecasting systems to work
effectively, computational algorithms must re-
liably identify periods of increased probability
of seizure occurrence. If a reasonably well-
performing algorithm could be implemented
to identify those periods, then it is possible
to warn patients only before seizures, enabling
them to live a close to normal life.

Recent research has shown that EEG signals
can be classiﬁed in four unique categories:
interictal (between seizures), preictal (immedi-
ately prior to seizure), ictal (during seizure)
and postictal (after seizure). In this project, we
applied machine learning algorithms to iden-
tify potential seizure occurrence using training
datasets collected from both dog and human
subjects. Speciﬁcally, we aimed to differentiate
between data collected during preictal and in-
terictal states, and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy.

Based on the results of the initial learning
algorithms used, we decided to run aditional
algorithms on the most promising features, in-
cluding dimension reduction using PCA anal-
ysis and support vector machines on the pre-
processed data.

2 DATA OVERVIEW

T HE data used in this project is provided

by the American Epilepsy Seizure Predic-
tion Contest, which is sponsored by the In-

3.1 Feature Extraction
We start with visually analyzing the raw data
to gain insights of the EEG signal characteris-
tics. A few initial features we looked at includ-
ing mean, variance, extreme values, period,

2

Let the sequence x(n) be a preprocessed
and fused input signal, then the instantaneous
energy is given by x(n)2. Considering that a
sliding window is used, the energy of the signal
becomes the average power over the window
mathematically deﬁned as

nN(cid:88)

E[n] =

1
N

x(i)2

i=(n−1)N +1

Fig. 1. Extreme value-related feature. Shows
30 positive (i.e. preictal) (blue) and 30 negative
(red) training examples. The x-axis denotes the
number of examples. For every example, we
compute the number of EEG values that fall
within the 10th to 90th percentile range of all
15 electrodes. From the diagram we can see
the blue labeled positive training examples in
general have lower deviations of extreme values
from the mean.

and spectral energy distribution derived from
Fourier transformations. For example, ﬁgure 1
shows an extreme value related feature and
how value of that feature differs among pos-
itive and negative training examples.

Based on these ﬁrst observations and pre-
vious research in literature, we decided to
use a two-step approach for feature extraction.
We ﬁrst extracted ﬁrst-level features from the
raw data, then extracted second-level features
from ﬁrst-level features, and ﬁnally trained the
model and based predictions using the second-
level features.

3.1.1 First-level features
We implemented several ﬁrst-level features, in-
cluding curve length, energy, spectral entropy,
and energy of wavelet packets. The result is
that the signal energy best differentiates be-
tween positive and negative samples while
maintaining the information of the original raw
data. A detailed implementation is as follow-
ing.

where N is the size of the sliding window
expressed in number of points, range from 1
to 15; n is the discrete time index, range from
1 to 239766 in our data samples.

3.1.2 Second-level features
To generate prediction indicators we extracted
20 different second-level features from the ﬁrst-
level features for each sample. These included
sample minimum, maximum, median, mean,
variance, standard deviation, skewness, kurto-
sis, slope, geometric mean, trapez, sum and
derivative. Some of these features did not nec-
essarily give good results initially, but we keep
them in the list for developing the objective
feature vector.

3.2 Feature Selection
We started with the ﬁlters and wrappers
method for feature selection, and ﬁnalized with
the minimum Redundancy Maximum Rele-
vance (mRMR) algorithm (Ding and Peng,
2005). The algorithm ranks a set of features
minimizing the redundancy among the subset
of features while maximizing the relevance of
the features. It ﬁrst runs an F-test as a relevance
measure, and then a computation of the Pear-
son’s correlation as a redundancy measure. Af-
ter selecting the ﬁrst feature, it iterates through
the rest of the features and ranks them based
on mRMR score.

(cid:88)

j∈S

1
|S|

{F (i, s) − (

mRM Rscore = max
i∈ΩS

|c(i, j)|)}
(1)
Using this method, we select 4 features: norm
of variance, variance of variance, kurtosis, and
skewness.

3.3 PCA Variance Analysis
Because of the success with features based on
variance, we decided to do additional anal-
ysis on related features. Speciﬁcally, we ran
a dimension-reduction PCA analysis on each
traning example available from one of the dog
subjects (dog 5).

For each of the 450 interictal and 30 preictal
10-minute segments available, we ﬁrst normal-
ized the data and calculated its covariance
matrix to get its eigenvector basis. The data was
then projected onto each basis element, and the
variance across the vector was calculated. The
resulting feature vector contains the variance
along each of the 15 principle components.

Next we ran various SVM algorithms using
different kernels over differenct combinations
of the feature set,
including comparing the
top two principle component variances, top
three, and all 15. The kernels used included the
standard linear kernel, and the gaussian (radial
basis function) kernel. The beneﬁt of using the
rbf kernel is that it projects the data into an
inﬁnite-dimensional space without requiring
much additional computation cost. Generally
it is easier to get better separation of data in
higher dimensions.

K(x, z) = e

(cid:107)x−z(cid:107)2

2σ2

(2)

Because of the large quantity of negative
(interictal) data and relatively small amount of
preictal data, we added L1 regularization and
weighted the preictal data regulatization terms
heavily compared to the interictal values. Then
we adjusted the decision boundary so that the
error rate of predicting (rare) preictal events
was within ten percent of the error rate of
predicting (common) interictal events.

In order to test training error vs testing error,
we cross validated using a 70%/30% training
data to test data ratio, leaving 315 interictal
and 21 preictal data sets for training, and 135
interictal and 9 preictal data sets for testing.

4 RESULTS

T HE results shown in table 1 are obtained

from learning on 114 labeled training sam-
ples (30 positive) on 2 dog subjects. The learned

3

parameters are then used to predict labels of
78 additional samples for the same 2 dogs.
It appears that a RBF (Gaussian) kernel SVM
with cost adjustment towards avoiding false
negatives gives the best results.

TABLE 1

Training and Testing Error Rates of

Second-Level Features

Model

False neg
(Train)
Log. Reg.
13.3%
Lin. SVM 10.0%
RBF SVM 13.3%
RBF
SVM+CA*

6.7%

False pos
(Train)
17.2%
29.8%
10.7%

False neg
(Test)
16.7%
11.1%
14.8%

False pos
(Test)
27.8%
48.1%
16.7%

16.7%

9.3%

24.1%

4.1 PCA Variance Results
Please see table 2 and the following ﬁgures for
PCA results. The data is taken from dog subject
5, using 315 interictal and 21 preictal samples
for training and 135 interictal and 9 preictal
samples for testing.

Training and Testing Error Rates of PCA

TABLE 2

Variance

Model

Lin. SVM
kernel-2d
RBF SVM
kernel-2d
σ = 1
RBF SVM
kernel-2d
σ = 10
RBF SVM
kernel-3d
σ = 0.8
RBF SVM
kernel-15d
σ = 1

False neg
(Train)

False pos
(Train)

False neg
(Test)

False pos
(Test)

22.2%

19.2%

17.1%

16.0%

5.6%

0.7%

82.7%

82.0%

25.0%

21.1%

0.7%

85.7%

16.0%

13.0%

0.7%

80.4%

46.2%

0.6%

5.6%

10.0%

5 DISCUSSION
One interesting observation is how good vari-
ance is in differentiating preictal and interic-
tal samples; and contrary to our initial guess

Seizure Prediction from

Intracranial EEG Recordings

Alex Fu, Spencer Gibbs, and Yuqi Liu

1

ternational Epilepsy Electrophysiology Portal
(www.ieeg.org) and hosted by Kaggle.com.

The competition provides iEEG datasets for
ﬁve dogs and two human subjects, each di-
vided into preictal training examples, interictal
training examples, and test examples. Each ex-
ample contains data collected by 15 electrodes
over a span of 10 minutes, with a sampling
frequency of 400Hz; therefore, each example
has a 15 x 240,000 matrix with voltage record-
ings of the 15 electrodes. Essentially, we have
3.6 million predictor variables for each data
set, with 480 data sets available for just one
of the subjects. The total amount of available
data, when uncompressed, is 99.3 Gb. With
such high dimensional data, our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability.
3 METHODS

W E ﬁrst applied feature selection tech-

niques and chose 3 summary statistics
as features, then applied logistic regression and
SVM for sample classiﬁcation.

!

1 INTRODUCTION

S EIZURE forecasting systems hold promise

for improving the quality of life for pa-
tients with epilepsy. One proposed forecasting
method relies on continuous intracranial elec-
troencephalography (iEEG) recording to look
for telltale feature sets in EEG data that suggest
imminent seizure threats. In order for EEG
–based seizure forecasting systems to work
effectively, computational algorithms must re-
liably identify periods of increased probability
of seizure occurrence. If a reasonably well-
performing algorithm could be implemented
to identify those periods, then it is possible
to warn patients only before seizures, enabling
them to live a close to normal life.

Recent research has shown that EEG signals
can be classiﬁed in four unique categories:
interictal (between seizures), preictal (immedi-
ately prior to seizure), ictal (during seizure)
and postictal (after seizure). In this project, we
applied machine learning algorithms to iden-
tify potential seizure occurrence using training
datasets collected from both dog and human
subjects. Speciﬁcally, we aimed to differentiate
between data collected during preictal and in-
terictal states, and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy.

Based on the results of the initial learning
algorithms used, we decided to run aditional
algorithms on the most promising features, in-
cluding dimension reduction using PCA anal-
ysis and support vector machines on the pre-
processed data.

2 DATA OVERVIEW

T HE data used in this project is provided

by the American Epilepsy Seizure Predic-
tion Contest, which is sponsored by the In-

3.1 Feature Extraction
We start with visually analyzing the raw data
to gain insights of the EEG signal characteris-
tics. A few initial features we looked at includ-
ing mean, variance, extreme values, period,

2

Let the sequence x(n) be a preprocessed
and fused input signal, then the instantaneous
energy is given by x(n)2. Considering that a
sliding window is used, the energy of the signal
becomes the average power over the window
mathematically deﬁned as

nN(cid:88)

E[n] =

1
N

x(i)2

i=(n−1)N +1

Fig. 1. Extreme value-related feature. Shows
30 positive (i.e. preictal) (blue) and 30 negative
(red) training examples. The x-axis denotes the
number of examples. For every example, we
compute the number of EEG values that fall
within the 10th to 90th percentile range of all
15 electrodes. From the diagram we can see
the blue labeled positive training examples in
general have lower deviations of extreme values
from the mean.

and spectral energy distribution derived from
Fourier transformations. For example, ﬁgure 1
shows an extreme value related feature and
how value of that feature differs among pos-
itive and negative training examples.

Based on these ﬁrst observations and pre-
vious research in literature, we decided to
use a two-step approach for feature extraction.
We ﬁrst extracted ﬁrst-level features from the
raw data, then extracted second-level features
from ﬁrst-level features, and ﬁnally trained the
model and based predictions using the second-
level features.

3.1.1 First-level features
We implemented several ﬁrst-level features, in-
cluding curve length, energy, spectral entropy,
and energy of wavelet packets. The result is
that the signal energy best differentiates be-
tween positive and negative samples while
maintaining the information of the original raw
data. A detailed implementation is as follow-
ing.

where N is the size of the sliding window
expressed in number of points, range from 1
to 15; n is the discrete time index, range from
1 to 239766 in our data samples.

3.1.2 Second-level features
To generate prediction indicators we extracted
20 different second-level features from the ﬁrst-
level features for each sample. These included
sample minimum, maximum, median, mean,
variance, standard deviation, skewness, kurto-
sis, slope, geometric mean, trapez, sum and
derivative. Some of these features did not nec-
essarily give good results initially, but we keep
them in the list for developing the objective
feature vector.

3.2 Feature Selection
We started with the ﬁlters and wrappers
method for feature selection, and ﬁnalized with
the minimum Redundancy Maximum Rele-
vance (mRMR) algorithm (Ding and Peng,
2005). The algorithm ranks a set of features
minimizing the redundancy among the subset
of features while maximizing the relevance of
the features. It ﬁrst runs an F-test as a relevance
measure, and then a computation of the Pear-
son’s correlation as a redundancy measure. Af-
ter selecting the ﬁrst feature, it iterates through
the rest of the features and ranks them based
on mRMR score.

(cid:88)

j∈S

1
|S|

{F (i, s) − (

mRM Rscore = max
i∈ΩS

|c(i, j)|)}
(1)
Using this method, we select 4 features: norm
of variance, variance of variance, kurtosis, and
skewness.

3.3 PCA Variance Analysis
Because of the success with features based on
variance, we decided to do additional anal-
ysis on related features. Speciﬁcally, we ran
a dimension-reduction PCA analysis on each
traning example available from one of the dog
subjects (dog 5).

For each of the 450 interictal and 30 preictal
10-minute segments available, we ﬁrst normal-
ized the data and calculated its covariance
matrix to get its eigenvector basis. The data was
then projected onto each basis element, and the
variance across the vector was calculated. The
resulting feature vector contains the variance
along each of the 15 principle components.

Next we ran various SVM algorithms using
different kernels over differenct combinations
of the feature set,
including comparing the
top two principle component variances, top
three, and all 15. The kernels used included the
standard linear kernel, and the gaussian (radial
basis function) kernel. The beneﬁt of using the
rbf kernel is that it projects the data into an
inﬁnite-dimensional space without requiring
much additional computation cost. Generally
it is easier to get better separation of data in
higher dimensions.

K(x, z) = e

(cid:107)x−z(cid:107)2

2σ2

(2)

Because of the large quantity of negative
(interictal) data and relatively small amount of
preictal data, we added L1 regularization and
weighted the preictal data regulatization terms
heavily compared to the interictal values. Then
we adjusted the decision boundary so that the
error rate of predicting (rare) preictal events
was within ten percent of the error rate of
predicting (common) interictal events.

In order to test training error vs testing error,
we cross validated using a 70%/30% training
data to test data ratio, leaving 315 interictal
and 21 preictal data sets for training, and 135
interictal and 9 preictal data sets for testing.

4 RESULTS

T HE results shown in table 1 are obtained

from learning on 114 labeled training sam-
ples (30 positive) on 2 dog subjects. The learned

3

parameters are then used to predict labels of
78 additional samples for the same 2 dogs.
It appears that a RBF (Gaussian) kernel SVM
with cost adjustment towards avoiding false
negatives gives the best results.

TABLE 1

Training and Testing Error Rates of

Second-Level Features

Model

False neg
(Train)
Log. Reg.
13.3%
Lin. SVM 10.0%
RBF SVM 13.3%
RBF
SVM+CA*

6.7%

False pos
(Train)
17.2%
29.8%
10.7%

False neg
(Test)
16.7%
11.1%
14.8%

False pos
(Test)
27.8%
48.1%
16.7%

16.7%

9.3%

24.1%

4.1 PCA Variance Results
Please see table 2 and the following ﬁgures for
PCA results. The data is taken from dog subject
5, using 315 interictal and 21 preictal samples
for training and 135 interictal and 9 preictal
samples for testing.

Training and Testing Error Rates of PCA

TABLE 2

Variance

Model

Lin. SVM
kernel-2d
RBF SVM
kernel-2d
σ = 1
RBF SVM
kernel-2d
σ = 10
RBF SVM
kernel-3d
σ = 0.8
RBF SVM
kernel-15d
σ = 1

False neg
(Train)

False pos
(Train)

False neg
(Test)

False pos
(Test)

22.2%

19.2%

17.1%

16.0%

5.6%

0.7%

82.7%

82.0%

25.0%

21.1%

0.7%

85.7%

16.0%

13.0%

0.7%

80.4%

46.2%

0.6%

5.6%

10.0%

5 DISCUSSION
One interesting observation is how good vari-
ance is in differentiating preictal and interic-
tal samples; and contrary to our initial guess

4

Fig. 2. Normalized Variance On First Two Prin-
ciple Components

Fig. 4. Normalized Variance On First Two Princi-
ple Components, with Gaussian Kernel Support
Boundaries, σ = 1

Fig. 5. Normalized Variance On First Three Prin-
ciple Components with Gaussian Kernel Sup-
port Boundaries, σ = 0.8

Fig. 3. Normalized Variance On First Two Prin-
ciple Components, with Linear Kernel Support
Boundaries

that iEEG recordings should ﬂuctuate more
right before seizures strike, variance actually
tends to actually attenuate. In the implemen-
tation process, we also found that simpler fea-
tures, like nth moments of the data, actually
served as better features than those obtained
through more complex transformations like
Fourier Transform.

The learning results are promising, with only

9.3% false negative and 24.1% false positive
after cost adjustment. But in practical use, those
error rates are still way too high. This is partly
due to the limitation on computing power -
given the massive size of each sample (3.6 mil-
lion recordings), it takes a signiﬁcant amount of
time to process more than 30 data samples at a
time; another limitation is our somewhat super-
ﬁcial understanding of the iEEG data structure
- with better understanding of the data, we
could probably develop features better reﬂect-
ing the deep structure of the recordings, such as
ones on potential shape changes when entering

Seizure Prediction from

Intracranial EEG Recordings

Alex Fu, Spencer Gibbs, and Yuqi Liu

1

ternational Epilepsy Electrophysiology Portal
(www.ieeg.org) and hosted by Kaggle.com.

The competition provides iEEG datasets for
ﬁve dogs and two human subjects, each di-
vided into preictal training examples, interictal
training examples, and test examples. Each ex-
ample contains data collected by 15 electrodes
over a span of 10 minutes, with a sampling
frequency of 400Hz; therefore, each example
has a 15 x 240,000 matrix with voltage record-
ings of the 15 electrodes. Essentially, we have
3.6 million predictor variables for each data
set, with 480 data sets available for just one
of the subjects. The total amount of available
data, when uncompressed, is 99.3 Gb. With
such high dimensional data, our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability.
3 METHODS

W E ﬁrst applied feature selection tech-

niques and chose 3 summary statistics
as features, then applied logistic regression and
SVM for sample classiﬁcation.

!

1 INTRODUCTION

S EIZURE forecasting systems hold promise

for improving the quality of life for pa-
tients with epilepsy. One proposed forecasting
method relies on continuous intracranial elec-
troencephalography (iEEG) recording to look
for telltale feature sets in EEG data that suggest
imminent seizure threats. In order for EEG
–based seizure forecasting systems to work
effectively, computational algorithms must re-
liably identify periods of increased probability
of seizure occurrence. If a reasonably well-
performing algorithm could be implemented
to identify those periods, then it is possible
to warn patients only before seizures, enabling
them to live a close to normal life.

Recent research has shown that EEG signals
can be classiﬁed in four unique categories:
interictal (between seizures), preictal (immedi-
ately prior to seizure), ictal (during seizure)
and postictal (after seizure). In this project, we
applied machine learning algorithms to iden-
tify potential seizure occurrence using training
datasets collected from both dog and human
subjects. Speciﬁcally, we aimed to differentiate
between data collected during preictal and in-
terictal states, and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy.

Based on the results of the initial learning
algorithms used, we decided to run aditional
algorithms on the most promising features, in-
cluding dimension reduction using PCA anal-
ysis and support vector machines on the pre-
processed data.

2 DATA OVERVIEW

T HE data used in this project is provided

by the American Epilepsy Seizure Predic-
tion Contest, which is sponsored by the In-

3.1 Feature Extraction
We start with visually analyzing the raw data
to gain insights of the EEG signal characteris-
tics. A few initial features we looked at includ-
ing mean, variance, extreme values, period,

2

Let the sequence x(n) be a preprocessed
and fused input signal, then the instantaneous
energy is given by x(n)2. Considering that a
sliding window is used, the energy of the signal
becomes the average power over the window
mathematically deﬁned as

nN(cid:88)

E[n] =

1
N

x(i)2

i=(n−1)N +1

Fig. 1. Extreme value-related feature. Shows
30 positive (i.e. preictal) (blue) and 30 negative
(red) training examples. The x-axis denotes the
number of examples. For every example, we
compute the number of EEG values that fall
within the 10th to 90th percentile range of all
15 electrodes. From the diagram we can see
the blue labeled positive training examples in
general have lower deviations of extreme values
from the mean.

and spectral energy distribution derived from
Fourier transformations. For example, ﬁgure 1
shows an extreme value related feature and
how value of that feature differs among pos-
itive and negative training examples.

Based on these ﬁrst observations and pre-
vious research in literature, we decided to
use a two-step approach for feature extraction.
We ﬁrst extracted ﬁrst-level features from the
raw data, then extracted second-level features
from ﬁrst-level features, and ﬁnally trained the
model and based predictions using the second-
level features.

3.1.1 First-level features
We implemented several ﬁrst-level features, in-
cluding curve length, energy, spectral entropy,
and energy of wavelet packets. The result is
that the signal energy best differentiates be-
tween positive and negative samples while
maintaining the information of the original raw
data. A detailed implementation is as follow-
ing.

where N is the size of the sliding window
expressed in number of points, range from 1
to 15; n is the discrete time index, range from
1 to 239766 in our data samples.

3.1.2 Second-level features
To generate prediction indicators we extracted
20 different second-level features from the ﬁrst-
level features for each sample. These included
sample minimum, maximum, median, mean,
variance, standard deviation, skewness, kurto-
sis, slope, geometric mean, trapez, sum and
derivative. Some of these features did not nec-
essarily give good results initially, but we keep
them in the list for developing the objective
feature vector.

3.2 Feature Selection
We started with the ﬁlters and wrappers
method for feature selection, and ﬁnalized with
the minimum Redundancy Maximum Rele-
vance (mRMR) algorithm (Ding and Peng,
2005). The algorithm ranks a set of features
minimizing the redundancy among the subset
of features while maximizing the relevance of
the features. It ﬁrst runs an F-test as a relevance
measure, and then a computation of the Pear-
son’s correlation as a redundancy measure. Af-
ter selecting the ﬁrst feature, it iterates through
the rest of the features and ranks them based
on mRMR score.

(cid:88)

j∈S

1
|S|

{F (i, s) − (

mRM Rscore = max
i∈ΩS

|c(i, j)|)}
(1)
Using this method, we select 4 features: norm
of variance, variance of variance, kurtosis, and
skewness.

3.3 PCA Variance Analysis
Because of the success with features based on
variance, we decided to do additional anal-
ysis on related features. Speciﬁcally, we ran
a dimension-reduction PCA analysis on each
traning example available from one of the dog
subjects (dog 5).

For each of the 450 interictal and 30 preictal
10-minute segments available, we ﬁrst normal-
ized the data and calculated its covariance
matrix to get its eigenvector basis. The data was
then projected onto each basis element, and the
variance across the vector was calculated. The
resulting feature vector contains the variance
along each of the 15 principle components.

Next we ran various SVM algorithms using
different kernels over differenct combinations
of the feature set,
including comparing the
top two principle component variances, top
three, and all 15. The kernels used included the
standard linear kernel, and the gaussian (radial
basis function) kernel. The beneﬁt of using the
rbf kernel is that it projects the data into an
inﬁnite-dimensional space without requiring
much additional computation cost. Generally
it is easier to get better separation of data in
higher dimensions.

K(x, z) = e

(cid:107)x−z(cid:107)2

2σ2

(2)

Because of the large quantity of negative
(interictal) data and relatively small amount of
preictal data, we added L1 regularization and
weighted the preictal data regulatization terms
heavily compared to the interictal values. Then
we adjusted the decision boundary so that the
error rate of predicting (rare) preictal events
was within ten percent of the error rate of
predicting (common) interictal events.

In order to test training error vs testing error,
we cross validated using a 70%/30% training
data to test data ratio, leaving 315 interictal
and 21 preictal data sets for training, and 135
interictal and 9 preictal data sets for testing.

4 RESULTS

T HE results shown in table 1 are obtained

from learning on 114 labeled training sam-
ples (30 positive) on 2 dog subjects. The learned

3

parameters are then used to predict labels of
78 additional samples for the same 2 dogs.
It appears that a RBF (Gaussian) kernel SVM
with cost adjustment towards avoiding false
negatives gives the best results.

TABLE 1

Training and Testing Error Rates of

Second-Level Features

Model

False neg
(Train)
Log. Reg.
13.3%
Lin. SVM 10.0%
RBF SVM 13.3%
RBF
SVM+CA*

6.7%

False pos
(Train)
17.2%
29.8%
10.7%

False neg
(Test)
16.7%
11.1%
14.8%

False pos
(Test)
27.8%
48.1%
16.7%

16.7%

9.3%

24.1%

4.1 PCA Variance Results
Please see table 2 and the following ﬁgures for
PCA results. The data is taken from dog subject
5, using 315 interictal and 21 preictal samples
for training and 135 interictal and 9 preictal
samples for testing.

Training and Testing Error Rates of PCA

TABLE 2

Variance

Model

Lin. SVM
kernel-2d
RBF SVM
kernel-2d
σ = 1
RBF SVM
kernel-2d
σ = 10
RBF SVM
kernel-3d
σ = 0.8
RBF SVM
kernel-15d
σ = 1

False neg
(Train)

False pos
(Train)

False neg
(Test)

False pos
(Test)

22.2%

19.2%

17.1%

16.0%

5.6%

0.7%

82.7%

82.0%

25.0%

21.1%

0.7%

85.7%

16.0%

13.0%

0.7%

80.4%

46.2%

0.6%

5.6%

10.0%

5 DISCUSSION
One interesting observation is how good vari-
ance is in differentiating preictal and interic-
tal samples; and contrary to our initial guess

4

Fig. 2. Normalized Variance On First Two Prin-
ciple Components

Fig. 4. Normalized Variance On First Two Princi-
ple Components, with Gaussian Kernel Support
Boundaries, σ = 1

Fig. 5. Normalized Variance On First Three Prin-
ciple Components with Gaussian Kernel Sup-
port Boundaries, σ = 0.8

Fig. 3. Normalized Variance On First Two Prin-
ciple Components, with Linear Kernel Support
Boundaries

that iEEG recordings should ﬂuctuate more
right before seizures strike, variance actually
tends to actually attenuate. In the implemen-
tation process, we also found that simpler fea-
tures, like nth moments of the data, actually
served as better features than those obtained
through more complex transformations like
Fourier Transform.

The learning results are promising, with only

9.3% false negative and 24.1% false positive
after cost adjustment. But in practical use, those
error rates are still way too high. This is partly
due to the limitation on computing power -
given the massive size of each sample (3.6 mil-
lion recordings), it takes a signiﬁcant amount of
time to process more than 30 data samples at a
time; another limitation is our somewhat super-
ﬁcial understanding of the iEEG data structure
- with better understanding of the data, we
could probably develop features better reﬂect-
ing the deep structure of the recordings, such as
ones on potential shape changes when entering

preictal states.

5.1 PCA Variance
The results of the PCA variance analysis sup-
port the theory of reduced magnitudes of vari-
ance during preictal periods. Figure 2 shows
the normalized variance along the ﬁrst two
principle components. There does appear to
be some signiﬁcant structure to the data but
too much mixing to provide good preditability.
Noticibly most of the preictal data is in a
small low magnitude clump, conﬁrming the
previous results of comparitively low variance
in preictal data. Figure 3 shows the same data
with a linear SVM applied. Figure 4 shows the
same data with a gaussian (rbf) kernel on a
reduced data set (250 interictal, 30 preictal). By
applying the gaussian kernel we see that the
support boundaries can ﬂow around the data
more easily. However this may make it more
suseptable to overﬁtting.

Figure ?? shows the data comparing the ﬁrst
three principle component variances on 250
interictal and 30 preictal data sets. Figure 5
shows the same results with a gaussian kernel
applied. Again as in the 2d case the separation
is not very good, but also not without informa-
tion.

Table 2 shows the results of training and
testing error rates. Clearly the rates are far too
high for practical use since high positive error
rates would mean a patient would simply ig-
nore warnings after a while, and high negative
error rates mean we are missing dangerous
seizure events. It is interesting to note that the
covariance does show some degree of structure
suggesting the electrode signals are not inde-
pendent.

6 CONCLUSION

W E have shown a statistically signiﬁcant

corollation between iEEG signal vari-
ance and whether the subject is in an interictal
or preictal state. As a seizure approches it
seems that iEEG signals begin to die down
slightly into a muted state, before erupting
during the seizure. We found that variance,
variance of variance, skewedness and kertosis

5

were the best features based on a mRMR se-
lection algithm, and using a gaussian kernel
with a support vector machine generated the
best prediction error rates. Further analysis of
variance with PCA and gaussian kernel SVMs
conﬁrmed the reduced preictal variance result
and showed some structure in the signal co-
variance but did not generate any signiﬁcantly
better prediction error rates.
7 FUTURE WORK

I N addition to trying a wider range of fea-

tures, some other directions include addi-
tional dimensionality reduction to select only
relevant electrodes, and analysis of the 60 min
preitcal states as an integral period. Another
interesting direction would be to preprocess
the data after running ICA analysis on each
sample set. Suppose there were some domi-
nant source generators in the brain such as
some lobes or neural bundles whose activation
might signal seizure imminence. Additionally
suppose electrical signals add linearly so that
the signal received by each electrode is a linear
mapping from the signal generating neurons.
Then in running ICA we could extract the
source signal itself which then might be pro-
cessed further with Fourier analysis or other
techniques to look for something source-signal
speciﬁc. Another area we started to explore but
did not get results yet from is analyzing the
spectral composition of the signals. We would
like to look at the Fourier Transform of the
data and see how energy is distributed across
the power spectral density in interictal versus
preictal signals.
REFERENCES
[1] American Epilepsy Society Seizure Prediction Challenge. [On-

line]. Available: http://www.kaggle.com.

[2] Bruno Direito et al., Feature selection in high dimensional EEG
features spaces for epileptic seizure prediction, presented at the
18th IFAC World Congress, Milano, Italy, 2011.

[3] Maryann D’Alessandro et al. Epileptic Seizure Prediction
Using Hybrid Feature Selection Over Multiple Intracranial
EEG Electrode Contacts: A Report of Four Patients, in IEEE
Transactions on Biomedical Engineering, Vol. 50, No. 5,
2003, pp. 603-615.

[4] Hanchuan Peng, Fuhui Long, and Chris Ding. Feature selec-
tion based on mutual information: criteria of max-dependency,
max-relevance, and min-redundancy, in IEEE Transactions on
Pattern Analysis and Machine Intelligence, Vol. 27, No. 8,
pp.1226-1238, 2005.

