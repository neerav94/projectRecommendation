Medical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Medical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Figure 1. Example liver lesion, indicated by the red arrow,
in a CT scan.

Figure 2. A gradient vector, shown in black, intersecting a
histogram tile, shown in yellow.

Our dataset consists of 30 annotated liver lesions from
CT scans. The annotations provide a few points on the
boundary of each lesion, and were created by board-
certied radiologists. These annotations allow us to
extract features only from the lesions, disregarding
other image content.

Each CT scan contains a massive amount of data,
commonly having an (x, y, z) resolution of around
0.7Ã— 0.7Ã— 1.2mm. This is signicantly reduced by ex-
tracting the lesions, which may have a radius of around
20 voxels. Still, given our limited dataset, it is not
prudent to train on image data directly. Rather, we
extract a set of image features describing the shape
and texture of each lesion, allowing us to summarize
the relevant content in a low-dimensional space. The
following sections describe the two types of features
used for training.

3.1. SIFT3D features

The rst type of features are 3D image descriptors,
previously designed for a dierent work. Here I will
give a rough overview of their properties and moti-
vation, without delving into too much detail, as im-
age feature engineering is outside the scope of CS 229.
The features are a higher-dimensional analogue of the
Scale-Invariant Feature Transform from the computer
vision literature (Lowe, 2004).

The input to the feature extraction program is a set
of abdominal computed tomography (CT) scans, and
a set of annotations of the liver lesions in those scans.
The annotations are ordered sets of points tracing
the boundary of each lesion. We assign a coordinate
x = (x, y, z) and scale Ïƒ to each lesion by taking the
center and radius of the minimum bounding sphere of
the annotation points. Assuming the annotations scale
consistently with the images, the scale parameter en-
sures scale-invariance of the features.

It remains to extract the feature vectors. There are
many variants on this idea, but the approach used here

is an array of weighted histograms describing the dis-
tribution of image gradient orientations. That is, for
each pixel in some window W (cid:51) x, we approximate
the gradient of the image data âˆ‡Ix, and add this vec-
tor to a weighted histogram based on its orientation,
as shown in gure 2. In practice, this is a robust repre-
sentation of the shape of an object about a coordinate
x.

3.2. Haralick texture features

The second type of features are Haralick texture fea-
tures. These were originally developed by Haralick et
al. for classication of satellite images (Haralick et al.,
1973). Haralick used his simple texture features, to-
gether with piecewise linear regression, to accurately
classify land into several usage categories, such as city
and farmland.

Haralick's texture features are computed from a ma-
trix P , which is known as the gray-level co-occurence
matrix (GLCM). Its elements Pij give an estimate of
the probability that a pixel of intensity i neighbors one
of intensity j. Note that this joint probability distribu-
tion is discrete, which assumes that the image intensity
values are quantized. This is not terribly inaccurate,
as images are captured and stored in a quantized form.
Knowing this, it is straightforward to estimate these
probabilities as

Pij =

# pixels i neighboring pixels j

total # pixels

.

Note that this matrix is computed only within the le-
sion boundaries, as we are trying to describe only the
texture of the lesion itself. Here we have used an infor-
mal notation, as the concept of one pixel neighboring
another is quite easy to intuit, but less so to formalize
algebraically.

For our purposes, not enough to use the matrix P as
training input. Images are commonly quantized into
256 dierent intensity values, in which case P is of size

Medical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Figure 1. Example liver lesion, indicated by the red arrow,
in a CT scan.

Figure 2. A gradient vector, shown in black, intersecting a
histogram tile, shown in yellow.

Our dataset consists of 30 annotated liver lesions from
CT scans. The annotations provide a few points on the
boundary of each lesion, and were created by board-
certied radiologists. These annotations allow us to
extract features only from the lesions, disregarding
other image content.

Each CT scan contains a massive amount of data,
commonly having an (x, y, z) resolution of around
0.7Ã— 0.7Ã— 1.2mm. This is signicantly reduced by ex-
tracting the lesions, which may have a radius of around
20 voxels. Still, given our limited dataset, it is not
prudent to train on image data directly. Rather, we
extract a set of image features describing the shape
and texture of each lesion, allowing us to summarize
the relevant content in a low-dimensional space. The
following sections describe the two types of features
used for training.

3.1. SIFT3D features

The rst type of features are 3D image descriptors,
previously designed for a dierent work. Here I will
give a rough overview of their properties and moti-
vation, without delving into too much detail, as im-
age feature engineering is outside the scope of CS 229.
The features are a higher-dimensional analogue of the
Scale-Invariant Feature Transform from the computer
vision literature (Lowe, 2004).

The input to the feature extraction program is a set
of abdominal computed tomography (CT) scans, and
a set of annotations of the liver lesions in those scans.
The annotations are ordered sets of points tracing
the boundary of each lesion. We assign a coordinate
x = (x, y, z) and scale Ïƒ to each lesion by taking the
center and radius of the minimum bounding sphere of
the annotation points. Assuming the annotations scale
consistently with the images, the scale parameter en-
sures scale-invariance of the features.

It remains to extract the feature vectors. There are
many variants on this idea, but the approach used here

is an array of weighted histograms describing the dis-
tribution of image gradient orientations. That is, for
each pixel in some window W (cid:51) x, we approximate
the gradient of the image data âˆ‡Ix, and add this vec-
tor to a weighted histogram based on its orientation,
as shown in gure 2. In practice, this is a robust repre-
sentation of the shape of an object about a coordinate
x.

3.2. Haralick texture features

The second type of features are Haralick texture fea-
tures. These were originally developed by Haralick et
al. for classication of satellite images (Haralick et al.,
1973). Haralick used his simple texture features, to-
gether with piecewise linear regression, to accurately
classify land into several usage categories, such as city
and farmland.

Haralick's texture features are computed from a ma-
trix P , which is known as the gray-level co-occurence
matrix (GLCM). Its elements Pij give an estimate of
the probability that a pixel of intensity i neighbors one
of intensity j. Note that this joint probability distribu-
tion is discrete, which assumes that the image intensity
values are quantized. This is not terribly inaccurate,
as images are captured and stored in a quantized form.
Knowing this, it is straightforward to estimate these
probabilities as

Pij =

# pixels i neighboring pixels j

total # pixels

.

Note that this matrix is computed only within the le-
sion boundaries, as we are trying to describe only the
texture of the lesion itself. Here we have used an infor-
mal notation, as the concept of one pixel neighboring
another is quite easy to intuit, but less so to formalize
algebraically.

For our purposes, not enough to use the matrix P as
training input. Images are commonly quantized into
256 dierent intensity values, in which case P is of size

Contrast Correlation Energy Homogeneity

.36

.92

.46

.97

Table 1. Texture features for the lesion from gure 1.

considers only the relationship between the query im-
age and an individual training data point.
In total,
this yields m distinct regression problems, each with
m training examples (x(j), Aij).

256 Ã— 256. This large matrix could hardly be called a
summary of the image data. Thus, Haralick computed
a feature vector of statistics summarizing the content
of P :

Contrast =

Correlation =

Energy =

Homogeneity =

ij

(cid:88)
(cid:88)
(cid:88)
(cid:88)

ij

ij

ij

Pij|i âˆ’ j|2

(i âˆ’ Âµi)(j âˆ’ Âµj)

ÏƒiÏƒj

Pij

P 2
ij

Pij

1 + |i âˆ’ j|

where Âµi, Ïƒi, Âµj, Ïƒj are the mean and standard devia-
tion of the marginal distributions Pi, Pj, respectively.
Note that Haralick originally dened 13 dierent tex-
ture features, but we list only those used in this work.
We refer the reader to the original article for the in-
terpretation of these features (Haralick et al., 1973).

As an example, table 1 shows the four texture features
for the lesion from gure 1.

4. Learning algorithm

Having described the dataset and features, we will now
formally express the goals of the CBIR system, and de-
rive a machine learning algorithm approximating those
goals. Section 4.1 describes the ranking problem and
quantication of ranking accuracy, while section 4.2
describes a regression algorithm for predicting the rel-
evance scores.

4.1. Ranking overview

Having extracted image features, it remains to use ma-
chine learning to assign search rankings to a query
point. Given a query feature vector, we must generate
a permutation of the vector (1, 2, ..., m) ranking the m
training features in terms of relevance to the query,
where 1 is the most relevant and m the least.

To this end, we derive the following supervised learn-
ing algorithm: given a query feature x, predict the
relevance to each training feature x(i). Then, com-
pute the search ranking function rj(x) by sorting the
relevance scores.
In the literature, this is known as
the point-wise approach to the ranking problem, as it

The sorting step is justied upon considering the
goal of the learning algorithm. Our objective is to
maximize the normalized discounted cumulative gain
(NDCG) from cross-validation. NDCG is a widely-
used measure of search performance. First, dene the
discounted cumulative gain (DCG) of the jth query as

p(cid:88)

i=1

2yi âˆ’ 1
log2(i + 1)

DCGj =

where yi = Arj (i),j is the relevance score of the ith
result in the jth query.

Having dened the DCG, the NDCG is simply

NDCGj =

DCGj
âˆ—
DCG
j

,

âˆ—
j is given by the optimal ranking function
where DCG
for the jth query. From here, it is clear that, given
a set of predicted relevance scores, sorting the scores
yields the optimal NDCG.

4.2. Regression for optimal ranking

In the previous section, we described a machine learn-
ing approach to ranking using m distinct regression
problems. In this section, we will formalize the regres-
sion problem in an attempt to achieve optimal ranking.
We will see that, for most datasets, optimal ranking is
not possible within our framework, and instead strike
a compromise between data delity and ranking sub-
optimality.

4.2.1. Pairwise distance features

Before delving into the specics of the ranking prob-
lem, we note a useful transformation of the image fea-
tures specic to this application. Given a query im-
age, we wish to predict its similarity to a training im-
age. Thus, it is not the image features themselves that
are of interest, but the dierences between them. We
therefore dene a new feature vector as follows:
let
qs, ts âˆˆ R768 be the SIFT3D features from the query
lesion q and the training lesion t, respectively. Sim-
ilarly, let qt1, ..., tt4, qt1, ..., ty be the four texture fea-
tures from the query and training images, respectively.
Then, the pairwise distance feature vector x is com-
puted as

x =(cid:0)(cid:107)qs âˆ’ ts(cid:107)2,

|qt1 âˆ’ tt2|,

...,

|qt4 âˆ’ tt4|(cid:1) .

Medical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Figure 1. Example liver lesion, indicated by the red arrow,
in a CT scan.

Figure 2. A gradient vector, shown in black, intersecting a
histogram tile, shown in yellow.

Our dataset consists of 30 annotated liver lesions from
CT scans. The annotations provide a few points on the
boundary of each lesion, and were created by board-
certied radiologists. These annotations allow us to
extract features only from the lesions, disregarding
other image content.

Each CT scan contains a massive amount of data,
commonly having an (x, y, z) resolution of around
0.7Ã— 0.7Ã— 1.2mm. This is signicantly reduced by ex-
tracting the lesions, which may have a radius of around
20 voxels. Still, given our limited dataset, it is not
prudent to train on image data directly. Rather, we
extract a set of image features describing the shape
and texture of each lesion, allowing us to summarize
the relevant content in a low-dimensional space. The
following sections describe the two types of features
used for training.

3.1. SIFT3D features

The rst type of features are 3D image descriptors,
previously designed for a dierent work. Here I will
give a rough overview of their properties and moti-
vation, without delving into too much detail, as im-
age feature engineering is outside the scope of CS 229.
The features are a higher-dimensional analogue of the
Scale-Invariant Feature Transform from the computer
vision literature (Lowe, 2004).

The input to the feature extraction program is a set
of abdominal computed tomography (CT) scans, and
a set of annotations of the liver lesions in those scans.
The annotations are ordered sets of points tracing
the boundary of each lesion. We assign a coordinate
x = (x, y, z) and scale Ïƒ to each lesion by taking the
center and radius of the minimum bounding sphere of
the annotation points. Assuming the annotations scale
consistently with the images, the scale parameter en-
sures scale-invariance of the features.

It remains to extract the feature vectors. There are
many variants on this idea, but the approach used here

is an array of weighted histograms describing the dis-
tribution of image gradient orientations. That is, for
each pixel in some window W (cid:51) x, we approximate
the gradient of the image data âˆ‡Ix, and add this vec-
tor to a weighted histogram based on its orientation,
as shown in gure 2. In practice, this is a robust repre-
sentation of the shape of an object about a coordinate
x.

3.2. Haralick texture features

The second type of features are Haralick texture fea-
tures. These were originally developed by Haralick et
al. for classication of satellite images (Haralick et al.,
1973). Haralick used his simple texture features, to-
gether with piecewise linear regression, to accurately
classify land into several usage categories, such as city
and farmland.

Haralick's texture features are computed from a ma-
trix P , which is known as the gray-level co-occurence
matrix (GLCM). Its elements Pij give an estimate of
the probability that a pixel of intensity i neighbors one
of intensity j. Note that this joint probability distribu-
tion is discrete, which assumes that the image intensity
values are quantized. This is not terribly inaccurate,
as images are captured and stored in a quantized form.
Knowing this, it is straightforward to estimate these
probabilities as

Pij =

# pixels i neighboring pixels j

total # pixels

.

Note that this matrix is computed only within the le-
sion boundaries, as we are trying to describe only the
texture of the lesion itself. Here we have used an infor-
mal notation, as the concept of one pixel neighboring
another is quite easy to intuit, but less so to formalize
algebraically.

For our purposes, not enough to use the matrix P as
training input. Images are commonly quantized into
256 dierent intensity values, in which case P is of size

Contrast Correlation Energy Homogeneity

.36

.92

.46

.97

Table 1. Texture features for the lesion from gure 1.

considers only the relationship between the query im-
age and an individual training data point.
In total,
this yields m distinct regression problems, each with
m training examples (x(j), Aij).

256 Ã— 256. This large matrix could hardly be called a
summary of the image data. Thus, Haralick computed
a feature vector of statistics summarizing the content
of P :

Contrast =

Correlation =

Energy =

Homogeneity =

ij

(cid:88)
(cid:88)
(cid:88)
(cid:88)

ij

ij

ij

Pij|i âˆ’ j|2

(i âˆ’ Âµi)(j âˆ’ Âµj)

ÏƒiÏƒj

Pij

P 2
ij

Pij

1 + |i âˆ’ j|

where Âµi, Ïƒi, Âµj, Ïƒj are the mean and standard devia-
tion of the marginal distributions Pi, Pj, respectively.
Note that Haralick originally dened 13 dierent tex-
ture features, but we list only those used in this work.
We refer the reader to the original article for the in-
terpretation of these features (Haralick et al., 1973).

As an example, table 1 shows the four texture features
for the lesion from gure 1.

4. Learning algorithm

Having described the dataset and features, we will now
formally express the goals of the CBIR system, and de-
rive a machine learning algorithm approximating those
goals. Section 4.1 describes the ranking problem and
quantication of ranking accuracy, while section 4.2
describes a regression algorithm for predicting the rel-
evance scores.

4.1. Ranking overview

Having extracted image features, it remains to use ma-
chine learning to assign search rankings to a query
point. Given a query feature vector, we must generate
a permutation of the vector (1, 2, ..., m) ranking the m
training features in terms of relevance to the query,
where 1 is the most relevant and m the least.

To this end, we derive the following supervised learn-
ing algorithm: given a query feature x, predict the
relevance to each training feature x(i). Then, com-
pute the search ranking function rj(x) by sorting the
relevance scores.
In the literature, this is known as
the point-wise approach to the ranking problem, as it

The sorting step is justied upon considering the
goal of the learning algorithm. Our objective is to
maximize the normalized discounted cumulative gain
(NDCG) from cross-validation. NDCG is a widely-
used measure of search performance. First, dene the
discounted cumulative gain (DCG) of the jth query as

p(cid:88)

i=1

2yi âˆ’ 1
log2(i + 1)

DCGj =

where yi = Arj (i),j is the relevance score of the ith
result in the jth query.

Having dened the DCG, the NDCG is simply

NDCGj =

DCGj
âˆ—
DCG
j

,

âˆ—
j is given by the optimal ranking function
where DCG
for the jth query. From here, it is clear that, given
a set of predicted relevance scores, sorting the scores
yields the optimal NDCG.

4.2. Regression for optimal ranking

In the previous section, we described a machine learn-
ing approach to ranking using m distinct regression
problems. In this section, we will formalize the regres-
sion problem in an attempt to achieve optimal ranking.
We will see that, for most datasets, optimal ranking is
not possible within our framework, and instead strike
a compromise between data delity and ranking sub-
optimality.

4.2.1. Pairwise distance features

Before delving into the specics of the ranking prob-
lem, we note a useful transformation of the image fea-
tures specic to this application. Given a query im-
age, we wish to predict its similarity to a training im-
age. Thus, it is not the image features themselves that
are of interest, but the dierences between them. We
therefore dene a new feature vector as follows:
let
qs, ts âˆˆ R768 be the SIFT3D features from the query
lesion q and the training lesion t, respectively. Sim-
ilarly, let qt1, ..., tt4, qt1, ..., ty be the four texture fea-
tures from the query and training images, respectively.
Then, the pairwise distance feature vector x is com-
puted as

x =(cid:0)(cid:107)qs âˆ’ ts(cid:107)2,

|qt1 âˆ’ tt2|,

...,

|qt4 âˆ’ tt4|(cid:1) .

Note that this is a nonlinear feature mapping from
the 772-dimensional
image feature space to a 5-
dimensional space. This mitigates overtting on our
small dataset. Furthermore, we have observed no per-
formance loss from this mapping.

4.2.2. Optimal Ranking

We wish to nd a mapping Ï† : Rn â†’ R such that
Ï†(x(i)) gives an optimal ranking. Rankings are ob-
tained by ordering Ï†(x(i)), such that x(i) is ranked
prior to x(j) if and only if Ï†(x(i)) > Ï†(x(j)). Let
x(1), y(1) denote the most relevant item, x(2), y(2) the
second-most, etc. In this notation, x is the pairwise
feature vector from section 4.2.1, and y is its corre-
sponding relevance score with respect to the train-
ing image. Any solution satisfying the following con-
straints will produce an optimal ranking:

where N is the number of training examples, z is a
vector of dummy variables, and Î±, Î² are constant pa-
rameters.

Let us dissect this algorithm. The rst term of the
objective is just the mean squared error of the pre-
dicted relevance scores. The dummy variables z are
constrained to lie within the set of ane regressors
giving no more than a Î²-suboptimal ranking. The
term(cid:107)a âˆ’ z(cid:107)2 gives the distance between the regres-
sor a and this Î²-suboptimal set. The parameter Î±
negotiates between the often-competing objectives of
data delity and optimal ranking.

This seemingly complicated model can be simplied.
In practice, we replace < with â‰¤, as most solvers
do not dierentiate between the two.
In this case,
if Î² = 0, the only feasible solution is often z = 0.
Substituting this into the objective, we have

Ï†(x(1)) > Ï†(x(2))

...

Ï†(x(Nâˆ’1) > Ï†(x(N )).

minimize

1
N

(cid:16)

aT x(i) + b âˆ’ y(i)(cid:17)2

N(cid:88)

i=1

+ Î±(cid:107)a(cid:107)2

(2)

Converting to standard form, we have
Ï†(x(iâˆ’1)) âˆ’ Ï†(x(i)) < 0.

This is a convex set if Ï†(x(i)) âˆ’ Ï†(x(j)) is a convex
function of the parameters of Ï†.
In the case that
Ï†(x) = aT x + b, we have

aT x(iâˆ’1) âˆ’ aT x(i) < 0
aT (x(iâˆ’1) âˆ’ x(i)) < 0

which is clearly convex.

4.2.3. Sub-optimal compromise

We have shown in section 4.2.2 that the set of ane
regressors resulting in an optimal ranking of the train-
ing set is convex. Thus, we can quickly nd a regressor
which optimally ranks the training set, if one exists.
However, this is not so useful in practice, as for most
datasets with more training examples than feature di-
mensions, there is no regressor satisfying these equa-
tions, i.e. the set of optimal regressors is empty. To
avoid this diculty, we must strike a compromise by
allowing some slack in the constraints.
In this case,
we would like to dierentiate between sub-optimal so-
lutions according to their delity to the training rele-
vance scores. Thus, we arrive at the following convex
optimization problem:

(cid:80)N

i=1

(cid:0)aT x(i) + b âˆ’ y(i)(cid:1)2

zT (x(2) âˆ’ x(1)) < Î²

+ Î±(cid:107)a âˆ’ z(cid:107)2

(1)

minimize

subject to

1
N

...

zT (x(N ) âˆ’ x(Nâˆ’1)) < Î²

which is just regularized linear regression. In fact, we
shall see in section 5 that our algorithm with reason-
ably small Î² performs essentially the same as regular-
ized linear regression. Note, however, that with Î² > 0
the optimal value of z is not necessarily z = 0, so the
algorithm is not identical to regularized linear regres-
sion.

5. Results

We computed the performance for a variety of sub-
samples of the training set, using leave-one-out cross-
validation. The cross-validation scheme is as fol-
lows: for each round, we withhold one lesion from the
dataset. Then, we train all N âˆ’ 1 regressors predicting
the relevance of a query image to each of the N âˆ’ 1
remaining training lesions. This is done without the
benet of the withheld lesion. Finally, we predict and
rank the similarities of the withheld lesion to each of
the N âˆ’ 1 training lesions. This gives the ranking re-
sults from a single query, from which we compute a
single NDCG. Repeat this process N times, each time
withholding a dierent lesion. The nal performance
estimate is the average NDCG over all N folds.

The parameters for our algorithm from problem 1 were
Î± = 0.1, Î² = 1. We solved the optimization problem
with CVX, a popular modeling tool for convex pro-
grams (Grant & Boyd, 2014). For comparison, we
computed three additional scores. The rst is the
worst possible NDCG for this data, averaged over all
folds, computed from the worst possible ranking. The
second is the score from the regularized linear regres-

Medical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Figure 1. Example liver lesion, indicated by the red arrow,
in a CT scan.

Figure 2. A gradient vector, shown in black, intersecting a
histogram tile, shown in yellow.

Our dataset consists of 30 annotated liver lesions from
CT scans. The annotations provide a few points on the
boundary of each lesion, and were created by board-
certied radiologists. These annotations allow us to
extract features only from the lesions, disregarding
other image content.

Each CT scan contains a massive amount of data,
commonly having an (x, y, z) resolution of around
0.7Ã— 0.7Ã— 1.2mm. This is signicantly reduced by ex-
tracting the lesions, which may have a radius of around
20 voxels. Still, given our limited dataset, it is not
prudent to train on image data directly. Rather, we
extract a set of image features describing the shape
and texture of each lesion, allowing us to summarize
the relevant content in a low-dimensional space. The
following sections describe the two types of features
used for training.

3.1. SIFT3D features

The rst type of features are 3D image descriptors,
previously designed for a dierent work. Here I will
give a rough overview of their properties and moti-
vation, without delving into too much detail, as im-
age feature engineering is outside the scope of CS 229.
The features are a higher-dimensional analogue of the
Scale-Invariant Feature Transform from the computer
vision literature (Lowe, 2004).

The input to the feature extraction program is a set
of abdominal computed tomography (CT) scans, and
a set of annotations of the liver lesions in those scans.
The annotations are ordered sets of points tracing
the boundary of each lesion. We assign a coordinate
x = (x, y, z) and scale Ïƒ to each lesion by taking the
center and radius of the minimum bounding sphere of
the annotation points. Assuming the annotations scale
consistently with the images, the scale parameter en-
sures scale-invariance of the features.

It remains to extract the feature vectors. There are
many variants on this idea, but the approach used here

is an array of weighted histograms describing the dis-
tribution of image gradient orientations. That is, for
each pixel in some window W (cid:51) x, we approximate
the gradient of the image data âˆ‡Ix, and add this vec-
tor to a weighted histogram based on its orientation,
as shown in gure 2. In practice, this is a robust repre-
sentation of the shape of an object about a coordinate
x.

3.2. Haralick texture features

The second type of features are Haralick texture fea-
tures. These were originally developed by Haralick et
al. for classication of satellite images (Haralick et al.,
1973). Haralick used his simple texture features, to-
gether with piecewise linear regression, to accurately
classify land into several usage categories, such as city
and farmland.

Haralick's texture features are computed from a ma-
trix P , which is known as the gray-level co-occurence
matrix (GLCM). Its elements Pij give an estimate of
the probability that a pixel of intensity i neighbors one
of intensity j. Note that this joint probability distribu-
tion is discrete, which assumes that the image intensity
values are quantized. This is not terribly inaccurate,
as images are captured and stored in a quantized form.
Knowing this, it is straightforward to estimate these
probabilities as

Pij =

# pixels i neighboring pixels j

total # pixels

.

Note that this matrix is computed only within the le-
sion boundaries, as we are trying to describe only the
texture of the lesion itself. Here we have used an infor-
mal notation, as the concept of one pixel neighboring
another is quite easy to intuit, but less so to formalize
algebraically.

For our purposes, not enough to use the matrix P as
training input. Images are commonly quantized into
256 dierent intensity values, in which case P is of size

Contrast Correlation Energy Homogeneity

.36

.92

.46

.97

Table 1. Texture features for the lesion from gure 1.

considers only the relationship between the query im-
age and an individual training data point.
In total,
this yields m distinct regression problems, each with
m training examples (x(j), Aij).

256 Ã— 256. This large matrix could hardly be called a
summary of the image data. Thus, Haralick computed
a feature vector of statistics summarizing the content
of P :

Contrast =

Correlation =

Energy =

Homogeneity =

ij

(cid:88)
(cid:88)
(cid:88)
(cid:88)

ij

ij

ij

Pij|i âˆ’ j|2

(i âˆ’ Âµi)(j âˆ’ Âµj)

ÏƒiÏƒj

Pij

P 2
ij

Pij

1 + |i âˆ’ j|

where Âµi, Ïƒi, Âµj, Ïƒj are the mean and standard devia-
tion of the marginal distributions Pi, Pj, respectively.
Note that Haralick originally dened 13 dierent tex-
ture features, but we list only those used in this work.
We refer the reader to the original article for the in-
terpretation of these features (Haralick et al., 1973).

As an example, table 1 shows the four texture features
for the lesion from gure 1.

4. Learning algorithm

Having described the dataset and features, we will now
formally express the goals of the CBIR system, and de-
rive a machine learning algorithm approximating those
goals. Section 4.1 describes the ranking problem and
quantication of ranking accuracy, while section 4.2
describes a regression algorithm for predicting the rel-
evance scores.

4.1. Ranking overview

Having extracted image features, it remains to use ma-
chine learning to assign search rankings to a query
point. Given a query feature vector, we must generate
a permutation of the vector (1, 2, ..., m) ranking the m
training features in terms of relevance to the query,
where 1 is the most relevant and m the least.

To this end, we derive the following supervised learn-
ing algorithm: given a query feature x, predict the
relevance to each training feature x(i). Then, com-
pute the search ranking function rj(x) by sorting the
relevance scores.
In the literature, this is known as
the point-wise approach to the ranking problem, as it

The sorting step is justied upon considering the
goal of the learning algorithm. Our objective is to
maximize the normalized discounted cumulative gain
(NDCG) from cross-validation. NDCG is a widely-
used measure of search performance. First, dene the
discounted cumulative gain (DCG) of the jth query as

p(cid:88)

i=1

2yi âˆ’ 1
log2(i + 1)

DCGj =

where yi = Arj (i),j is the relevance score of the ith
result in the jth query.

Having dened the DCG, the NDCG is simply

NDCGj =

DCGj
âˆ—
DCG
j

,

âˆ—
j is given by the optimal ranking function
where DCG
for the jth query. From here, it is clear that, given
a set of predicted relevance scores, sorting the scores
yields the optimal NDCG.

4.2. Regression for optimal ranking

In the previous section, we described a machine learn-
ing approach to ranking using m distinct regression
problems. In this section, we will formalize the regres-
sion problem in an attempt to achieve optimal ranking.
We will see that, for most datasets, optimal ranking is
not possible within our framework, and instead strike
a compromise between data delity and ranking sub-
optimality.

4.2.1. Pairwise distance features

Before delving into the specics of the ranking prob-
lem, we note a useful transformation of the image fea-
tures specic to this application. Given a query im-
age, we wish to predict its similarity to a training im-
age. Thus, it is not the image features themselves that
are of interest, but the dierences between them. We
therefore dene a new feature vector as follows:
let
qs, ts âˆˆ R768 be the SIFT3D features from the query
lesion q and the training lesion t, respectively. Sim-
ilarly, let qt1, ..., tt4, qt1, ..., ty be the four texture fea-
tures from the query and training images, respectively.
Then, the pairwise distance feature vector x is com-
puted as

x =(cid:0)(cid:107)qs âˆ’ ts(cid:107)2,

|qt1 âˆ’ tt2|,

...,

|qt4 âˆ’ tt4|(cid:1) .

Note that this is a nonlinear feature mapping from
the 772-dimensional
image feature space to a 5-
dimensional space. This mitigates overtting on our
small dataset. Furthermore, we have observed no per-
formance loss from this mapping.

4.2.2. Optimal Ranking

We wish to nd a mapping Ï† : Rn â†’ R such that
Ï†(x(i)) gives an optimal ranking. Rankings are ob-
tained by ordering Ï†(x(i)), such that x(i) is ranked
prior to x(j) if and only if Ï†(x(i)) > Ï†(x(j)). Let
x(1), y(1) denote the most relevant item, x(2), y(2) the
second-most, etc. In this notation, x is the pairwise
feature vector from section 4.2.1, and y is its corre-
sponding relevance score with respect to the train-
ing image. Any solution satisfying the following con-
straints will produce an optimal ranking:

where N is the number of training examples, z is a
vector of dummy variables, and Î±, Î² are constant pa-
rameters.

Let us dissect this algorithm. The rst term of the
objective is just the mean squared error of the pre-
dicted relevance scores. The dummy variables z are
constrained to lie within the set of ane regressors
giving no more than a Î²-suboptimal ranking. The
term(cid:107)a âˆ’ z(cid:107)2 gives the distance between the regres-
sor a and this Î²-suboptimal set. The parameter Î±
negotiates between the often-competing objectives of
data delity and optimal ranking.

This seemingly complicated model can be simplied.
In practice, we replace < with â‰¤, as most solvers
do not dierentiate between the two.
In this case,
if Î² = 0, the only feasible solution is often z = 0.
Substituting this into the objective, we have

Ï†(x(1)) > Ï†(x(2))

...

Ï†(x(Nâˆ’1) > Ï†(x(N )).

minimize

1
N

(cid:16)

aT x(i) + b âˆ’ y(i)(cid:17)2

N(cid:88)

i=1

+ Î±(cid:107)a(cid:107)2

(2)

Converting to standard form, we have
Ï†(x(iâˆ’1)) âˆ’ Ï†(x(i)) < 0.

This is a convex set if Ï†(x(i)) âˆ’ Ï†(x(j)) is a convex
function of the parameters of Ï†.
In the case that
Ï†(x) = aT x + b, we have

aT x(iâˆ’1) âˆ’ aT x(i) < 0
aT (x(iâˆ’1) âˆ’ x(i)) < 0

which is clearly convex.

4.2.3. Sub-optimal compromise

We have shown in section 4.2.2 that the set of ane
regressors resulting in an optimal ranking of the train-
ing set is convex. Thus, we can quickly nd a regressor
which optimally ranks the training set, if one exists.
However, this is not so useful in practice, as for most
datasets with more training examples than feature di-
mensions, there is no regressor satisfying these equa-
tions, i.e. the set of optimal regressors is empty. To
avoid this diculty, we must strike a compromise by
allowing some slack in the constraints.
In this case,
we would like to dierentiate between sub-optimal so-
lutions according to their delity to the training rele-
vance scores. Thus, we arrive at the following convex
optimization problem:

(cid:80)N

i=1

(cid:0)aT x(i) + b âˆ’ y(i)(cid:1)2

zT (x(2) âˆ’ x(1)) < Î²

+ Î±(cid:107)a âˆ’ z(cid:107)2

(1)

minimize

subject to

1
N

...

zT (x(N ) âˆ’ x(Nâˆ’1)) < Î²

which is just regularized linear regression. In fact, we
shall see in section 5 that our algorithm with reason-
ably small Î² performs essentially the same as regular-
ized linear regression. Note, however, that with Î² > 0
the optimal value of z is not necessarily z = 0, so the
algorithm is not identical to regularized linear regres-
sion.

5. Results

We computed the performance for a variety of sub-
samples of the training set, using leave-one-out cross-
validation. The cross-validation scheme is as fol-
lows: for each round, we withhold one lesion from the
dataset. Then, we train all N âˆ’ 1 regressors predicting
the relevance of a query image to each of the N âˆ’ 1
remaining training lesions. This is done without the
benet of the withheld lesion. Finally, we predict and
rank the similarities of the withheld lesion to each of
the N âˆ’ 1 training lesions. This gives the ranking re-
sults from a single query, from which we compute a
single NDCG. Repeat this process N times, each time
withholding a dierent lesion. The nal performance
estimate is the average NDCG over all N folds.

The parameters for our algorithm from problem 1 were
Î± = 0.1, Î² = 1. We solved the optimization problem
with CVX, a popular modeling tool for convex pro-
grams (Grant & Boyd, 2014). For comparison, we
computed three additional scores. The rst is the
worst possible NDCG for this data, averaged over all
folds, computed from the worst possible ranking. The
second is the score from the regularized linear regres-

In the future, we plan to extend the algorithmic ideas
from section 4.2. We might try adding features, or
mapping features to a higher-dimensional space, in an
attempt to produce a less-trivial optimal-ranking set.
Almost paradoxically, optimal ranking is guaranteed
only when the number of parameters equals or exceeds
the number of training elements, a cardinal sin of ma-
chine learning. The problem might be alleviated by
use of a more complicated regressor, but it is challeng-
ing to nd one for which the problem remains convex.

Another possible avenue of exploration is optimizing
over all regressors simultaneously. In this work we have
penalized the suboptimality of the ranking of a single
regressor. But since the outputs of dierent regressors
are directly compared in a search query, should not
we enforce optimal ranking across regressors as well?
We might also enforce symmetry between regressors,
i.e. aT
j xi + bj. There is no shortage
of avenues for exploration, but it is not clear which
are both nontrivial, i.e. more substantial than mere
regularization, and computationally tractable.

i xj + bi = aT

References

Glmnet.

at
http://web.stanford.edu/~hastie/glmnet_matlab/,
accessed November 13th, 2015.

Available

Akgul, Ceyhun Burak, Rubin, Daniel L., Napel,
Sandy, Beaulieu, Christopher F., Greenspan, Hayit,
and Acar, Burak. Content-based image retrieval
in radiology: Current status and future directions.
Journal of Digital Imaging, 24(2):208222, 2011.

de Gonzalez A, Berrington, M, Mahesh, K, Kim, and
et al. Projected cancer risks from computed tomo-
graphic scans performed in the united states in 2007.
Archives of Internal Medicine, 169(22):20712077,
2009. doi: 10.1001/archinternmed.2009.440.

Grant, Michael and Boyd, Stephen. CVX: Matlab soft-
ware for disciplined convex programming, version
2.1. http://cvxr.com/cvx, 2014.

Haralick, R.M., Shanmugam, K., and Dinstein,
Its'Hak. Textural features for image classication.
Systems, Man and Cybernetics, IEEE Transactions
on, SMC-3(6):610621, Nov 1973. ISSN 0018-9472.
doi: 10.1109/TSMC.1973.4309314.

Lowe, David G.

image

Distinctive
from scale-invariant keypoints.
Journal
November
10.1023/B:VISI.0000029664.99615.94.
http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94.

features
International
60(2):91110,
doi:
URL

of Computer Vision,

2004.

ISSN 0920-5691.

Figure 3. Mean NDCG for the various algorithms. Possible
scores range between the purple line and 1.

sion problem 2, which is trained by the GLMnet li-
brary, with cross-validation for the regularization pa-
rameter Î± (Glm). This shows the close relationship be-
tween regularized linear regression and our algorithm.
The third is an unsupervised algorithm, showing the
benet of supervised learning. The unsupervised rank-
ing algorithm simply takes y = exp(âˆ’(cid:107)x(cid:107)2), where
(cid:107)x(cid:107)2 estimates the similarity of the query and training
lesion, and eâˆ’x is a positive, monotonically decreasing
function. Results for all of these algorithms are shown
in gure 3.

In most applications, gure 3 would be called a learn-
ing curve, hopefully showing the benet of an in-
creased training set. However, for each round we rank
all N training items. The ranking problem becomes
more dicult as we have more items to rank, and more
opportunities to rank a highly-relevant item far down
the list. Thus, we can see that the NDCG increases
initially, but past the midpoint of the graph the benet
of more training data is outweighed by the increased
diculty of the task.

The results show that supervised learning outperforms
unsupervised, although all three results are encourag-
ing. Our algorithm performs almost identically with
regularized linear regression, a result theoretically ex-
plained in section 4.2.3. Although they are not tech-
nically the same for Î² > 0, this investigation could be
used as a theoretical justication for the use of regular-
ization in the ranking problem. Despite encouraging
results, we believe better performance is necessary for
clinical usefulness. Possible improvements will be dis-
cussed in section 6.

6. Conclusions and future work

We have extracted image features from a dataset of
CT liver lesions, derived a supervised learning algo-
rithm for ranking, and reported the results in a cross-
validation framework. Results were encouraging, but
leave room for improvement.

0.60.70.80.911015202530NDCG Number of images GLMProposedUnsupervisedWorst caseMedical image retrieval based on 3D lesion content

Blaine Rister

December 11, 2015

Abstract

the problem.

Content-based image retrieval is an emerg-
ing technology which could provide decision
support to radiologists. This paper describes
a system for content-based image retrieval
based on 3D features extracted from liver
lesions in abdominal computed tomography
images. A supervised learning algorithm is
developed to transform image features into
search rankings. In our experiments, the su-
pervised learning provides some benet over
unsupervised methods.

1. Introduction

Content-based image retrieval is the task of searching
a database for similar images to a given query image.
Rather than relying on metadata, as do many commer-
cial search engines, content-based retrieval systems use
image processing and computer vision to describe the
content of an image. For example, two images having
similar color distributions might be marked as simi-
lar. Content-based retrieval algorithms can augment
metadata-based retrieval, or replace it in application
domains for which metadata is unavailable or unreli-
able.

This report describes a content-based image retrieval
system for 3D medical images. Rather than search-
ing by holistic image features, which are irrelevant in
the medical context, the system extracts features di-
rectly from lesions, ranking each lesion on a case-by-
case basis. Lesion similarity is predicted by a super-
vised learning algorithm using 3D image features as
input.

Such a system could benet practicing radiologists.
Some diseases are very rare, such that a radiologist
might only see a handful of cases in his or her career.
In these situations, a radiologist could search through
a database for similar cases to gain more insight into

Final project report for CS 229 at Stanford University,
2015.

1

2. Background and prior work

Content-based image retrieval is a well-established re-
search area, albeit less so in the medical context. The
reader can refer to Akgul et al.
for a survey of the
eld and discussion of challenges faced in developing
CBIR systems for medical use (Akgul et al., 2011).
This project is a follow-up on the work of Napel et
al., who studied content-based image retrieval using
the same image dataset, but with dierent features
and learning algorithms (Napel et al., 2010). Napel
et al. used a combination of image features based on
shape and texture, along with a boosting-like learning
algorithm, to predict pairwise similarity between le-
sions. Homaniger et al mined radiology text reports
to extract training supervision from a larger dataset.
Despite previous attempts at medical content-based
image retrieval, there is still room for improvement on
the state-of-the-art.

This project diers from previous work in two as-
pects. Firstly, it uses recently-developed 3D image fea-
tures, constituting an improvement over 2D features
and some previous attempts at 3D features. Secondly,
it uses a modied regression algorithm that specically
takes the ranking problem into account.

3. Dataset and features

Before describing the details of our training data,
we will brush up on the basics of computed tomog-
raphy (CT) scans. CT scans are essentially three-
dimensional X-ray images, reconstructed from multi-
ple one-dimensional measurements taken by a moving
measurement device. CT scans are among the most
popular types of medical images, with over 72 million
performed in the United States alone in the year 2007
(de Gonzalez A et al., 2009). They are commonly used
to diagnose and monitor cancer, among other diseases.
As seen in gure 1, liver lesions are clearly visible in
CT scans as dark areas surrounded by the lighter liver
tissue.

Figure 1. Example liver lesion, indicated by the red arrow,
in a CT scan.

Figure 2. A gradient vector, shown in black, intersecting a
histogram tile, shown in yellow.

Our dataset consists of 30 annotated liver lesions from
CT scans. The annotations provide a few points on the
boundary of each lesion, and were created by board-
certied radiologists. These annotations allow us to
extract features only from the lesions, disregarding
other image content.

Each CT scan contains a massive amount of data,
commonly having an (x, y, z) resolution of around
0.7Ã— 0.7Ã— 1.2mm. This is signicantly reduced by ex-
tracting the lesions, which may have a radius of around
20 voxels. Still, given our limited dataset, it is not
prudent to train on image data directly. Rather, we
extract a set of image features describing the shape
and texture of each lesion, allowing us to summarize
the relevant content in a low-dimensional space. The
following sections describe the two types of features
used for training.

3.1. SIFT3D features

The rst type of features are 3D image descriptors,
previously designed for a dierent work. Here I will
give a rough overview of their properties and moti-
vation, without delving into too much detail, as im-
age feature engineering is outside the scope of CS 229.
The features are a higher-dimensional analogue of the
Scale-Invariant Feature Transform from the computer
vision literature (Lowe, 2004).

The input to the feature extraction program is a set
of abdominal computed tomography (CT) scans, and
a set of annotations of the liver lesions in those scans.
The annotations are ordered sets of points tracing
the boundary of each lesion. We assign a coordinate
x = (x, y, z) and scale Ïƒ to each lesion by taking the
center and radius of the minimum bounding sphere of
the annotation points. Assuming the annotations scale
consistently with the images, the scale parameter en-
sures scale-invariance of the features.

It remains to extract the feature vectors. There are
many variants on this idea, but the approach used here

is an array of weighted histograms describing the dis-
tribution of image gradient orientations. That is, for
each pixel in some window W (cid:51) x, we approximate
the gradient of the image data âˆ‡Ix, and add this vec-
tor to a weighted histogram based on its orientation,
as shown in gure 2. In practice, this is a robust repre-
sentation of the shape of an object about a coordinate
x.

3.2. Haralick texture features

The second type of features are Haralick texture fea-
tures. These were originally developed by Haralick et
al. for classication of satellite images (Haralick et al.,
1973). Haralick used his simple texture features, to-
gether with piecewise linear regression, to accurately
classify land into several usage categories, such as city
and farmland.

Haralick's texture features are computed from a ma-
trix P , which is known as the gray-level co-occurence
matrix (GLCM). Its elements Pij give an estimate of
the probability that a pixel of intensity i neighbors one
of intensity j. Note that this joint probability distribu-
tion is discrete, which assumes that the image intensity
values are quantized. This is not terribly inaccurate,
as images are captured and stored in a quantized form.
Knowing this, it is straightforward to estimate these
probabilities as

Pij =

# pixels i neighboring pixels j

total # pixels

.

Note that this matrix is computed only within the le-
sion boundaries, as we are trying to describe only the
texture of the lesion itself. Here we have used an infor-
mal notation, as the concept of one pixel neighboring
another is quite easy to intuit, but less so to formalize
algebraically.

For our purposes, not enough to use the matrix P as
training input. Images are commonly quantized into
256 dierent intensity values, in which case P is of size

Contrast Correlation Energy Homogeneity

.36

.92

.46

.97

Table 1. Texture features for the lesion from gure 1.

considers only the relationship between the query im-
age and an individual training data point.
In total,
this yields m distinct regression problems, each with
m training examples (x(j), Aij).

256 Ã— 256. This large matrix could hardly be called a
summary of the image data. Thus, Haralick computed
a feature vector of statistics summarizing the content
of P :

Contrast =

Correlation =

Energy =

Homogeneity =

ij

(cid:88)
(cid:88)
(cid:88)
(cid:88)

ij

ij

ij

Pij|i âˆ’ j|2

(i âˆ’ Âµi)(j âˆ’ Âµj)

ÏƒiÏƒj

Pij

P 2
ij

Pij

1 + |i âˆ’ j|

where Âµi, Ïƒi, Âµj, Ïƒj are the mean and standard devia-
tion of the marginal distributions Pi, Pj, respectively.
Note that Haralick originally dened 13 dierent tex-
ture features, but we list only those used in this work.
We refer the reader to the original article for the in-
terpretation of these features (Haralick et al., 1973).

As an example, table 1 shows the four texture features
for the lesion from gure 1.

4. Learning algorithm

Having described the dataset and features, we will now
formally express the goals of the CBIR system, and de-
rive a machine learning algorithm approximating those
goals. Section 4.1 describes the ranking problem and
quantication of ranking accuracy, while section 4.2
describes a regression algorithm for predicting the rel-
evance scores.

4.1. Ranking overview

Having extracted image features, it remains to use ma-
chine learning to assign search rankings to a query
point. Given a query feature vector, we must generate
a permutation of the vector (1, 2, ..., m) ranking the m
training features in terms of relevance to the query,
where 1 is the most relevant and m the least.

To this end, we derive the following supervised learn-
ing algorithm: given a query feature x, predict the
relevance to each training feature x(i). Then, com-
pute the search ranking function rj(x) by sorting the
relevance scores.
In the literature, this is known as
the point-wise approach to the ranking problem, as it

The sorting step is justied upon considering the
goal of the learning algorithm. Our objective is to
maximize the normalized discounted cumulative gain
(NDCG) from cross-validation. NDCG is a widely-
used measure of search performance. First, dene the
discounted cumulative gain (DCG) of the jth query as

p(cid:88)

i=1

2yi âˆ’ 1
log2(i + 1)

DCGj =

where yi = Arj (i),j is the relevance score of the ith
result in the jth query.

Having dened the DCG, the NDCG is simply

NDCGj =

DCGj
âˆ—
DCG
j

,

âˆ—
j is given by the optimal ranking function
where DCG
for the jth query. From here, it is clear that, given
a set of predicted relevance scores, sorting the scores
yields the optimal NDCG.

4.2. Regression for optimal ranking

In the previous section, we described a machine learn-
ing approach to ranking using m distinct regression
problems. In this section, we will formalize the regres-
sion problem in an attempt to achieve optimal ranking.
We will see that, for most datasets, optimal ranking is
not possible within our framework, and instead strike
a compromise between data delity and ranking sub-
optimality.

4.2.1. Pairwise distance features

Before delving into the specics of the ranking prob-
lem, we note a useful transformation of the image fea-
tures specic to this application. Given a query im-
age, we wish to predict its similarity to a training im-
age. Thus, it is not the image features themselves that
are of interest, but the dierences between them. We
therefore dene a new feature vector as follows:
let
qs, ts âˆˆ R768 be the SIFT3D features from the query
lesion q and the training lesion t, respectively. Sim-
ilarly, let qt1, ..., tt4, qt1, ..., ty be the four texture fea-
tures from the query and training images, respectively.
Then, the pairwise distance feature vector x is com-
puted as

x =(cid:0)(cid:107)qs âˆ’ ts(cid:107)2,

|qt1 âˆ’ tt2|,

...,

|qt4 âˆ’ tt4|(cid:1) .

Note that this is a nonlinear feature mapping from
the 772-dimensional
image feature space to a 5-
dimensional space. This mitigates overtting on our
small dataset. Furthermore, we have observed no per-
formance loss from this mapping.

4.2.2. Optimal Ranking

We wish to nd a mapping Ï† : Rn â†’ R such that
Ï†(x(i)) gives an optimal ranking. Rankings are ob-
tained by ordering Ï†(x(i)), such that x(i) is ranked
prior to x(j) if and only if Ï†(x(i)) > Ï†(x(j)). Let
x(1), y(1) denote the most relevant item, x(2), y(2) the
second-most, etc. In this notation, x is the pairwise
feature vector from section 4.2.1, and y is its corre-
sponding relevance score with respect to the train-
ing image. Any solution satisfying the following con-
straints will produce an optimal ranking:

where N is the number of training examples, z is a
vector of dummy variables, and Î±, Î² are constant pa-
rameters.

Let us dissect this algorithm. The rst term of the
objective is just the mean squared error of the pre-
dicted relevance scores. The dummy variables z are
constrained to lie within the set of ane regressors
giving no more than a Î²-suboptimal ranking. The
term(cid:107)a âˆ’ z(cid:107)2 gives the distance between the regres-
sor a and this Î²-suboptimal set. The parameter Î±
negotiates between the often-competing objectives of
data delity and optimal ranking.

This seemingly complicated model can be simplied.
In practice, we replace < with â‰¤, as most solvers
do not dierentiate between the two.
In this case,
if Î² = 0, the only feasible solution is often z = 0.
Substituting this into the objective, we have

Ï†(x(1)) > Ï†(x(2))

...

Ï†(x(Nâˆ’1) > Ï†(x(N )).

minimize

1
N

(cid:16)

aT x(i) + b âˆ’ y(i)(cid:17)2

N(cid:88)

i=1

+ Î±(cid:107)a(cid:107)2

(2)

Converting to standard form, we have
Ï†(x(iâˆ’1)) âˆ’ Ï†(x(i)) < 0.

This is a convex set if Ï†(x(i)) âˆ’ Ï†(x(j)) is a convex
function of the parameters of Ï†.
In the case that
Ï†(x) = aT x + b, we have

aT x(iâˆ’1) âˆ’ aT x(i) < 0
aT (x(iâˆ’1) âˆ’ x(i)) < 0

which is clearly convex.

4.2.3. Sub-optimal compromise

We have shown in section 4.2.2 that the set of ane
regressors resulting in an optimal ranking of the train-
ing set is convex. Thus, we can quickly nd a regressor
which optimally ranks the training set, if one exists.
However, this is not so useful in practice, as for most
datasets with more training examples than feature di-
mensions, there is no regressor satisfying these equa-
tions, i.e. the set of optimal regressors is empty. To
avoid this diculty, we must strike a compromise by
allowing some slack in the constraints.
In this case,
we would like to dierentiate between sub-optimal so-
lutions according to their delity to the training rele-
vance scores. Thus, we arrive at the following convex
optimization problem:

(cid:80)N

i=1

(cid:0)aT x(i) + b âˆ’ y(i)(cid:1)2

zT (x(2) âˆ’ x(1)) < Î²

+ Î±(cid:107)a âˆ’ z(cid:107)2

(1)

minimize

subject to

1
N

...

zT (x(N ) âˆ’ x(Nâˆ’1)) < Î²

which is just regularized linear regression. In fact, we
shall see in section 5 that our algorithm with reason-
ably small Î² performs essentially the same as regular-
ized linear regression. Note, however, that with Î² > 0
the optimal value of z is not necessarily z = 0, so the
algorithm is not identical to regularized linear regres-
sion.

5. Results

We computed the performance for a variety of sub-
samples of the training set, using leave-one-out cross-
validation. The cross-validation scheme is as fol-
lows: for each round, we withhold one lesion from the
dataset. Then, we train all N âˆ’ 1 regressors predicting
the relevance of a query image to each of the N âˆ’ 1
remaining training lesions. This is done without the
benet of the withheld lesion. Finally, we predict and
rank the similarities of the withheld lesion to each of
the N âˆ’ 1 training lesions. This gives the ranking re-
sults from a single query, from which we compute a
single NDCG. Repeat this process N times, each time
withholding a dierent lesion. The nal performance
estimate is the average NDCG over all N folds.

The parameters for our algorithm from problem 1 were
Î± = 0.1, Î² = 1. We solved the optimization problem
with CVX, a popular modeling tool for convex pro-
grams (Grant & Boyd, 2014). For comparison, we
computed three additional scores. The rst is the
worst possible NDCG for this data, averaged over all
folds, computed from the worst possible ranking. The
second is the score from the regularized linear regres-

In the future, we plan to extend the algorithmic ideas
from section 4.2. We might try adding features, or
mapping features to a higher-dimensional space, in an
attempt to produce a less-trivial optimal-ranking set.
Almost paradoxically, optimal ranking is guaranteed
only when the number of parameters equals or exceeds
the number of training elements, a cardinal sin of ma-
chine learning. The problem might be alleviated by
use of a more complicated regressor, but it is challeng-
ing to nd one for which the problem remains convex.

Another possible avenue of exploration is optimizing
over all regressors simultaneously. In this work we have
penalized the suboptimality of the ranking of a single
regressor. But since the outputs of dierent regressors
are directly compared in a search query, should not
we enforce optimal ranking across regressors as well?
We might also enforce symmetry between regressors,
i.e. aT
j xi + bj. There is no shortage
of avenues for exploration, but it is not clear which
are both nontrivial, i.e. more substantial than mere
regularization, and computationally tractable.

i xj + bi = aT

References

Glmnet.

at
http://web.stanford.edu/~hastie/glmnet_matlab/,
accessed November 13th, 2015.

Available

Akgul, Ceyhun Burak, Rubin, Daniel L., Napel,
Sandy, Beaulieu, Christopher F., Greenspan, Hayit,
and Acar, Burak. Content-based image retrieval
in radiology: Current status and future directions.
Journal of Digital Imaging, 24(2):208222, 2011.

de Gonzalez A, Berrington, M, Mahesh, K, Kim, and
et al. Projected cancer risks from computed tomo-
graphic scans performed in the united states in 2007.
Archives of Internal Medicine, 169(22):20712077,
2009. doi: 10.1001/archinternmed.2009.440.

Grant, Michael and Boyd, Stephen. CVX: Matlab soft-
ware for disciplined convex programming, version
2.1. http://cvxr.com/cvx, 2014.

Haralick, R.M., Shanmugam, K., and Dinstein,
Its'Hak. Textural features for image classication.
Systems, Man and Cybernetics, IEEE Transactions
on, SMC-3(6):610621, Nov 1973. ISSN 0018-9472.
doi: 10.1109/TSMC.1973.4309314.

Lowe, David G.

image

Distinctive
from scale-invariant keypoints.
Journal
November
10.1023/B:VISI.0000029664.99615.94.
http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94.

features
International
60(2):91110,
doi:
URL

of Computer Vision,

2004.

ISSN 0920-5691.

Figure 3. Mean NDCG for the various algorithms. Possible
scores range between the purple line and 1.

sion problem 2, which is trained by the GLMnet li-
brary, with cross-validation for the regularization pa-
rameter Î± (Glm). This shows the close relationship be-
tween regularized linear regression and our algorithm.
The third is an unsupervised algorithm, showing the
benet of supervised learning. The unsupervised rank-
ing algorithm simply takes y = exp(âˆ’(cid:107)x(cid:107)2), where
(cid:107)x(cid:107)2 estimates the similarity of the query and training
lesion, and eâˆ’x is a positive, monotonically decreasing
function. Results for all of these algorithms are shown
in gure 3.

In most applications, gure 3 would be called a learn-
ing curve, hopefully showing the benet of an in-
creased training set. However, for each round we rank
all N training items. The ranking problem becomes
more dicult as we have more items to rank, and more
opportunities to rank a highly-relevant item far down
the list. Thus, we can see that the NDCG increases
initially, but past the midpoint of the graph the benet
of more training data is outweighed by the increased
diculty of the task.

The results show that supervised learning outperforms
unsupervised, although all three results are encourag-
ing. Our algorithm performs almost identically with
regularized linear regression, a result theoretically ex-
plained in section 4.2.3. Although they are not tech-
nically the same for Î² > 0, this investigation could be
used as a theoretical justication for the use of regular-
ization in the ranking problem. Despite encouraging
results, we believe better performance is necessary for
clinical usefulness. Possible improvements will be dis-
cussed in section 6.

6. Conclusions and future work

We have extracted image features from a dataset of
CT liver lesions, derived a supervised learning algo-
rithm for ranking, and reported the results in a cross-
validation framework. Results were encouraging, but
leave room for improvement.

0.60.70.80.911015202530NDCG Number of images GLMProposedUnsupervisedWorst caseNapel, Sandy A., Beaulieu, Chistopher F., Rodriguez,
Cesar, Cui, Jingyu, Xu, JiaJing, Gupta, Ankit, Ko-
renblum, Daniel, Greenspan, Hayit, Ma, Yongjun,
and Rubin, Daniel L. Automated retrieval of ct im-
ages of liver lesions on the basis of image similarity:
Method and preliminary results. Radiology, 256(1),
July 2010.

