CS 229 Final Project Report  

Drugs store sales forecast using Machine Learning 
Hongyu Xiong (hxiong2), Xi Wu (wuxi), Jingying Yue (jingying) 

 

Nowadays medical-related sales prediction is of great interest; with reliable sales 

 
 

 

 

 

The Kaggle website provides us training data of 1115 Rossmann stores’ daily sales dated 

1 Introduction 
 
prediction, medical companies could allocate their resources more wisely and make better profits. 
We join a Kaggle competition to predict the everyday drug sale for each store based on the store, 
promotion and competitor data. We aim to apply different machine learning techniques to tune 
the model and make predictions on drug sales using time series analysis. 
2 Data 
 
back to 2013, with 1,017,209 entries in total. The training data includes features of promotion 
and competitors’ information. Since we are not able to access to the real sales amount for testing 
during Kaggle competition, we decide to use 70% of the contest given training data as the 
training set for our model, the rest 30% as test set for cross validation. For now, the cross 
validation will be our estimated test error.  
3 Method and Results 
 
Since the problem involves time series data, we intend to use time series analysis model 
to deal with it in the first place. We establish auto-regression (AR) model and train it using the 
data we have to get the parameters. We test AR models with different order numbers, and 
calculate the test errors. 
 
Now we want to see how stores are different according to their different features. First, we 
establish a time-independent model by averaging the daily sales per store and collapsing the time 
dimension; in this frame we use Random Forest to select features and then use Support Vector 
Regression to fit different features (such as assortment type and competitors) to each store's 
mean sales. 
 
instead of one by one in the first section. 
 
3.1 Time Series Analysis 
 
evolution. From the plots, we recognize that it's a time series data and for a certain store, its daily 
sales evolve periodically with a period of a year. For example, according to Figure 2, we can see 
that there will be sales peaks at certain dates around January and May, but in general the sales 
keep at a constant level. 
3.1.1 Auto-Regression (AR) Model 

Finally, we manage to generalize the time series model to predict several stores at a time, 

In the time series analysis part, we predicted each store's sale based on just its past data. 

In order to get a big picture, we first plot several stores daily sales with respect to time 

 

CS 229 Final Project Report  

Drugs store sales forecast using Machine Learning 
Hongyu Xiong (hxiong2), Xi Wu (wuxi), Jingying Yue (jingying) 

 

Nowadays medical-related sales prediction is of great interest; with reliable sales 

 
 

 

 

 

The Kaggle website provides us training data of 1115 Rossmann stores’ daily sales dated 

1 Introduction 
 
prediction, medical companies could allocate their resources more wisely and make better profits. 
We join a Kaggle competition to predict the everyday drug sale for each store based on the store, 
promotion and competitor data. We aim to apply different machine learning techniques to tune 
the model and make predictions on drug sales using time series analysis. 
2 Data 
 
back to 2013, with 1,017,209 entries in total. The training data includes features of promotion 
and competitors’ information. Since we are not able to access to the real sales amount for testing 
during Kaggle competition, we decide to use 70% of the contest given training data as the 
training set for our model, the rest 30% as test set for cross validation. For now, the cross 
validation will be our estimated test error.  
3 Method and Results 
 
Since the problem involves time series data, we intend to use time series analysis model 
to deal with it in the first place. We establish auto-regression (AR) model and train it using the 
data we have to get the parameters. We test AR models with different order numbers, and 
calculate the test errors. 
 
Now we want to see how stores are different according to their different features. First, we 
establish a time-independent model by averaging the daily sales per store and collapsing the time 
dimension; in this frame we use Random Forest to select features and then use Support Vector 
Regression to fit different features (such as assortment type and competitors) to each store's 
mean sales. 
 
instead of one by one in the first section. 
 
3.1 Time Series Analysis 
 
evolution. From the plots, we recognize that it's a time series data and for a certain store, its daily 
sales evolve periodically with a period of a year. For example, according to Figure 2, we can see 
that there will be sales peaks at certain dates around January and May, but in general the sales 
keep at a constant level. 
3.1.1 Auto-Regression (AR) Model 

Finally, we manage to generalize the time series model to predict several stores at a time, 

In the time series analysis part, we predicted each store's sale based on just its past data. 

In order to get a big picture, we first plot several stores daily sales with respect to time 

 

Since the prediction for the daily sale for each store from past data seems to be a time 

 
series problem, we manage to solve this problem by building a time series analysis model. The 
basic method we are using is auto-regression (AR) model. 

CS 229 Final Project Report  

X

t

=

p

∑

1
=

i

Xϕ

i

ε−
i
t

+

t

  

We looked online and discovered a package called "Forecast" in R, which does auto-

 
regression. We made some revision so the program could do what we want. To use this model, 
we pre-process the data to make weekly sales as a time unit. The first reason we want to do that 
is because that "zero Sunday sales" makes it hard to use daily sales as a time unit, and monthly 
sale would kill all the detail patterns; the second reason is that we plot sales at different days in a 
week through time, and discover that they basically follow the same pattern (Figure 1). Since we 
condense the daily sales to weekly sales at the beginning, after we predicted the weekly sales we 
still have to regenerate sales on each day in that week. We assume a normal distribution N(µ, σ2) 
with µ equal to the weekly sales and variance σ2 to be trained. We compare AR models with 
order p = 1, 2, 5, 10, 20 to see which order number fit best.  

Figure 1 Sales of store1 on different days of the week 

 

 

For each order p, we train parameters φ, ε, µ, and σ with 70% of the data and cross 

3.1.2 Cross-validation 
 
validation with the remain 30% to get the test error. The cost function we are using is the sum of 
the square of the difference between predicted and real daily sales of store1. The table below is 
the comparison among test errors using different order number.  
Order  p  
Test  Error  
(10^10)  
 
As we can see order number p = 2 yields the lowest test errors. We plot the predicted 
sales of store1 (Figure 3). If we compare Fig 2 and Fig 3, we can see the model capture the 
general pattern of the store1's daily sales.  

2  
0.47354  

10  
2.1463  

20  
1.9401  

5  
2.4489  

1  
1.4447  

 

 

CS 229 Final Project Report  

Drugs store sales forecast using Machine Learning 
Hongyu Xiong (hxiong2), Xi Wu (wuxi), Jingying Yue (jingying) 

 

Nowadays medical-related sales prediction is of great interest; with reliable sales 

 
 

 

 

 

The Kaggle website provides us training data of 1115 Rossmann stores’ daily sales dated 

1 Introduction 
 
prediction, medical companies could allocate their resources more wisely and make better profits. 
We join a Kaggle competition to predict the everyday drug sale for each store based on the store, 
promotion and competitor data. We aim to apply different machine learning techniques to tune 
the model and make predictions on drug sales using time series analysis. 
2 Data 
 
back to 2013, with 1,017,209 entries in total. The training data includes features of promotion 
and competitors’ information. Since we are not able to access to the real sales amount for testing 
during Kaggle competition, we decide to use 70% of the contest given training data as the 
training set for our model, the rest 30% as test set for cross validation. For now, the cross 
validation will be our estimated test error.  
3 Method and Results 
 
Since the problem involves time series data, we intend to use time series analysis model 
to deal with it in the first place. We establish auto-regression (AR) model and train it using the 
data we have to get the parameters. We test AR models with different order numbers, and 
calculate the test errors. 
 
Now we want to see how stores are different according to their different features. First, we 
establish a time-independent model by averaging the daily sales per store and collapsing the time 
dimension; in this frame we use Random Forest to select features and then use Support Vector 
Regression to fit different features (such as assortment type and competitors) to each store's 
mean sales. 
 
instead of one by one in the first section. 
 
3.1 Time Series Analysis 
 
evolution. From the plots, we recognize that it's a time series data and for a certain store, its daily 
sales evolve periodically with a period of a year. For example, according to Figure 2, we can see 
that there will be sales peaks at certain dates around January and May, but in general the sales 
keep at a constant level. 
3.1.1 Auto-Regression (AR) Model 

Finally, we manage to generalize the time series model to predict several stores at a time, 

In the time series analysis part, we predicted each store's sale based on just its past data. 

In order to get a big picture, we first plot several stores daily sales with respect to time 

 

Since the prediction for the daily sale for each store from past data seems to be a time 

 
series problem, we manage to solve this problem by building a time series analysis model. The 
basic method we are using is auto-regression (AR) model. 

CS 229 Final Project Report  

X

t

=

p

∑

1
=

i

Xϕ

i

ε−
i
t

+

t

  

We looked online and discovered a package called "Forecast" in R, which does auto-

 
regression. We made some revision so the program could do what we want. To use this model, 
we pre-process the data to make weekly sales as a time unit. The first reason we want to do that 
is because that "zero Sunday sales" makes it hard to use daily sales as a time unit, and monthly 
sale would kill all the detail patterns; the second reason is that we plot sales at different days in a 
week through time, and discover that they basically follow the same pattern (Figure 1). Since we 
condense the daily sales to weekly sales at the beginning, after we predicted the weekly sales we 
still have to regenerate sales on each day in that week. We assume a normal distribution N(µ, σ2) 
with µ equal to the weekly sales and variance σ2 to be trained. We compare AR models with 
order p = 1, 2, 5, 10, 20 to see which order number fit best.  

Figure 1 Sales of store1 on different days of the week 

 

 

For each order p, we train parameters φ, ε, µ, and σ with 70% of the data and cross 

3.1.2 Cross-validation 
 
validation with the remain 30% to get the test error. The cost function we are using is the sum of 
the square of the difference between predicted and real daily sales of store1. The table below is 
the comparison among test errors using different order number.  
Order  p  
Test  Error  
(10^10)  
 
As we can see order number p = 2 yields the lowest test errors. We plot the predicted 
sales of store1 (Figure 3). If we compare Fig 2 and Fig 3, we can see the model capture the 
general pattern of the store1's daily sales.  

2  
0.47354  

10  
2.1463  

20  
1.9401  

5  
2.4489  

1  
1.4447  

 

 

CS 229 Final Project Report  

 
Specifically speaking, for sales on Tuesday, Wednesday and Thursday, our predictions 
are within 10% of the real daily sales. However, it gives conservative predictions for Mondays 
and Fridays, when sales are apparently higher compared to other days in a week. 
 

 

Figure 3 Predicted daily sales of store1 

 

Since there are so many factors influencing the sales, such as store types, promotions, 

        Figure 2 Sales of store1 at daily base       
3.2 Random Forest 
 
competitors, and even holidays, we are trying to identify the most important features that 
influence the sales. We use random forest to do that; in order to decrease the amount of data to 
test the model and the program, we average the daily sales for each store, so the amount of data 
decrease from a million to a thousand. 
 
CompetitionSinceMonth and CompetitionSinceYear to a new variable CompetitionExistMonth. Similarly, 
we create a new variable PromoExistMonth from four promotion variables. We also scale the variable 
CompetitionDistance by 100.  

In the raw data provided, five parameters have missing data points. We first combine 

 
Figure 4 Feature selection through random forest 

We built a model using the "random Forest" package in R. Our model was built on 500 

 
trees and 8 variables in the "store.csv" and the mean of sales for each store as the response 
variable. We used na.omit for the missing values and generated the variable importance plot for 
the feature selection. The out-of-bag errors were traced for the model. 

 

CS 229 Final Project Report  

Drugs store sales forecast using Machine Learning 
Hongyu Xiong (hxiong2), Xi Wu (wuxi), Jingying Yue (jingying) 

 

Nowadays medical-related sales prediction is of great interest; with reliable sales 

 
 

 

 

 

The Kaggle website provides us training data of 1115 Rossmann stores’ daily sales dated 

1 Introduction 
 
prediction, medical companies could allocate their resources more wisely and make better profits. 
We join a Kaggle competition to predict the everyday drug sale for each store based on the store, 
promotion and competitor data. We aim to apply different machine learning techniques to tune 
the model and make predictions on drug sales using time series analysis. 
2 Data 
 
back to 2013, with 1,017,209 entries in total. The training data includes features of promotion 
and competitors’ information. Since we are not able to access to the real sales amount for testing 
during Kaggle competition, we decide to use 70% of the contest given training data as the 
training set for our model, the rest 30% as test set for cross validation. For now, the cross 
validation will be our estimated test error.  
3 Method and Results 
 
Since the problem involves time series data, we intend to use time series analysis model 
to deal with it in the first place. We establish auto-regression (AR) model and train it using the 
data we have to get the parameters. We test AR models with different order numbers, and 
calculate the test errors. 
 
Now we want to see how stores are different according to their different features. First, we 
establish a time-independent model by averaging the daily sales per store and collapsing the time 
dimension; in this frame we use Random Forest to select features and then use Support Vector 
Regression to fit different features (such as assortment type and competitors) to each store's 
mean sales. 
 
instead of one by one in the first section. 
 
3.1 Time Series Analysis 
 
evolution. From the plots, we recognize that it's a time series data and for a certain store, its daily 
sales evolve periodically with a period of a year. For example, according to Figure 2, we can see 
that there will be sales peaks at certain dates around January and May, but in general the sales 
keep at a constant level. 
3.1.1 Auto-Regression (AR) Model 

Finally, we manage to generalize the time series model to predict several stores at a time, 

In the time series analysis part, we predicted each store's sale based on just its past data. 

In order to get a big picture, we first plot several stores daily sales with respect to time 

 

Since the prediction for the daily sale for each store from past data seems to be a time 

 
series problem, we manage to solve this problem by building a time series analysis model. The 
basic method we are using is auto-regression (AR) model. 

CS 229 Final Project Report  

X

t

=

p

∑

1
=

i

Xϕ

i

ε−
i
t

+

t

  

We looked online and discovered a package called "Forecast" in R, which does auto-

 
regression. We made some revision so the program could do what we want. To use this model, 
we pre-process the data to make weekly sales as a time unit. The first reason we want to do that 
is because that "zero Sunday sales" makes it hard to use daily sales as a time unit, and monthly 
sale would kill all the detail patterns; the second reason is that we plot sales at different days in a 
week through time, and discover that they basically follow the same pattern (Figure 1). Since we 
condense the daily sales to weekly sales at the beginning, after we predicted the weekly sales we 
still have to regenerate sales on each day in that week. We assume a normal distribution N(µ, σ2) 
with µ equal to the weekly sales and variance σ2 to be trained. We compare AR models with 
order p = 1, 2, 5, 10, 20 to see which order number fit best.  

Figure 1 Sales of store1 on different days of the week 

 

 

For each order p, we train parameters φ, ε, µ, and σ with 70% of the data and cross 

3.1.2 Cross-validation 
 
validation with the remain 30% to get the test error. The cost function we are using is the sum of 
the square of the difference between predicted and real daily sales of store1. The table below is 
the comparison among test errors using different order number.  
Order  p  
Test  Error  
(10^10)  
 
As we can see order number p = 2 yields the lowest test errors. We plot the predicted 
sales of store1 (Figure 3). If we compare Fig 2 and Fig 3, we can see the model capture the 
general pattern of the store1's daily sales.  

2  
0.47354  

10  
2.1463  

20  
1.9401  

5  
2.4489  

1  
1.4447  

 

 

CS 229 Final Project Report  

 
Specifically speaking, for sales on Tuesday, Wednesday and Thursday, our predictions 
are within 10% of the real daily sales. However, it gives conservative predictions for Mondays 
and Fridays, when sales are apparently higher compared to other days in a week. 
 

 

Figure 3 Predicted daily sales of store1 

 

Since there are so many factors influencing the sales, such as store types, promotions, 

        Figure 2 Sales of store1 at daily base       
3.2 Random Forest 
 
competitors, and even holidays, we are trying to identify the most important features that 
influence the sales. We use random forest to do that; in order to decrease the amount of data to 
test the model and the program, we average the daily sales for each store, so the amount of data 
decrease from a million to a thousand. 
 
CompetitionSinceMonth and CompetitionSinceYear to a new variable CompetitionExistMonth. Similarly, 
we create a new variable PromoExistMonth from four promotion variables. We also scale the variable 
CompetitionDistance by 100.  

In the raw data provided, five parameters have missing data points. We first combine 

 
Figure 4 Feature selection through random forest 

We built a model using the "random Forest" package in R. Our model was built on 500 

 
trees and 8 variables in the "store.csv" and the mean of sales for each store as the response 
variable. We used na.omit for the missing values and generated the variable importance plot for 
the feature selection. The out-of-bag errors were traced for the model. 

 

CS 229 Final Project Report  

 

As you can see from the plot, the feature Assortment is the most important variable 

 
It seems that the out-of-bag errors are pretty small. But we will have to dig more into the 
data and model fitting to find out if it's overfitting. The variable importance plot is as following: 
 
because including it could make the biggest reduction in the MSE. Also notice that 
CompetitionExistence is the least important one among all variables in the store characteristics. 
3.3 Support Vector Regression (SVR) 
 
We used Support Vector Regression (SVR) method to find relation between each store's 
mean sales and different kind of features. SVR is a variation of Support Vector Machine (SVM). 
The essence of SVM is to find a classification boundary with maximum margins to the feature 
points; by similar token, SVR is to find a regression curve with minimum margins to the feature 
points. We used the standard liblinear2.1 package in MATLAB to implement SVR. 

2

ω

w b
,

min

1
      
2
y
⎧
⎪
s t
. .            
⎨
T
ω
⎪⎩

i
( )

i
( )

x
T
ω
b y
)
+−

b
− ≤
i
( )
≤

            for  i 1,  2,  ...  ,m

=

ε
ε

  

−
x
i
(

According to the data, there are four different store types (a, b, c, d) and three different 
 
assortment types (a, b, c), in total 8 combinations (aa, ac, ba, bb, ca, cc, da, dc). We ran SVR 
algorithm with linear kernel according to different combinations. 
Test  Error  
(10^8)  
Linear  

0.00412   0.110  

(b,  b)  

(d,  a)  

(d,  c)  

(b,  a)  

0.378  

0.263  

(a,  c)  

(c,  a)  

(c,  c)  

(a,  a)  

1.60  

2.63  

2.61  

1.09  

 

 

1.09  

0.228  

0.378  

0.00938   0.106  

0.00497   0.107  

0.385  

0.305  

1.09  

933  

1.57  

2.49  

2.62  

Linear  +  
Parabola  
Sqrt  +  
Parabola  
3.4 Extension for Time Series Model 
 

1.57  

1.15*10
^7  

In this model we used a method similar to seasonalized times series regression, in which 

prediction of sales Y=T×SI. We adjusted this equation to Y=T×DI, in which Y means the 
daily sale prediction, T means the sale trend, and DI means daily sale index. To obtain T, we 
linearly fitted of all historical sales data of a single store with equation y=a+bt, in which a=
-. , and b= /-/0. Then to predict sale at time t1, Tt1 =a+bt1. DI was obtained from 
DI for January 2nd, we got historical sales on January 2nd, say s3, s4, s5, at time point t3, t4, t5, 
respectively, and linearly fitted sales y3, y4, y5, then DI=35 67-7+60-0+68-8 . DI reflects the sales 
s3=0, we just ignores it when calculating DI. Instead in the final prediction we assigned sales 

fluctuations at different periods within a year. We take considerations for zero sales cases, and if 

historical data, and the 365 days in a year each has a different DI. For example, if we wish to get 

on Sundays to be zero, based on observations of historical data, and holiday dates with all 
historical sales data equal to zero, like January 1st, were also predicted to be zero. We used 76% 
historical data for training, and 24% for testing, and the cost functions for 10 stores were listed. 

 

CS 229 Final Project Report  

Drugs store sales forecast using Machine Learning 
Hongyu Xiong (hxiong2), Xi Wu (wuxi), Jingying Yue (jingying) 

 

Nowadays medical-related sales prediction is of great interest; with reliable sales 

 
 

 

 

 

The Kaggle website provides us training data of 1115 Rossmann stores’ daily sales dated 

1 Introduction 
 
prediction, medical companies could allocate their resources more wisely and make better profits. 
We join a Kaggle competition to predict the everyday drug sale for each store based on the store, 
promotion and competitor data. We aim to apply different machine learning techniques to tune 
the model and make predictions on drug sales using time series analysis. 
2 Data 
 
back to 2013, with 1,017,209 entries in total. The training data includes features of promotion 
and competitors’ information. Since we are not able to access to the real sales amount for testing 
during Kaggle competition, we decide to use 70% of the contest given training data as the 
training set for our model, the rest 30% as test set for cross validation. For now, the cross 
validation will be our estimated test error.  
3 Method and Results 
 
Since the problem involves time series data, we intend to use time series analysis model 
to deal with it in the first place. We establish auto-regression (AR) model and train it using the 
data we have to get the parameters. We test AR models with different order numbers, and 
calculate the test errors. 
 
Now we want to see how stores are different according to their different features. First, we 
establish a time-independent model by averaging the daily sales per store and collapsing the time 
dimension; in this frame we use Random Forest to select features and then use Support Vector 
Regression to fit different features (such as assortment type and competitors) to each store's 
mean sales. 
 
instead of one by one in the first section. 
 
3.1 Time Series Analysis 
 
evolution. From the plots, we recognize that it's a time series data and for a certain store, its daily 
sales evolve periodically with a period of a year. For example, according to Figure 2, we can see 
that there will be sales peaks at certain dates around January and May, but in general the sales 
keep at a constant level. 
3.1.1 Auto-Regression (AR) Model 

Finally, we manage to generalize the time series model to predict several stores at a time, 

In the time series analysis part, we predicted each store's sale based on just its past data. 

In order to get a big picture, we first plot several stores daily sales with respect to time 

 

Since the prediction for the daily sale for each store from past data seems to be a time 

 
series problem, we manage to solve this problem by building a time series analysis model. The 
basic method we are using is auto-regression (AR) model. 

CS 229 Final Project Report  

X

t

=

p

∑

1
=

i

Xϕ

i

ε−
i
t

+

t

  

We looked online and discovered a package called "Forecast" in R, which does auto-

 
regression. We made some revision so the program could do what we want. To use this model, 
we pre-process the data to make weekly sales as a time unit. The first reason we want to do that 
is because that "zero Sunday sales" makes it hard to use daily sales as a time unit, and monthly 
sale would kill all the detail patterns; the second reason is that we plot sales at different days in a 
week through time, and discover that they basically follow the same pattern (Figure 1). Since we 
condense the daily sales to weekly sales at the beginning, after we predicted the weekly sales we 
still have to regenerate sales on each day in that week. We assume a normal distribution N(µ, σ2) 
with µ equal to the weekly sales and variance σ2 to be trained. We compare AR models with 
order p = 1, 2, 5, 10, 20 to see which order number fit best.  

Figure 1 Sales of store1 on different days of the week 

 

 

For each order p, we train parameters φ, ε, µ, and σ with 70% of the data and cross 

3.1.2 Cross-validation 
 
validation with the remain 30% to get the test error. The cost function we are using is the sum of 
the square of the difference between predicted and real daily sales of store1. The table below is 
the comparison among test errors using different order number.  
Order  p  
Test  Error  
(10^10)  
 
As we can see order number p = 2 yields the lowest test errors. We plot the predicted 
sales of store1 (Figure 3). If we compare Fig 2 and Fig 3, we can see the model capture the 
general pattern of the store1's daily sales.  

2  
0.47354  

10  
2.1463  

20  
1.9401  

5  
2.4489  

1  
1.4447  

 

 

CS 229 Final Project Report  

 
Specifically speaking, for sales on Tuesday, Wednesday and Thursday, our predictions 
are within 10% of the real daily sales. However, it gives conservative predictions for Mondays 
and Fridays, when sales are apparently higher compared to other days in a week. 
 

 

Figure 3 Predicted daily sales of store1 

 

Since there are so many factors influencing the sales, such as store types, promotions, 

        Figure 2 Sales of store1 at daily base       
3.2 Random Forest 
 
competitors, and even holidays, we are trying to identify the most important features that 
influence the sales. We use random forest to do that; in order to decrease the amount of data to 
test the model and the program, we average the daily sales for each store, so the amount of data 
decrease from a million to a thousand. 
 
CompetitionSinceMonth and CompetitionSinceYear to a new variable CompetitionExistMonth. Similarly, 
we create a new variable PromoExistMonth from four promotion variables. We also scale the variable 
CompetitionDistance by 100.  

In the raw data provided, five parameters have missing data points. We first combine 

 
Figure 4 Feature selection through random forest 

We built a model using the "random Forest" package in R. Our model was built on 500 

 
trees and 8 variables in the "store.csv" and the mean of sales for each store as the response 
variable. We used na.omit for the missing values and generated the variable importance plot for 
the feature selection. The out-of-bag errors were traced for the model. 

 

CS 229 Final Project Report  

 

As you can see from the plot, the feature Assortment is the most important variable 

 
It seems that the out-of-bag errors are pretty small. But we will have to dig more into the 
data and model fitting to find out if it's overfitting. The variable importance plot is as following: 
 
because including it could make the biggest reduction in the MSE. Also notice that 
CompetitionExistence is the least important one among all variables in the store characteristics. 
3.3 Support Vector Regression (SVR) 
 
We used Support Vector Regression (SVR) method to find relation between each store's 
mean sales and different kind of features. SVR is a variation of Support Vector Machine (SVM). 
The essence of SVM is to find a classification boundary with maximum margins to the feature 
points; by similar token, SVR is to find a regression curve with minimum margins to the feature 
points. We used the standard liblinear2.1 package in MATLAB to implement SVR. 

2

ω

w b
,

min

1
      
2
y
⎧
⎪
s t
. .            
⎨
T
ω
⎪⎩

i
( )

i
( )

x
T
ω
b y
)
+−

b
− ≤
i
( )
≤

            for  i 1,  2,  ...  ,m

=

ε
ε

  

−
x
i
(

According to the data, there are four different store types (a, b, c, d) and three different 
 
assortment types (a, b, c), in total 8 combinations (aa, ac, ba, bb, ca, cc, da, dc). We ran SVR 
algorithm with linear kernel according to different combinations. 
Test  Error  
(10^8)  
Linear  

0.00412   0.110  

(b,  b)  

(d,  a)  

(d,  c)  

(b,  a)  

0.378  

0.263  

(a,  c)  

(c,  a)  

(c,  c)  

(a,  a)  

1.60  

2.63  

2.61  

1.09  

 

 

1.09  

0.228  

0.378  

0.00938   0.106  

0.00497   0.107  

0.385  

0.305  

1.09  

933  

1.57  

2.49  

2.62  

Linear  +  
Parabola  
Sqrt  +  
Parabola  
3.4 Extension for Time Series Model 
 

1.57  

1.15*10
^7  

In this model we used a method similar to seasonalized times series regression, in which 

prediction of sales Y=T×SI. We adjusted this equation to Y=T×DI, in which Y means the 
daily sale prediction, T means the sale trend, and DI means daily sale index. To obtain T, we 
linearly fitted of all historical sales data of a single store with equation y=a+bt, in which a=
-. , and b= /-/0. Then to predict sale at time t1, Tt1 =a+bt1. DI was obtained from 
DI for January 2nd, we got historical sales on January 2nd, say s3, s4, s5, at time point t3, t4, t5, 
respectively, and linearly fitted sales y3, y4, y5, then DI=35 67-7+60-0+68-8 . DI reflects the sales 
s3=0, we just ignores it when calculating DI. Instead in the final prediction we assigned sales 

fluctuations at different periods within a year. We take considerations for zero sales cases, and if 

historical data, and the 365 days in a year each has a different DI. For example, if we wish to get 

on Sundays to be zero, based on observations of historical data, and holiday dates with all 
historical sales data equal to zero, like January 1st, were also predicted to be zero. We used 76% 
historical data for training, and 24% for testing, and the cost functions for 10 stores were listed. 

 

CS 229 Final Project Report  

  
Test  Error  
(10^8)  
  
Test  Error  
(10^8)  

 

Store1  
1.3154  

Store6  
2.6773  

Store2  
4.0130  

Store7  
1.0367  

Store3  
6.8025  

Store8  
7.1013  

Store4  
5.9619  

Store9  
5.0954  

Store5  
5.3891  

Store10  
2.6067  

Figure 5 Comparison between raw and predicted sales of store 1 & 2. 

 

 

We use AR model to predict the sales with small discrepancy to the test data, and we use 

4 Conclusion and Prospective 
 
RF and SVR to find relations between store mean sales and other features.  There are certainly 
rooms for improvements. We can make further predictions on daily sales using SVR. Even 
though we found the relations between the features, and make fairly good predictions on average 
sales for each store. We think next we could try to use SVR see how the parameters set in AR 
change according to features. By doing so, we could automate the process of making predictions 
on daily sales for all the stores in the time series model. 
 
Reference: 
[1] Wensen Dai et al. “A Clustering-based Sales Forecasting Scheme Using Support Vector 
Regression for Computer Server.” Procedia Manufacturing 2 ( 2015 ) 82 – 86. 
[2] Marco Hulsmann et al. “General Sales Forecast Models for Automobile Markets and their 
Analysis.” Transactions on Machine Learning and Data Mining Vol. 5, No. 2 (2012) 65-86. 
 

 

 

