1.	 Â Introduction	 Â 

	 Â 	 Â 
The	 Â art	 Â of	 Â food	 Â and	 Â wine	 Â pairing	 Â has	 Â dated	 Â back	 Â 
centuries	 Â and	 Â since	 Â its	 Â first	 Â practice,	 Â has	 Â honed	 Â its	 Â rules	 Â 
and	 Â regulations	 Â on	 Â what	 Â pairs	 Â well	 Â together.	 Â 	 Â However,	 Â 
within	 Â these	 Â stringent	 Â rules,	 Â nuances	 Â and	 Â differing	 Â 
opinions	 Â exist	 Â that	 Â make	 Â selecting	 Â the	 Â perfect	 Â wine	 Â for	 Â a	 Â 
food	 Â more	 Â complicated	 Â than	 Â it	 Â may	 Â seem.	 Â 	 Â Even	 Â beyond	 Â 
this,	 Â the	 Â complexities	 Â involved	 Â when	 Â selecting	 Â a	 Â wine	 Â 
for	 Â an	 Â entire	 Â dinner	 Â are	 Â even	 Â larger.	 Â 	 Â The	 Â overall	 Â goal	 Â of	 Â 
the	 Â following	 Â presented	 Â algorithms	 Â will	 Â be	 Â to	 Â use	 Â these	 Â 
complexities	 Â and	 Â see	 Â if	 Â the	 Â nuances	 Â of	 Â wine	 Â pairing	 Â can	 Â 
be	 Â simplified.	 Â 	 Â More	 Â specifically,	 Â the	 Â goal	 Â of	 Â the	 Â NaÃ¯ve	 Â 
Bayes	 Â and	 Â K-Â­â€Means	 Â algorithms	 Â will	 Â be	 Â to	 Â predict	 Â either	 Â 
the	 Â color	 Â of	 Â the	 Â wine	 Â (red	 Â vs.	 Â white)	 Â or	 Â a	 Â specific	 Â type	 Â of	 Â 
wine	 Â (Chianti,	 Â Pinot	 Â Grigio,	 Â etc.)	 Â to	 Â pair	 Â with	 Â a	 Â dinner.	 Â 
	 Â 
The	 Â total	 Â number	 Â of	 Â datasets	 Â used	 Â in	 Â the	 Â 
algorithms	 Â 
that	 Â  certain	 Â 
is	 Â 
algorithms	 Â do	 Â not	 Â use	 Â all	 Â three	 Â datasets	 Â in	 Â order	 Â to	 Â 
predict	 Â a	 Â wine.	 Â 	 Â The	 Â first	 Â dataset	 Â contains	 Â self-Â­â€reviewed	 Â 
wine	 Â and	 Â food	 Â pairings	 Â in	 Â which	 Â a	 Â specific	 Â type	 Â of	 Â food	 Â 
is	 Â compared	 Â to	 Â multiple	 Â types	 Â of	 Â wine.	 Â 	 Â Each	 Â pairing	 Â is	 Â 
associated	 Â with	 Â a	 Â rating,	 Â ranging	 Â from	 Â 1	 Â â€“	 Â 5,	 Â that	 Â 
determines	 Â the	 Â quality	 Â of	 Â the	 Â pairing.	 Â 	 Â A	 Â depiction	 Â of	 Â this	 Â 
dataset	 Â is	 Â given	 Â below:	 Â 
	 Â 
	 Â 
	 Â 
The	 Â second	 Â dataset	 Â maps	 Â wines	 Â to	 Â a	 Â flavor	 Â 
profile.	 Â 	 Â Each	 Â flavor	 Â profile	 Â contains	 Â ten	 Â elements	 Â which	 Â 
ranged	 Â from	 Â a	 Â scale	 Â of	 Â 0	 Â â€“	 Â 5	 Â in	 Â which	 Â 0	 Â represents	 Â no	 Â 
presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine	 Â and	 Â 5	 Â represents	 Â a	 Â 
strong	 Â presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine.	 Â 	 Â An	 Â example	 Â of	 Â 
this	 Â is	 Â provided	 Â below:	 Â 
	 Â 

three;	 Â  however	 Â  note	 Â 

2.	 Â Dataset	 Â 

	 Â 

From	 Â Food	 Â to	 Â Wine	 Â 

Justin	 Â Meier	 Â 

	 Â 

	 Â 

CS229	 Â Final	 Â Project	 Â 

	 Â 
The	 Â third	 Â dataset	 Â was	 Â far	 Â more	 Â difficult	 Â to	 Â find	 Â 
and	 Â the	 Â data	 Â was	 Â only	 Â obtained	 Â after	 Â numerous	 Â emails	 Â 
to	 Â the	 Â company	 Â associated	 Â with	 Â the	 Â site.	 Â 	 Â The	 Â final	 Â 
dataset	 Â is	 Â a	 Â pairing	 Â of	 Â a	 Â specific	 Â wine	 Â to	 Â a	 Â specific	 Â dinner	 Â 
in	 Â which	 Â the	 Â ingredients	 Â of	 Â the	 Â dinner	 Â come	 Â as	 Â a	 Â list	 Â of	 Â 
foods.	 Â 	 Â This	 Â dataset	 Â is	 Â ultimately	 Â used	 Â as	 Â my	 Â testing	 Â 
dataset	 Â with	 Â which	 Â I	 Â test	 Â whether	 Â my	 Â algorithms	 Â 
produced	 Â the	 Â correct	 Â color	 Â or	 Â type	 Â of	 Â wine.	 Â 	 Â An	 Â example	 Â 
of	 Â this	 Â dataset	 Â is	 Â given	 Â below:	 Â 

	 Â 

	 Â 

	 Â 

3.1	 Â Raw	 Â Input	 Â Data	 Â 

3.	 Â Features	 Â &	 Â Preprocessing	 Â 

Total	 Â Pairings	 Â =	 Â 2521	 Â 
Unique	 Â Foods	 Â =	 Â 477	 Â 
Unique	 Â Wines	 Â =	 Â 131	 Â 
Dinners	 Â =	 Â 495	 Â 

Finally,	 Â for	 Â better	 Â clarity	 Â of	 Â the	 Â results	 Â presented	 Â later,	 Â 
listed	 Â below	 Â are	 Â some	 Â general	 Â dataset	 Â statistics	 Â that	 Â 
help	 Â to	 Â put	 Â the	 Â results	 Â in	 Â a	 Â better	 Â context.	 Â 
	 Â 
	 Â 
For	 Â the	 Â first	 Â dataset,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â three	 Â 
original	 Â features	 Â associated	 Â with	 Â the	 Â raw-Â­â€input	 Â data:	 Â a	 Â 
specific	 Â type	 Â of	 Â wine,	 Â whether	 Â the	 Â wine	 Â is	 Â red	 Â or	 Â white,	 Â 
and	 Â a	 Â user	 Â rating.	 Â 	 Â All	 Â of	 Â these	 Â features	 Â are	 Â mapped	 Â to	 Â a	 Â 
given	 Â food.	 Â 	 Â The	 Â original	 Â features	 Â associated	 Â with	 Â the	 Â 
raw-Â­â€input	 Â data	 Â for	 Â the	 Â second	 Â dataset	 Â are	 Â simply	 Â the	 Â 
listed	 Â 10	 Â flavors	 Â and	 Â their	 Â numeric	 Â value.	 Â 	 Â The	 Â specific	 Â 
flavors	 Â are	 Â body,	 Â red	 Â fruit,	 Â black	 Â fruit,	 Â floral,	 Â herbaceous,	 Â 
pepper,	 Â earth,	 Â baking	 Â spice,	 Â leather,	 Â and	 Â astringency.	 Â 	 Â 
The	 Â third	 Â datasets	 Â features	 Â are	 Â a	 Â list	 Â of	 Â foods	 Â that	 Â 
composed	 Â a	 Â dinner	 Â and	 Â this	 Â list	 Â was	 Â mapped	 Â to	 Â a	 Â 
particular	 Â wine.	 Â 
	 Â 
The	 Â derived	 Â data	 Â comes	 Â from	 Â a	 Â combination	 Â of	 Â 
all	 Â three	 Â datasets.	 Â 	 Â The	 Â first	 Â step	 Â involves	 Â calculating	 Â an	 Â 
average	 Â wine	 Â flavor	 Â profile	 Â for	 Â each	 Â food	 Â found	 Â within	 Â 

3.2	 Â Derived	 Â Features:	 Â 

1.	 Â Introduction	 Â 

	 Â 	 Â 
The	 Â art	 Â of	 Â food	 Â and	 Â wine	 Â pairing	 Â has	 Â dated	 Â back	 Â 
centuries	 Â and	 Â since	 Â its	 Â first	 Â practice,	 Â has	 Â honed	 Â its	 Â rules	 Â 
and	 Â regulations	 Â on	 Â what	 Â pairs	 Â well	 Â together.	 Â 	 Â However,	 Â 
within	 Â these	 Â stringent	 Â rules,	 Â nuances	 Â and	 Â differing	 Â 
opinions	 Â exist	 Â that	 Â make	 Â selecting	 Â the	 Â perfect	 Â wine	 Â for	 Â a	 Â 
food	 Â more	 Â complicated	 Â than	 Â it	 Â may	 Â seem.	 Â 	 Â Even	 Â beyond	 Â 
this,	 Â the	 Â complexities	 Â involved	 Â when	 Â selecting	 Â a	 Â wine	 Â 
for	 Â an	 Â entire	 Â dinner	 Â are	 Â even	 Â larger.	 Â 	 Â The	 Â overall	 Â goal	 Â of	 Â 
the	 Â following	 Â presented	 Â algorithms	 Â will	 Â be	 Â to	 Â use	 Â these	 Â 
complexities	 Â and	 Â see	 Â if	 Â the	 Â nuances	 Â of	 Â wine	 Â pairing	 Â can	 Â 
be	 Â simplified.	 Â 	 Â More	 Â specifically,	 Â the	 Â goal	 Â of	 Â the	 Â NaÃ¯ve	 Â 
Bayes	 Â and	 Â K-Â­â€Means	 Â algorithms	 Â will	 Â be	 Â to	 Â predict	 Â either	 Â 
the	 Â color	 Â of	 Â the	 Â wine	 Â (red	 Â vs.	 Â white)	 Â or	 Â a	 Â specific	 Â type	 Â of	 Â 
wine	 Â (Chianti,	 Â Pinot	 Â Grigio,	 Â etc.)	 Â to	 Â pair	 Â with	 Â a	 Â dinner.	 Â 
	 Â 
The	 Â total	 Â number	 Â of	 Â datasets	 Â used	 Â in	 Â the	 Â 
algorithms	 Â 
that	 Â  certain	 Â 
is	 Â 
algorithms	 Â do	 Â not	 Â use	 Â all	 Â three	 Â datasets	 Â in	 Â order	 Â to	 Â 
predict	 Â a	 Â wine.	 Â 	 Â The	 Â first	 Â dataset	 Â contains	 Â self-Â­â€reviewed	 Â 
wine	 Â and	 Â food	 Â pairings	 Â in	 Â which	 Â a	 Â specific	 Â type	 Â of	 Â food	 Â 
is	 Â compared	 Â to	 Â multiple	 Â types	 Â of	 Â wine.	 Â 	 Â Each	 Â pairing	 Â is	 Â 
associated	 Â with	 Â a	 Â rating,	 Â ranging	 Â from	 Â 1	 Â â€“	 Â 5,	 Â that	 Â 
determines	 Â the	 Â quality	 Â of	 Â the	 Â pairing.	 Â 	 Â A	 Â depiction	 Â of	 Â this	 Â 
dataset	 Â is	 Â given	 Â below:	 Â 
	 Â 
	 Â 
	 Â 
The	 Â second	 Â dataset	 Â maps	 Â wines	 Â to	 Â a	 Â flavor	 Â 
profile.	 Â 	 Â Each	 Â flavor	 Â profile	 Â contains	 Â ten	 Â elements	 Â which	 Â 
ranged	 Â from	 Â a	 Â scale	 Â of	 Â 0	 Â â€“	 Â 5	 Â in	 Â which	 Â 0	 Â represents	 Â no	 Â 
presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine	 Â and	 Â 5	 Â represents	 Â a	 Â 
strong	 Â presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine.	 Â 	 Â An	 Â example	 Â of	 Â 
this	 Â is	 Â provided	 Â below:	 Â 
	 Â 

three;	 Â  however	 Â  note	 Â 

2.	 Â Dataset	 Â 

	 Â 

From	 Â Food	 Â to	 Â Wine	 Â 

Justin	 Â Meier	 Â 

	 Â 

	 Â 

CS229	 Â Final	 Â Project	 Â 

	 Â 
The	 Â third	 Â dataset	 Â was	 Â far	 Â more	 Â difficult	 Â to	 Â find	 Â 
and	 Â the	 Â data	 Â was	 Â only	 Â obtained	 Â after	 Â numerous	 Â emails	 Â 
to	 Â the	 Â company	 Â associated	 Â with	 Â the	 Â site.	 Â 	 Â The	 Â final	 Â 
dataset	 Â is	 Â a	 Â pairing	 Â of	 Â a	 Â specific	 Â wine	 Â to	 Â a	 Â specific	 Â dinner	 Â 
in	 Â which	 Â the	 Â ingredients	 Â of	 Â the	 Â dinner	 Â come	 Â as	 Â a	 Â list	 Â of	 Â 
foods.	 Â 	 Â This	 Â dataset	 Â is	 Â ultimately	 Â used	 Â as	 Â my	 Â testing	 Â 
dataset	 Â with	 Â which	 Â I	 Â test	 Â whether	 Â my	 Â algorithms	 Â 
produced	 Â the	 Â correct	 Â color	 Â or	 Â type	 Â of	 Â wine.	 Â 	 Â An	 Â example	 Â 
of	 Â this	 Â dataset	 Â is	 Â given	 Â below:	 Â 

	 Â 

	 Â 

	 Â 

3.1	 Â Raw	 Â Input	 Â Data	 Â 

3.	 Â Features	 Â &	 Â Preprocessing	 Â 

Total	 Â Pairings	 Â =	 Â 2521	 Â 
Unique	 Â Foods	 Â =	 Â 477	 Â 
Unique	 Â Wines	 Â =	 Â 131	 Â 
Dinners	 Â =	 Â 495	 Â 

Finally,	 Â for	 Â better	 Â clarity	 Â of	 Â the	 Â results	 Â presented	 Â later,	 Â 
listed	 Â below	 Â are	 Â some	 Â general	 Â dataset	 Â statistics	 Â that	 Â 
help	 Â to	 Â put	 Â the	 Â results	 Â in	 Â a	 Â better	 Â context.	 Â 
	 Â 
	 Â 
For	 Â the	 Â first	 Â dataset,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â three	 Â 
original	 Â features	 Â associated	 Â with	 Â the	 Â raw-Â­â€input	 Â data:	 Â a	 Â 
specific	 Â type	 Â of	 Â wine,	 Â whether	 Â the	 Â wine	 Â is	 Â red	 Â or	 Â white,	 Â 
and	 Â a	 Â user	 Â rating.	 Â 	 Â All	 Â of	 Â these	 Â features	 Â are	 Â mapped	 Â to	 Â a	 Â 
given	 Â food.	 Â 	 Â The	 Â original	 Â features	 Â associated	 Â with	 Â the	 Â 
raw-Â­â€input	 Â data	 Â for	 Â the	 Â second	 Â dataset	 Â are	 Â simply	 Â the	 Â 
listed	 Â 10	 Â flavors	 Â and	 Â their	 Â numeric	 Â value.	 Â 	 Â The	 Â specific	 Â 
flavors	 Â are	 Â body,	 Â red	 Â fruit,	 Â black	 Â fruit,	 Â floral,	 Â herbaceous,	 Â 
pepper,	 Â earth,	 Â baking	 Â spice,	 Â leather,	 Â and	 Â astringency.	 Â 	 Â 
The	 Â third	 Â datasets	 Â features	 Â are	 Â a	 Â list	 Â of	 Â foods	 Â that	 Â 
composed	 Â a	 Â dinner	 Â and	 Â this	 Â list	 Â was	 Â mapped	 Â to	 Â a	 Â 
particular	 Â wine.	 Â 
	 Â 
The	 Â derived	 Â data	 Â comes	 Â from	 Â a	 Â combination	 Â of	 Â 
all	 Â three	 Â datasets.	 Â 	 Â The	 Â first	 Â step	 Â involves	 Â calculating	 Â an	 Â 
average	 Â wine	 Â flavor	 Â profile	 Â for	 Â each	 Â food	 Â found	 Â within	 Â 

3.2	 Â Derived	 Â Features:	 Â 

the	 Â first	 Â dataset.	 Â 	 Â The	 Â averaged	 Â wine	 Â flavor	 Â profile	 Â 
results	 Â from	 Â taking	 Â the	 Â flavor	 Â profiles	 Â for	 Â each	 Â wine,	 Â 
multiplying	 Â them	 Â by	 Â their	 Â rating,	 Â adding	 Â all	 Â of	 Â these	 Â 
flavor	 Â profiles	 Â together,	 Â and	 Â dividing	 Â by	 Â the	 Â sum	 Â of	 Â the	 Â 
ratings	 Â found	 Â for	 Â each	 Â pairing	 Â of	 Â the	 Â given	 Â food	 Â to	 Â its	 Â 
wine.	 Â 	 Â This	 Â process	 Â ensures	 Â that	 Â the	 Â flavor	 Â profile	 Â is	 Â an	 Â 
average	 Â of	 Â all	 Â the	 Â flavor	 Â profiles	 Â of	 Â the	 Â wines	 Â associated	 Â 
with	 Â the	 Â food	 Â and	 Â also	 Â ensures	 Â that	 Â wines	 Â that	 Â have	 Â a	 Â 
higher	 Â ratings	 Â received	 Â more	 Â input	 Â in	 Â determining	 Â the	 Â 
flavor	 Â profile	 Â for	 Â the	 Â food.	 Â 
A	 Â similar	 Â process	 Â is	 Â used	 Â for	 Â determining	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â given	 Â dinner.	 Â 	 Â That	 Â is,	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â dinner	 Â is	 Â determined	 Â by	 Â 
averaging	 Â together	 Â the	 Â wine	 Â flavor	 Â profiles	 Â of	 Â the	 Â 
ingredients	 Â found	 Â within	 Â the	 Â dinner.	 Â 
After	 Â completing	 Â both	 Â of	 Â these	 Â transformations,	 Â 
a	 Â database	 Â exists	 Â that	 Â contains	 Â the	 Â averaged	 Â flavor	 Â 
individual	 Â 
for	 Â  each	 Â 
food	 Â  and	 Â  also	 Â  each	 Â 
profiles	 Â 
individual	 Â wine.	 Â 	 Â An	 Â illustration	 Â of	 Â this	 Â transformation	 Â 
can	 Â be	 Â pictured	 Â below,	 Â so	 Â as	 Â to	 Â better	 Â explain	 Â how	 Â the	 Â 
process	 Â worked:	 Â 
	 Â 	 Â ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)= Â 
	 Â 
ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â  ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘“ğ‘œğ‘œğ‘‘)=
! Â âˆˆ Â !"#$%(!""#)
1
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘¤ğ‘–ğ‘›ğ‘’ âˆ—ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”
 Â 
ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â 
 Â 
1
ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘‘ğ‘–ğ‘›ğ‘›ğ‘’ğ‘Ÿ)=
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘“ğ‘œğ‘œğ‘‘
	 Â 
 Â 
ğ‘›ğ‘¢ğ‘šğ‘‚ğ‘“ğ¼ğ‘›ğ‘”ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ‘ 
	 Â 
	 Â 
 Â 
The	 Â two	 Â types	 Â of	 Â models	 Â used	 Â are	 Â a	 Â NaÃ¯ve	 Â Bayes	 Â 
algorithm	 Â and	 Â a	 Â K-Â­â€Means	 Â algorithm.	 Â 	 Â The	 Â goal	 Â of	 Â both	 Â 
algorithms	 Â is	 Â to	 Â either	 Â predict	 Â a	 Â specific	 Â wine	 Â or	 Â to	 Â 
predict	 Â whether	 Â one	 Â should	 Â drink	 Â a	 Â red	 Â or	 Â white	 Â wine.	 Â 	 Â 
The	 Â input	 Â is	 Â the	 Â list	 Â of	 Â ingredients	 Â found	 Â within	 Â the	 Â 
third	 Â database,	 Â which	 Â uses	 Â the	 Â raw-Â­â€input	 Â variables	 Â and	 Â 
the	 Â derived	 Â variables	 Â to	 Â predict	 Â a	 Â specific	 Â type	 Â of	 Â wine.	 Â 	 Â 
The	 Â accuracy	 Â of	 Â prediction	 Â is	 Â given	 Â by	 Â whether	 Â the	 Â 
predicted	 Â wine	 Â was	 Â the	 Â color	 Â or	 Â the	 Â type	 Â of	 Â wine	 Â given	 Â 
by	 Â the	 Â third	 Â database	 Â of	 Â wines	 Â paired	 Â to	 Â dinners.	 Â 	 Â 	 Â 	 Â The	 Â 
specifics	 Â of	 Â the	 Â algorithms	 Â are	 Â listed	 Â below:	 Â 
	 Â 
The	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â uses	 Â the	 Â generalized	 Â 
NaÃ¯ve	 Â Bayes	 Â formula	 Â with	 Â multiples	 Â variables,	 Â given	 Â 
below:	 Â 	 Â 

4.	 Â Models	 Â &	 Â Results	 Â 

4.1	 Â NaÃ¯ve	 Â Bayes:	 Â 

 Â 

	 Â 

ğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â ğ‘ƒğ‘¥

ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!!
ğ‘ƒ(ğ‘“!â€¦ğ‘“!)
	 Â 
!
argmaxğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â argmax! ğ‘ƒğ‘¥
	 Â 
ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!
That	 Â is,	 Â the	 Â best	 Â prediction	 Â (whether	 Â it	 Â be	 Â a	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â or	 Â a	 Â specific	 Â wine),	 Â will	 Â be	 Â the	 Â label	 Â that	 Â 
produces	 Â the	 Â highest	 Â product	 Â when	 Â considering	 Â the	 Â 
probability	 Â that	 Â we	 Â have	 Â a	 Â specific	 Â ingredient	 Â given	 Â our	 Â 
label.	 Â 	 Â Below	 Â are	 Â the	 Â summaries	 Â of	 Â the	 Â two	 Â types	 Â of	 Â 
predictions	 Â that	 Â were	 Â made	 Â using	 Â NaÃ¯ve	 Â Bayes:	 Â 
	 Â 
For	 Â the	 Â red	 Â and	 Â white	 Â prediction,	 Â I	 Â use	 Â a	 Â 
combination	 Â  of	 Â  score	 Â  consideration	 Â  and	 Â  Laplace	 Â 
smoothing.	 Â 	 Â If	 Â I	 Â do	 Â not	 Â consider	 Â the	 Â ranking	 Â (no	 Â score	 Â 
consideration),	 Â then	 Â I	 Â simply	 Â calculate	 Â the	 Â probability	 Â of	 Â 
a	 Â food	 Â given	 Â a	 Â specific	 Â color	 Â based	 Â on	 Â the	 Â occurrence	 Â of	 Â 
the	 Â food	 Â and	 Â wine	 Â color	 Â together.	 Â 	 Â 	 Â 	 Â If	 Â I	 Â consider	 Â the	 Â 
score,	 Â then	 Â I	 Â use	 Â the	 Â ranking	 Â in	 Â determining	 Â the	 Â 
probability	 Â that	 Â a	 Â given	 Â food	 Â occurred	 Â given	 Â the	 Â color	 Â of	 Â 
the	 Â wine.	 Â 	 Â That	 Â is,	 Â wine	 Â pairings	 Â with	 Â higher	 Â rankings	 Â 
increase	 Â this	 Â probability,	 Â thereby	 Â giving	 Â preference	 Â to	 Â 
wines	 Â that	 Â are	 Â paired	 Â well	 Â with	 Â a	 Â food.	 Â 
	 Â Laplace	 Â 
smoothing	 Â works	 Â normally	 Â when	 Â there	 Â is	 Â no	 Â score	 Â 
consideration.	 Â 
is	 Â  score	 Â 
there	 Â 
	 Â  However,	 Â  when	 Â 
consideration,	 Â the	 Â smoothing	 Â parameter	 Â is	 Â given	 Â as	 Â the	 Â 
average	 Â of	 Â all	 Â the	 Â ratings	 Â of	 Â food	 Â and	 Â wine.	 Â 	 Â The	 Â 
four	 Â 
these	 Â 
accuracy	 Â  of	 Â 
types	 Â  of	 Â  NaÃ¯ve	 Â  Bayes	 Â 
classification	 Â can	 Â be	 Â seen	 Â below:	 Â 

4.1.1	 Â Red	 Â vs.	 Â White	 Â Prediction:	 Â 

	 Â 

	 Â 

Red	 Â vs.	 Â White	 Â 

	 Â 
No	 Â Laplace	 Â 
No	 Â Score	 Â 
Laplace	 Â 
No	 Â Score	 Â 
No	 Â Laplace	 Â 
Score	 Â 
Laplace	 Â 

Red	 Â  Pred.	 Â 
Accuracy	 Â 
38.2%	 Â 
88.4%	 Â 
38.2%	 Â 
91.6%	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
89.4%	 Â 
77.3%	 Â 
89.5%	 Â 
73.0%	 Â 

Both	 Â  Pred.	 Â 
Accuracy	 Â 
63.1%	 Â 
	 Â 
83.0%	 Â 
63.2%	 Â 
81.6%	 Â 

1.	 Â Introduction	 Â 

	 Â 	 Â 
The	 Â art	 Â of	 Â food	 Â and	 Â wine	 Â pairing	 Â has	 Â dated	 Â back	 Â 
centuries	 Â and	 Â since	 Â its	 Â first	 Â practice,	 Â has	 Â honed	 Â its	 Â rules	 Â 
and	 Â regulations	 Â on	 Â what	 Â pairs	 Â well	 Â together.	 Â 	 Â However,	 Â 
within	 Â these	 Â stringent	 Â rules,	 Â nuances	 Â and	 Â differing	 Â 
opinions	 Â exist	 Â that	 Â make	 Â selecting	 Â the	 Â perfect	 Â wine	 Â for	 Â a	 Â 
food	 Â more	 Â complicated	 Â than	 Â it	 Â may	 Â seem.	 Â 	 Â Even	 Â beyond	 Â 
this,	 Â the	 Â complexities	 Â involved	 Â when	 Â selecting	 Â a	 Â wine	 Â 
for	 Â an	 Â entire	 Â dinner	 Â are	 Â even	 Â larger.	 Â 	 Â The	 Â overall	 Â goal	 Â of	 Â 
the	 Â following	 Â presented	 Â algorithms	 Â will	 Â be	 Â to	 Â use	 Â these	 Â 
complexities	 Â and	 Â see	 Â if	 Â the	 Â nuances	 Â of	 Â wine	 Â pairing	 Â can	 Â 
be	 Â simplified.	 Â 	 Â More	 Â specifically,	 Â the	 Â goal	 Â of	 Â the	 Â NaÃ¯ve	 Â 
Bayes	 Â and	 Â K-Â­â€Means	 Â algorithms	 Â will	 Â be	 Â to	 Â predict	 Â either	 Â 
the	 Â color	 Â of	 Â the	 Â wine	 Â (red	 Â vs.	 Â white)	 Â or	 Â a	 Â specific	 Â type	 Â of	 Â 
wine	 Â (Chianti,	 Â Pinot	 Â Grigio,	 Â etc.)	 Â to	 Â pair	 Â with	 Â a	 Â dinner.	 Â 
	 Â 
The	 Â total	 Â number	 Â of	 Â datasets	 Â used	 Â in	 Â the	 Â 
algorithms	 Â 
that	 Â  certain	 Â 
is	 Â 
algorithms	 Â do	 Â not	 Â use	 Â all	 Â three	 Â datasets	 Â in	 Â order	 Â to	 Â 
predict	 Â a	 Â wine.	 Â 	 Â The	 Â first	 Â dataset	 Â contains	 Â self-Â­â€reviewed	 Â 
wine	 Â and	 Â food	 Â pairings	 Â in	 Â which	 Â a	 Â specific	 Â type	 Â of	 Â food	 Â 
is	 Â compared	 Â to	 Â multiple	 Â types	 Â of	 Â wine.	 Â 	 Â Each	 Â pairing	 Â is	 Â 
associated	 Â with	 Â a	 Â rating,	 Â ranging	 Â from	 Â 1	 Â â€“	 Â 5,	 Â that	 Â 
determines	 Â the	 Â quality	 Â of	 Â the	 Â pairing.	 Â 	 Â A	 Â depiction	 Â of	 Â this	 Â 
dataset	 Â is	 Â given	 Â below:	 Â 
	 Â 
	 Â 
	 Â 
The	 Â second	 Â dataset	 Â maps	 Â wines	 Â to	 Â a	 Â flavor	 Â 
profile.	 Â 	 Â Each	 Â flavor	 Â profile	 Â contains	 Â ten	 Â elements	 Â which	 Â 
ranged	 Â from	 Â a	 Â scale	 Â of	 Â 0	 Â â€“	 Â 5	 Â in	 Â which	 Â 0	 Â represents	 Â no	 Â 
presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine	 Â and	 Â 5	 Â represents	 Â a	 Â 
strong	 Â presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine.	 Â 	 Â An	 Â example	 Â of	 Â 
this	 Â is	 Â provided	 Â below:	 Â 
	 Â 

three;	 Â  however	 Â  note	 Â 

2.	 Â Dataset	 Â 

	 Â 

From	 Â Food	 Â to	 Â Wine	 Â 

Justin	 Â Meier	 Â 

	 Â 

	 Â 

CS229	 Â Final	 Â Project	 Â 

	 Â 
The	 Â third	 Â dataset	 Â was	 Â far	 Â more	 Â difficult	 Â to	 Â find	 Â 
and	 Â the	 Â data	 Â was	 Â only	 Â obtained	 Â after	 Â numerous	 Â emails	 Â 
to	 Â the	 Â company	 Â associated	 Â with	 Â the	 Â site.	 Â 	 Â The	 Â final	 Â 
dataset	 Â is	 Â a	 Â pairing	 Â of	 Â a	 Â specific	 Â wine	 Â to	 Â a	 Â specific	 Â dinner	 Â 
in	 Â which	 Â the	 Â ingredients	 Â of	 Â the	 Â dinner	 Â come	 Â as	 Â a	 Â list	 Â of	 Â 
foods.	 Â 	 Â This	 Â dataset	 Â is	 Â ultimately	 Â used	 Â as	 Â my	 Â testing	 Â 
dataset	 Â with	 Â which	 Â I	 Â test	 Â whether	 Â my	 Â algorithms	 Â 
produced	 Â the	 Â correct	 Â color	 Â or	 Â type	 Â of	 Â wine.	 Â 	 Â An	 Â example	 Â 
of	 Â this	 Â dataset	 Â is	 Â given	 Â below:	 Â 

	 Â 

	 Â 

	 Â 

3.1	 Â Raw	 Â Input	 Â Data	 Â 

3.	 Â Features	 Â &	 Â Preprocessing	 Â 

Total	 Â Pairings	 Â =	 Â 2521	 Â 
Unique	 Â Foods	 Â =	 Â 477	 Â 
Unique	 Â Wines	 Â =	 Â 131	 Â 
Dinners	 Â =	 Â 495	 Â 

Finally,	 Â for	 Â better	 Â clarity	 Â of	 Â the	 Â results	 Â presented	 Â later,	 Â 
listed	 Â below	 Â are	 Â some	 Â general	 Â dataset	 Â statistics	 Â that	 Â 
help	 Â to	 Â put	 Â the	 Â results	 Â in	 Â a	 Â better	 Â context.	 Â 
	 Â 
	 Â 
For	 Â the	 Â first	 Â dataset,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â three	 Â 
original	 Â features	 Â associated	 Â with	 Â the	 Â raw-Â­â€input	 Â data:	 Â a	 Â 
specific	 Â type	 Â of	 Â wine,	 Â whether	 Â the	 Â wine	 Â is	 Â red	 Â or	 Â white,	 Â 
and	 Â a	 Â user	 Â rating.	 Â 	 Â All	 Â of	 Â these	 Â features	 Â are	 Â mapped	 Â to	 Â a	 Â 
given	 Â food.	 Â 	 Â The	 Â original	 Â features	 Â associated	 Â with	 Â the	 Â 
raw-Â­â€input	 Â data	 Â for	 Â the	 Â second	 Â dataset	 Â are	 Â simply	 Â the	 Â 
listed	 Â 10	 Â flavors	 Â and	 Â their	 Â numeric	 Â value.	 Â 	 Â The	 Â specific	 Â 
flavors	 Â are	 Â body,	 Â red	 Â fruit,	 Â black	 Â fruit,	 Â floral,	 Â herbaceous,	 Â 
pepper,	 Â earth,	 Â baking	 Â spice,	 Â leather,	 Â and	 Â astringency.	 Â 	 Â 
The	 Â third	 Â datasets	 Â features	 Â are	 Â a	 Â list	 Â of	 Â foods	 Â that	 Â 
composed	 Â a	 Â dinner	 Â and	 Â this	 Â list	 Â was	 Â mapped	 Â to	 Â a	 Â 
particular	 Â wine.	 Â 
	 Â 
The	 Â derived	 Â data	 Â comes	 Â from	 Â a	 Â combination	 Â of	 Â 
all	 Â three	 Â datasets.	 Â 	 Â The	 Â first	 Â step	 Â involves	 Â calculating	 Â an	 Â 
average	 Â wine	 Â flavor	 Â profile	 Â for	 Â each	 Â food	 Â found	 Â within	 Â 

3.2	 Â Derived	 Â Features:	 Â 

the	 Â first	 Â dataset.	 Â 	 Â The	 Â averaged	 Â wine	 Â flavor	 Â profile	 Â 
results	 Â from	 Â taking	 Â the	 Â flavor	 Â profiles	 Â for	 Â each	 Â wine,	 Â 
multiplying	 Â them	 Â by	 Â their	 Â rating,	 Â adding	 Â all	 Â of	 Â these	 Â 
flavor	 Â profiles	 Â together,	 Â and	 Â dividing	 Â by	 Â the	 Â sum	 Â of	 Â the	 Â 
ratings	 Â found	 Â for	 Â each	 Â pairing	 Â of	 Â the	 Â given	 Â food	 Â to	 Â its	 Â 
wine.	 Â 	 Â This	 Â process	 Â ensures	 Â that	 Â the	 Â flavor	 Â profile	 Â is	 Â an	 Â 
average	 Â of	 Â all	 Â the	 Â flavor	 Â profiles	 Â of	 Â the	 Â wines	 Â associated	 Â 
with	 Â the	 Â food	 Â and	 Â also	 Â ensures	 Â that	 Â wines	 Â that	 Â have	 Â a	 Â 
higher	 Â ratings	 Â received	 Â more	 Â input	 Â in	 Â determining	 Â the	 Â 
flavor	 Â profile	 Â for	 Â the	 Â food.	 Â 
A	 Â similar	 Â process	 Â is	 Â used	 Â for	 Â determining	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â given	 Â dinner.	 Â 	 Â That	 Â is,	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â dinner	 Â is	 Â determined	 Â by	 Â 
averaging	 Â together	 Â the	 Â wine	 Â flavor	 Â profiles	 Â of	 Â the	 Â 
ingredients	 Â found	 Â within	 Â the	 Â dinner.	 Â 
After	 Â completing	 Â both	 Â of	 Â these	 Â transformations,	 Â 
a	 Â database	 Â exists	 Â that	 Â contains	 Â the	 Â averaged	 Â flavor	 Â 
individual	 Â 
for	 Â  each	 Â 
food	 Â  and	 Â  also	 Â  each	 Â 
profiles	 Â 
individual	 Â wine.	 Â 	 Â An	 Â illustration	 Â of	 Â this	 Â transformation	 Â 
can	 Â be	 Â pictured	 Â below,	 Â so	 Â as	 Â to	 Â better	 Â explain	 Â how	 Â the	 Â 
process	 Â worked:	 Â 
	 Â 	 Â ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)= Â 
	 Â 
ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â  ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘“ğ‘œğ‘œğ‘‘)=
! Â âˆˆ Â !"#$%(!""#)
1
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘¤ğ‘–ğ‘›ğ‘’ âˆ—ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”
 Â 
ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â 
 Â 
1
ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘‘ğ‘–ğ‘›ğ‘›ğ‘’ğ‘Ÿ)=
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘“ğ‘œğ‘œğ‘‘
	 Â 
 Â 
ğ‘›ğ‘¢ğ‘šğ‘‚ğ‘“ğ¼ğ‘›ğ‘”ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ‘ 
	 Â 
	 Â 
 Â 
The	 Â two	 Â types	 Â of	 Â models	 Â used	 Â are	 Â a	 Â NaÃ¯ve	 Â Bayes	 Â 
algorithm	 Â and	 Â a	 Â K-Â­â€Means	 Â algorithm.	 Â 	 Â The	 Â goal	 Â of	 Â both	 Â 
algorithms	 Â is	 Â to	 Â either	 Â predict	 Â a	 Â specific	 Â wine	 Â or	 Â to	 Â 
predict	 Â whether	 Â one	 Â should	 Â drink	 Â a	 Â red	 Â or	 Â white	 Â wine.	 Â 	 Â 
The	 Â input	 Â is	 Â the	 Â list	 Â of	 Â ingredients	 Â found	 Â within	 Â the	 Â 
third	 Â database,	 Â which	 Â uses	 Â the	 Â raw-Â­â€input	 Â variables	 Â and	 Â 
the	 Â derived	 Â variables	 Â to	 Â predict	 Â a	 Â specific	 Â type	 Â of	 Â wine.	 Â 	 Â 
The	 Â accuracy	 Â of	 Â prediction	 Â is	 Â given	 Â by	 Â whether	 Â the	 Â 
predicted	 Â wine	 Â was	 Â the	 Â color	 Â or	 Â the	 Â type	 Â of	 Â wine	 Â given	 Â 
by	 Â the	 Â third	 Â database	 Â of	 Â wines	 Â paired	 Â to	 Â dinners.	 Â 	 Â 	 Â 	 Â The	 Â 
specifics	 Â of	 Â the	 Â algorithms	 Â are	 Â listed	 Â below:	 Â 
	 Â 
The	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â uses	 Â the	 Â generalized	 Â 
NaÃ¯ve	 Â Bayes	 Â formula	 Â with	 Â multiples	 Â variables,	 Â given	 Â 
below:	 Â 	 Â 

4.	 Â Models	 Â &	 Â Results	 Â 

4.1	 Â NaÃ¯ve	 Â Bayes:	 Â 

 Â 

	 Â 

ğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â ğ‘ƒğ‘¥

ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!!
ğ‘ƒ(ğ‘“!â€¦ğ‘“!)
	 Â 
!
argmaxğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â argmax! ğ‘ƒğ‘¥
	 Â 
ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!
That	 Â is,	 Â the	 Â best	 Â prediction	 Â (whether	 Â it	 Â be	 Â a	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â or	 Â a	 Â specific	 Â wine),	 Â will	 Â be	 Â the	 Â label	 Â that	 Â 
produces	 Â the	 Â highest	 Â product	 Â when	 Â considering	 Â the	 Â 
probability	 Â that	 Â we	 Â have	 Â a	 Â specific	 Â ingredient	 Â given	 Â our	 Â 
label.	 Â 	 Â Below	 Â are	 Â the	 Â summaries	 Â of	 Â the	 Â two	 Â types	 Â of	 Â 
predictions	 Â that	 Â were	 Â made	 Â using	 Â NaÃ¯ve	 Â Bayes:	 Â 
	 Â 
For	 Â the	 Â red	 Â and	 Â white	 Â prediction,	 Â I	 Â use	 Â a	 Â 
combination	 Â  of	 Â  score	 Â  consideration	 Â  and	 Â  Laplace	 Â 
smoothing.	 Â 	 Â If	 Â I	 Â do	 Â not	 Â consider	 Â the	 Â ranking	 Â (no	 Â score	 Â 
consideration),	 Â then	 Â I	 Â simply	 Â calculate	 Â the	 Â probability	 Â of	 Â 
a	 Â food	 Â given	 Â a	 Â specific	 Â color	 Â based	 Â on	 Â the	 Â occurrence	 Â of	 Â 
the	 Â food	 Â and	 Â wine	 Â color	 Â together.	 Â 	 Â 	 Â 	 Â If	 Â I	 Â consider	 Â the	 Â 
score,	 Â then	 Â I	 Â use	 Â the	 Â ranking	 Â in	 Â determining	 Â the	 Â 
probability	 Â that	 Â a	 Â given	 Â food	 Â occurred	 Â given	 Â the	 Â color	 Â of	 Â 
the	 Â wine.	 Â 	 Â That	 Â is,	 Â wine	 Â pairings	 Â with	 Â higher	 Â rankings	 Â 
increase	 Â this	 Â probability,	 Â thereby	 Â giving	 Â preference	 Â to	 Â 
wines	 Â that	 Â are	 Â paired	 Â well	 Â with	 Â a	 Â food.	 Â 
	 Â Laplace	 Â 
smoothing	 Â works	 Â normally	 Â when	 Â there	 Â is	 Â no	 Â score	 Â 
consideration.	 Â 
is	 Â  score	 Â 
there	 Â 
	 Â  However,	 Â  when	 Â 
consideration,	 Â the	 Â smoothing	 Â parameter	 Â is	 Â given	 Â as	 Â the	 Â 
average	 Â of	 Â all	 Â the	 Â ratings	 Â of	 Â food	 Â and	 Â wine.	 Â 	 Â The	 Â 
four	 Â 
these	 Â 
accuracy	 Â  of	 Â 
types	 Â  of	 Â  NaÃ¯ve	 Â  Bayes	 Â 
classification	 Â can	 Â be	 Â seen	 Â below:	 Â 

4.1.1	 Â Red	 Â vs.	 Â White	 Â Prediction:	 Â 

	 Â 

	 Â 

Red	 Â vs.	 Â White	 Â 

	 Â 
No	 Â Laplace	 Â 
No	 Â Score	 Â 
Laplace	 Â 
No	 Â Score	 Â 
No	 Â Laplace	 Â 
Score	 Â 
Laplace	 Â 

Red	 Â  Pred.	 Â 
Accuracy	 Â 
38.2%	 Â 
88.4%	 Â 
38.2%	 Â 
91.6%	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
89.4%	 Â 
77.3%	 Â 
89.5%	 Â 
73.0%	 Â 

Both	 Â  Pred.	 Â 
Accuracy	 Â 
63.1%	 Â 
	 Â 
83.0%	 Â 
63.2%	 Â 
81.6%	 Â 

4.1.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

Score	 Â 
	 Â 
When	 Â calculating	 Â the	 Â probabilities	 Â for	 Â finding	 Â a	 Â 
specific	 Â wine,	 Â the	 Â algorithm	 Â uses	 Â the	 Â model	 Â with	 Â the	 Â 
maximum	 Â total	 Â accuracy	 Â from	 Â the	 Â red/white	 Â prediction	 Â 
problem.	 Â 	 Â In	 Â this	 Â case,	 Â the	 Â probabilities	 Â involve	 Â no	 Â score	 Â 
consideration	 Â but	 Â do	 Â involve	 Â Laplace	 Â smoothing.	 Â 
In	 Â order	 Â to	 Â best	 Â interpret	 Â the	 Â accuracy	 Â of	 Â the	 Â 
algorithm,	 Â I	 Â decided	 Â to	 Â not	 Â only	 Â keep	 Â track	 Â of	 Â the	 Â top	 Â 
wine	 Â predicted	 Â by	 Â the	 Â algorithm	 Â by	 Â varying	 Â top	 Â wine	 Â 
predictions.	 Â 	 Â Then,	 Â the	 Â accuracy	 Â of	 Â the	 Â algorithm	 Â is	 Â 
determined	 Â by	 Â whether	 Â the	 Â actual	 Â wine	 Â paired	 Â with	 Â the	 Â 
dinner	 Â is	 Â found	 Â within	 Â the	 Â top	 Â N	 Â wines	 Â that	 Â were	 Â kept	 Â 
track	 Â of.	 Â 	 Â The	 Â results	 Â of	 Â this	 Â are	 Â demonstrated	 Â below:	 Â 
	 Â 

detailed	 Â above	 Â and	 Â then	 Â the	 Â prediction	 Â for	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â is	 Â given	 Â based	 Â on	 Â the	 Â color	 Â of	 Â the	 Â predicted	 Â 
wine.	 Â 	 Â Ultimately,	 Â my	 Â k-Â­â€means	 Â algorithm	 Â would	 Â not	 Â 
converge	 Â in	 Â a	 Â measurable	 Â and	 Â feasible	 Â time	 Â range	 Â and	 Â 
despite	 Â numerous	 Â attempts	 Â to	 Â resolve	 Â this	 Â issue,	 Â it	 Â still	 Â 
remains.	 Â 
	 Â I	 Â tried	 Â a	 Â multitude	 Â of	 Â things,	 Â including	 Â 
decreasing	 Â the	 Â side	 Â of	 Â the	 Â variables	 Â associated	 Â with	 Â 
calculating	 Â the	 Â Euclidean	 Â distance	 Â between	 Â the	 Â points	 Â 
and	 Â the	 Â centroids.	 Â 	 Â Instead,	 Â I	 Â decided	 Â to	 Â change	 Â the	 Â 
number	 Â of	 Â iterations	 Â The	 Â results	 Â of	 Â this	 Â are	 Â shown	 Â 
below:	 Â 
	 Â 

	 Â 

4.2	 Â K-Â­â€Means	 Â 

Specific	 Â Wine	 Â (with	 Â top	 Â N	 Â wines)	 Â 

8.5%	 Â 
18.0%	 Â 
26.0%	 Â 
37.5%	 Â 
74.7%	 Â 
90.4%	 Â 

N	 Â =	 Â 1	 Â 
N	 Â =	 Â 3	 Â 
N	 Â =	 Â 5	 Â 
N	 Â =	 Â 10	 Â 
N	 Â =	 Â 20	 Â 
N	 Â =	 Â 30	 Â 
	 Â 	 Â 
The	 Â K-Â­â€Means	 Â algorithm	 Â functions	 Â as	 Â a	 Â normal	 Â K-Â­â€
Means	 Â algorithm	 Â with	 Â the	 Â variables	 Â used	 Â to	 Â determine	 Â 
distance	 Â being	 Â the	 Â values	 Â associated	 Â with	 Â the	 Â flavor	 Â 
profile,	 Â from	 Â 0	 Â to5.	 Â 	 Â The	 Â points	 Â of	 Â the	 Â algorithm	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â dinners	 Â and	 Â the	 Â centroids	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â wine,	 Â given	 Â by	 Â the	 Â original	 Â data	 Â 
from	 Â the	 Â second	 Â database.	 Â 	 Â As	 Â each	 Â point	 Â converges	 Â 
closer	 Â to	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â predicts	 Â the	 Â wine	 Â 
represented	 Â by	 Â the	 Â centroid	 Â for	 Â the	 Â dinner	 Â represented	 Â 
by	 Â the	 Â point.	 Â 	 Â These	 Â same	 Â ideas	 Â are	 Â used	 Â to	 Â calculate	 Â 
both	 Â the	 Â color	 Â of	 Â the	 Â wine	 Â as	 Â well	 Â as	 Â a	 Â specific	 Â type	 Â of	 Â 
wine.	 Â 	 Â The	 Â specifics	 Â and	 Â results	 Â of	 Â each	 Â of	 Â these	 Â is	 Â given	 Â 
below:	 Â 
	 Â 
This	 Â algorithm	 Â can	 Â be	 Â approached	 Â in	 Â two	 Â 
separate	 Â ways.	 Â 	 Â The	 Â first	 Â follows	 Â the	 Â exact	 Â procedure	 Â 

4.2.1	 Â Red	 Â vs.	 Â White	 Â Wine	 Â Prediction	 Â 

	 Â 

	 Â 	 Â 

Red	 Â vs.	 Â White	 Â from	 Â Specific	 Â Wine	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
100%	 Â 
86.6%	 Â 
72.8%	 Â 
51.0%	 Â 
11.7%	 Â 

	 Â 
Both	 Â  Pred.	 Â 
Red	 Â 
Pred.	 Â 
	 Â 
Accuracy	 Â 
Accuracy	 Â 
87.0%	 Â 
69.5%	 Â 
Iters	 Â =	 Â 1	 Â 
81.3%	 Â 
74.0%	 Â 
Iters	 Â =	 Â 5	 Â 
74.5%	 Â 
76.8%	 Â 
Iters	 Â =	 Â 10	 Â 
83.1%	 Â 
64.7%	 Â 
Iters	 Â =	 Â 20	 Â 
47.1%	 Â 
94.9%	 Â 
Iters	 Â =	 Â 50	 Â 
	 Â 
The	 Â second	 Â approach	 Â involves	 Â computing	 Â an	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â red	 Â wine	 Â and	 Â for	 Â a	 Â white	 Â 
wine	 Â by	 Â averaging	 Â together	 Â all	 Â the	 Â red	 Â wine	 Â flavor	 Â 
profiles	 Â and	 Â all	 Â the	 Â white	 Â wine	 Â flavor	 Â profiles.	 Â 	 Â From	 Â 
here,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â two	 Â centroids	 Â representing	 Â all	 Â 
of	 Â the	 Â white	 Â wines	 Â and	 Â all	 Â the	 Â red	 Â wines.	 Â 	 Â Therefore,	 Â as	 Â a	 Â 
dinner	 Â converges	 Â on	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â would	 Â 
associate	 Â it	 Â with	 Â the	 Â color	 Â that	 Â centroid	 Â represented.	 Â 	 Â 
The	 Â results	 Â of	 Â both	 Â of	 Â these	 Â algorithms	 Â are	 Â given	 Â below.	 Â 
	 Â Red	 Â vs.	 Â White	 Â Prediction	 Â Accuracy	 Â 
with	 Â Averaged	 Â Red/White	 Â Flavor	 Â Profiles	 Â 
White	 Â Pred.	 Â 
Red	 Â 
Both	 Â  Pred.	 Â 
Pred.	 Â 
Accuracy	 Â 
Accuracy	 Â 
Accuracy	 Â 
	 Â 80.0%	 Â 
	 Â 61.7%	 Â 
	 Â 70.9%	 Â 
	 Â 
	 Â 
For	 Â finding	 Â a	 Â specific	 Â wine,	 Â I	 Â use	 Â the	 Â number	 Â of	 Â 
iterations	 Â that	 Â produced	 Â the	 Â highest	 Â accuracy	 Â when	 Â 
predicting	 Â the	 Â color	 Â of	 Â the	 Â wine.	 Â 	 Â This	 Â occurrs	 Â when	 Â 

4.2.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

1.	 Â Introduction	 Â 

	 Â 	 Â 
The	 Â art	 Â of	 Â food	 Â and	 Â wine	 Â pairing	 Â has	 Â dated	 Â back	 Â 
centuries	 Â and	 Â since	 Â its	 Â first	 Â practice,	 Â has	 Â honed	 Â its	 Â rules	 Â 
and	 Â regulations	 Â on	 Â what	 Â pairs	 Â well	 Â together.	 Â 	 Â However,	 Â 
within	 Â these	 Â stringent	 Â rules,	 Â nuances	 Â and	 Â differing	 Â 
opinions	 Â exist	 Â that	 Â make	 Â selecting	 Â the	 Â perfect	 Â wine	 Â for	 Â a	 Â 
food	 Â more	 Â complicated	 Â than	 Â it	 Â may	 Â seem.	 Â 	 Â Even	 Â beyond	 Â 
this,	 Â the	 Â complexities	 Â involved	 Â when	 Â selecting	 Â a	 Â wine	 Â 
for	 Â an	 Â entire	 Â dinner	 Â are	 Â even	 Â larger.	 Â 	 Â The	 Â overall	 Â goal	 Â of	 Â 
the	 Â following	 Â presented	 Â algorithms	 Â will	 Â be	 Â to	 Â use	 Â these	 Â 
complexities	 Â and	 Â see	 Â if	 Â the	 Â nuances	 Â of	 Â wine	 Â pairing	 Â can	 Â 
be	 Â simplified.	 Â 	 Â More	 Â specifically,	 Â the	 Â goal	 Â of	 Â the	 Â NaÃ¯ve	 Â 
Bayes	 Â and	 Â K-Â­â€Means	 Â algorithms	 Â will	 Â be	 Â to	 Â predict	 Â either	 Â 
the	 Â color	 Â of	 Â the	 Â wine	 Â (red	 Â vs.	 Â white)	 Â or	 Â a	 Â specific	 Â type	 Â of	 Â 
wine	 Â (Chianti,	 Â Pinot	 Â Grigio,	 Â etc.)	 Â to	 Â pair	 Â with	 Â a	 Â dinner.	 Â 
	 Â 
The	 Â total	 Â number	 Â of	 Â datasets	 Â used	 Â in	 Â the	 Â 
algorithms	 Â 
that	 Â  certain	 Â 
is	 Â 
algorithms	 Â do	 Â not	 Â use	 Â all	 Â three	 Â datasets	 Â in	 Â order	 Â to	 Â 
predict	 Â a	 Â wine.	 Â 	 Â The	 Â first	 Â dataset	 Â contains	 Â self-Â­â€reviewed	 Â 
wine	 Â and	 Â food	 Â pairings	 Â in	 Â which	 Â a	 Â specific	 Â type	 Â of	 Â food	 Â 
is	 Â compared	 Â to	 Â multiple	 Â types	 Â of	 Â wine.	 Â 	 Â Each	 Â pairing	 Â is	 Â 
associated	 Â with	 Â a	 Â rating,	 Â ranging	 Â from	 Â 1	 Â â€“	 Â 5,	 Â that	 Â 
determines	 Â the	 Â quality	 Â of	 Â the	 Â pairing.	 Â 	 Â A	 Â depiction	 Â of	 Â this	 Â 
dataset	 Â is	 Â given	 Â below:	 Â 
	 Â 
	 Â 
	 Â 
The	 Â second	 Â dataset	 Â maps	 Â wines	 Â to	 Â a	 Â flavor	 Â 
profile.	 Â 	 Â Each	 Â flavor	 Â profile	 Â contains	 Â ten	 Â elements	 Â which	 Â 
ranged	 Â from	 Â a	 Â scale	 Â of	 Â 0	 Â â€“	 Â 5	 Â in	 Â which	 Â 0	 Â represents	 Â no	 Â 
presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine	 Â and	 Â 5	 Â represents	 Â a	 Â 
strong	 Â presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine.	 Â 	 Â An	 Â example	 Â of	 Â 
this	 Â is	 Â provided	 Â below:	 Â 
	 Â 

three;	 Â  however	 Â  note	 Â 

2.	 Â Dataset	 Â 

	 Â 

From	 Â Food	 Â to	 Â Wine	 Â 

Justin	 Â Meier	 Â 

	 Â 

	 Â 

CS229	 Â Final	 Â Project	 Â 

	 Â 
The	 Â third	 Â dataset	 Â was	 Â far	 Â more	 Â difficult	 Â to	 Â find	 Â 
and	 Â the	 Â data	 Â was	 Â only	 Â obtained	 Â after	 Â numerous	 Â emails	 Â 
to	 Â the	 Â company	 Â associated	 Â with	 Â the	 Â site.	 Â 	 Â The	 Â final	 Â 
dataset	 Â is	 Â a	 Â pairing	 Â of	 Â a	 Â specific	 Â wine	 Â to	 Â a	 Â specific	 Â dinner	 Â 
in	 Â which	 Â the	 Â ingredients	 Â of	 Â the	 Â dinner	 Â come	 Â as	 Â a	 Â list	 Â of	 Â 
foods.	 Â 	 Â This	 Â dataset	 Â is	 Â ultimately	 Â used	 Â as	 Â my	 Â testing	 Â 
dataset	 Â with	 Â which	 Â I	 Â test	 Â whether	 Â my	 Â algorithms	 Â 
produced	 Â the	 Â correct	 Â color	 Â or	 Â type	 Â of	 Â wine.	 Â 	 Â An	 Â example	 Â 
of	 Â this	 Â dataset	 Â is	 Â given	 Â below:	 Â 

	 Â 

	 Â 

	 Â 

3.1	 Â Raw	 Â Input	 Â Data	 Â 

3.	 Â Features	 Â &	 Â Preprocessing	 Â 

Total	 Â Pairings	 Â =	 Â 2521	 Â 
Unique	 Â Foods	 Â =	 Â 477	 Â 
Unique	 Â Wines	 Â =	 Â 131	 Â 
Dinners	 Â =	 Â 495	 Â 

Finally,	 Â for	 Â better	 Â clarity	 Â of	 Â the	 Â results	 Â presented	 Â later,	 Â 
listed	 Â below	 Â are	 Â some	 Â general	 Â dataset	 Â statistics	 Â that	 Â 
help	 Â to	 Â put	 Â the	 Â results	 Â in	 Â a	 Â better	 Â context.	 Â 
	 Â 
	 Â 
For	 Â the	 Â first	 Â dataset,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â three	 Â 
original	 Â features	 Â associated	 Â with	 Â the	 Â raw-Â­â€input	 Â data:	 Â a	 Â 
specific	 Â type	 Â of	 Â wine,	 Â whether	 Â the	 Â wine	 Â is	 Â red	 Â or	 Â white,	 Â 
and	 Â a	 Â user	 Â rating.	 Â 	 Â All	 Â of	 Â these	 Â features	 Â are	 Â mapped	 Â to	 Â a	 Â 
given	 Â food.	 Â 	 Â The	 Â original	 Â features	 Â associated	 Â with	 Â the	 Â 
raw-Â­â€input	 Â data	 Â for	 Â the	 Â second	 Â dataset	 Â are	 Â simply	 Â the	 Â 
listed	 Â 10	 Â flavors	 Â and	 Â their	 Â numeric	 Â value.	 Â 	 Â The	 Â specific	 Â 
flavors	 Â are	 Â body,	 Â red	 Â fruit,	 Â black	 Â fruit,	 Â floral,	 Â herbaceous,	 Â 
pepper,	 Â earth,	 Â baking	 Â spice,	 Â leather,	 Â and	 Â astringency.	 Â 	 Â 
The	 Â third	 Â datasets	 Â features	 Â are	 Â a	 Â list	 Â of	 Â foods	 Â that	 Â 
composed	 Â a	 Â dinner	 Â and	 Â this	 Â list	 Â was	 Â mapped	 Â to	 Â a	 Â 
particular	 Â wine.	 Â 
	 Â 
The	 Â derived	 Â data	 Â comes	 Â from	 Â a	 Â combination	 Â of	 Â 
all	 Â three	 Â datasets.	 Â 	 Â The	 Â first	 Â step	 Â involves	 Â calculating	 Â an	 Â 
average	 Â wine	 Â flavor	 Â profile	 Â for	 Â each	 Â food	 Â found	 Â within	 Â 

3.2	 Â Derived	 Â Features:	 Â 

the	 Â first	 Â dataset.	 Â 	 Â The	 Â averaged	 Â wine	 Â flavor	 Â profile	 Â 
results	 Â from	 Â taking	 Â the	 Â flavor	 Â profiles	 Â for	 Â each	 Â wine,	 Â 
multiplying	 Â them	 Â by	 Â their	 Â rating,	 Â adding	 Â all	 Â of	 Â these	 Â 
flavor	 Â profiles	 Â together,	 Â and	 Â dividing	 Â by	 Â the	 Â sum	 Â of	 Â the	 Â 
ratings	 Â found	 Â for	 Â each	 Â pairing	 Â of	 Â the	 Â given	 Â food	 Â to	 Â its	 Â 
wine.	 Â 	 Â This	 Â process	 Â ensures	 Â that	 Â the	 Â flavor	 Â profile	 Â is	 Â an	 Â 
average	 Â of	 Â all	 Â the	 Â flavor	 Â profiles	 Â of	 Â the	 Â wines	 Â associated	 Â 
with	 Â the	 Â food	 Â and	 Â also	 Â ensures	 Â that	 Â wines	 Â that	 Â have	 Â a	 Â 
higher	 Â ratings	 Â received	 Â more	 Â input	 Â in	 Â determining	 Â the	 Â 
flavor	 Â profile	 Â for	 Â the	 Â food.	 Â 
A	 Â similar	 Â process	 Â is	 Â used	 Â for	 Â determining	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â given	 Â dinner.	 Â 	 Â That	 Â is,	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â dinner	 Â is	 Â determined	 Â by	 Â 
averaging	 Â together	 Â the	 Â wine	 Â flavor	 Â profiles	 Â of	 Â the	 Â 
ingredients	 Â found	 Â within	 Â the	 Â dinner.	 Â 
After	 Â completing	 Â both	 Â of	 Â these	 Â transformations,	 Â 
a	 Â database	 Â exists	 Â that	 Â contains	 Â the	 Â averaged	 Â flavor	 Â 
individual	 Â 
for	 Â  each	 Â 
food	 Â  and	 Â  also	 Â  each	 Â 
profiles	 Â 
individual	 Â wine.	 Â 	 Â An	 Â illustration	 Â of	 Â this	 Â transformation	 Â 
can	 Â be	 Â pictured	 Â below,	 Â so	 Â as	 Â to	 Â better	 Â explain	 Â how	 Â the	 Â 
process	 Â worked:	 Â 
	 Â 	 Â ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)= Â 
	 Â 
ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â  ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘“ğ‘œğ‘œğ‘‘)=
! Â âˆˆ Â !"#$%(!""#)
1
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘¤ğ‘–ğ‘›ğ‘’ âˆ—ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”
 Â 
ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â 
 Â 
1
ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘‘ğ‘–ğ‘›ğ‘›ğ‘’ğ‘Ÿ)=
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘“ğ‘œğ‘œğ‘‘
	 Â 
 Â 
ğ‘›ğ‘¢ğ‘šğ‘‚ğ‘“ğ¼ğ‘›ğ‘”ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ‘ 
	 Â 
	 Â 
 Â 
The	 Â two	 Â types	 Â of	 Â models	 Â used	 Â are	 Â a	 Â NaÃ¯ve	 Â Bayes	 Â 
algorithm	 Â and	 Â a	 Â K-Â­â€Means	 Â algorithm.	 Â 	 Â The	 Â goal	 Â of	 Â both	 Â 
algorithms	 Â is	 Â to	 Â either	 Â predict	 Â a	 Â specific	 Â wine	 Â or	 Â to	 Â 
predict	 Â whether	 Â one	 Â should	 Â drink	 Â a	 Â red	 Â or	 Â white	 Â wine.	 Â 	 Â 
The	 Â input	 Â is	 Â the	 Â list	 Â of	 Â ingredients	 Â found	 Â within	 Â the	 Â 
third	 Â database,	 Â which	 Â uses	 Â the	 Â raw-Â­â€input	 Â variables	 Â and	 Â 
the	 Â derived	 Â variables	 Â to	 Â predict	 Â a	 Â specific	 Â type	 Â of	 Â wine.	 Â 	 Â 
The	 Â accuracy	 Â of	 Â prediction	 Â is	 Â given	 Â by	 Â whether	 Â the	 Â 
predicted	 Â wine	 Â was	 Â the	 Â color	 Â or	 Â the	 Â type	 Â of	 Â wine	 Â given	 Â 
by	 Â the	 Â third	 Â database	 Â of	 Â wines	 Â paired	 Â to	 Â dinners.	 Â 	 Â 	 Â 	 Â The	 Â 
specifics	 Â of	 Â the	 Â algorithms	 Â are	 Â listed	 Â below:	 Â 
	 Â 
The	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â uses	 Â the	 Â generalized	 Â 
NaÃ¯ve	 Â Bayes	 Â formula	 Â with	 Â multiples	 Â variables,	 Â given	 Â 
below:	 Â 	 Â 

4.	 Â Models	 Â &	 Â Results	 Â 

4.1	 Â NaÃ¯ve	 Â Bayes:	 Â 

 Â 

	 Â 

ğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â ğ‘ƒğ‘¥

ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!!
ğ‘ƒ(ğ‘“!â€¦ğ‘“!)
	 Â 
!
argmaxğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â argmax! ğ‘ƒğ‘¥
	 Â 
ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!
That	 Â is,	 Â the	 Â best	 Â prediction	 Â (whether	 Â it	 Â be	 Â a	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â or	 Â a	 Â specific	 Â wine),	 Â will	 Â be	 Â the	 Â label	 Â that	 Â 
produces	 Â the	 Â highest	 Â product	 Â when	 Â considering	 Â the	 Â 
probability	 Â that	 Â we	 Â have	 Â a	 Â specific	 Â ingredient	 Â given	 Â our	 Â 
label.	 Â 	 Â Below	 Â are	 Â the	 Â summaries	 Â of	 Â the	 Â two	 Â types	 Â of	 Â 
predictions	 Â that	 Â were	 Â made	 Â using	 Â NaÃ¯ve	 Â Bayes:	 Â 
	 Â 
For	 Â the	 Â red	 Â and	 Â white	 Â prediction,	 Â I	 Â use	 Â a	 Â 
combination	 Â  of	 Â  score	 Â  consideration	 Â  and	 Â  Laplace	 Â 
smoothing.	 Â 	 Â If	 Â I	 Â do	 Â not	 Â consider	 Â the	 Â ranking	 Â (no	 Â score	 Â 
consideration),	 Â then	 Â I	 Â simply	 Â calculate	 Â the	 Â probability	 Â of	 Â 
a	 Â food	 Â given	 Â a	 Â specific	 Â color	 Â based	 Â on	 Â the	 Â occurrence	 Â of	 Â 
the	 Â food	 Â and	 Â wine	 Â color	 Â together.	 Â 	 Â 	 Â 	 Â If	 Â I	 Â consider	 Â the	 Â 
score,	 Â then	 Â I	 Â use	 Â the	 Â ranking	 Â in	 Â determining	 Â the	 Â 
probability	 Â that	 Â a	 Â given	 Â food	 Â occurred	 Â given	 Â the	 Â color	 Â of	 Â 
the	 Â wine.	 Â 	 Â That	 Â is,	 Â wine	 Â pairings	 Â with	 Â higher	 Â rankings	 Â 
increase	 Â this	 Â probability,	 Â thereby	 Â giving	 Â preference	 Â to	 Â 
wines	 Â that	 Â are	 Â paired	 Â well	 Â with	 Â a	 Â food.	 Â 
	 Â Laplace	 Â 
smoothing	 Â works	 Â normally	 Â when	 Â there	 Â is	 Â no	 Â score	 Â 
consideration.	 Â 
is	 Â  score	 Â 
there	 Â 
	 Â  However,	 Â  when	 Â 
consideration,	 Â the	 Â smoothing	 Â parameter	 Â is	 Â given	 Â as	 Â the	 Â 
average	 Â of	 Â all	 Â the	 Â ratings	 Â of	 Â food	 Â and	 Â wine.	 Â 	 Â The	 Â 
four	 Â 
these	 Â 
accuracy	 Â  of	 Â 
types	 Â  of	 Â  NaÃ¯ve	 Â  Bayes	 Â 
classification	 Â can	 Â be	 Â seen	 Â below:	 Â 

4.1.1	 Â Red	 Â vs.	 Â White	 Â Prediction:	 Â 

	 Â 

	 Â 

Red	 Â vs.	 Â White	 Â 

	 Â 
No	 Â Laplace	 Â 
No	 Â Score	 Â 
Laplace	 Â 
No	 Â Score	 Â 
No	 Â Laplace	 Â 
Score	 Â 
Laplace	 Â 

Red	 Â  Pred.	 Â 
Accuracy	 Â 
38.2%	 Â 
88.4%	 Â 
38.2%	 Â 
91.6%	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
89.4%	 Â 
77.3%	 Â 
89.5%	 Â 
73.0%	 Â 

Both	 Â  Pred.	 Â 
Accuracy	 Â 
63.1%	 Â 
	 Â 
83.0%	 Â 
63.2%	 Â 
81.6%	 Â 

4.1.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

Score	 Â 
	 Â 
When	 Â calculating	 Â the	 Â probabilities	 Â for	 Â finding	 Â a	 Â 
specific	 Â wine,	 Â the	 Â algorithm	 Â uses	 Â the	 Â model	 Â with	 Â the	 Â 
maximum	 Â total	 Â accuracy	 Â from	 Â the	 Â red/white	 Â prediction	 Â 
problem.	 Â 	 Â In	 Â this	 Â case,	 Â the	 Â probabilities	 Â involve	 Â no	 Â score	 Â 
consideration	 Â but	 Â do	 Â involve	 Â Laplace	 Â smoothing.	 Â 
In	 Â order	 Â to	 Â best	 Â interpret	 Â the	 Â accuracy	 Â of	 Â the	 Â 
algorithm,	 Â I	 Â decided	 Â to	 Â not	 Â only	 Â keep	 Â track	 Â of	 Â the	 Â top	 Â 
wine	 Â predicted	 Â by	 Â the	 Â algorithm	 Â by	 Â varying	 Â top	 Â wine	 Â 
predictions.	 Â 	 Â Then,	 Â the	 Â accuracy	 Â of	 Â the	 Â algorithm	 Â is	 Â 
determined	 Â by	 Â whether	 Â the	 Â actual	 Â wine	 Â paired	 Â with	 Â the	 Â 
dinner	 Â is	 Â found	 Â within	 Â the	 Â top	 Â N	 Â wines	 Â that	 Â were	 Â kept	 Â 
track	 Â of.	 Â 	 Â The	 Â results	 Â of	 Â this	 Â are	 Â demonstrated	 Â below:	 Â 
	 Â 

detailed	 Â above	 Â and	 Â then	 Â the	 Â prediction	 Â for	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â is	 Â given	 Â based	 Â on	 Â the	 Â color	 Â of	 Â the	 Â predicted	 Â 
wine.	 Â 	 Â Ultimately,	 Â my	 Â k-Â­â€means	 Â algorithm	 Â would	 Â not	 Â 
converge	 Â in	 Â a	 Â measurable	 Â and	 Â feasible	 Â time	 Â range	 Â and	 Â 
despite	 Â numerous	 Â attempts	 Â to	 Â resolve	 Â this	 Â issue,	 Â it	 Â still	 Â 
remains.	 Â 
	 Â I	 Â tried	 Â a	 Â multitude	 Â of	 Â things,	 Â including	 Â 
decreasing	 Â the	 Â side	 Â of	 Â the	 Â variables	 Â associated	 Â with	 Â 
calculating	 Â the	 Â Euclidean	 Â distance	 Â between	 Â the	 Â points	 Â 
and	 Â the	 Â centroids.	 Â 	 Â Instead,	 Â I	 Â decided	 Â to	 Â change	 Â the	 Â 
number	 Â of	 Â iterations	 Â The	 Â results	 Â of	 Â this	 Â are	 Â shown	 Â 
below:	 Â 
	 Â 

	 Â 

4.2	 Â K-Â­â€Means	 Â 

Specific	 Â Wine	 Â (with	 Â top	 Â N	 Â wines)	 Â 

8.5%	 Â 
18.0%	 Â 
26.0%	 Â 
37.5%	 Â 
74.7%	 Â 
90.4%	 Â 

N	 Â =	 Â 1	 Â 
N	 Â =	 Â 3	 Â 
N	 Â =	 Â 5	 Â 
N	 Â =	 Â 10	 Â 
N	 Â =	 Â 20	 Â 
N	 Â =	 Â 30	 Â 
	 Â 	 Â 
The	 Â K-Â­â€Means	 Â algorithm	 Â functions	 Â as	 Â a	 Â normal	 Â K-Â­â€
Means	 Â algorithm	 Â with	 Â the	 Â variables	 Â used	 Â to	 Â determine	 Â 
distance	 Â being	 Â the	 Â values	 Â associated	 Â with	 Â the	 Â flavor	 Â 
profile,	 Â from	 Â 0	 Â to5.	 Â 	 Â The	 Â points	 Â of	 Â the	 Â algorithm	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â dinners	 Â and	 Â the	 Â centroids	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â wine,	 Â given	 Â by	 Â the	 Â original	 Â data	 Â 
from	 Â the	 Â second	 Â database.	 Â 	 Â As	 Â each	 Â point	 Â converges	 Â 
closer	 Â to	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â predicts	 Â the	 Â wine	 Â 
represented	 Â by	 Â the	 Â centroid	 Â for	 Â the	 Â dinner	 Â represented	 Â 
by	 Â the	 Â point.	 Â 	 Â These	 Â same	 Â ideas	 Â are	 Â used	 Â to	 Â calculate	 Â 
both	 Â the	 Â color	 Â of	 Â the	 Â wine	 Â as	 Â well	 Â as	 Â a	 Â specific	 Â type	 Â of	 Â 
wine.	 Â 	 Â The	 Â specifics	 Â and	 Â results	 Â of	 Â each	 Â of	 Â these	 Â is	 Â given	 Â 
below:	 Â 
	 Â 
This	 Â algorithm	 Â can	 Â be	 Â approached	 Â in	 Â two	 Â 
separate	 Â ways.	 Â 	 Â The	 Â first	 Â follows	 Â the	 Â exact	 Â procedure	 Â 

4.2.1	 Â Red	 Â vs.	 Â White	 Â Wine	 Â Prediction	 Â 

	 Â 

	 Â 	 Â 

Red	 Â vs.	 Â White	 Â from	 Â Specific	 Â Wine	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
100%	 Â 
86.6%	 Â 
72.8%	 Â 
51.0%	 Â 
11.7%	 Â 

	 Â 
Both	 Â  Pred.	 Â 
Red	 Â 
Pred.	 Â 
	 Â 
Accuracy	 Â 
Accuracy	 Â 
87.0%	 Â 
69.5%	 Â 
Iters	 Â =	 Â 1	 Â 
81.3%	 Â 
74.0%	 Â 
Iters	 Â =	 Â 5	 Â 
74.5%	 Â 
76.8%	 Â 
Iters	 Â =	 Â 10	 Â 
83.1%	 Â 
64.7%	 Â 
Iters	 Â =	 Â 20	 Â 
47.1%	 Â 
94.9%	 Â 
Iters	 Â =	 Â 50	 Â 
	 Â 
The	 Â second	 Â approach	 Â involves	 Â computing	 Â an	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â red	 Â wine	 Â and	 Â for	 Â a	 Â white	 Â 
wine	 Â by	 Â averaging	 Â together	 Â all	 Â the	 Â red	 Â wine	 Â flavor	 Â 
profiles	 Â and	 Â all	 Â the	 Â white	 Â wine	 Â flavor	 Â profiles.	 Â 	 Â From	 Â 
here,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â two	 Â centroids	 Â representing	 Â all	 Â 
of	 Â the	 Â white	 Â wines	 Â and	 Â all	 Â the	 Â red	 Â wines.	 Â 	 Â Therefore,	 Â as	 Â a	 Â 
dinner	 Â converges	 Â on	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â would	 Â 
associate	 Â it	 Â with	 Â the	 Â color	 Â that	 Â centroid	 Â represented.	 Â 	 Â 
The	 Â results	 Â of	 Â both	 Â of	 Â these	 Â algorithms	 Â are	 Â given	 Â below.	 Â 
	 Â Red	 Â vs.	 Â White	 Â Prediction	 Â Accuracy	 Â 
with	 Â Averaged	 Â Red/White	 Â Flavor	 Â Profiles	 Â 
White	 Â Pred.	 Â 
Red	 Â 
Both	 Â  Pred.	 Â 
Pred.	 Â 
Accuracy	 Â 
Accuracy	 Â 
Accuracy	 Â 
	 Â 80.0%	 Â 
	 Â 61.7%	 Â 
	 Â 70.9%	 Â 
	 Â 
	 Â 
For	 Â finding	 Â a	 Â specific	 Â wine,	 Â I	 Â use	 Â the	 Â number	 Â of	 Â 
iterations	 Â that	 Â produced	 Â the	 Â highest	 Â accuracy	 Â when	 Â 
predicting	 Â the	 Â color	 Â of	 Â the	 Â wine.	 Â 	 Â This	 Â occurrs	 Â when	 Â 

4.2.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

there	 Â was	 Â only	 Â one	 Â iteration.	 Â 	 Â Much	 Â like	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â 
equivalent	 Â to	 Â solve	 Â this	 Â algorithm,	 Â the	 Â algorithm	 Â keeps	 Â 
track	 Â of	 Â the	 Â top	 Â N	 Â predicted	 Â wines	 Â rather	 Â than	 Â simply	 Â 
the	 Â top	 Â predicted	 Â wine	 Â so	 Â as	 Â to	 Â better	 Â show	 Â the	 Â 
accuracy	 Â of	 Â the	 Â algorithm.	 Â 	 Â In	 Â order	 Â to	 Â calculate	 Â the	 Â top	 Â 
N	 Â wines	 Â given	 Â that	 Â the	 Â wine	 Â is	 Â grouped	 Â to	 Â a	 Â specific	 Â 
centroid	 Â and,	 Â therefore,	 Â only	 Â one	 Â specific	 Â wine,	 Â the	 Â 
algorithm	 Â calculates	 Â the	 Â Euclidian	 Â distance	 Â from	 Â the	 Â 
point	 Â to	 Â all	 Â other	 Â centroids	 Â and	 Â kept	 Â track	 Â of	 Â the	 Â top	 Â N	 Â 
centroids	 Â that	 Â have	 Â the	 Â smallest	 Â distance.	 Â 	 Â The	 Â results	 Â of	 Â 
this	 Â algorithm	 Â can	 Â be	 Â seen	 Â below:	 Â 
	 Â 

N	 Â =	 Â 1	 Â 
N	 Â =	 Â 3	 Â 
N	 Â =	 Â 5	 Â 
N	 Â =	 Â 10	 Â 
N	 Â =	 Â 20	 Â 
N	 Â =	 Â 30	 Â 

8.6%	 Â 
18.0%	 Â 
26.3%	 Â 
37.6%	 Â 
75.1%	 Â 
95.2%	 Â 

Specific	 Â Wine	 Â (with	 Â top	 Â N	 Â wines)	 Â 

	 Â 

5.	 Â Discussion	 Â 
5.1	 Â NaÃ¯ve	 Â Bayes	 Â 

	 Â 	 Â 
Overall,	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â functioned	 Â 
quite	 Â well	 Â in	 Â predicting	 Â both	 Â the	 Â color	 Â of	 Â the	 Â wine	 Â and	 Â a	 Â 
specific	 Â type	 Â of	 Â wine.	 Â 	 Â In	 Â terms	 Â of	 Â score	 Â consideration	 Â 
it	 Â  was	 Â  evident	 Â  that	 Â  the	 Â  algorithm	 Â 
and	 Â  Laplace,	 Â 
performed	 Â best	 Â when	 Â Laplace	 Â smoothing	 Â was	 Â applied	 Â 
and	 Â had	 Â a	 Â negligible	 Â difference	 Â with	 Â score	 Â consideration	 Â 
as	 Â opposed	 Â to	 Â no	 Â score	 Â consideration.	 Â 
The	 Â increasing	 Â in	 Â the	 Â accuracy	 Â with	 Â Laplace	 Â 
smoothing	 Â makes	 Â sense.	 Â 	 Â Going	 Â through	 Â the	 Â database,	 Â I	 Â 
noticed	 Â a	 Â few	 Â foods	 Â that	 Â occurred	 Â with	 Â white	 Â wines	 Â with	 Â 
low	 Â ranks	 Â and	 Â then	 Â only	 Â a	 Â few	 Â red	 Â wines	 Â with	 Â high	 Â 
ranks.	 Â 	 Â Ultimately,	 Â the	 Â Lagrange	 Â smoothing	 Â more	 Â evenly	 Â 
distributes	 Â the	 Â probability	 Â given	 Â a	 Â red	 Â or	 Â white	 Â wine	 Â 
and	 Â thereby	 Â increases	 Â the	 Â overall	 Â accuracy	 Â of	 Â the	 Â 
equation.	 Â 	 Â This	 Â is	 Â further	 Â demonstrated	 Â by	 Â an	 Â increase	 Â 
in	 Â the	 Â accuracy	 Â of	 Â red	 Â wine	 Â prediction	 Â with	 Â a	 Â decrease	 Â 
in	 Â the	 Â accuracy	 Â of	 Â white	 Â wine	 Â prediction.	 Â 
In	 Â terms	 Â of	 Â predicting	 Â a	 Â specific	 Â wine,	 Â the	 Â 
results	 Â far	 Â exceed	 Â what	 Â would	 Â be	 Â expected.	 Â 	 Â With	 Â a	 Â total	 Â 

	 Â 

5.2	 Â K-Â­â€Means	 Â 

of	 Â 131	 Â wines,	 Â the	 Â accuracy	 Â of	 Â randomly	 Â selecting	 Â a	 Â 
single	 Â correct	 Â wine	 Â from	 Â this	 Â set	 Â would	 Â be	 Â 0.76%	 Â but	 Â 
the	 Â algorithm	 Â is	 Â able	 Â to	 Â predict	 Â the	 Â top	 Â wine	 Â with	 Â 8.0%	 Â 
accuracy,	 Â more	 Â than	 Â 10	 Â fold	 Â better	 Â than	 Â guessing.	 Â 	 Â As	 Â 
well,	 Â the	 Â algorithm	 Â sad	 Â the	 Â correct	 Â wine	 Â in	 Â the	 Â top	 Â 30	 Â 
guesses	 Â 90%	 Â of	 Â the	 Â time,	 Â demonstrating	 Â that	 Â the	 Â 
algorithm	 Â is	 Â able	 Â to	 Â recognize	 Â the	 Â correct	 Â wine	 Â as	 Â a	 Â 
strong	 Â contender,	 Â if	 Â even	 Â it	 Â doesnâ€™t	 Â select	 Â the	 Â wine	 Â as	 Â 
the	 Â number	 Â one	 Â choice.	 Â 
	 Â 
Overall,	 Â the	 Â K-Â­â€Means	 Â model	 Â has	 Â a	 Â high	 Â accuracy	 Â 
rate	 Â but,	 Â based	 Â on	 Â consistency,	 Â functions	 Â worse	 Â than	 Â the	 Â 
NaÃ¯ve-Â­â€Bayes	 Â model,	 Â as	 Â demonstrated	 Â by	 Â the	 Â K-Â­â€Means	 Â 
attempt	 Â to	 Â predict	 Â the	 Â color	 Â of	 Â wine	 Â to	 Â pair	 Â with	 Â the	 Â 
dinner.	 Â 	 Â In	 Â addition	 Â to	 Â its	 Â inability	 Â to	 Â converge,	 Â the	 Â K-Â­â€
Means	 Â model	 Â also	 Â varies	 Â drastically	 Â on	 Â the	 Â accuracy	 Â for	 Â 
red	 Â wines	 Â and	 Â the	 Â accuracy	 Â for	 Â white	 Â wines.	 Â 	 Â That	 Â is,	 Â 
with	 Â fewer	 Â iterations,	 Â the	 Â accuracy	 Â for	 Â white	 Â wine	 Â 
prediction	 Â is	 Â much	 Â higher,	 Â reaching	 Â a	 Â peak	 Â of	 Â 100%,	 Â in	 Â 
fact,	 Â with	 Â a	 Â single	 Â iteration.	 Â 	 Â However,	 Â as	 Â the	 Â number	 Â of	 Â 
iterations	 Â increased,	 Â the	 Â accuracy	 Â of	 Â white	 Â wine	 Â drops	 Â 
to	 Â a	 Â low	 Â of	 Â 11.7%	 Â with	 Â 50	 Â iterations.	 Â 	 Â This	 Â effect	 Â is	 Â 
reversed	 Â for	 Â the	 Â accuracy	 Â of	 Â a	 Â red	 Â wine	 Â prediction.	 Â 
One	 Â theory	 Â I	 Â have	 Â behind	 Â this	 Â phenomenon	 Â is	 Â 
that	 Â quite	 Â a	 Â few	 Â of	 Â the	 Â dinners	 Â that	 Â are	 Â extremely	 Â 
strongly	 Â associated	 Â with	 Â a	 Â white	 Â wine.	 Â 	 Â That	 Â is,	 Â there	 Â are	 Â 
a	 Â few	 Â white-Â­â€wine-Â­â€paired	 Â dinners	 Â that	 Â have	 Â only	 Â highly	 Â 
white	 Â wine	 Â weighted	 Â ingredients	 Â such	 Â as	 Â any	 Â type	 Â of	 Â 
lemon,	 Â 
fish,	 Â  clam,	 Â  mussels,	 Â 
lime,	 Â  any	 Â  number	 Â  of	 Â 
vegetables,	 Â and	 Â olive	 Â oil.	 Â 
	 Â Essentially,	 Â any	 Â type	 Â of	 Â 
seafood	 Â dish.	 Â 	 Â However,	 Â there	 Â are	 Â a	 Â variety	 Â of	 Â white-Â­â€
wine-Â­â€paired	 Â dishes	 Â and	 Â nearly	 Â all	 Â red-Â­â€wine-Â­â€paired	 Â 
dishes	 Â that	 Â contain	 Â both	 Â ingredients	 Â strongly	 Â associated	 Â 
with	 Â red	 Â wine	 Â and	 Â ingredients	 Â associated	 Â with	 Â white	 Â 
wines.	 Â 	 Â Therefore,	 Â at	 Â the	 Â beginning,	 Â the	 Â white	 Â wine	 Â 
prediction	 Â is	 Â high.	 Â 	 Â However,	 Â as	 Â the	 Â number	 Â of	 Â iterations	 Â 
increases,	 Â the	 Â white	 Â wine	 Â centroids	 Â become	 Â more	 Â 
similar	 Â to	 Â the	 Â extreme	 Â white-Â­â€wine-Â­â€paired	 Â dishes.	 Â 	 Â As	 Â 
this	 Â occurs,	 Â more	 Â dishes	 Â will	 Â be	 Â paired	 Â with	 Â a	 Â red	 Â wine	 Â 
because	 Â only	 Â the	 Â few	 Â cases	 Â of	 Â extreme	 Â white-Â­â€wine	 Â 
paired	 Â dishes	 Â will	 Â be	 Â clustered	 Â with	 Â a	 Â white	 Â wine	 Â 
centroid,	 Â thereby	 Â decreasing	 Â the	 Â accuracy	 Â of	 Â predicting	 Â 
a	 Â white	 Â wine	 Â and	 Â increasing	 Â the	 Â accuracy	 Â of	 Â predicting	 Â a	 Â 
red	 Â wine.	 Â For	 Â predicting	 Â a	 Â specific	 Â type	 Â of	 Â wine,	 Â the	 Â K-Â­â€
Mean	 Â models	 Â accuracy	 Â 
is	 Â  extremely	 Â  close	 Â  to	 Â  the	 Â 
accuracy	 Â achieved	 Â in	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â model.	 Â 	 Â That	 Â is,	 Â 
with	 Â only	 Â selecting	 Â the	 Â one	 Â predicted	 Â wine,	 Â the	 Â model	 Â 
accurately	 Â predicts	 Â the	 Â correct	 Â wine	 Â 8.1%	 Â of	 Â the	 Â time.	 Â 	 Â 
And	 Â with	 Â selecting	 Â the	 Â top	 Â 30	 Â predicted	 Â wines,	 Â the	 Â 
model	 Â accurately	 Â predicted	 Â the	 Â correct	 Â wine	 Â in	 Â these	 Â 
predictions	 Â 95.2%	 Â of	 Â the	 Â time.	 Â 
	 Â 	 Â 

6.	 Â Conclusion	 Â 

1.	 Â Introduction	 Â 

	 Â 	 Â 
The	 Â art	 Â of	 Â food	 Â and	 Â wine	 Â pairing	 Â has	 Â dated	 Â back	 Â 
centuries	 Â and	 Â since	 Â its	 Â first	 Â practice,	 Â has	 Â honed	 Â its	 Â rules	 Â 
and	 Â regulations	 Â on	 Â what	 Â pairs	 Â well	 Â together.	 Â 	 Â However,	 Â 
within	 Â these	 Â stringent	 Â rules,	 Â nuances	 Â and	 Â differing	 Â 
opinions	 Â exist	 Â that	 Â make	 Â selecting	 Â the	 Â perfect	 Â wine	 Â for	 Â a	 Â 
food	 Â more	 Â complicated	 Â than	 Â it	 Â may	 Â seem.	 Â 	 Â Even	 Â beyond	 Â 
this,	 Â the	 Â complexities	 Â involved	 Â when	 Â selecting	 Â a	 Â wine	 Â 
for	 Â an	 Â entire	 Â dinner	 Â are	 Â even	 Â larger.	 Â 	 Â The	 Â overall	 Â goal	 Â of	 Â 
the	 Â following	 Â presented	 Â algorithms	 Â will	 Â be	 Â to	 Â use	 Â these	 Â 
complexities	 Â and	 Â see	 Â if	 Â the	 Â nuances	 Â of	 Â wine	 Â pairing	 Â can	 Â 
be	 Â simplified.	 Â 	 Â More	 Â specifically,	 Â the	 Â goal	 Â of	 Â the	 Â NaÃ¯ve	 Â 
Bayes	 Â and	 Â K-Â­â€Means	 Â algorithms	 Â will	 Â be	 Â to	 Â predict	 Â either	 Â 
the	 Â color	 Â of	 Â the	 Â wine	 Â (red	 Â vs.	 Â white)	 Â or	 Â a	 Â specific	 Â type	 Â of	 Â 
wine	 Â (Chianti,	 Â Pinot	 Â Grigio,	 Â etc.)	 Â to	 Â pair	 Â with	 Â a	 Â dinner.	 Â 
	 Â 
The	 Â total	 Â number	 Â of	 Â datasets	 Â used	 Â in	 Â the	 Â 
algorithms	 Â 
that	 Â  certain	 Â 
is	 Â 
algorithms	 Â do	 Â not	 Â use	 Â all	 Â three	 Â datasets	 Â in	 Â order	 Â to	 Â 
predict	 Â a	 Â wine.	 Â 	 Â The	 Â first	 Â dataset	 Â contains	 Â self-Â­â€reviewed	 Â 
wine	 Â and	 Â food	 Â pairings	 Â in	 Â which	 Â a	 Â specific	 Â type	 Â of	 Â food	 Â 
is	 Â compared	 Â to	 Â multiple	 Â types	 Â of	 Â wine.	 Â 	 Â Each	 Â pairing	 Â is	 Â 
associated	 Â with	 Â a	 Â rating,	 Â ranging	 Â from	 Â 1	 Â â€“	 Â 5,	 Â that	 Â 
determines	 Â the	 Â quality	 Â of	 Â the	 Â pairing.	 Â 	 Â A	 Â depiction	 Â of	 Â this	 Â 
dataset	 Â is	 Â given	 Â below:	 Â 
	 Â 
	 Â 
	 Â 
The	 Â second	 Â dataset	 Â maps	 Â wines	 Â to	 Â a	 Â flavor	 Â 
profile.	 Â 	 Â Each	 Â flavor	 Â profile	 Â contains	 Â ten	 Â elements	 Â which	 Â 
ranged	 Â from	 Â a	 Â scale	 Â of	 Â 0	 Â â€“	 Â 5	 Â in	 Â which	 Â 0	 Â represents	 Â no	 Â 
presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine	 Â and	 Â 5	 Â represents	 Â a	 Â 
strong	 Â presence	 Â of	 Â the	 Â taste	 Â in	 Â the	 Â wine.	 Â 	 Â An	 Â example	 Â of	 Â 
this	 Â is	 Â provided	 Â below:	 Â 
	 Â 

three;	 Â  however	 Â  note	 Â 

2.	 Â Dataset	 Â 

	 Â 

From	 Â Food	 Â to	 Â Wine	 Â 

Justin	 Â Meier	 Â 

	 Â 

	 Â 

CS229	 Â Final	 Â Project	 Â 

	 Â 
The	 Â third	 Â dataset	 Â was	 Â far	 Â more	 Â difficult	 Â to	 Â find	 Â 
and	 Â the	 Â data	 Â was	 Â only	 Â obtained	 Â after	 Â numerous	 Â emails	 Â 
to	 Â the	 Â company	 Â associated	 Â with	 Â the	 Â site.	 Â 	 Â The	 Â final	 Â 
dataset	 Â is	 Â a	 Â pairing	 Â of	 Â a	 Â specific	 Â wine	 Â to	 Â a	 Â specific	 Â dinner	 Â 
in	 Â which	 Â the	 Â ingredients	 Â of	 Â the	 Â dinner	 Â come	 Â as	 Â a	 Â list	 Â of	 Â 
foods.	 Â 	 Â This	 Â dataset	 Â is	 Â ultimately	 Â used	 Â as	 Â my	 Â testing	 Â 
dataset	 Â with	 Â which	 Â I	 Â test	 Â whether	 Â my	 Â algorithms	 Â 
produced	 Â the	 Â correct	 Â color	 Â or	 Â type	 Â of	 Â wine.	 Â 	 Â An	 Â example	 Â 
of	 Â this	 Â dataset	 Â is	 Â given	 Â below:	 Â 

	 Â 

	 Â 

	 Â 

3.1	 Â Raw	 Â Input	 Â Data	 Â 

3.	 Â Features	 Â &	 Â Preprocessing	 Â 

Total	 Â Pairings	 Â =	 Â 2521	 Â 
Unique	 Â Foods	 Â =	 Â 477	 Â 
Unique	 Â Wines	 Â =	 Â 131	 Â 
Dinners	 Â =	 Â 495	 Â 

Finally,	 Â for	 Â better	 Â clarity	 Â of	 Â the	 Â results	 Â presented	 Â later,	 Â 
listed	 Â below	 Â are	 Â some	 Â general	 Â dataset	 Â statistics	 Â that	 Â 
help	 Â to	 Â put	 Â the	 Â results	 Â in	 Â a	 Â better	 Â context.	 Â 
	 Â 
	 Â 
For	 Â the	 Â first	 Â dataset,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â three	 Â 
original	 Â features	 Â associated	 Â with	 Â the	 Â raw-Â­â€input	 Â data:	 Â a	 Â 
specific	 Â type	 Â of	 Â wine,	 Â whether	 Â the	 Â wine	 Â is	 Â red	 Â or	 Â white,	 Â 
and	 Â a	 Â user	 Â rating.	 Â 	 Â All	 Â of	 Â these	 Â features	 Â are	 Â mapped	 Â to	 Â a	 Â 
given	 Â food.	 Â 	 Â The	 Â original	 Â features	 Â associated	 Â with	 Â the	 Â 
raw-Â­â€input	 Â data	 Â for	 Â the	 Â second	 Â dataset	 Â are	 Â simply	 Â the	 Â 
listed	 Â 10	 Â flavors	 Â and	 Â their	 Â numeric	 Â value.	 Â 	 Â The	 Â specific	 Â 
flavors	 Â are	 Â body,	 Â red	 Â fruit,	 Â black	 Â fruit,	 Â floral,	 Â herbaceous,	 Â 
pepper,	 Â earth,	 Â baking	 Â spice,	 Â leather,	 Â and	 Â astringency.	 Â 	 Â 
The	 Â third	 Â datasets	 Â features	 Â are	 Â a	 Â list	 Â of	 Â foods	 Â that	 Â 
composed	 Â a	 Â dinner	 Â and	 Â this	 Â list	 Â was	 Â mapped	 Â to	 Â a	 Â 
particular	 Â wine.	 Â 
	 Â 
The	 Â derived	 Â data	 Â comes	 Â from	 Â a	 Â combination	 Â of	 Â 
all	 Â three	 Â datasets.	 Â 	 Â The	 Â first	 Â step	 Â involves	 Â calculating	 Â an	 Â 
average	 Â wine	 Â flavor	 Â profile	 Â for	 Â each	 Â food	 Â found	 Â within	 Â 

3.2	 Â Derived	 Â Features:	 Â 

the	 Â first	 Â dataset.	 Â 	 Â The	 Â averaged	 Â wine	 Â flavor	 Â profile	 Â 
results	 Â from	 Â taking	 Â the	 Â flavor	 Â profiles	 Â for	 Â each	 Â wine,	 Â 
multiplying	 Â them	 Â by	 Â their	 Â rating,	 Â adding	 Â all	 Â of	 Â these	 Â 
flavor	 Â profiles	 Â together,	 Â and	 Â dividing	 Â by	 Â the	 Â sum	 Â of	 Â the	 Â 
ratings	 Â found	 Â for	 Â each	 Â pairing	 Â of	 Â the	 Â given	 Â food	 Â to	 Â its	 Â 
wine.	 Â 	 Â This	 Â process	 Â ensures	 Â that	 Â the	 Â flavor	 Â profile	 Â is	 Â an	 Â 
average	 Â of	 Â all	 Â the	 Â flavor	 Â profiles	 Â of	 Â the	 Â wines	 Â associated	 Â 
with	 Â the	 Â food	 Â and	 Â also	 Â ensures	 Â that	 Â wines	 Â that	 Â have	 Â a	 Â 
higher	 Â ratings	 Â received	 Â more	 Â input	 Â in	 Â determining	 Â the	 Â 
flavor	 Â profile	 Â for	 Â the	 Â food.	 Â 
A	 Â similar	 Â process	 Â is	 Â used	 Â for	 Â determining	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â given	 Â dinner.	 Â 	 Â That	 Â is,	 Â the	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â dinner	 Â is	 Â determined	 Â by	 Â 
averaging	 Â together	 Â the	 Â wine	 Â flavor	 Â profiles	 Â of	 Â the	 Â 
ingredients	 Â found	 Â within	 Â the	 Â dinner.	 Â 
After	 Â completing	 Â both	 Â of	 Â these	 Â transformations,	 Â 
a	 Â database	 Â exists	 Â that	 Â contains	 Â the	 Â averaged	 Â flavor	 Â 
individual	 Â 
for	 Â  each	 Â 
food	 Â  and	 Â  also	 Â  each	 Â 
profiles	 Â 
individual	 Â wine.	 Â 	 Â An	 Â illustration	 Â of	 Â this	 Â transformation	 Â 
can	 Â be	 Â pictured	 Â below,	 Â so	 Â as	 Â to	 Â better	 Â explain	 Â how	 Â the	 Â 
process	 Â worked:	 Â 
	 Â 	 Â ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)= Â 
	 Â 
ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â  ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘“ğ‘œğ‘œğ‘‘)=
! Â âˆˆ Â !"#$%(!""#)
1
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘¤ğ‘–ğ‘›ğ‘’ âˆ—ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”
 Â 
ğ‘…ğ‘ğ‘¡ğ‘’ğ‘†ğ‘¢ğ‘š(ğ‘“ğ‘œğ‘œğ‘‘)
	 Â 
 Â 
1
ğ¹ğ‘™ğ‘ğ‘£ğ‘ƒğ‘Ÿğ‘œğ‘“(ğ‘‘ğ‘–ğ‘›ğ‘›ğ‘’ğ‘Ÿ)=
ğ‘“ğ‘™ğ‘ğ‘£ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘“ğ‘“ğ‘œğ‘œğ‘‘
	 Â 
 Â 
ğ‘›ğ‘¢ğ‘šğ‘‚ğ‘“ğ¼ğ‘›ğ‘”ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ‘ 
	 Â 
	 Â 
 Â 
The	 Â two	 Â types	 Â of	 Â models	 Â used	 Â are	 Â a	 Â NaÃ¯ve	 Â Bayes	 Â 
algorithm	 Â and	 Â a	 Â K-Â­â€Means	 Â algorithm.	 Â 	 Â The	 Â goal	 Â of	 Â both	 Â 
algorithms	 Â is	 Â to	 Â either	 Â predict	 Â a	 Â specific	 Â wine	 Â or	 Â to	 Â 
predict	 Â whether	 Â one	 Â should	 Â drink	 Â a	 Â red	 Â or	 Â white	 Â wine.	 Â 	 Â 
The	 Â input	 Â is	 Â the	 Â list	 Â of	 Â ingredients	 Â found	 Â within	 Â the	 Â 
third	 Â database,	 Â which	 Â uses	 Â the	 Â raw-Â­â€input	 Â variables	 Â and	 Â 
the	 Â derived	 Â variables	 Â to	 Â predict	 Â a	 Â specific	 Â type	 Â of	 Â wine.	 Â 	 Â 
The	 Â accuracy	 Â of	 Â prediction	 Â is	 Â given	 Â by	 Â whether	 Â the	 Â 
predicted	 Â wine	 Â was	 Â the	 Â color	 Â or	 Â the	 Â type	 Â of	 Â wine	 Â given	 Â 
by	 Â the	 Â third	 Â database	 Â of	 Â wines	 Â paired	 Â to	 Â dinners.	 Â 	 Â 	 Â 	 Â The	 Â 
specifics	 Â of	 Â the	 Â algorithms	 Â are	 Â listed	 Â below:	 Â 
	 Â 
The	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â uses	 Â the	 Â generalized	 Â 
NaÃ¯ve	 Â Bayes	 Â formula	 Â with	 Â multiples	 Â variables,	 Â given	 Â 
below:	 Â 	 Â 

4.	 Â Models	 Â &	 Â Results	 Â 

4.1	 Â NaÃ¯ve	 Â Bayes:	 Â 

 Â 

	 Â 

ğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â ğ‘ƒğ‘¥

ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!!
ğ‘ƒ(ğ‘“!â€¦ğ‘“!)
	 Â 
!
argmaxğ‘ƒğ‘¥ğ‘“!â€¦ğ‘“! = Â argmax! ğ‘ƒğ‘¥
	 Â 
ğ‘ƒğ‘“!ğ‘¥)
	 Â 
!!!
That	 Â is,	 Â the	 Â best	 Â prediction	 Â (whether	 Â it	 Â be	 Â a	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â or	 Â a	 Â specific	 Â wine),	 Â will	 Â be	 Â the	 Â label	 Â that	 Â 
produces	 Â the	 Â highest	 Â product	 Â when	 Â considering	 Â the	 Â 
probability	 Â that	 Â we	 Â have	 Â a	 Â specific	 Â ingredient	 Â given	 Â our	 Â 
label.	 Â 	 Â Below	 Â are	 Â the	 Â summaries	 Â of	 Â the	 Â two	 Â types	 Â of	 Â 
predictions	 Â that	 Â were	 Â made	 Â using	 Â NaÃ¯ve	 Â Bayes:	 Â 
	 Â 
For	 Â the	 Â red	 Â and	 Â white	 Â prediction,	 Â I	 Â use	 Â a	 Â 
combination	 Â  of	 Â  score	 Â  consideration	 Â  and	 Â  Laplace	 Â 
smoothing.	 Â 	 Â If	 Â I	 Â do	 Â not	 Â consider	 Â the	 Â ranking	 Â (no	 Â score	 Â 
consideration),	 Â then	 Â I	 Â simply	 Â calculate	 Â the	 Â probability	 Â of	 Â 
a	 Â food	 Â given	 Â a	 Â specific	 Â color	 Â based	 Â on	 Â the	 Â occurrence	 Â of	 Â 
the	 Â food	 Â and	 Â wine	 Â color	 Â together.	 Â 	 Â 	 Â 	 Â If	 Â I	 Â consider	 Â the	 Â 
score,	 Â then	 Â I	 Â use	 Â the	 Â ranking	 Â in	 Â determining	 Â the	 Â 
probability	 Â that	 Â a	 Â given	 Â food	 Â occurred	 Â given	 Â the	 Â color	 Â of	 Â 
the	 Â wine.	 Â 	 Â That	 Â is,	 Â wine	 Â pairings	 Â with	 Â higher	 Â rankings	 Â 
increase	 Â this	 Â probability,	 Â thereby	 Â giving	 Â preference	 Â to	 Â 
wines	 Â that	 Â are	 Â paired	 Â well	 Â with	 Â a	 Â food.	 Â 
	 Â Laplace	 Â 
smoothing	 Â works	 Â normally	 Â when	 Â there	 Â is	 Â no	 Â score	 Â 
consideration.	 Â 
is	 Â  score	 Â 
there	 Â 
	 Â  However,	 Â  when	 Â 
consideration,	 Â the	 Â smoothing	 Â parameter	 Â is	 Â given	 Â as	 Â the	 Â 
average	 Â of	 Â all	 Â the	 Â ratings	 Â of	 Â food	 Â and	 Â wine.	 Â 	 Â The	 Â 
four	 Â 
these	 Â 
accuracy	 Â  of	 Â 
types	 Â  of	 Â  NaÃ¯ve	 Â  Bayes	 Â 
classification	 Â can	 Â be	 Â seen	 Â below:	 Â 

4.1.1	 Â Red	 Â vs.	 Â White	 Â Prediction:	 Â 

	 Â 

	 Â 

Red	 Â vs.	 Â White	 Â 

	 Â 
No	 Â Laplace	 Â 
No	 Â Score	 Â 
Laplace	 Â 
No	 Â Score	 Â 
No	 Â Laplace	 Â 
Score	 Â 
Laplace	 Â 

Red	 Â  Pred.	 Â 
Accuracy	 Â 
38.2%	 Â 
88.4%	 Â 
38.2%	 Â 
91.6%	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
89.4%	 Â 
77.3%	 Â 
89.5%	 Â 
73.0%	 Â 

Both	 Â  Pred.	 Â 
Accuracy	 Â 
63.1%	 Â 
	 Â 
83.0%	 Â 
63.2%	 Â 
81.6%	 Â 

4.1.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

Score	 Â 
	 Â 
When	 Â calculating	 Â the	 Â probabilities	 Â for	 Â finding	 Â a	 Â 
specific	 Â wine,	 Â the	 Â algorithm	 Â uses	 Â the	 Â model	 Â with	 Â the	 Â 
maximum	 Â total	 Â accuracy	 Â from	 Â the	 Â red/white	 Â prediction	 Â 
problem.	 Â 	 Â In	 Â this	 Â case,	 Â the	 Â probabilities	 Â involve	 Â no	 Â score	 Â 
consideration	 Â but	 Â do	 Â involve	 Â Laplace	 Â smoothing.	 Â 
In	 Â order	 Â to	 Â best	 Â interpret	 Â the	 Â accuracy	 Â of	 Â the	 Â 
algorithm,	 Â I	 Â decided	 Â to	 Â not	 Â only	 Â keep	 Â track	 Â of	 Â the	 Â top	 Â 
wine	 Â predicted	 Â by	 Â the	 Â algorithm	 Â by	 Â varying	 Â top	 Â wine	 Â 
predictions.	 Â 	 Â Then,	 Â the	 Â accuracy	 Â of	 Â the	 Â algorithm	 Â is	 Â 
determined	 Â by	 Â whether	 Â the	 Â actual	 Â wine	 Â paired	 Â with	 Â the	 Â 
dinner	 Â is	 Â found	 Â within	 Â the	 Â top	 Â N	 Â wines	 Â that	 Â were	 Â kept	 Â 
track	 Â of.	 Â 	 Â The	 Â results	 Â of	 Â this	 Â are	 Â demonstrated	 Â below:	 Â 
	 Â 

detailed	 Â above	 Â and	 Â then	 Â the	 Â prediction	 Â for	 Â the	 Â color	 Â of	 Â 
the	 Â wine	 Â is	 Â given	 Â based	 Â on	 Â the	 Â color	 Â of	 Â the	 Â predicted	 Â 
wine.	 Â 	 Â Ultimately,	 Â my	 Â k-Â­â€means	 Â algorithm	 Â would	 Â not	 Â 
converge	 Â in	 Â a	 Â measurable	 Â and	 Â feasible	 Â time	 Â range	 Â and	 Â 
despite	 Â numerous	 Â attempts	 Â to	 Â resolve	 Â this	 Â issue,	 Â it	 Â still	 Â 
remains.	 Â 
	 Â I	 Â tried	 Â a	 Â multitude	 Â of	 Â things,	 Â including	 Â 
decreasing	 Â the	 Â side	 Â of	 Â the	 Â variables	 Â associated	 Â with	 Â 
calculating	 Â the	 Â Euclidean	 Â distance	 Â between	 Â the	 Â points	 Â 
and	 Â the	 Â centroids.	 Â 	 Â Instead,	 Â I	 Â decided	 Â to	 Â change	 Â the	 Â 
number	 Â of	 Â iterations	 Â The	 Â results	 Â of	 Â this	 Â are	 Â shown	 Â 
below:	 Â 
	 Â 

	 Â 

4.2	 Â K-Â­â€Means	 Â 

Specific	 Â Wine	 Â (with	 Â top	 Â N	 Â wines)	 Â 

8.5%	 Â 
18.0%	 Â 
26.0%	 Â 
37.5%	 Â 
74.7%	 Â 
90.4%	 Â 

N	 Â =	 Â 1	 Â 
N	 Â =	 Â 3	 Â 
N	 Â =	 Â 5	 Â 
N	 Â =	 Â 10	 Â 
N	 Â =	 Â 20	 Â 
N	 Â =	 Â 30	 Â 
	 Â 	 Â 
The	 Â K-Â­â€Means	 Â algorithm	 Â functions	 Â as	 Â a	 Â normal	 Â K-Â­â€
Means	 Â algorithm	 Â with	 Â the	 Â variables	 Â used	 Â to	 Â determine	 Â 
distance	 Â being	 Â the	 Â values	 Â associated	 Â with	 Â the	 Â flavor	 Â 
profile,	 Â from	 Â 0	 Â to5.	 Â 	 Â The	 Â points	 Â of	 Â the	 Â algorithm	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â dinners	 Â and	 Â the	 Â centroids	 Â are	 Â the	 Â 
flavor	 Â profiles	 Â of	 Â the	 Â wine,	 Â given	 Â by	 Â the	 Â original	 Â data	 Â 
from	 Â the	 Â second	 Â database.	 Â 	 Â As	 Â each	 Â point	 Â converges	 Â 
closer	 Â to	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â predicts	 Â the	 Â wine	 Â 
represented	 Â by	 Â the	 Â centroid	 Â for	 Â the	 Â dinner	 Â represented	 Â 
by	 Â the	 Â point.	 Â 	 Â These	 Â same	 Â ideas	 Â are	 Â used	 Â to	 Â calculate	 Â 
both	 Â the	 Â color	 Â of	 Â the	 Â wine	 Â as	 Â well	 Â as	 Â a	 Â specific	 Â type	 Â of	 Â 
wine.	 Â 	 Â The	 Â specifics	 Â and	 Â results	 Â of	 Â each	 Â of	 Â these	 Â is	 Â given	 Â 
below:	 Â 
	 Â 
This	 Â algorithm	 Â can	 Â be	 Â approached	 Â in	 Â two	 Â 
separate	 Â ways.	 Â 	 Â The	 Â first	 Â follows	 Â the	 Â exact	 Â procedure	 Â 

4.2.1	 Â Red	 Â vs.	 Â White	 Â Wine	 Â Prediction	 Â 

	 Â 

	 Â 	 Â 

Red	 Â vs.	 Â White	 Â from	 Â Specific	 Â Wine	 Â 

White	 Â Pred.	 Â 
Accuracy	 Â 
100%	 Â 
86.6%	 Â 
72.8%	 Â 
51.0%	 Â 
11.7%	 Â 

	 Â 
Both	 Â  Pred.	 Â 
Red	 Â 
Pred.	 Â 
	 Â 
Accuracy	 Â 
Accuracy	 Â 
87.0%	 Â 
69.5%	 Â 
Iters	 Â =	 Â 1	 Â 
81.3%	 Â 
74.0%	 Â 
Iters	 Â =	 Â 5	 Â 
74.5%	 Â 
76.8%	 Â 
Iters	 Â =	 Â 10	 Â 
83.1%	 Â 
64.7%	 Â 
Iters	 Â =	 Â 20	 Â 
47.1%	 Â 
94.9%	 Â 
Iters	 Â =	 Â 50	 Â 
	 Â 
The	 Â second	 Â approach	 Â involves	 Â computing	 Â an	 Â 
average	 Â flavor	 Â profile	 Â for	 Â a	 Â red	 Â wine	 Â and	 Â for	 Â a	 Â white	 Â 
wine	 Â by	 Â averaging	 Â together	 Â all	 Â the	 Â red	 Â wine	 Â flavor	 Â 
profiles	 Â and	 Â all	 Â the	 Â white	 Â wine	 Â flavor	 Â profiles.	 Â 	 Â From	 Â 
here,	 Â there	 Â are	 Â a	 Â total	 Â of	 Â two	 Â centroids	 Â representing	 Â all	 Â 
of	 Â the	 Â white	 Â wines	 Â and	 Â all	 Â the	 Â red	 Â wines.	 Â 	 Â Therefore,	 Â as	 Â a	 Â 
dinner	 Â converges	 Â on	 Â a	 Â centroid,	 Â the	 Â algorithm	 Â would	 Â 
associate	 Â it	 Â with	 Â the	 Â color	 Â that	 Â centroid	 Â represented.	 Â 	 Â 
The	 Â results	 Â of	 Â both	 Â of	 Â these	 Â algorithms	 Â are	 Â given	 Â below.	 Â 
	 Â Red	 Â vs.	 Â White	 Â Prediction	 Â Accuracy	 Â 
with	 Â Averaged	 Â Red/White	 Â Flavor	 Â Profiles	 Â 
White	 Â Pred.	 Â 
Red	 Â 
Both	 Â  Pred.	 Â 
Pred.	 Â 
Accuracy	 Â 
Accuracy	 Â 
Accuracy	 Â 
	 Â 80.0%	 Â 
	 Â 61.7%	 Â 
	 Â 70.9%	 Â 
	 Â 
	 Â 
For	 Â finding	 Â a	 Â specific	 Â wine,	 Â I	 Â use	 Â the	 Â number	 Â of	 Â 
iterations	 Â that	 Â produced	 Â the	 Â highest	 Â accuracy	 Â when	 Â 
predicting	 Â the	 Â color	 Â of	 Â the	 Â wine.	 Â 	 Â This	 Â occurrs	 Â when	 Â 

4.2.2	 Â Specific	 Â Wine	 Â Prediction:	 Â 

there	 Â was	 Â only	 Â one	 Â iteration.	 Â 	 Â Much	 Â like	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â 
equivalent	 Â to	 Â solve	 Â this	 Â algorithm,	 Â the	 Â algorithm	 Â keeps	 Â 
track	 Â of	 Â the	 Â top	 Â N	 Â predicted	 Â wines	 Â rather	 Â than	 Â simply	 Â 
the	 Â top	 Â predicted	 Â wine	 Â so	 Â as	 Â to	 Â better	 Â show	 Â the	 Â 
accuracy	 Â of	 Â the	 Â algorithm.	 Â 	 Â In	 Â order	 Â to	 Â calculate	 Â the	 Â top	 Â 
N	 Â wines	 Â given	 Â that	 Â the	 Â wine	 Â is	 Â grouped	 Â to	 Â a	 Â specific	 Â 
centroid	 Â and,	 Â therefore,	 Â only	 Â one	 Â specific	 Â wine,	 Â the	 Â 
algorithm	 Â calculates	 Â the	 Â Euclidian	 Â distance	 Â from	 Â the	 Â 
point	 Â to	 Â all	 Â other	 Â centroids	 Â and	 Â kept	 Â track	 Â of	 Â the	 Â top	 Â N	 Â 
centroids	 Â that	 Â have	 Â the	 Â smallest	 Â distance.	 Â 	 Â The	 Â results	 Â of	 Â 
this	 Â algorithm	 Â can	 Â be	 Â seen	 Â below:	 Â 
	 Â 

N	 Â =	 Â 1	 Â 
N	 Â =	 Â 3	 Â 
N	 Â =	 Â 5	 Â 
N	 Â =	 Â 10	 Â 
N	 Â =	 Â 20	 Â 
N	 Â =	 Â 30	 Â 

8.6%	 Â 
18.0%	 Â 
26.3%	 Â 
37.6%	 Â 
75.1%	 Â 
95.2%	 Â 

Specific	 Â Wine	 Â (with	 Â top	 Â N	 Â wines)	 Â 

	 Â 

5.	 Â Discussion	 Â 
5.1	 Â NaÃ¯ve	 Â Bayes	 Â 

	 Â 	 Â 
Overall,	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â algorithm	 Â functioned	 Â 
quite	 Â well	 Â in	 Â predicting	 Â both	 Â the	 Â color	 Â of	 Â the	 Â wine	 Â and	 Â a	 Â 
specific	 Â type	 Â of	 Â wine.	 Â 	 Â In	 Â terms	 Â of	 Â score	 Â consideration	 Â 
it	 Â  was	 Â  evident	 Â  that	 Â  the	 Â  algorithm	 Â 
and	 Â  Laplace,	 Â 
performed	 Â best	 Â when	 Â Laplace	 Â smoothing	 Â was	 Â applied	 Â 
and	 Â had	 Â a	 Â negligible	 Â difference	 Â with	 Â score	 Â consideration	 Â 
as	 Â opposed	 Â to	 Â no	 Â score	 Â consideration.	 Â 
The	 Â increasing	 Â in	 Â the	 Â accuracy	 Â with	 Â Laplace	 Â 
smoothing	 Â makes	 Â sense.	 Â 	 Â Going	 Â through	 Â the	 Â database,	 Â I	 Â 
noticed	 Â a	 Â few	 Â foods	 Â that	 Â occurred	 Â with	 Â white	 Â wines	 Â with	 Â 
low	 Â ranks	 Â and	 Â then	 Â only	 Â a	 Â few	 Â red	 Â wines	 Â with	 Â high	 Â 
ranks.	 Â 	 Â Ultimately,	 Â the	 Â Lagrange	 Â smoothing	 Â more	 Â evenly	 Â 
distributes	 Â the	 Â probability	 Â given	 Â a	 Â red	 Â or	 Â white	 Â wine	 Â 
and	 Â thereby	 Â increases	 Â the	 Â overall	 Â accuracy	 Â of	 Â the	 Â 
equation.	 Â 	 Â This	 Â is	 Â further	 Â demonstrated	 Â by	 Â an	 Â increase	 Â 
in	 Â the	 Â accuracy	 Â of	 Â red	 Â wine	 Â prediction	 Â with	 Â a	 Â decrease	 Â 
in	 Â the	 Â accuracy	 Â of	 Â white	 Â wine	 Â prediction.	 Â 
In	 Â terms	 Â of	 Â predicting	 Â a	 Â specific	 Â wine,	 Â the	 Â 
results	 Â far	 Â exceed	 Â what	 Â would	 Â be	 Â expected.	 Â 	 Â With	 Â a	 Â total	 Â 

	 Â 

5.2	 Â K-Â­â€Means	 Â 

of	 Â 131	 Â wines,	 Â the	 Â accuracy	 Â of	 Â randomly	 Â selecting	 Â a	 Â 
single	 Â correct	 Â wine	 Â from	 Â this	 Â set	 Â would	 Â be	 Â 0.76%	 Â but	 Â 
the	 Â algorithm	 Â is	 Â able	 Â to	 Â predict	 Â the	 Â top	 Â wine	 Â with	 Â 8.0%	 Â 
accuracy,	 Â more	 Â than	 Â 10	 Â fold	 Â better	 Â than	 Â guessing.	 Â 	 Â As	 Â 
well,	 Â the	 Â algorithm	 Â sad	 Â the	 Â correct	 Â wine	 Â in	 Â the	 Â top	 Â 30	 Â 
guesses	 Â 90%	 Â of	 Â the	 Â time,	 Â demonstrating	 Â that	 Â the	 Â 
algorithm	 Â is	 Â able	 Â to	 Â recognize	 Â the	 Â correct	 Â wine	 Â as	 Â a	 Â 
strong	 Â contender,	 Â if	 Â even	 Â it	 Â doesnâ€™t	 Â select	 Â the	 Â wine	 Â as	 Â 
the	 Â number	 Â one	 Â choice.	 Â 
	 Â 
Overall,	 Â the	 Â K-Â­â€Means	 Â model	 Â has	 Â a	 Â high	 Â accuracy	 Â 
rate	 Â but,	 Â based	 Â on	 Â consistency,	 Â functions	 Â worse	 Â than	 Â the	 Â 
NaÃ¯ve-Â­â€Bayes	 Â model,	 Â as	 Â demonstrated	 Â by	 Â the	 Â K-Â­â€Means	 Â 
attempt	 Â to	 Â predict	 Â the	 Â color	 Â of	 Â wine	 Â to	 Â pair	 Â with	 Â the	 Â 
dinner.	 Â 	 Â In	 Â addition	 Â to	 Â its	 Â inability	 Â to	 Â converge,	 Â the	 Â K-Â­â€
Means	 Â model	 Â also	 Â varies	 Â drastically	 Â on	 Â the	 Â accuracy	 Â for	 Â 
red	 Â wines	 Â and	 Â the	 Â accuracy	 Â for	 Â white	 Â wines.	 Â 	 Â That	 Â is,	 Â 
with	 Â fewer	 Â iterations,	 Â the	 Â accuracy	 Â for	 Â white	 Â wine	 Â 
prediction	 Â is	 Â much	 Â higher,	 Â reaching	 Â a	 Â peak	 Â of	 Â 100%,	 Â in	 Â 
fact,	 Â with	 Â a	 Â single	 Â iteration.	 Â 	 Â However,	 Â as	 Â the	 Â number	 Â of	 Â 
iterations	 Â increased,	 Â the	 Â accuracy	 Â of	 Â white	 Â wine	 Â drops	 Â 
to	 Â a	 Â low	 Â of	 Â 11.7%	 Â with	 Â 50	 Â iterations.	 Â 	 Â This	 Â effect	 Â is	 Â 
reversed	 Â for	 Â the	 Â accuracy	 Â of	 Â a	 Â red	 Â wine	 Â prediction.	 Â 
One	 Â theory	 Â I	 Â have	 Â behind	 Â this	 Â phenomenon	 Â is	 Â 
that	 Â quite	 Â a	 Â few	 Â of	 Â the	 Â dinners	 Â that	 Â are	 Â extremely	 Â 
strongly	 Â associated	 Â with	 Â a	 Â white	 Â wine.	 Â 	 Â That	 Â is,	 Â there	 Â are	 Â 
a	 Â few	 Â white-Â­â€wine-Â­â€paired	 Â dinners	 Â that	 Â have	 Â only	 Â highly	 Â 
white	 Â wine	 Â weighted	 Â ingredients	 Â such	 Â as	 Â any	 Â type	 Â of	 Â 
lemon,	 Â 
fish,	 Â  clam,	 Â  mussels,	 Â 
lime,	 Â  any	 Â  number	 Â  of	 Â 
vegetables,	 Â and	 Â olive	 Â oil.	 Â 
	 Â Essentially,	 Â any	 Â type	 Â of	 Â 
seafood	 Â dish.	 Â 	 Â However,	 Â there	 Â are	 Â a	 Â variety	 Â of	 Â white-Â­â€
wine-Â­â€paired	 Â dishes	 Â and	 Â nearly	 Â all	 Â red-Â­â€wine-Â­â€paired	 Â 
dishes	 Â that	 Â contain	 Â both	 Â ingredients	 Â strongly	 Â associated	 Â 
with	 Â red	 Â wine	 Â and	 Â ingredients	 Â associated	 Â with	 Â white	 Â 
wines.	 Â 	 Â Therefore,	 Â at	 Â the	 Â beginning,	 Â the	 Â white	 Â wine	 Â 
prediction	 Â is	 Â high.	 Â 	 Â However,	 Â as	 Â the	 Â number	 Â of	 Â iterations	 Â 
increases,	 Â the	 Â white	 Â wine	 Â centroids	 Â become	 Â more	 Â 
similar	 Â to	 Â the	 Â extreme	 Â white-Â­â€wine-Â­â€paired	 Â dishes.	 Â 	 Â As	 Â 
this	 Â occurs,	 Â more	 Â dishes	 Â will	 Â be	 Â paired	 Â with	 Â a	 Â red	 Â wine	 Â 
because	 Â only	 Â the	 Â few	 Â cases	 Â of	 Â extreme	 Â white-Â­â€wine	 Â 
paired	 Â dishes	 Â will	 Â be	 Â clustered	 Â with	 Â a	 Â white	 Â wine	 Â 
centroid,	 Â thereby	 Â decreasing	 Â the	 Â accuracy	 Â of	 Â predicting	 Â 
a	 Â white	 Â wine	 Â and	 Â increasing	 Â the	 Â accuracy	 Â of	 Â predicting	 Â a	 Â 
red	 Â wine.	 Â For	 Â predicting	 Â a	 Â specific	 Â type	 Â of	 Â wine,	 Â the	 Â K-Â­â€
Mean	 Â models	 Â accuracy	 Â 
is	 Â  extremely	 Â  close	 Â  to	 Â  the	 Â 
accuracy	 Â achieved	 Â in	 Â the	 Â NaÃ¯ve	 Â Bayes	 Â model.	 Â 	 Â That	 Â is,	 Â 
with	 Â only	 Â selecting	 Â the	 Â one	 Â predicted	 Â wine,	 Â the	 Â model	 Â 
accurately	 Â predicts	 Â the	 Â correct	 Â wine	 Â 8.1%	 Â of	 Â the	 Â time.	 Â 	 Â 
And	 Â with	 Â selecting	 Â the	 Â top	 Â 30	 Â predicted	 Â wines,	 Â the	 Â 
model	 Â accurately	 Â predicted	 Â the	 Â correct	 Â wine	 Â in	 Â these	 Â 
predictions	 Â 95.2%	 Â of	 Â the	 Â time.	 Â 
	 Â 	 Â 

6.	 Â Conclusion	 Â 

the	 Â case	 Â for	 Â the	 Â three	 Â databases	 Â used	 Â in	 Â the	 Â models,	 Â 
having	 Â more	 Â databases	 Â to	 Â test	 Â this	 Â would	 Â be	 Â ideal.	 Â 
	 Â 
Iâ€™d	 Â love	 Â to	 Â continue	 Â working	 Â on	 Â this	 Â project	 Â in	 Â 
hopes	 Â of	 Â making	 Â it	 Â a	 Â practical	 Â application	 Â that	 Â a	 Â variety	 Â 
of	 Â people	 Â could	 Â use	 Â to	 Â help	 Â pair	 Â a	 Â wine	 Â with	 Â their	 Â meal.	 Â 	 Â 
In	 Â  fact,	 Â  while	 Â  at	 Â  the	 Â  poster	 Â  presentation,	 Â  I	 Â  was	 Â 
confronted	 Â by	 Â a	 Â man	 Â working	 Â on	 Â an	 Â iPhone	 Â application	 Â 
that	 Â paired	 Â a	 Â wine	 Â with	 Â a	 Â list	 Â of	 Â ingredients	 Â and	 Â then	 Â 
went	 Â a	 Â step	 Â further	 Â and	 Â showed	 Â a	 Â specific	 Â vintage	 Â and	 Â 
also	 Â the	 Â best	 Â place	 Â to	 Â buy	 Â the	 Â wine	 Â in	 Â order	 Â to	 Â obtain	 Â the	 Â 
cheapest	 Â price.	 Â 	 Â 	 Â Hopefully	 Â I	 Â am	 Â able	 Â to	 Â continue	 Â 
working	 Â on	 Â my	 Â models	 Â and	 Â help	 Â contribute	 Â to	 Â this	 Â 
application.	 Â 
	 Â 
What	 Â To	 Â Pair	 Â [Online].	 Â Available:	 Â 
http://www.whattopair.com	 Â 
	 Â M.	 Â Puckette.	 Â (2014,	 Â Sept.	 Â 22).	 Â Flavor	 Â Profiles	 Â of	 Â Wines	 Â 
(Infographic)	 Â [Online]	 Â Available:	 Â 
http://winefolly.com/review/red-Â­â€wine-Â­â€flavor-Â­â€profiles/	 Â 
	 Â 
Match	 Â My	 Â Wine	 Â [Online].	 Â Available:	 Â 
http://www.matchmywine.com/	 Â 
	 Â 

References	 Â 

	 Â 
Based	 Â on	 Â the	 Â results	 Â of	 Â the	 Â two	 Â algorithms,	 Â the	 Â 
naÃ¯ve	 Â Bayes	 Â is	 Â more	 Â consistent	 Â at	 Â predicting	 Â the	 Â color	 Â of	 Â 
the	 Â wine.	 Â 	 Â In	 Â terms	 Â of	 Â predicting	 Â a	 Â specific	 Â type	 Â of	 Â wine,	 Â 
both	 Â algorithms	 Â perform	 Â well	 Â with	 Â negligible	 Â accuracy	 Â 
difference	 Â between	 Â the	 Â two.	 Â 
In	 Â terms	 Â of	 Â the	 Â broad	 Â conclusion	 Â draw	 Â from	 Â the	 Â 
	 Â 
results,	 Â it	 Â seems	 Â that	 Â there	 Â exists	 Â a	 Â strong	 Â set	 Â of	 Â rules	 Â 
that	 Â dominate	 Â how	 Â wine	 Â and	 Â food	 Â pair	 Â together.	 Â 	 Â Our	 Â 
original	 Â features	 Â and	 Â derived	 Â features	 Â originate	 Â from	 Â 
the	 Â first	 Â two	 Â databases	 Â whereas	 Â our	 Â method	 Â for	 Â 
checking	 Â accuracy	 Â came	 Â from	 Â an	 Â entirely	 Â different	 Â 
database.	 Â 	 Â With	 Â the	 Â accuracy	 Â demonstrated	 Â by	 Â training	 Â 
and	 Â testing	 Â on	 Â completely	 Â separate	 Â databases,	 Â it	 Â seems	 Â 
that	 Â all	 Â three	 Â databases	 Â have	 Â an	 Â underlying	 Â theme	 Â of	 Â 
wine	 Â and	 Â food	 Â pairing	 Â that	 Â tied	 Â them	 Â together.	 Â 	 Â That	 Â is,	 Â 
if	 Â any	 Â of	 Â the	 Â databases	 Â did	 Â not	 Â accurately	 Â reflect	 Â the	 Â 
wine/food	 Â pairing	 Â rules	 Â demonstrated	 Â in	 Â the	 Â others,	 Â we	 Â 
would	 Â likely	 Â not	 Â see	 Â this	 Â high	 Â level	 Â of	 Â prediction	 Â 
accuracy.	 Â 	 Â Therefore,	 Â using	 Â my	 Â models,	 Â it	 Â seems	 Â that	 Â 
there	 Â is	 Â a	 Â strict	 Â set	 Â of	 Â rules	 Â that	 Â apply	 Â to	 Â wine/food	 Â 
pairing.	 Â 
Finally,	 Â in	 Â terms	 Â of	 Â progressing	 Â from	 Â wine	 Â to	 Â 
	 Â 
food	 Â pairing	 Â into	 Â wine	 Â to	 Â dinner	 Â pairing,	 Â it	 Â seems	 Â that	 Â 
many	 Â of	 Â the	 Â same	 Â rules	 Â are	 Â still	 Â applicable.	 Â 	 Â That	 Â is,	 Â 
using	 Â the	 Â rules	 Â and	 Â nuances	 Â of	 Â wine/food	 Â pairing,	 Â one	 Â 
can	 Â predict	 Â with	 Â a	 Â high	 Â level	 Â of	 Â accuracy	 Â a	 Â wine	 Â that	 Â 
pairs	 Â with	 Â a	 Â grouping	 Â of	 Â food	 Â as	 Â well.	 Â 	 Â Therefore,	 Â it	 Â 
seems	 Â that	 Â the	 Â rules	 Â for	 Â wine	 Â pairing	 Â rules	 Â are	 Â specific	 Â 
enough	 Â to	 Â be	 Â represented	 Â accurately	 Â across	 Â a	 Â variety	 Â of	 Â 
databases	 Â and	 Â with	 Â a	 Â variety	 Â of	 Â models,	 Â but	 Â are	 Â also	 Â 
generalized	 Â  enough	 Â 
for	 Â  having	 Â 
multiple	 Â foods.	 Â 
	 Â 
I	 Â think	 Â the	 Â one	 Â thing	 Â that	 Â would	 Â drastically	 Â 
increase	 Â the	 Â accuracy	 Â of	 Â the	 Â algorithm	 Â would	 Â be	 Â 
considering	 Â the	 Â importance	 Â that	 Â each	 Â food	 Â plays	 Â in	 Â the	 Â 
meal.	 Â 	 Â That	 Â is,	 Â meat	 Â is	 Â usually	 Â paired	 Â with	 Â a	 Â red	 Â wine	 Â 
whereas	 Â most	 Â vegetables	 Â are	 Â usually	 Â paired	 Â with	 Â a	 Â 
white	 Â wine.	 Â 	 Â However,	 Â in	 Â a	 Â case	 Â where	 Â we	 Â have	 Â a	 Â meat	 Â 
as	 Â the	 Â main	 Â component	 Â of	 Â the	 Â dish	 Â and	 Â the	 Â vegetable	 Â as	 Â 
the	 Â side	 Â component,	 Â it	 Â would	 Â seem	 Â that	 Â the	 Â meat	 Â should	 Â 
play	 Â a	 Â larger	 Â role	 Â in	 Â determining	 Â both	 Â what	 Â color	 Â wine	 Â 
to	 Â have	 Â and	 Â what	 Â specific	 Â type	 Â of	 Â wine	 Â to	 Â have.	 Â 	 Â 
Although	 Â difficult,	 Â this	 Â could	 Â be	 Â done	 Â by	 Â obtaining	 Â the	 Â 
estimated	 Â or	 Â averaged	 Â weight	 Â of	 Â each	 Â ingredient	 Â in	 Â the	 Â 
meal	 Â and	 Â using	 Â this	 Â as	 Â a	 Â weight	 Â to	 Â weight	 Â the	 Â influence	 Â 
of	 Â each	 Â ingredient	 Â on	 Â predicting	 Â a	 Â wine.	 Â 	 Â I	 Â would	 Â also	 Â do	 Â 
more	 Â analysis	 Â of	 Â the	 Â K=Means	 Â algorithm	 Â in	 Â an	 Â attempt	 Â 
to	 Â better	 Â understand	 Â why	 Â it	 Â predicts	 Â white	 Â wines	 Â with	 Â 
such	 Â high	 Â accuracy	 Â when	 Â it	 Â has	 Â so	 Â few	 Â iterations	 Â but	 Â 
with	 Â such	 Â low	 Â accuracy	 Â when	 Â it	 Â has	 Â a	 Â larger	 Â number	 Â of	 Â 
iterations.	 Â 	 Â Finally,	 Â I	 Â think	 Â have	 Â more	 Â databases	 Â to	 Â use	 Â 
would	 Â be	 Â extremely	 Â helping,	 Â especially	 Â in	 Â bolstering	 Â the	 Â 
idea	 Â that	 Â strict	 Â wine	 Â pairing	 Â rules	 Â exist	 Â across	 Â a	 Â 
multitude	 Â of	 Â databases.	 Â 	 Â Although	 Â this	 Â appeared	 Â to	 Â be	 Â 

to	 Â  accommodate	 Â 

7.	 Â Future	 Â 

