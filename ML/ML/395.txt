Predicting Seizure Onset in Epileptic Patients

Using Intracranial EEG Recordings

Janet An

Stanford University

Amy Bearman

Stanford University

Catherine Dong

Stanford University

janeta94@stanford.edu

abearman@stanford.edu

cdong@stanford.edu

Abstract—Intracranial EEG-based monitoring systems
have the potential ability to predict seizure onset, but preictal
(pre-seizure) states are difﬁcult to identify and are often
confused with normal variations in brain activity. Our goal
was to distinguish between EEG recordings covering preictal
brain activity an hour prior to a seizure, and those recording
purely interictal (non-seizure) activity. We modeled this as a
binary classiﬁcation problem, computing several linear and
nonlinear bivariate features (maximal cross-correlation and
Euclidean distance) over pairs of EEG channels. We trained
support vector machines, logistic regression, and neighbors-
based classiﬁcation to discriminate interictal from preictal
patterns of features. Among the evaluated methods, L2-
regularized logistic regression was most successful, predicting
with 85.7% accuracy and an F1 score of 86.7%.

Index Terms—Seizure prediction, logistic regression, EEG,

machine learning.

I. INTRODUCTION

About 1% of the world’s population is afﬂicted with
epilepsy. Although seizures occur infrequently (99% of a
patient’s life is spent in the interictal (non-seizure state),
the possibility of a spontaneous seizure causes constant
anxiety for patients and inhibits their ability to lead normal
lives. Sufﬁciently high doses of anticonvulsant medications
can be effective in 60-80% of patients, but because they
often come with signiﬁcant side effects, these medications
should only be administered when necessary, i.e., before
a seizure. Therefore, some method of predicting seizure
onset is needed to alert epileptic patients to administer
medication and avoid risky activities, such as swimming
or driving.

Intracranial electrocorticography (EEG) monitoring sys-
tems have the potential ability to predict seizure onset
by measuring electrical activity in the brain, as recorded
from multiple electrodes implanted directly on the surface
of the brain. However, even with this data, preictal (pre-
seizure) states are difﬁcult to identify and often confused
with normal variations in brain activity.

Because epilepsy is such a prevalent neurological dis-
order, with unexpected seizures having such dangerous
consequences, attempts to develop seizure forecasting
systems have been recorded in a number of previous
papers. One aspect of the prediction process that all of
the researchers have had to handle is selecting relevant

features from the enormous datasets of EEG recordings.
Different approaches to feature selection that have been
undertaken include choosing a small subset of the elec-
trode channels using recursive feature elimination, as well
as spectral analysis using wavelet transform to compress
EEG recordings into a small number of features. After
running their algorithms, mostly using various types of
SVMs,
the previous papers report varying degrees of
success, with accuracies ranging from just barely over
50% to around 85%. Many of these papers report that
future work to be done to improve the accuracy of these
prediction algorithms include dimensionality reduction of
the data and better feature extraction to obtain potentially
hidden information.

Our goal is to apply a variety of machine learning
classiﬁcation methods to this EEG data in order to more
accurately model the probability that a patient is in a
preictal state.

II. DATA

Annotated intracranial EEG (iEEG) data is freely avail-
able at the International Epilepsy Electrophysiology Portal.
There are iEEG data clips for both human and canine sub-
jects. The data for each subject is organized into ten minute
clips labeled ”Preictal” for pre-seizure data segments, or
”Interictal” for non-seizure data segments. Preictal training
and testing data segments are provided covering one hour
prior to seizure with a ﬁve minute seizure horizon (i.e.
1:05 to 0:05 before seizure onset). Interictal data is chosen
randomly from the full data record, with the restriction that
the interictal segments be as far away as possible from any
seizure to avoid contamination with preictal or postictal
signals. The pre-seizure horizon ensures that seizures can
be predicted with enough time for the subject to take
appropriate action (such as administer medication).

Fig. 1: EEG data over 1 hour pre-seizure window

Predicting Seizure Onset in Epileptic Patients

Using Intracranial EEG Recordings

Janet An

Stanford University

Amy Bearman

Stanford University

Catherine Dong

Stanford University

janeta94@stanford.edu

abearman@stanford.edu

cdong@stanford.edu

Abstract—Intracranial EEG-based monitoring systems
have the potential ability to predict seizure onset, but preictal
(pre-seizure) states are difﬁcult to identify and are often
confused with normal variations in brain activity. Our goal
was to distinguish between EEG recordings covering preictal
brain activity an hour prior to a seizure, and those recording
purely interictal (non-seizure) activity. We modeled this as a
binary classiﬁcation problem, computing several linear and
nonlinear bivariate features (maximal cross-correlation and
Euclidean distance) over pairs of EEG channels. We trained
support vector machines, logistic regression, and neighbors-
based classiﬁcation to discriminate interictal from preictal
patterns of features. Among the evaluated methods, L2-
regularized logistic regression was most successful, predicting
with 85.7% accuracy and an F1 score of 86.7%.

Index Terms—Seizure prediction, logistic regression, EEG,

machine learning.

I. INTRODUCTION

About 1% of the world’s population is afﬂicted with
epilepsy. Although seizures occur infrequently (99% of a
patient’s life is spent in the interictal (non-seizure state),
the possibility of a spontaneous seizure causes constant
anxiety for patients and inhibits their ability to lead normal
lives. Sufﬁciently high doses of anticonvulsant medications
can be effective in 60-80% of patients, but because they
often come with signiﬁcant side effects, these medications
should only be administered when necessary, i.e., before
a seizure. Therefore, some method of predicting seizure
onset is needed to alert epileptic patients to administer
medication and avoid risky activities, such as swimming
or driving.

Intracranial electrocorticography (EEG) monitoring sys-
tems have the potential ability to predict seizure onset
by measuring electrical activity in the brain, as recorded
from multiple electrodes implanted directly on the surface
of the brain. However, even with this data, preictal (pre-
seizure) states are difﬁcult to identify and often confused
with normal variations in brain activity.

Because epilepsy is such a prevalent neurological dis-
order, with unexpected seizures having such dangerous
consequences, attempts to develop seizure forecasting
systems have been recorded in a number of previous
papers. One aspect of the prediction process that all of
the researchers have had to handle is selecting relevant

features from the enormous datasets of EEG recordings.
Different approaches to feature selection that have been
undertaken include choosing a small subset of the elec-
trode channels using recursive feature elimination, as well
as spectral analysis using wavelet transform to compress
EEG recordings into a small number of features. After
running their algorithms, mostly using various types of
SVMs,
the previous papers report varying degrees of
success, with accuracies ranging from just barely over
50% to around 85%. Many of these papers report that
future work to be done to improve the accuracy of these
prediction algorithms include dimensionality reduction of
the data and better feature extraction to obtain potentially
hidden information.

Our goal is to apply a variety of machine learning
classiﬁcation methods to this EEG data in order to more
accurately model the probability that a patient is in a
preictal state.

II. DATA

Annotated intracranial EEG (iEEG) data is freely avail-
able at the International Epilepsy Electrophysiology Portal.
There are iEEG data clips for both human and canine sub-
jects. The data for each subject is organized into ten minute
clips labeled ”Preictal” for pre-seizure data segments, or
”Interictal” for non-seizure data segments. Preictal training
and testing data segments are provided covering one hour
prior to seizure with a ﬁve minute seizure horizon (i.e.
1:05 to 0:05 before seizure onset). Interictal data is chosen
randomly from the full data record, with the restriction that
the interictal segments be as far away as possible from any
seizure to avoid contamination with preictal or postictal
signals. The pre-seizure horizon ensures that seizures can
be predicted with enough time for the subject to take
appropriate action (such as administer medication).

Fig. 1: EEG data over 1 hour pre-seizure window

Each data clip contains a matrix of EEG sample values
arranged row × column as electrode channel × time. In
our subject’s data set, there are 15 electrode channels and
240,000 iEEG readings sampled at 400 Hz. The recordings
span multiple months up to a year, and record 30 seizures
in our subject (up to 100 in other subjects). We used 5
hours of interictal data and 5 hours of preictal data for
training. There are 60 data clips (30 preictal, 30 interictal),
for 36,000 total examples in both the training and testing
data sets.

III. PREPROCESSING

A. Normalization

Since the range of voltage readings in the EEG dataset
vary widely, we normalized the data to avoid heavily
weighting readings that are very positive or very negative.
For each segment, we calculated the minimum voltage
reading over all 15 channels, as well as the range of the
data for that segment. We normalized each EEG reading,
x, by computing:

are computed on each channel separately. In past studies,
bivariate features have been more successful than uni-
variate ones in seizure prediction tasks. Though there is
little understanding of the preictal brain state, neuroscience
researchers hypothesize that there is correlation between
the synchronization of brain activity and seizure onset.
This synchronization hypothesis motivated our choice to
use bivariate features.

A. Maximal Cross-Correlation

Cross-correlation is a measure of similarity of two
waveforms as a function of a time-lag applied to one
of them. Cross-correlation (C) values between two pairs
(xi, xj) of EEG channels were computed at delays τ
ranging from -0.5 to 0.5 seconds in order to account for
the propagation and processing time of brainwaves. We
retained the maximal value of cross-correlation:

(cid:41)

(cid:112)Ci(0) · Cb(0)

Ca,b(τ )

x :=

x = min(x)

| max(x) − min(x)|

(1)

where

(cid:40)

N−τ(cid:80)

Ca,b = max

τ

 1

(2)

(3)

B. Independent Components Analysis

We attempted to use ICA to separate the EEG data into
maximally independent components, in order to potentially
remove noisy artifacts such as eye movement, heartbeat,
or muscle activity on the scalp. We extracted the unmixing
matrix, W , in order to recover the “sources” (i.e., the in-
dependent components, including the heartbeat waveform)
by computing s(i) = W x(i). However, we did not recover
any obvious artifacts, and running our models on the
independent sources did not give us higher performance
metrics, so we decided to use the original data. It
is
possible that ICA was not successful because the EEG
sources were not temporally independent, or that there
were non-negligible propagation delays from the sources
to the electrodes [6].

IV. FEATURE EXTRACTION FROM EEG

The challenge was to distinguish between ten minute
long data clips covering an hour prior to a seizure, and data
clips of the same length recording purely interictal (non-
seizure) activity. Predicting seizure onset can be modeled
as a binary classiﬁcation problem, where data clips are
labeled as ±1 (negative for interictal and positive for
preictal). Our goal was to construct a function that maps
from a feature vector x taken from a data segment to a
correct labeling of the segment.

As a baseline, we created a feature matrix where each
EEG channel reading was one feature. For more advanced
feature selection, we also computed bivariate features over
1 second windows that measure a relationship between
two EEG channels, rather than univariate features which

2

Ca,b(τ ) =

N−τ
Cb,a(−τ )

t=1

xa(t + τ )xb(τ )

τ ≥ 0

τ < 0

and N is the number of readings within the analysis
window (N = 400 in our case). We also retained the non-
delayed cross-correlation between the two signals.

B. Euclidean Distance

Euclidean distance measures the distance in state-space
between the trajectories of two EEG channels. First, each
channel was time delay embedded into a trajectory with a
time delay τ = 6 readings and an embedding dimension
d = 10, as seen in [3]:

x(t) = {x(t − (d − 1)τ ), . . . , x(t − τ ), x(t)}

(4)

Then, we computed the distance of each time-delay em-
bedded vector to its K nearest neighbors in state space:

n(cid:88)

t=1

1
K

1
K

1
N

K(cid:80)
K(cid:80)

k=1

k=1

(cid:107)xa(t) − xa(ta

(cid:107)xa(t) − xa(tb

2

k)(cid:107)2
k)(cid:107)2

2

(5)

where:
{ta
1, ta
{tb
1, tb

2, . . . , ta

2, . . . , tb

K} are the time indices of the K nearest
K} are the time indices of the K nearest

neighbors of xa(t), and

neighbors of xb(t).

Predicting Seizure Onset in Epileptic Patients

Using Intracranial EEG Recordings

Janet An

Stanford University

Amy Bearman

Stanford University

Catherine Dong

Stanford University

janeta94@stanford.edu

abearman@stanford.edu

cdong@stanford.edu

Abstract—Intracranial EEG-based monitoring systems
have the potential ability to predict seizure onset, but preictal
(pre-seizure) states are difﬁcult to identify and are often
confused with normal variations in brain activity. Our goal
was to distinguish between EEG recordings covering preictal
brain activity an hour prior to a seizure, and those recording
purely interictal (non-seizure) activity. We modeled this as a
binary classiﬁcation problem, computing several linear and
nonlinear bivariate features (maximal cross-correlation and
Euclidean distance) over pairs of EEG channels. We trained
support vector machines, logistic regression, and neighbors-
based classiﬁcation to discriminate interictal from preictal
patterns of features. Among the evaluated methods, L2-
regularized logistic regression was most successful, predicting
with 85.7% accuracy and an F1 score of 86.7%.

Index Terms—Seizure prediction, logistic regression, EEG,

machine learning.

I. INTRODUCTION

About 1% of the world’s population is afﬂicted with
epilepsy. Although seizures occur infrequently (99% of a
patient’s life is spent in the interictal (non-seizure state),
the possibility of a spontaneous seizure causes constant
anxiety for patients and inhibits their ability to lead normal
lives. Sufﬁciently high doses of anticonvulsant medications
can be effective in 60-80% of patients, but because they
often come with signiﬁcant side effects, these medications
should only be administered when necessary, i.e., before
a seizure. Therefore, some method of predicting seizure
onset is needed to alert epileptic patients to administer
medication and avoid risky activities, such as swimming
or driving.

Intracranial electrocorticography (EEG) monitoring sys-
tems have the potential ability to predict seizure onset
by measuring electrical activity in the brain, as recorded
from multiple electrodes implanted directly on the surface
of the brain. However, even with this data, preictal (pre-
seizure) states are difﬁcult to identify and often confused
with normal variations in brain activity.

Because epilepsy is such a prevalent neurological dis-
order, with unexpected seizures having such dangerous
consequences, attempts to develop seizure forecasting
systems have been recorded in a number of previous
papers. One aspect of the prediction process that all of
the researchers have had to handle is selecting relevant

features from the enormous datasets of EEG recordings.
Different approaches to feature selection that have been
undertaken include choosing a small subset of the elec-
trode channels using recursive feature elimination, as well
as spectral analysis using wavelet transform to compress
EEG recordings into a small number of features. After
running their algorithms, mostly using various types of
SVMs,
the previous papers report varying degrees of
success, with accuracies ranging from just barely over
50% to around 85%. Many of these papers report that
future work to be done to improve the accuracy of these
prediction algorithms include dimensionality reduction of
the data and better feature extraction to obtain potentially
hidden information.

Our goal is to apply a variety of machine learning
classiﬁcation methods to this EEG data in order to more
accurately model the probability that a patient is in a
preictal state.

II. DATA

Annotated intracranial EEG (iEEG) data is freely avail-
able at the International Epilepsy Electrophysiology Portal.
There are iEEG data clips for both human and canine sub-
jects. The data for each subject is organized into ten minute
clips labeled ”Preictal” for pre-seizure data segments, or
”Interictal” for non-seizure data segments. Preictal training
and testing data segments are provided covering one hour
prior to seizure with a ﬁve minute seizure horizon (i.e.
1:05 to 0:05 before seizure onset). Interictal data is chosen
randomly from the full data record, with the restriction that
the interictal segments be as far away as possible from any
seizure to avoid contamination with preictal or postictal
signals. The pre-seizure horizon ensures that seizures can
be predicted with enough time for the subject to take
appropriate action (such as administer medication).

Fig. 1: EEG data over 1 hour pre-seizure window

Each data clip contains a matrix of EEG sample values
arranged row × column as electrode channel × time. In
our subject’s data set, there are 15 electrode channels and
240,000 iEEG readings sampled at 400 Hz. The recordings
span multiple months up to a year, and record 30 seizures
in our subject (up to 100 in other subjects). We used 5
hours of interictal data and 5 hours of preictal data for
training. There are 60 data clips (30 preictal, 30 interictal),
for 36,000 total examples in both the training and testing
data sets.

III. PREPROCESSING

A. Normalization

Since the range of voltage readings in the EEG dataset
vary widely, we normalized the data to avoid heavily
weighting readings that are very positive or very negative.
For each segment, we calculated the minimum voltage
reading over all 15 channels, as well as the range of the
data for that segment. We normalized each EEG reading,
x, by computing:

are computed on each channel separately. In past studies,
bivariate features have been more successful than uni-
variate ones in seizure prediction tasks. Though there is
little understanding of the preictal brain state, neuroscience
researchers hypothesize that there is correlation between
the synchronization of brain activity and seizure onset.
This synchronization hypothesis motivated our choice to
use bivariate features.

A. Maximal Cross-Correlation

Cross-correlation is a measure of similarity of two
waveforms as a function of a time-lag applied to one
of them. Cross-correlation (C) values between two pairs
(xi, xj) of EEG channels were computed at delays τ
ranging from -0.5 to 0.5 seconds in order to account for
the propagation and processing time of brainwaves. We
retained the maximal value of cross-correlation:

(cid:41)

(cid:112)Ci(0) · Cb(0)

Ca,b(τ )

x :=

x = min(x)

| max(x) − min(x)|

(1)

where

(cid:40)

N−τ(cid:80)

Ca,b = max

τ

 1

(2)

(3)

B. Independent Components Analysis

We attempted to use ICA to separate the EEG data into
maximally independent components, in order to potentially
remove noisy artifacts such as eye movement, heartbeat,
or muscle activity on the scalp. We extracted the unmixing
matrix, W , in order to recover the “sources” (i.e., the in-
dependent components, including the heartbeat waveform)
by computing s(i) = W x(i). However, we did not recover
any obvious artifacts, and running our models on the
independent sources did not give us higher performance
metrics, so we decided to use the original data. It
is
possible that ICA was not successful because the EEG
sources were not temporally independent, or that there
were non-negligible propagation delays from the sources
to the electrodes [6].

IV. FEATURE EXTRACTION FROM EEG

The challenge was to distinguish between ten minute
long data clips covering an hour prior to a seizure, and data
clips of the same length recording purely interictal (non-
seizure) activity. Predicting seizure onset can be modeled
as a binary classiﬁcation problem, where data clips are
labeled as ±1 (negative for interictal and positive for
preictal). Our goal was to construct a function that maps
from a feature vector x taken from a data segment to a
correct labeling of the segment.

As a baseline, we created a feature matrix where each
EEG channel reading was one feature. For more advanced
feature selection, we also computed bivariate features over
1 second windows that measure a relationship between
two EEG channels, rather than univariate features which

2

Ca,b(τ ) =

N−τ
Cb,a(−τ )

t=1

xa(t + τ )xb(τ )

τ ≥ 0

τ < 0

and N is the number of readings within the analysis
window (N = 400 in our case). We also retained the non-
delayed cross-correlation between the two signals.

B. Euclidean Distance

Euclidean distance measures the distance in state-space
between the trajectories of two EEG channels. First, each
channel was time delay embedded into a trajectory with a
time delay τ = 6 readings and an embedding dimension
d = 10, as seen in [3]:

x(t) = {x(t − (d − 1)τ ), . . . , x(t − τ ), x(t)}

(4)

Then, we computed the distance of each time-delay em-
bedded vector to its K nearest neighbors in state space:

n(cid:88)

t=1

1
K

1
K

1
N

K(cid:80)
K(cid:80)

k=1

k=1

(cid:107)xa(t) − xa(ta

(cid:107)xa(t) − xa(tb

2

k)(cid:107)2
k)(cid:107)2

2

(5)

where:
{ta
1, ta
{tb
1, tb

2, . . . , ta

2, . . . , tb

K} are the time indices of the K nearest
K} are the time indices of the K nearest

neighbors of xa(t), and

neighbors of xb(t).

l(cid:88)

i=1

ξi ≥ 0

γ > 0

(6)

(7)

(8)

C. Pearson Correlation

The Pearson correlation coefﬁcient measures the linear
relationship between two time series (x, y), giving a value
between +1 and -1, where 1 is total positive correlation, 0
is no correlation, and -1 is total negative correlation. The
formula for Pearson correlation coefﬁcient when applied
to a sample is:

3) L1-regularized, L2-loss Linear Kernel SVM: Solves

the following primal problem:

(cid:107)w(cid:107)1 + C

min

w

(max(0, 1 − yiwT xi))2

(11)

4) RBF Kernel Support Vector Classiﬁcation: Solves

the following optimization problem:

min
w,b,ξ

1
2

wT w + C

l(cid:88)

i=1

ξi

subject to: yi(wT φ(xi) + b) ≥ 1 − ξi

(12)

r =

1

n − 1

where

¯x =

1
n

n(cid:88)

i=1

n(cid:88)

i=1

(cid:17)

sx

(cid:16) xi − ¯x
(cid:17)(cid:16) yi − ¯y
(cid:118)(cid:117)(cid:117)(cid:116) 1
n(cid:88)

sy

n − 1

i=1

xi, and sx =

(xi − ¯x)2

using the kernel: K(xi, xj) = exp (−γ (cid:107)xi − xj(cid:107)2)

are the sample mean and sample standard deviation, re-
spectively. This expression gives the correlation coefﬁcient
as the mean of the products of the standard scores.

D. Spearman Correlation

The Spearman correlation coefﬁcient is deﬁned as the
Pearson correlation coefﬁcient between the ranked vari-
ables:

ρ = 1 − 6(cid:80) d2

i

n(n2 − 1)

where di = xi − yi is the difference between ranks.

V. MODELS

After selecting our features, we proceeded to run multi-
ple learning algorithms using our dataset in order to select
the model with the highest training accuracy and cross
validation accuracy. In this section, we present the models
we tried and how we found the optimal parameters for
these models.

A. Model Selection

We trained our data on various types of solvers in
the LIBLINEAR package, as well as with varying kernel
options in the LIBSVM package (see [1] and [4]).

1) L2-Regularized Logistic Regression: Solves the fol-

lowing unconstrained optimization problem:

min

w

1
2

wT w + C

log(1 + e−yiwT xi)

(9)

where C is the cost parameter which determines the

degree of misclassiﬁcation of the objective function.

2) L2-regularized, L2-loss Linear Kernel SVM (primal):

Solves the following primal problem:

l(cid:88)

i=1

l(cid:88)

min

w

1
2

wT w + C

(max (0, 1 − yiwT xi))2.

(10)

i=1

3

k=1

K(cid:88)
(cid:118)(cid:117)(cid:117)(cid:116) n(cid:88)

5) Sigmoid Kernel Support Vector Classiﬁcation: This
SVM solves the same optimization problem as in RBF
Kernel Support Vector Classiﬁcation, but with the kernel
function:

K(xi, xj) = tanh(γxT

i xj + r)

(13)

6) K-Nearest Neighbors Classiﬁcation: Neighbors-
based classiﬁcation labels each example, x(k), according
to:

ˆf (x(q)) = arg max
v∈V

d(v, f (x(k)))

(14)

where each training example v is sampled from the train-
ing set V and:

d(x(i), x(j)) =

r − xj
r)2
(xi

(15)

r=1

The results of our testing are shown in TABLE I.
Because we have signiﬁcantly more training instances
than features, we tried non-linear kernels to increase the
model complexity for higher accuracy. However, we found
the computational time of the LIBSVM software on our
dataset to be much too slow to run in real time, even
after scaling our data to a [0, 1] range. After comparing
all of our models, we found that L2-regularized Logistic
Regression in the LIBLINEAR package was the optimal
model in terms of accuracy and computational time.

B. Parameter Selection

For L2-regularized logistic regression, the only param-
eter to optimize is the value of the cost parameter C in
the formulation for the L2-regularized logistic regression
optimization problem (9). To ﬁnd the optimal value of
C, we ﬁrst performed coarse grid search by running the
algorithm using exponentially increasing values for C,
from 2−2 to 213. A portion of the resulting plot is shown
in Fig. 2. The value in this range that resulted in the lowest
cross validation error was C = 16. We then centered in on

Predicting Seizure Onset in Epileptic Patients

Using Intracranial EEG Recordings

Janet An

Stanford University

Amy Bearman

Stanford University

Catherine Dong

Stanford University

janeta94@stanford.edu

abearman@stanford.edu

cdong@stanford.edu

Abstract—Intracranial EEG-based monitoring systems
have the potential ability to predict seizure onset, but preictal
(pre-seizure) states are difﬁcult to identify and are often
confused with normal variations in brain activity. Our goal
was to distinguish between EEG recordings covering preictal
brain activity an hour prior to a seizure, and those recording
purely interictal (non-seizure) activity. We modeled this as a
binary classiﬁcation problem, computing several linear and
nonlinear bivariate features (maximal cross-correlation and
Euclidean distance) over pairs of EEG channels. We trained
support vector machines, logistic regression, and neighbors-
based classiﬁcation to discriminate interictal from preictal
patterns of features. Among the evaluated methods, L2-
regularized logistic regression was most successful, predicting
with 85.7% accuracy and an F1 score of 86.7%.

Index Terms—Seizure prediction, logistic regression, EEG,

machine learning.

I. INTRODUCTION

About 1% of the world’s population is afﬂicted with
epilepsy. Although seizures occur infrequently (99% of a
patient’s life is spent in the interictal (non-seizure state),
the possibility of a spontaneous seizure causes constant
anxiety for patients and inhibits their ability to lead normal
lives. Sufﬁciently high doses of anticonvulsant medications
can be effective in 60-80% of patients, but because they
often come with signiﬁcant side effects, these medications
should only be administered when necessary, i.e., before
a seizure. Therefore, some method of predicting seizure
onset is needed to alert epileptic patients to administer
medication and avoid risky activities, such as swimming
or driving.

Intracranial electrocorticography (EEG) monitoring sys-
tems have the potential ability to predict seizure onset
by measuring electrical activity in the brain, as recorded
from multiple electrodes implanted directly on the surface
of the brain. However, even with this data, preictal (pre-
seizure) states are difﬁcult to identify and often confused
with normal variations in brain activity.

Because epilepsy is such a prevalent neurological dis-
order, with unexpected seizures having such dangerous
consequences, attempts to develop seizure forecasting
systems have been recorded in a number of previous
papers. One aspect of the prediction process that all of
the researchers have had to handle is selecting relevant

features from the enormous datasets of EEG recordings.
Different approaches to feature selection that have been
undertaken include choosing a small subset of the elec-
trode channels using recursive feature elimination, as well
as spectral analysis using wavelet transform to compress
EEG recordings into a small number of features. After
running their algorithms, mostly using various types of
SVMs,
the previous papers report varying degrees of
success, with accuracies ranging from just barely over
50% to around 85%. Many of these papers report that
future work to be done to improve the accuracy of these
prediction algorithms include dimensionality reduction of
the data and better feature extraction to obtain potentially
hidden information.

Our goal is to apply a variety of machine learning
classiﬁcation methods to this EEG data in order to more
accurately model the probability that a patient is in a
preictal state.

II. DATA

Annotated intracranial EEG (iEEG) data is freely avail-
able at the International Epilepsy Electrophysiology Portal.
There are iEEG data clips for both human and canine sub-
jects. The data for each subject is organized into ten minute
clips labeled ”Preictal” for pre-seizure data segments, or
”Interictal” for non-seizure data segments. Preictal training
and testing data segments are provided covering one hour
prior to seizure with a ﬁve minute seizure horizon (i.e.
1:05 to 0:05 before seizure onset). Interictal data is chosen
randomly from the full data record, with the restriction that
the interictal segments be as far away as possible from any
seizure to avoid contamination with preictal or postictal
signals. The pre-seizure horizon ensures that seizures can
be predicted with enough time for the subject to take
appropriate action (such as administer medication).

Fig. 1: EEG data over 1 hour pre-seizure window

Each data clip contains a matrix of EEG sample values
arranged row × column as electrode channel × time. In
our subject’s data set, there are 15 electrode channels and
240,000 iEEG readings sampled at 400 Hz. The recordings
span multiple months up to a year, and record 30 seizures
in our subject (up to 100 in other subjects). We used 5
hours of interictal data and 5 hours of preictal data for
training. There are 60 data clips (30 preictal, 30 interictal),
for 36,000 total examples in both the training and testing
data sets.

III. PREPROCESSING

A. Normalization

Since the range of voltage readings in the EEG dataset
vary widely, we normalized the data to avoid heavily
weighting readings that are very positive or very negative.
For each segment, we calculated the minimum voltage
reading over all 15 channels, as well as the range of the
data for that segment. We normalized each EEG reading,
x, by computing:

are computed on each channel separately. In past studies,
bivariate features have been more successful than uni-
variate ones in seizure prediction tasks. Though there is
little understanding of the preictal brain state, neuroscience
researchers hypothesize that there is correlation between
the synchronization of brain activity and seizure onset.
This synchronization hypothesis motivated our choice to
use bivariate features.

A. Maximal Cross-Correlation

Cross-correlation is a measure of similarity of two
waveforms as a function of a time-lag applied to one
of them. Cross-correlation (C) values between two pairs
(xi, xj) of EEG channels were computed at delays τ
ranging from -0.5 to 0.5 seconds in order to account for
the propagation and processing time of brainwaves. We
retained the maximal value of cross-correlation:

(cid:41)

(cid:112)Ci(0) · Cb(0)

Ca,b(τ )

x :=

x = min(x)

| max(x) − min(x)|

(1)

where

(cid:40)

N−τ(cid:80)

Ca,b = max

τ

 1

(2)

(3)

B. Independent Components Analysis

We attempted to use ICA to separate the EEG data into
maximally independent components, in order to potentially
remove noisy artifacts such as eye movement, heartbeat,
or muscle activity on the scalp. We extracted the unmixing
matrix, W , in order to recover the “sources” (i.e., the in-
dependent components, including the heartbeat waveform)
by computing s(i) = W x(i). However, we did not recover
any obvious artifacts, and running our models on the
independent sources did not give us higher performance
metrics, so we decided to use the original data. It
is
possible that ICA was not successful because the EEG
sources were not temporally independent, or that there
were non-negligible propagation delays from the sources
to the electrodes [6].

IV. FEATURE EXTRACTION FROM EEG

The challenge was to distinguish between ten minute
long data clips covering an hour prior to a seizure, and data
clips of the same length recording purely interictal (non-
seizure) activity. Predicting seizure onset can be modeled
as a binary classiﬁcation problem, where data clips are
labeled as ±1 (negative for interictal and positive for
preictal). Our goal was to construct a function that maps
from a feature vector x taken from a data segment to a
correct labeling of the segment.

As a baseline, we created a feature matrix where each
EEG channel reading was one feature. For more advanced
feature selection, we also computed bivariate features over
1 second windows that measure a relationship between
two EEG channels, rather than univariate features which

2

Ca,b(τ ) =

N−τ
Cb,a(−τ )

t=1

xa(t + τ )xb(τ )

τ ≥ 0

τ < 0

and N is the number of readings within the analysis
window (N = 400 in our case). We also retained the non-
delayed cross-correlation between the two signals.

B. Euclidean Distance

Euclidean distance measures the distance in state-space
between the trajectories of two EEG channels. First, each
channel was time delay embedded into a trajectory with a
time delay τ = 6 readings and an embedding dimension
d = 10, as seen in [3]:

x(t) = {x(t − (d − 1)τ ), . . . , x(t − τ ), x(t)}

(4)

Then, we computed the distance of each time-delay em-
bedded vector to its K nearest neighbors in state space:

n(cid:88)

t=1

1
K

1
K

1
N

K(cid:80)
K(cid:80)

k=1

k=1

(cid:107)xa(t) − xa(ta

(cid:107)xa(t) − xa(tb

2

k)(cid:107)2
k)(cid:107)2

2

(5)

where:
{ta
1, ta
{tb
1, tb

2, . . . , ta

2, . . . , tb

K} are the time indices of the K nearest
K} are the time indices of the K nearest

neighbors of xa(t), and

neighbors of xb(t).

l(cid:88)

i=1

ξi ≥ 0

γ > 0

(6)

(7)

(8)

C. Pearson Correlation

The Pearson correlation coefﬁcient measures the linear
relationship between two time series (x, y), giving a value
between +1 and -1, where 1 is total positive correlation, 0
is no correlation, and -1 is total negative correlation. The
formula for Pearson correlation coefﬁcient when applied
to a sample is:

3) L1-regularized, L2-loss Linear Kernel SVM: Solves

the following primal problem:

(cid:107)w(cid:107)1 + C

min

w

(max(0, 1 − yiwT xi))2

(11)

4) RBF Kernel Support Vector Classiﬁcation: Solves

the following optimization problem:

min
w,b,ξ

1
2

wT w + C

l(cid:88)

i=1

ξi

subject to: yi(wT φ(xi) + b) ≥ 1 − ξi

(12)

r =

1

n − 1

where

¯x =

1
n

n(cid:88)

i=1

n(cid:88)

i=1

(cid:17)

sx

(cid:16) xi − ¯x
(cid:17)(cid:16) yi − ¯y
(cid:118)(cid:117)(cid:117)(cid:116) 1
n(cid:88)

sy

n − 1

i=1

xi, and sx =

(xi − ¯x)2

using the kernel: K(xi, xj) = exp (−γ (cid:107)xi − xj(cid:107)2)

are the sample mean and sample standard deviation, re-
spectively. This expression gives the correlation coefﬁcient
as the mean of the products of the standard scores.

D. Spearman Correlation

The Spearman correlation coefﬁcient is deﬁned as the
Pearson correlation coefﬁcient between the ranked vari-
ables:

ρ = 1 − 6(cid:80) d2

i

n(n2 − 1)

where di = xi − yi is the difference between ranks.

V. MODELS

After selecting our features, we proceeded to run multi-
ple learning algorithms using our dataset in order to select
the model with the highest training accuracy and cross
validation accuracy. In this section, we present the models
we tried and how we found the optimal parameters for
these models.

A. Model Selection

We trained our data on various types of solvers in
the LIBLINEAR package, as well as with varying kernel
options in the LIBSVM package (see [1] and [4]).

1) L2-Regularized Logistic Regression: Solves the fol-

lowing unconstrained optimization problem:

min

w

1
2

wT w + C

log(1 + e−yiwT xi)

(9)

where C is the cost parameter which determines the

degree of misclassiﬁcation of the objective function.

2) L2-regularized, L2-loss Linear Kernel SVM (primal):

Solves the following primal problem:

l(cid:88)

i=1

l(cid:88)

min

w

1
2

wT w + C

(max (0, 1 − yiwT xi))2.

(10)

i=1

3

k=1

K(cid:88)
(cid:118)(cid:117)(cid:117)(cid:116) n(cid:88)

5) Sigmoid Kernel Support Vector Classiﬁcation: This
SVM solves the same optimization problem as in RBF
Kernel Support Vector Classiﬁcation, but with the kernel
function:

K(xi, xj) = tanh(γxT

i xj + r)

(13)

6) K-Nearest Neighbors Classiﬁcation: Neighbors-
based classiﬁcation labels each example, x(k), according
to:

ˆf (x(q)) = arg max
v∈V

d(v, f (x(k)))

(14)

where each training example v is sampled from the train-
ing set V and:

d(x(i), x(j)) =

r − xj
r)2
(xi

(15)

r=1

The results of our testing are shown in TABLE I.
Because we have signiﬁcantly more training instances
than features, we tried non-linear kernels to increase the
model complexity for higher accuracy. However, we found
the computational time of the LIBSVM software on our
dataset to be much too slow to run in real time, even
after scaling our data to a [0, 1] range. After comparing
all of our models, we found that L2-regularized Logistic
Regression in the LIBLINEAR package was the optimal
model in terms of accuracy and computational time.

B. Parameter Selection

For L2-regularized logistic regression, the only param-
eter to optimize is the value of the cost parameter C in
the formulation for the L2-regularized logistic regression
optimization problem (9). To ﬁnd the optimal value of
C, we ﬁrst performed coarse grid search by running the
algorithm using exponentially increasing values for C,
from 2−2 to 213. A portion of the resulting plot is shown
in Fig. 2. The value in this range that resulted in the lowest
cross validation error was C = 16. We then centered in on

TABLE I: Performance of different models

B. Ablative Analysis

Model

linar

linar

L2-reg LR (primal)
L2-reg, L2-loss,
kernel SVM (dual)
L2-reg, L2-loss,
kernel SVM (primal)
L2-reg, L1-loss,
kernel SVM (dual)
L1-reg, L2-loss,
kernel SVM
RBF kernel SVM
Sigmoid kernel SVM
KNN

linar

linar

Training
Accuracy
86.2472%
–

5-Fold CV
accuracy
85.7194%
–

Num It-
erations
16
max

85.9361%

85.6694%

16

–

–

max

86.2639%

85.8444%

52

100%
50%
100%

50%
50%
54.2000%

1800
180
–

this value and performed ﬁne grid search with a smaller
range, and ﬁnally deduced that C = 16 was the optimal
value.

Fig. 2: Cross-validation error for different values of C

A. Single Feature Performance

VI. RESULTS

TABLE II shows the accuracies from running L2-
regularized logistic regression on each of the feature types
individually. It includes the baseline features (univariate),
linear features (MCC), and nonlinear features (Euclidean
distance, similarity, Spearman correlation, Pearson corre-
lation). The best cross-validation accuracy achieved with
a single feature type was 78.4% (using maximum cross-
correlation). However, using a combination of feature
types increased this accuracy by about 7%, as discussed
in the next subsection.

TABLE II: Individual Feature Accuracies

Feature Type

Univariate
Euclidean distance
Max cross-correlation
MCC with time delay
Similarity coefﬁcient
Spearman correlation
Pearson correlation

Training
Accuracy
52.0222%
70.4472%
78.6972%
54.9806%
52.6000%
76.7472%
77.1833%

5-Fold CV
accuracy
51.3694%
70.1194%
78.4000%
54.2750%
52.2167%
76.4944%
76.9444%

To choose an optimal feature set, we performed ablative
analysis, starting with all features and removing them
one at a time to see how each feature impacts perfor-
mance. As shown in TABLE III, removing the Pearson
and Spearman correlation features actually increased the
cross-validation accuracy by a small amount. From there,
removing the time-delayed features decreased accuracy
by about 2.5%, removing the maximum cross-correlation
features decreased accuracy by about 13%, and removing
Euclidean distance features decreased accuracy by about
19%, leaving us with the baseline accuracy of about 51%.
Using these results, we determined that the optimal feature
subset consists of univariate, Euclidean distance, max-
imum cross-correlation, and time delay features, which
gives us an cross-validation accuracy of 85.725%.

TABLE III: Ablative analysis on feature combinations

Feature Combination

Univariate + Euclidean +
MCC + MCC w/ time delay
+ Pearson + Spearman
Univariate + Euclidean +
MCC + MCC w/ time delay
+ Pearson
Univariate + Euclidean +
MCC + MCC w/ time delay
Univariate + Euclidean +
MCC
Univariate + Euclidean
Univariate

Training
Accuracy
85.9917%

5-Fold CV
accuracy
85.4944%

86.0111%

85.6583%

85.9500%

85.7250%

83.7639%

83.2917%

70.4472%
52.0222%

70.1194%
51.3694%

C. Precision and Recall

For seizure prediction, high recall is especially impor-
tant so that seizure warnings are not missed. However,
a relatively high precision is also important
to avoid
unnecessary stress caused by false positives. By adjusting
the threshold probability at which to output a positive
prediction (Fig. 3), we determined that we acheived a
maximum F1 score of 86.68% at a threshold of 0.4502
(TABLE IV).
TABLE IV: Confusion matrix and relevant values at the
threshold probability that gives the maximum F1 score.

Actual

Preictal
Interictal

Total

Prediction

Preictal
14,094
1,243
15,337

Interictal

3,906
16,757
20,663

Total
18,000
18,000
36,000

Precision
Recall

Speciﬁcity
F1 Score

0.8110
0.9309
0.7830
0.8668

4

Predicting Seizure Onset in Epileptic Patients

Using Intracranial EEG Recordings

Janet An

Stanford University

Amy Bearman

Stanford University

Catherine Dong

Stanford University

janeta94@stanford.edu

abearman@stanford.edu

cdong@stanford.edu

Abstract—Intracranial EEG-based monitoring systems
have the potential ability to predict seizure onset, but preictal
(pre-seizure) states are difﬁcult to identify and are often
confused with normal variations in brain activity. Our goal
was to distinguish between EEG recordings covering preictal
brain activity an hour prior to a seizure, and those recording
purely interictal (non-seizure) activity. We modeled this as a
binary classiﬁcation problem, computing several linear and
nonlinear bivariate features (maximal cross-correlation and
Euclidean distance) over pairs of EEG channels. We trained
support vector machines, logistic regression, and neighbors-
based classiﬁcation to discriminate interictal from preictal
patterns of features. Among the evaluated methods, L2-
regularized logistic regression was most successful, predicting
with 85.7% accuracy and an F1 score of 86.7%.

Index Terms—Seizure prediction, logistic regression, EEG,

machine learning.

I. INTRODUCTION

About 1% of the world’s population is afﬂicted with
epilepsy. Although seizures occur infrequently (99% of a
patient’s life is spent in the interictal (non-seizure state),
the possibility of a spontaneous seizure causes constant
anxiety for patients and inhibits their ability to lead normal
lives. Sufﬁciently high doses of anticonvulsant medications
can be effective in 60-80% of patients, but because they
often come with signiﬁcant side effects, these medications
should only be administered when necessary, i.e., before
a seizure. Therefore, some method of predicting seizure
onset is needed to alert epileptic patients to administer
medication and avoid risky activities, such as swimming
or driving.

Intracranial electrocorticography (EEG) monitoring sys-
tems have the potential ability to predict seizure onset
by measuring electrical activity in the brain, as recorded
from multiple electrodes implanted directly on the surface
of the brain. However, even with this data, preictal (pre-
seizure) states are difﬁcult to identify and often confused
with normal variations in brain activity.

Because epilepsy is such a prevalent neurological dis-
order, with unexpected seizures having such dangerous
consequences, attempts to develop seizure forecasting
systems have been recorded in a number of previous
papers. One aspect of the prediction process that all of
the researchers have had to handle is selecting relevant

features from the enormous datasets of EEG recordings.
Different approaches to feature selection that have been
undertaken include choosing a small subset of the elec-
trode channels using recursive feature elimination, as well
as spectral analysis using wavelet transform to compress
EEG recordings into a small number of features. After
running their algorithms, mostly using various types of
SVMs,
the previous papers report varying degrees of
success, with accuracies ranging from just barely over
50% to around 85%. Many of these papers report that
future work to be done to improve the accuracy of these
prediction algorithms include dimensionality reduction of
the data and better feature extraction to obtain potentially
hidden information.

Our goal is to apply a variety of machine learning
classiﬁcation methods to this EEG data in order to more
accurately model the probability that a patient is in a
preictal state.

II. DATA

Annotated intracranial EEG (iEEG) data is freely avail-
able at the International Epilepsy Electrophysiology Portal.
There are iEEG data clips for both human and canine sub-
jects. The data for each subject is organized into ten minute
clips labeled ”Preictal” for pre-seizure data segments, or
”Interictal” for non-seizure data segments. Preictal training
and testing data segments are provided covering one hour
prior to seizure with a ﬁve minute seizure horizon (i.e.
1:05 to 0:05 before seizure onset). Interictal data is chosen
randomly from the full data record, with the restriction that
the interictal segments be as far away as possible from any
seizure to avoid contamination with preictal or postictal
signals. The pre-seizure horizon ensures that seizures can
be predicted with enough time for the subject to take
appropriate action (such as administer medication).

Fig. 1: EEG data over 1 hour pre-seizure window

Each data clip contains a matrix of EEG sample values
arranged row × column as electrode channel × time. In
our subject’s data set, there are 15 electrode channels and
240,000 iEEG readings sampled at 400 Hz. The recordings
span multiple months up to a year, and record 30 seizures
in our subject (up to 100 in other subjects). We used 5
hours of interictal data and 5 hours of preictal data for
training. There are 60 data clips (30 preictal, 30 interictal),
for 36,000 total examples in both the training and testing
data sets.

III. PREPROCESSING

A. Normalization

Since the range of voltage readings in the EEG dataset
vary widely, we normalized the data to avoid heavily
weighting readings that are very positive or very negative.
For each segment, we calculated the minimum voltage
reading over all 15 channels, as well as the range of the
data for that segment. We normalized each EEG reading,
x, by computing:

are computed on each channel separately. In past studies,
bivariate features have been more successful than uni-
variate ones in seizure prediction tasks. Though there is
little understanding of the preictal brain state, neuroscience
researchers hypothesize that there is correlation between
the synchronization of brain activity and seizure onset.
This synchronization hypothesis motivated our choice to
use bivariate features.

A. Maximal Cross-Correlation

Cross-correlation is a measure of similarity of two
waveforms as a function of a time-lag applied to one
of them. Cross-correlation (C) values between two pairs
(xi, xj) of EEG channels were computed at delays τ
ranging from -0.5 to 0.5 seconds in order to account for
the propagation and processing time of brainwaves. We
retained the maximal value of cross-correlation:

(cid:41)

(cid:112)Ci(0) · Cb(0)

Ca,b(τ )

x :=

x = min(x)

| max(x) − min(x)|

(1)

where

(cid:40)

N−τ(cid:80)

Ca,b = max

τ

 1

(2)

(3)

B. Independent Components Analysis

We attempted to use ICA to separate the EEG data into
maximally independent components, in order to potentially
remove noisy artifacts such as eye movement, heartbeat,
or muscle activity on the scalp. We extracted the unmixing
matrix, W , in order to recover the “sources” (i.e., the in-
dependent components, including the heartbeat waveform)
by computing s(i) = W x(i). However, we did not recover
any obvious artifacts, and running our models on the
independent sources did not give us higher performance
metrics, so we decided to use the original data. It
is
possible that ICA was not successful because the EEG
sources were not temporally independent, or that there
were non-negligible propagation delays from the sources
to the electrodes [6].

IV. FEATURE EXTRACTION FROM EEG

The challenge was to distinguish between ten minute
long data clips covering an hour prior to a seizure, and data
clips of the same length recording purely interictal (non-
seizure) activity. Predicting seizure onset can be modeled
as a binary classiﬁcation problem, where data clips are
labeled as ±1 (negative for interictal and positive for
preictal). Our goal was to construct a function that maps
from a feature vector x taken from a data segment to a
correct labeling of the segment.

As a baseline, we created a feature matrix where each
EEG channel reading was one feature. For more advanced
feature selection, we also computed bivariate features over
1 second windows that measure a relationship between
two EEG channels, rather than univariate features which

2

Ca,b(τ ) =

N−τ
Cb,a(−τ )

t=1

xa(t + τ )xb(τ )

τ ≥ 0

τ < 0

and N is the number of readings within the analysis
window (N = 400 in our case). We also retained the non-
delayed cross-correlation between the two signals.

B. Euclidean Distance

Euclidean distance measures the distance in state-space
between the trajectories of two EEG channels. First, each
channel was time delay embedded into a trajectory with a
time delay τ = 6 readings and an embedding dimension
d = 10, as seen in [3]:

x(t) = {x(t − (d − 1)τ ), . . . , x(t − τ ), x(t)}

(4)

Then, we computed the distance of each time-delay em-
bedded vector to its K nearest neighbors in state space:

n(cid:88)

t=1

1
K

1
K

1
N

K(cid:80)
K(cid:80)

k=1

k=1

(cid:107)xa(t) − xa(ta

(cid:107)xa(t) − xa(tb

2

k)(cid:107)2
k)(cid:107)2

2

(5)

where:
{ta
1, ta
{tb
1, tb

2, . . . , ta

2, . . . , tb

K} are the time indices of the K nearest
K} are the time indices of the K nearest

neighbors of xa(t), and

neighbors of xb(t).

l(cid:88)

i=1

ξi ≥ 0

γ > 0

(6)

(7)

(8)

C. Pearson Correlation

The Pearson correlation coefﬁcient measures the linear
relationship between two time series (x, y), giving a value
between +1 and -1, where 1 is total positive correlation, 0
is no correlation, and -1 is total negative correlation. The
formula for Pearson correlation coefﬁcient when applied
to a sample is:

3) L1-regularized, L2-loss Linear Kernel SVM: Solves

the following primal problem:

(cid:107)w(cid:107)1 + C

min

w

(max(0, 1 − yiwT xi))2

(11)

4) RBF Kernel Support Vector Classiﬁcation: Solves

the following optimization problem:

min
w,b,ξ

1
2

wT w + C

l(cid:88)

i=1

ξi

subject to: yi(wT φ(xi) + b) ≥ 1 − ξi

(12)

r =

1

n − 1

where

¯x =

1
n

n(cid:88)

i=1

n(cid:88)

i=1

(cid:17)

sx

(cid:16) xi − ¯x
(cid:17)(cid:16) yi − ¯y
(cid:118)(cid:117)(cid:117)(cid:116) 1
n(cid:88)

sy

n − 1

i=1

xi, and sx =

(xi − ¯x)2

using the kernel: K(xi, xj) = exp (−γ (cid:107)xi − xj(cid:107)2)

are the sample mean and sample standard deviation, re-
spectively. This expression gives the correlation coefﬁcient
as the mean of the products of the standard scores.

D. Spearman Correlation

The Spearman correlation coefﬁcient is deﬁned as the
Pearson correlation coefﬁcient between the ranked vari-
ables:

ρ = 1 − 6(cid:80) d2

i

n(n2 − 1)

where di = xi − yi is the difference between ranks.

V. MODELS

After selecting our features, we proceeded to run multi-
ple learning algorithms using our dataset in order to select
the model with the highest training accuracy and cross
validation accuracy. In this section, we present the models
we tried and how we found the optimal parameters for
these models.

A. Model Selection

We trained our data on various types of solvers in
the LIBLINEAR package, as well as with varying kernel
options in the LIBSVM package (see [1] and [4]).

1) L2-Regularized Logistic Regression: Solves the fol-

lowing unconstrained optimization problem:

min

w

1
2

wT w + C

log(1 + e−yiwT xi)

(9)

where C is the cost parameter which determines the

degree of misclassiﬁcation of the objective function.

2) L2-regularized, L2-loss Linear Kernel SVM (primal):

Solves the following primal problem:

l(cid:88)

i=1

l(cid:88)

min

w

1
2

wT w + C

(max (0, 1 − yiwT xi))2.

(10)

i=1

3

k=1

K(cid:88)
(cid:118)(cid:117)(cid:117)(cid:116) n(cid:88)

5) Sigmoid Kernel Support Vector Classiﬁcation: This
SVM solves the same optimization problem as in RBF
Kernel Support Vector Classiﬁcation, but with the kernel
function:

K(xi, xj) = tanh(γxT

i xj + r)

(13)

6) K-Nearest Neighbors Classiﬁcation: Neighbors-
based classiﬁcation labels each example, x(k), according
to:

ˆf (x(q)) = arg max
v∈V

d(v, f (x(k)))

(14)

where each training example v is sampled from the train-
ing set V and:

d(x(i), x(j)) =

r − xj
r)2
(xi

(15)

r=1

The results of our testing are shown in TABLE I.
Because we have signiﬁcantly more training instances
than features, we tried non-linear kernels to increase the
model complexity for higher accuracy. However, we found
the computational time of the LIBSVM software on our
dataset to be much too slow to run in real time, even
after scaling our data to a [0, 1] range. After comparing
all of our models, we found that L2-regularized Logistic
Regression in the LIBLINEAR package was the optimal
model in terms of accuracy and computational time.

B. Parameter Selection

For L2-regularized logistic regression, the only param-
eter to optimize is the value of the cost parameter C in
the formulation for the L2-regularized logistic regression
optimization problem (9). To ﬁnd the optimal value of
C, we ﬁrst performed coarse grid search by running the
algorithm using exponentially increasing values for C,
from 2−2 to 213. A portion of the resulting plot is shown
in Fig. 2. The value in this range that resulted in the lowest
cross validation error was C = 16. We then centered in on

TABLE I: Performance of different models

B. Ablative Analysis

Model

linar

linar

L2-reg LR (primal)
L2-reg, L2-loss,
kernel SVM (dual)
L2-reg, L2-loss,
kernel SVM (primal)
L2-reg, L1-loss,
kernel SVM (dual)
L1-reg, L2-loss,
kernel SVM
RBF kernel SVM
Sigmoid kernel SVM
KNN

linar

linar

Training
Accuracy
86.2472%
–

5-Fold CV
accuracy
85.7194%
–

Num It-
erations
16
max

85.9361%

85.6694%

16

–

–

max

86.2639%

85.8444%

52

100%
50%
100%

50%
50%
54.2000%

1800
180
–

this value and performed ﬁne grid search with a smaller
range, and ﬁnally deduced that C = 16 was the optimal
value.

Fig. 2: Cross-validation error for different values of C

A. Single Feature Performance

VI. RESULTS

TABLE II shows the accuracies from running L2-
regularized logistic regression on each of the feature types
individually. It includes the baseline features (univariate),
linear features (MCC), and nonlinear features (Euclidean
distance, similarity, Spearman correlation, Pearson corre-
lation). The best cross-validation accuracy achieved with
a single feature type was 78.4% (using maximum cross-
correlation). However, using a combination of feature
types increased this accuracy by about 7%, as discussed
in the next subsection.

TABLE II: Individual Feature Accuracies

Feature Type

Univariate
Euclidean distance
Max cross-correlation
MCC with time delay
Similarity coefﬁcient
Spearman correlation
Pearson correlation

Training
Accuracy
52.0222%
70.4472%
78.6972%
54.9806%
52.6000%
76.7472%
77.1833%

5-Fold CV
accuracy
51.3694%
70.1194%
78.4000%
54.2750%
52.2167%
76.4944%
76.9444%

To choose an optimal feature set, we performed ablative
analysis, starting with all features and removing them
one at a time to see how each feature impacts perfor-
mance. As shown in TABLE III, removing the Pearson
and Spearman correlation features actually increased the
cross-validation accuracy by a small amount. From there,
removing the time-delayed features decreased accuracy
by about 2.5%, removing the maximum cross-correlation
features decreased accuracy by about 13%, and removing
Euclidean distance features decreased accuracy by about
19%, leaving us with the baseline accuracy of about 51%.
Using these results, we determined that the optimal feature
subset consists of univariate, Euclidean distance, max-
imum cross-correlation, and time delay features, which
gives us an cross-validation accuracy of 85.725%.

TABLE III: Ablative analysis on feature combinations

Feature Combination

Univariate + Euclidean +
MCC + MCC w/ time delay
+ Pearson + Spearman
Univariate + Euclidean +
MCC + MCC w/ time delay
+ Pearson
Univariate + Euclidean +
MCC + MCC w/ time delay
Univariate + Euclidean +
MCC
Univariate + Euclidean
Univariate

Training
Accuracy
85.9917%

5-Fold CV
accuracy
85.4944%

86.0111%

85.6583%

85.9500%

85.7250%

83.7639%

83.2917%

70.4472%
52.0222%

70.1194%
51.3694%

C. Precision and Recall

For seizure prediction, high recall is especially impor-
tant so that seizure warnings are not missed. However,
a relatively high precision is also important
to avoid
unnecessary stress caused by false positives. By adjusting
the threshold probability at which to output a positive
prediction (Fig. 3), we determined that we acheived a
maximum F1 score of 86.68% at a threshold of 0.4502
(TABLE IV).
TABLE IV: Confusion matrix and relevant values at the
threshold probability that gives the maximum F1 score.

Actual

Preictal
Interictal

Total

Prediction

Preictal
14,094
1,243
15,337

Interictal

3,906
16,757
20,663

Total
18,000
18,000
36,000

Precision
Recall

Speciﬁcity
F1 Score

0.8110
0.9309
0.7830
0.8668

4

(a) Precision-recall curves

(b) ROC curves

Fig. 3: Precision-recall and ROC curves for different
feature combinations

D. Error Diagnostics

Fig. 4: Training and cross-validation error for different
feature combinations

To diagnose the bias vs. variance of our learning algo-
rithm, we plotted the training error and the test error for
different training set sizes (Fig. 4), starting with just the 15
baseline univariate features (1 feature for each electrode
channel). Because the training error and test error both
plateaued to about the same values, we conﬁrmed that
we did not have high variance, and a larger training set
would not increase accuracy. However, since the value at

5

which the error converged was higher than our desired
error, we determined that our classiﬁer was suffering
from high bias, so adding more features could help. We
then concatenated the 105 Euclidean distance features
onto the original features, and noticed that the training
and test errors decreased. Next, we concatenated on the
maximal cross-correlation features and noticed another
decrease in error. Finally, after adding on the maximal
cross-correlation with time delay features, we were able
to reach a more desirable level of accuracy.

VII. CONCLUSION

In this project we implemented a supervised binary
classiﬁer for EEG recordings. Throughout the course of
our work, we progressed from a basic feature set with
just one feature for each electrode channel, to a more
complex feature space encapsulating non-linear and linear
correlations between pairs of electrode channels. Through
this process, we were able to increase our cross validation
accuracy from just over 50% to 85.7%, corresponding to
an F1 score of 86.68%.

VIII. FUTURE WORK

We would like to try different models and feature
combinations on multiple subjects, since we did not get a
chance to experiment with more than one subject and the
International Epilepsy Electrophysiology Portal has many
more intracranial EEG datasets. We might try computing
more complicated nonlinear features, such as dynamical
entrainment or wavelet-based measures of synchrony. In
the future, we could also compute relationships on more
than two EEG channels, and eliminate pairs of channels
that do not contribute much to the ﬁnal prediction, in
order to prevent the dimension of our feature vector from
increasing linearly with the number of types of features
added.

REFERENCES

[1] C.-C. Chang and C.-J. Lin, “LIBSVM: a library for

sup-
port vector machines,” in ACM Transactions on Intelligent Sys-
tems and Technology, 2:27:1–27:27, 2011. Software available at
http://www.csie.ntu.edu.tw/ cjlin/libsvm.

[2] F. S. Bao, et al., PyEEG: An Open Source Python Module
for EEG/MEG Feature Extraction, in Computational Intelligence
and Neuroscience, vol. 2011, Article ID 406391, 7 pages, 2011.
doi:10.1155/2011/406391.

[3] P. Mirowski, et al., “Classiﬁcation of Patterns of EEG Synchro-
nization for Seizure Prediction” Electroencephalography and Clinical
Neurophysiology, 120 (11):19271940, Nov 2009.

[4] R.-E.

Fan,

et

al., LIBLINEAR: A Library

[5] A. Shoeb and J. Guttag, “Application of Machine Learning to
Epileptic Seizure Detection,” in Proceedings of the International
Conference on Machine Learning, Haifa, Israel, 2010.

[6] T. P. Jung and S. Makeig. ”Removing Artifacts from EEG.” ICA

EEG Tutorial. Web. 11 Dec. 2014.

Linear Classiﬁcation,
Research
http://www.csie.ntu.edu.tw/ cjlin/liblinear.

in
1871-1874.

9(2008),

Journal

of Machine

Software

for Large
Learning
at

available

