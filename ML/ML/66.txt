FarmX: Leaf based disease identiﬁcation in farms

CS 229 Project Report

Fall 2015

Kushal Chawda

Chanchal Hazra

{kchawda,chanchal}@stanford.edu

1.

Introduction

The delay and inaccuracy of identiﬁcation plant diseases
is causing signiﬁcant reduction in both quality and quan-
tity of agricultural products. For example, It is estimated
that total losses are amounting to approximately 12% of
the produce [1]. Since the current practice of detection
and identiﬁcation of plant diseases is mostly based on vi-
sual observation by the experts [2], Automatic detection
of plant and related diseases based on a leaf image would
be very helpful for the farming world and it will speed
up deployment of remedy quickly to reduce or eliminate
damage from the disease.

The input to our implementation is a picture of a dis-
eased leaf along with the healthy and diseased portions.
The output is the name of the disease that is aﬀect-
ing the leaf. In this project we evaluate several machine
learning techniques to (i) Identify the diseased area (We
used K-Means and Gaussian Mixture) and (ii) Identify
the disease (We used Linear SVM, Quadratic SVM, K-
Means and LDA) by classifying among four classes of
diseases.

2. Related work

We have seen a few publications where researchers are
attempting to automate methods to detect the plant dis-
eases based on images [7] [8] [9].

In [10] used texture CCM features and a Mahalanobis
distance based classiﬁer to achieve 95% accuracy. They
also used a neural network with lower accuracy numbers.
They physically photographed images themselves using
a black background.

The Leafsnap system for leaf classiﬁcation [3], used
gaussian mixtures for initial segmentation and used top-
hat transformation on top of the segmented image to re-
move the stem. They generated curvature features using
Histogram of curvature over sale and classiﬁed images
using K-Means.They used the HSV color space

ALRahamneh et al. [7] Used K-means for initial seg-
mentation and used ostu’s method for thresholding and
masking healthy images. They used mainly texture fea-
tures and got a high level of accuracy (94%). HSI color
space was used here.

In [9], Barbados et al. used intensity histograms from
each of diﬀerent color spaces (HSV, L*a*b* and CMYK)
and used modiﬁed pairwise voting system to gauge the
likelihoods of a particular disease being present in that
leaf. Only intensity information was used. They physi-

cally photographed the diseased leaves with a black back-
ground. They got accuracy ranging from 9% to 100% for
selected diseases.

In our view, using a camera independent color space
and using texture only features seemed to be good
choices to approach the problem. Also, like others we de-
cided to manually collect the data-set, however we used
public domain images from the Internet. We also decided
to compare the two methods for background separation
(k-means vs Gaussian Mixtures). Unlike others, we lim-
ited the number of texture features to just Contrast, Cor-
relation, Energy and Homogeneity.

3. The Dataset

Since the dataset for diseased leaf images were not pub-
licly available, we used a subset of images having Cre-
ative Commons Licence from the ﬂickr website of Dr.
Scott Nelson [4]. We manually downloaded images for
four categories of diseases:

• Bacterial Blight(26 images)
• Rust(36 Images)
• Corynespora Leaf Spot(43 Images)
• Mildew (26 Images)

Blight

Leaf Spot

Mildew

Rust

Fig. 1. Sample Images from our data-set

4. High Level Framework

The high level framework is outlined as follows:

• Background Removal: We wanted to extract fea-
tures from only the diseased portion of the leaf.

1

FarmX: Leaf based disease identiﬁcation in farms

CS 229 Project Report

Fall 2015

Kushal Chawda

Chanchal Hazra

{kchawda,chanchal}@stanford.edu

1.

Introduction

The delay and inaccuracy of identiﬁcation plant diseases
is causing signiﬁcant reduction in both quality and quan-
tity of agricultural products. For example, It is estimated
that total losses are amounting to approximately 12% of
the produce [1]. Since the current practice of detection
and identiﬁcation of plant diseases is mostly based on vi-
sual observation by the experts [2], Automatic detection
of plant and related diseases based on a leaf image would
be very helpful for the farming world and it will speed
up deployment of remedy quickly to reduce or eliminate
damage from the disease.

The input to our implementation is a picture of a dis-
eased leaf along with the healthy and diseased portions.
The output is the name of the disease that is aﬀect-
ing the leaf. In this project we evaluate several machine
learning techniques to (i) Identify the diseased area (We
used K-Means and Gaussian Mixture) and (ii) Identify
the disease (We used Linear SVM, Quadratic SVM, K-
Means and LDA) by classifying among four classes of
diseases.

2. Related work

We have seen a few publications where researchers are
attempting to automate methods to detect the plant dis-
eases based on images [7] [8] [9].

In [10] used texture CCM features and a Mahalanobis
distance based classiﬁer to achieve 95% accuracy. They
also used a neural network with lower accuracy numbers.
They physically photographed images themselves using
a black background.

The Leafsnap system for leaf classiﬁcation [3], used
gaussian mixtures for initial segmentation and used top-
hat transformation on top of the segmented image to re-
move the stem. They generated curvature features using
Histogram of curvature over sale and classiﬁed images
using K-Means.They used the HSV color space

ALRahamneh et al. [7] Used K-means for initial seg-
mentation and used ostu’s method for thresholding and
masking healthy images. They used mainly texture fea-
tures and got a high level of accuracy (94%). HSI color
space was used here.

In [9], Barbados et al. used intensity histograms from
each of diﬀerent color spaces (HSV, L*a*b* and CMYK)
and used modiﬁed pairwise voting system to gauge the
likelihoods of a particular disease being present in that
leaf. Only intensity information was used. They physi-

cally photographed the diseased leaves with a black back-
ground. They got accuracy ranging from 9% to 100% for
selected diseases.

In our view, using a camera independent color space
and using texture only features seemed to be good
choices to approach the problem. Also, like others we de-
cided to manually collect the data-set, however we used
public domain images from the Internet. We also decided
to compare the two methods for background separation
(k-means vs Gaussian Mixtures). Unlike others, we lim-
ited the number of texture features to just Contrast, Cor-
relation, Energy and Homogeneity.

3. The Dataset

Since the dataset for diseased leaf images were not pub-
licly available, we used a subset of images having Cre-
ative Commons Licence from the ﬂickr website of Dr.
Scott Nelson [4]. We manually downloaded images for
four categories of diseases:

• Bacterial Blight(26 images)
• Rust(36 Images)
• Corynespora Leaf Spot(43 Images)
• Mildew (26 Images)

Blight

Leaf Spot

Mildew

Rust

Fig. 1. Sample Images from our data-set

4. High Level Framework

The high level framework is outlined as follows:

• Background Removal: We wanted to extract fea-
tures from only the diseased portion of the leaf.

1

Fig. 2. Image Processing Pipeline

Hence this step removes the healthy portion of the
leaf.
• Feature Extraction: We chose only texture features
(Contrast, Correlation, Energy and Homogenity),
since we found our dataset contained diseases of
varying texture and wanted to extract only the tex-
ture features.
• Classiﬁcation and Error analysis: We consider four
models (Linear SVM, Quadratic SVM, LDA and K-
Means) for classiﬁcation and generate confusion ma-
trices and performance metrics.

5. Background Removal

A. Choosing the color space

Since our dataset had images with varying lighting condi-
tions, we wanted to choose a color space that is more re-
silient to this [5]. We chose the (Hue, Saturation, Value)
HSV color spaces since the hue value remains same for
varying lighting conditions. We also found a convenient
function in Matlab(rgb2hsv) to convert RGB to HSV,
which made it a good choice to start with. Fig. 3 shows
a comparison between RGB and HSV channels of the
input image.

is more resilient to changes in lighting conditions [5].
We chose the (Hue, Saturation, Value) HSV color spaces
since the hue value remains same for varying lighting
conditions. We used rgb2hsv function in Matlab to do
this conversion. Fig. 3 shows the various channels of a
diseased leaf, comparing RGB channels with HSV chan-
nels. In this ﬁgure it can be seen that the S and V are
dominant for the diseased part and were thus used for
segmentation.

1.

k-means vs Mixture of Gaussians

We wanted to compare k-means vs. mixture of Gaussians
for segmentation and also wanted to arrive at optimal
value of the number of segments(k). We found good vi-
sual results with k=4 for k-means and 4 Gaussians for
Gaussian mixture. The reasoning behind selecting four
was that the leaf would be segmented by (i) healthy ar-
eas, (2) diseased areas, (3)leaf stem, (4)camera reﬂection
or water).

For each of the identiﬁed segments, we created four im-
ages which masked the pixels that did not belong to the
identiﬁed segment (All three components set to zero).
The advantage of doing this was that the segmented
portions could be viewed in the RGB space for visual
inspection (without conversion). Also since the segmen-
tation did not use the Hue channel for k-means or EM, it
can now be potentially used by converting back from the
identiﬁed cluster segments in the RGB space. Results of
this process is shown in Figure 4. Here we can see that
in case of EM with four Gaussians, the diseased part in-
cludes small part of the stem and surrounding healthy
areas, while in case of k-means separation is more dis-
tinct. However, in case of k-means the area of the dis-
eased part is lower due to the hard separation. This was
actually preferred, because our feature is texture based
and we don’t want to include healthy portions of the leaf
with the diseased part.

2. Choosing the diseased segment

In order to select the segment containing the diseased im-
age, we average the hue portion of the non zeroed pixels
across each segmented image and select the image that
is farthest away from the hue value of green (0.3333 in
Matlab). While this method works on most images, this
might not work for leaves where the healthy color is not
green. In such cases we manually correct set diseased im-
age to correct segment. Since the number of such images
were limited, we were easily able to do this. This was also
an important step since we did not want to incorrectly
use healthy images to training disease classiﬁers.

Fig. 3. RGB vs HSV Color Spaces

6. Features

A. Feature Extraction

B.

Image segmentation

Since our dataset contained images having varying light-
ning conditions, we wanted to choose a color space that

We used Gray-Level Co-occurrence Matrix (GLCM)
based features on each HSV channel of the segmented
image containing diseased areas. A GLCM matrix shows
how often a pixel with the intensity (gray-level) value i

2

FarmX: Leaf based disease identiﬁcation in farms

CS 229 Project Report

Fall 2015

Kushal Chawda

Chanchal Hazra

{kchawda,chanchal}@stanford.edu

1.

Introduction

The delay and inaccuracy of identiﬁcation plant diseases
is causing signiﬁcant reduction in both quality and quan-
tity of agricultural products. For example, It is estimated
that total losses are amounting to approximately 12% of
the produce [1]. Since the current practice of detection
and identiﬁcation of plant diseases is mostly based on vi-
sual observation by the experts [2], Automatic detection
of plant and related diseases based on a leaf image would
be very helpful for the farming world and it will speed
up deployment of remedy quickly to reduce or eliminate
damage from the disease.

The input to our implementation is a picture of a dis-
eased leaf along with the healthy and diseased portions.
The output is the name of the disease that is aﬀect-
ing the leaf. In this project we evaluate several machine
learning techniques to (i) Identify the diseased area (We
used K-Means and Gaussian Mixture) and (ii) Identify
the disease (We used Linear SVM, Quadratic SVM, K-
Means and LDA) by classifying among four classes of
diseases.

2. Related work

We have seen a few publications where researchers are
attempting to automate methods to detect the plant dis-
eases based on images [7] [8] [9].

In [10] used texture CCM features and a Mahalanobis
distance based classiﬁer to achieve 95% accuracy. They
also used a neural network with lower accuracy numbers.
They physically photographed images themselves using
a black background.

The Leafsnap system for leaf classiﬁcation [3], used
gaussian mixtures for initial segmentation and used top-
hat transformation on top of the segmented image to re-
move the stem. They generated curvature features using
Histogram of curvature over sale and classiﬁed images
using K-Means.They used the HSV color space

ALRahamneh et al. [7] Used K-means for initial seg-
mentation and used ostu’s method for thresholding and
masking healthy images. They used mainly texture fea-
tures and got a high level of accuracy (94%). HSI color
space was used here.

In [9], Barbados et al. used intensity histograms from
each of diﬀerent color spaces (HSV, L*a*b* and CMYK)
and used modiﬁed pairwise voting system to gauge the
likelihoods of a particular disease being present in that
leaf. Only intensity information was used. They physi-

cally photographed the diseased leaves with a black back-
ground. They got accuracy ranging from 9% to 100% for
selected diseases.

In our view, using a camera independent color space
and using texture only features seemed to be good
choices to approach the problem. Also, like others we de-
cided to manually collect the data-set, however we used
public domain images from the Internet. We also decided
to compare the two methods for background separation
(k-means vs Gaussian Mixtures). Unlike others, we lim-
ited the number of texture features to just Contrast, Cor-
relation, Energy and Homogeneity.

3. The Dataset

Since the dataset for diseased leaf images were not pub-
licly available, we used a subset of images having Cre-
ative Commons Licence from the ﬂickr website of Dr.
Scott Nelson [4]. We manually downloaded images for
four categories of diseases:

• Bacterial Blight(26 images)
• Rust(36 Images)
• Corynespora Leaf Spot(43 Images)
• Mildew (26 Images)

Blight

Leaf Spot

Mildew

Rust

Fig. 1. Sample Images from our data-set

4. High Level Framework

The high level framework is outlined as follows:

• Background Removal: We wanted to extract fea-
tures from only the diseased portion of the leaf.

1

Fig. 2. Image Processing Pipeline

Hence this step removes the healthy portion of the
leaf.
• Feature Extraction: We chose only texture features
(Contrast, Correlation, Energy and Homogenity),
since we found our dataset contained diseases of
varying texture and wanted to extract only the tex-
ture features.
• Classiﬁcation and Error analysis: We consider four
models (Linear SVM, Quadratic SVM, LDA and K-
Means) for classiﬁcation and generate confusion ma-
trices and performance metrics.

5. Background Removal

A. Choosing the color space

Since our dataset had images with varying lighting condi-
tions, we wanted to choose a color space that is more re-
silient to this [5]. We chose the (Hue, Saturation, Value)
HSV color spaces since the hue value remains same for
varying lighting conditions. We also found a convenient
function in Matlab(rgb2hsv) to convert RGB to HSV,
which made it a good choice to start with. Fig. 3 shows
a comparison between RGB and HSV channels of the
input image.

is more resilient to changes in lighting conditions [5].
We chose the (Hue, Saturation, Value) HSV color spaces
since the hue value remains same for varying lighting
conditions. We used rgb2hsv function in Matlab to do
this conversion. Fig. 3 shows the various channels of a
diseased leaf, comparing RGB channels with HSV chan-
nels. In this ﬁgure it can be seen that the S and V are
dominant for the diseased part and were thus used for
segmentation.

1.

k-means vs Mixture of Gaussians

We wanted to compare k-means vs. mixture of Gaussians
for segmentation and also wanted to arrive at optimal
value of the number of segments(k). We found good vi-
sual results with k=4 for k-means and 4 Gaussians for
Gaussian mixture. The reasoning behind selecting four
was that the leaf would be segmented by (i) healthy ar-
eas, (2) diseased areas, (3)leaf stem, (4)camera reﬂection
or water).

For each of the identiﬁed segments, we created four im-
ages which masked the pixels that did not belong to the
identiﬁed segment (All three components set to zero).
The advantage of doing this was that the segmented
portions could be viewed in the RGB space for visual
inspection (without conversion). Also since the segmen-
tation did not use the Hue channel for k-means or EM, it
can now be potentially used by converting back from the
identiﬁed cluster segments in the RGB space. Results of
this process is shown in Figure 4. Here we can see that
in case of EM with four Gaussians, the diseased part in-
cludes small part of the stem and surrounding healthy
areas, while in case of k-means separation is more dis-
tinct. However, in case of k-means the area of the dis-
eased part is lower due to the hard separation. This was
actually preferred, because our feature is texture based
and we don’t want to include healthy portions of the leaf
with the diseased part.

2. Choosing the diseased segment

In order to select the segment containing the diseased im-
age, we average the hue portion of the non zeroed pixels
across each segmented image and select the image that
is farthest away from the hue value of green (0.3333 in
Matlab). While this method works on most images, this
might not work for leaves where the healthy color is not
green. In such cases we manually correct set diseased im-
age to correct segment. Since the number of such images
were limited, we were easily able to do this. This was also
an important step since we did not want to incorrectly
use healthy images to training disease classiﬁers.

Fig. 3. RGB vs HSV Color Spaces

6. Features

A. Feature Extraction

B.

Image segmentation

Since our dataset contained images having varying light-
ning conditions, we wanted to choose a color space that

We used Gray-Level Co-occurrence Matrix (GLCM)
based features on each HSV channel of the segmented
image containing diseased areas. A GLCM matrix shows
how often a pixel with the intensity (gray-level) value i

2

and Value channels each respectively, we wanted to se-
lect the subset of these 12 features (F1-F12) that mini-
mize the cross validation error. We tried multiple models
and found the quadratic-SVM gave us best results. As
seen from Fig. 5, We chose features [F5,F6,F9,F10,F11]
since this gave us the best results and also because it
completely eliminated the Hue channel from feature se-
lection. Eliminating the Hue channel is desirable since it
makes our features more resilient to varying color condi-
tions.

Fig. 5. Top ten feature combination using forward search

Features 5 and 9 seemed to be dominant in being able
to visually cluster the subset of our selected feature set.
As seen in Fig. 6, we are able to visually cluster the data
after making a scatter plot of F5, vs F9

Fig. 4. Segmentation using EM vs k-means (4 parts)

occurs in a speciﬁc spatial relationship to a pixel with
the value j. Features were thus deﬁned as follows:

• Contrast: Measures local variations in the gray-

level co-occurrence matrix.

|i − j|2p(i, j))

(cid:33)

(cid:33)

(cid:32)(cid:88)
(cid:32)(cid:88)

i,j

i,j

• Correlation: Measures joint probability occur-

rence.

(i − µi)(j − µj)p(i, j)

σiσj

• Energy Provides the sum of squared elements in

the GLCM.

• Homogeneity: Measures closeness of the distribu-
tion of elements in the GLCM to the GLCM diago-
nal.

(cid:32)(cid:88)

i,j

(cid:32)(cid:88)

i,j

(cid:33)

(cid:33)

p(i, j)2

p(i, j)

1 + |i − j|

We extracted these four features from each of Hue,
Saturation and Value channel, resulting in 12 featurs in
total. We wanted to ﬁrst start with these features to see
how the results were before deciding to modify them.
We used Matlab’s ’graycomatrix’ and ’graycoprops’ func-
tions to extract the features from the selected HSV seg-
mented image channels.

B. Feature Selection

Fig. 6. Scatter plot of F5 vs F9 (Contrast in S channel
vs Contrast in the V Channel

7. Models

We used SVM (Linear and Quadratic), K-Means and
LDA to train and compare classiﬁcation performance:

Given these 4 features(Contrast, Correlation, Energy
and Homogeneity in order) from the Hue, Saturation

SVM: An SVM classiﬁes data that has exactly two
classes by ﬁnding the best hyperplane that separates all

3

FarmX: Leaf based disease identiﬁcation in farms

CS 229 Project Report

Fall 2015

Kushal Chawda

Chanchal Hazra

{kchawda,chanchal}@stanford.edu

1.

Introduction

The delay and inaccuracy of identiﬁcation plant diseases
is causing signiﬁcant reduction in both quality and quan-
tity of agricultural products. For example, It is estimated
that total losses are amounting to approximately 12% of
the produce [1]. Since the current practice of detection
and identiﬁcation of plant diseases is mostly based on vi-
sual observation by the experts [2], Automatic detection
of plant and related diseases based on a leaf image would
be very helpful for the farming world and it will speed
up deployment of remedy quickly to reduce or eliminate
damage from the disease.

The input to our implementation is a picture of a dis-
eased leaf along with the healthy and diseased portions.
The output is the name of the disease that is aﬀect-
ing the leaf. In this project we evaluate several machine
learning techniques to (i) Identify the diseased area (We
used K-Means and Gaussian Mixture) and (ii) Identify
the disease (We used Linear SVM, Quadratic SVM, K-
Means and LDA) by classifying among four classes of
diseases.

2. Related work

We have seen a few publications where researchers are
attempting to automate methods to detect the plant dis-
eases based on images [7] [8] [9].

In [10] used texture CCM features and a Mahalanobis
distance based classiﬁer to achieve 95% accuracy. They
also used a neural network with lower accuracy numbers.
They physically photographed images themselves using
a black background.

The Leafsnap system for leaf classiﬁcation [3], used
gaussian mixtures for initial segmentation and used top-
hat transformation on top of the segmented image to re-
move the stem. They generated curvature features using
Histogram of curvature over sale and classiﬁed images
using K-Means.They used the HSV color space

ALRahamneh et al. [7] Used K-means for initial seg-
mentation and used ostu’s method for thresholding and
masking healthy images. They used mainly texture fea-
tures and got a high level of accuracy (94%). HSI color
space was used here.

In [9], Barbados et al. used intensity histograms from
each of diﬀerent color spaces (HSV, L*a*b* and CMYK)
and used modiﬁed pairwise voting system to gauge the
likelihoods of a particular disease being present in that
leaf. Only intensity information was used. They physi-

cally photographed the diseased leaves with a black back-
ground. They got accuracy ranging from 9% to 100% for
selected diseases.

In our view, using a camera independent color space
and using texture only features seemed to be good
choices to approach the problem. Also, like others we de-
cided to manually collect the data-set, however we used
public domain images from the Internet. We also decided
to compare the two methods for background separation
(k-means vs Gaussian Mixtures). Unlike others, we lim-
ited the number of texture features to just Contrast, Cor-
relation, Energy and Homogeneity.

3. The Dataset

Since the dataset for diseased leaf images were not pub-
licly available, we used a subset of images having Cre-
ative Commons Licence from the ﬂickr website of Dr.
Scott Nelson [4]. We manually downloaded images for
four categories of diseases:

• Bacterial Blight(26 images)
• Rust(36 Images)
• Corynespora Leaf Spot(43 Images)
• Mildew (26 Images)

Blight

Leaf Spot

Mildew

Rust

Fig. 1. Sample Images from our data-set

4. High Level Framework

The high level framework is outlined as follows:

• Background Removal: We wanted to extract fea-
tures from only the diseased portion of the leaf.

1

Fig. 2. Image Processing Pipeline

Hence this step removes the healthy portion of the
leaf.
• Feature Extraction: We chose only texture features
(Contrast, Correlation, Energy and Homogenity),
since we found our dataset contained diseases of
varying texture and wanted to extract only the tex-
ture features.
• Classiﬁcation and Error analysis: We consider four
models (Linear SVM, Quadratic SVM, LDA and K-
Means) for classiﬁcation and generate confusion ma-
trices and performance metrics.

5. Background Removal

A. Choosing the color space

Since our dataset had images with varying lighting condi-
tions, we wanted to choose a color space that is more re-
silient to this [5]. We chose the (Hue, Saturation, Value)
HSV color spaces since the hue value remains same for
varying lighting conditions. We also found a convenient
function in Matlab(rgb2hsv) to convert RGB to HSV,
which made it a good choice to start with. Fig. 3 shows
a comparison between RGB and HSV channels of the
input image.

is more resilient to changes in lighting conditions [5].
We chose the (Hue, Saturation, Value) HSV color spaces
since the hue value remains same for varying lighting
conditions. We used rgb2hsv function in Matlab to do
this conversion. Fig. 3 shows the various channels of a
diseased leaf, comparing RGB channels with HSV chan-
nels. In this ﬁgure it can be seen that the S and V are
dominant for the diseased part and were thus used for
segmentation.

1.

k-means vs Mixture of Gaussians

We wanted to compare k-means vs. mixture of Gaussians
for segmentation and also wanted to arrive at optimal
value of the number of segments(k). We found good vi-
sual results with k=4 for k-means and 4 Gaussians for
Gaussian mixture. The reasoning behind selecting four
was that the leaf would be segmented by (i) healthy ar-
eas, (2) diseased areas, (3)leaf stem, (4)camera reﬂection
or water).

For each of the identiﬁed segments, we created four im-
ages which masked the pixels that did not belong to the
identiﬁed segment (All three components set to zero).
The advantage of doing this was that the segmented
portions could be viewed in the RGB space for visual
inspection (without conversion). Also since the segmen-
tation did not use the Hue channel for k-means or EM, it
can now be potentially used by converting back from the
identiﬁed cluster segments in the RGB space. Results of
this process is shown in Figure 4. Here we can see that
in case of EM with four Gaussians, the diseased part in-
cludes small part of the stem and surrounding healthy
areas, while in case of k-means separation is more dis-
tinct. However, in case of k-means the area of the dis-
eased part is lower due to the hard separation. This was
actually preferred, because our feature is texture based
and we don’t want to include healthy portions of the leaf
with the diseased part.

2. Choosing the diseased segment

In order to select the segment containing the diseased im-
age, we average the hue portion of the non zeroed pixels
across each segmented image and select the image that
is farthest away from the hue value of green (0.3333 in
Matlab). While this method works on most images, this
might not work for leaves where the healthy color is not
green. In such cases we manually correct set diseased im-
age to correct segment. Since the number of such images
were limited, we were easily able to do this. This was also
an important step since we did not want to incorrectly
use healthy images to training disease classiﬁers.

Fig. 3. RGB vs HSV Color Spaces

6. Features

A. Feature Extraction

B.

Image segmentation

Since our dataset contained images having varying light-
ning conditions, we wanted to choose a color space that

We used Gray-Level Co-occurrence Matrix (GLCM)
based features on each HSV channel of the segmented
image containing diseased areas. A GLCM matrix shows
how often a pixel with the intensity (gray-level) value i

2

and Value channels each respectively, we wanted to se-
lect the subset of these 12 features (F1-F12) that mini-
mize the cross validation error. We tried multiple models
and found the quadratic-SVM gave us best results. As
seen from Fig. 5, We chose features [F5,F6,F9,F10,F11]
since this gave us the best results and also because it
completely eliminated the Hue channel from feature se-
lection. Eliminating the Hue channel is desirable since it
makes our features more resilient to varying color condi-
tions.

Fig. 5. Top ten feature combination using forward search

Features 5 and 9 seemed to be dominant in being able
to visually cluster the subset of our selected feature set.
As seen in Fig. 6, we are able to visually cluster the data
after making a scatter plot of F5, vs F9

Fig. 4. Segmentation using EM vs k-means (4 parts)

occurs in a speciﬁc spatial relationship to a pixel with
the value j. Features were thus deﬁned as follows:

• Contrast: Measures local variations in the gray-

level co-occurrence matrix.

|i − j|2p(i, j))

(cid:33)

(cid:33)

(cid:32)(cid:88)
(cid:32)(cid:88)

i,j

i,j

• Correlation: Measures joint probability occur-

rence.

(i − µi)(j − µj)p(i, j)

σiσj

• Energy Provides the sum of squared elements in

the GLCM.

• Homogeneity: Measures closeness of the distribu-
tion of elements in the GLCM to the GLCM diago-
nal.

(cid:32)(cid:88)

i,j

(cid:32)(cid:88)

i,j

(cid:33)

(cid:33)

p(i, j)2

p(i, j)

1 + |i − j|

We extracted these four features from each of Hue,
Saturation and Value channel, resulting in 12 featurs in
total. We wanted to ﬁrst start with these features to see
how the results were before deciding to modify them.
We used Matlab’s ’graycomatrix’ and ’graycoprops’ func-
tions to extract the features from the selected HSV seg-
mented image channels.

B. Feature Selection

Fig. 6. Scatter plot of F5 vs F9 (Contrast in S channel
vs Contrast in the V Channel

7. Models

We used SVM (Linear and Quadratic), K-Means and
LDA to train and compare classiﬁcation performance:

Given these 4 features(Contrast, Correlation, Energy
and Homogeneity in order) from the Hue, Saturation

SVM: An SVM classiﬁes data that has exactly two
classes by ﬁnding the best hyperplane that separates all

3

points of one class from the other class. The best margin
hyperplane that maximizes the margin between the two
classes is given by the following optimization problem:

minγ,w,b

||w||2 + C

1
2

i

m(cid:88)

i=1

s.t. y(i)(wT x(i) + h) ≥ 1 − i, i = 1, ..., m

i ≥ 0, i = 1, ..., m

For SVM, we used an L1 soft margin classiﬁer with

C=1.

In order to achieve multi-class classiﬁcation, we use
the One-vs-One approach which constructs one classi-
ﬁer per pair of classes. During prediction, the class which
received the most votes is selected. In the event of a tie
the class with the highest aggregate classiﬁcation conﬁ-
dence is selected. This method thus builds N (N − 1)/2
classiﬁers, where N is the number of classes.

We compared results across two kernel functions:

• Linear Kernel: The linear kernel has the form:

K(xi, xi) =

xijx(cid:48)

ij

p(cid:88)

j=1

p(cid:88)

• Quadratic Kernel: Is a polynomial kernel and has

a much more ﬂexible decision boundary:

K(xi, xi) = (1 +

xijx(cid:48)

ij)2

We also wanted to use discriminative models:

j=1

(cid:88)

• LDA: We used mixtures of Gaussians with a diag-
onal covariance matrix to model the parameters of
a Gaussian for each class. The prediction tries to
minimize the classiﬁcation cost given by:

y = argminy=1...K

KP (k|x)C(y|k)

k=1

Where, y is the predicted classiﬁcation, K is the
number of classes, P (k|x) is the posterior probabil-
ity of class k for observation x and C(y|k)
• k-means:We use K-means as a classiﬁcation and
also as a segmentation algorithm. For segmentation,
the points are labelled belonging to k=4 clusters,
and for classiﬁcation the point is classiﬁed based on
the closest cluster centroid.

8. Results

We used several classiﬁcation models with 5-fold cross
validation to compare learning algorithms:

We used Matlab to compare results across: k-means,
Linear Discriminative Analysis, Linear SVM and
Quadratic SVM. The optimized feature selection gave
us a 2% improvement over the previous set of results

4

Fig. 7. Overview of results comparing background seg-
mentation methods (EM and k-means) along with the
performance for various learning algorithms

(with all 12 features). All the models were trained
and compared with the optimized feature selection
[F5,F6,F9,F10,F11].

Fig. 7 shows us the overall accuracy numbers. We see
accuracy of 93.1% on Quadratic SVM with K=4 back-
ground removal. This makes sense for a texture based
feature set because we need the hard separation. Confu-
sion Matrices are shown in Fig 8 and 10. We see in case of
the Linear SVM the maximum miss-classiﬁcation seems
to be between Blight and Leaf Spot, which also makes
sense because they are visually similar as seen in Fig. 1
We see that LDA does not perform as well as other
models. In case of Gaussian mixture based segmenta-
tion, We see that the texture based classiﬁcation seems
sensitive to ”noise” in the texture based features. We
were able to visually conﬁrm (As seen in Fig.4) that
diseased portion of the images segmented using GM in-
cluded healthy areas as well.

9. Conclusion/Future Work

For the best performing model (Quadratic SVM with K-
means background separation with K=4), chosen with
optimized feature set, we see our accuracy is 93.1%. The
Precision, Recall and F1 scores for each classiﬁer are
shown in Fig. 9 are within 85% to 100%.

Since we have fairly high accuracy, our next step would
be to focus on recommendations to treat the disease. In
order to do this better, we would have to identify the
species and build a dataset having recommendations.

As seen from the EM case, our model is sensitive to
inaccuracies in background removal, we would thus focus
on making it robust to be able better select the diseased
cluster and ensuring the diseased cluster does not have
healthy areas. Given more time, we could train a classi-
ﬁer to just recognize diseased segments of the image to
make the background separation more robust.

FarmX: Leaf based disease identiﬁcation in farms

CS 229 Project Report

Fall 2015

Kushal Chawda

Chanchal Hazra

{kchawda,chanchal}@stanford.edu

1.

Introduction

The delay and inaccuracy of identiﬁcation plant diseases
is causing signiﬁcant reduction in both quality and quan-
tity of agricultural products. For example, It is estimated
that total losses are amounting to approximately 12% of
the produce [1]. Since the current practice of detection
and identiﬁcation of plant diseases is mostly based on vi-
sual observation by the experts [2], Automatic detection
of plant and related diseases based on a leaf image would
be very helpful for the farming world and it will speed
up deployment of remedy quickly to reduce or eliminate
damage from the disease.

The input to our implementation is a picture of a dis-
eased leaf along with the healthy and diseased portions.
The output is the name of the disease that is aﬀect-
ing the leaf. In this project we evaluate several machine
learning techniques to (i) Identify the diseased area (We
used K-Means and Gaussian Mixture) and (ii) Identify
the disease (We used Linear SVM, Quadratic SVM, K-
Means and LDA) by classifying among four classes of
diseases.

2. Related work

We have seen a few publications where researchers are
attempting to automate methods to detect the plant dis-
eases based on images [7] [8] [9].

In [10] used texture CCM features and a Mahalanobis
distance based classiﬁer to achieve 95% accuracy. They
also used a neural network with lower accuracy numbers.
They physically photographed images themselves using
a black background.

The Leafsnap system for leaf classiﬁcation [3], used
gaussian mixtures for initial segmentation and used top-
hat transformation on top of the segmented image to re-
move the stem. They generated curvature features using
Histogram of curvature over sale and classiﬁed images
using K-Means.They used the HSV color space

ALRahamneh et al. [7] Used K-means for initial seg-
mentation and used ostu’s method for thresholding and
masking healthy images. They used mainly texture fea-
tures and got a high level of accuracy (94%). HSI color
space was used here.

In [9], Barbados et al. used intensity histograms from
each of diﬀerent color spaces (HSV, L*a*b* and CMYK)
and used modiﬁed pairwise voting system to gauge the
likelihoods of a particular disease being present in that
leaf. Only intensity information was used. They physi-

cally photographed the diseased leaves with a black back-
ground. They got accuracy ranging from 9% to 100% for
selected diseases.

In our view, using a camera independent color space
and using texture only features seemed to be good
choices to approach the problem. Also, like others we de-
cided to manually collect the data-set, however we used
public domain images from the Internet. We also decided
to compare the two methods for background separation
(k-means vs Gaussian Mixtures). Unlike others, we lim-
ited the number of texture features to just Contrast, Cor-
relation, Energy and Homogeneity.

3. The Dataset

Since the dataset for diseased leaf images were not pub-
licly available, we used a subset of images having Cre-
ative Commons Licence from the ﬂickr website of Dr.
Scott Nelson [4]. We manually downloaded images for
four categories of diseases:

• Bacterial Blight(26 images)
• Rust(36 Images)
• Corynespora Leaf Spot(43 Images)
• Mildew (26 Images)

Blight

Leaf Spot

Mildew

Rust

Fig. 1. Sample Images from our data-set

4. High Level Framework

The high level framework is outlined as follows:

• Background Removal: We wanted to extract fea-
tures from only the diseased portion of the leaf.

1

Fig. 2. Image Processing Pipeline

Hence this step removes the healthy portion of the
leaf.
• Feature Extraction: We chose only texture features
(Contrast, Correlation, Energy and Homogenity),
since we found our dataset contained diseases of
varying texture and wanted to extract only the tex-
ture features.
• Classiﬁcation and Error analysis: We consider four
models (Linear SVM, Quadratic SVM, LDA and K-
Means) for classiﬁcation and generate confusion ma-
trices and performance metrics.

5. Background Removal

A. Choosing the color space

Since our dataset had images with varying lighting condi-
tions, we wanted to choose a color space that is more re-
silient to this [5]. We chose the (Hue, Saturation, Value)
HSV color spaces since the hue value remains same for
varying lighting conditions. We also found a convenient
function in Matlab(rgb2hsv) to convert RGB to HSV,
which made it a good choice to start with. Fig. 3 shows
a comparison between RGB and HSV channels of the
input image.

is more resilient to changes in lighting conditions [5].
We chose the (Hue, Saturation, Value) HSV color spaces
since the hue value remains same for varying lighting
conditions. We used rgb2hsv function in Matlab to do
this conversion. Fig. 3 shows the various channels of a
diseased leaf, comparing RGB channels with HSV chan-
nels. In this ﬁgure it can be seen that the S and V are
dominant for the diseased part and were thus used for
segmentation.

1.

k-means vs Mixture of Gaussians

We wanted to compare k-means vs. mixture of Gaussians
for segmentation and also wanted to arrive at optimal
value of the number of segments(k). We found good vi-
sual results with k=4 for k-means and 4 Gaussians for
Gaussian mixture. The reasoning behind selecting four
was that the leaf would be segmented by (i) healthy ar-
eas, (2) diseased areas, (3)leaf stem, (4)camera reﬂection
or water).

For each of the identiﬁed segments, we created four im-
ages which masked the pixels that did not belong to the
identiﬁed segment (All three components set to zero).
The advantage of doing this was that the segmented
portions could be viewed in the RGB space for visual
inspection (without conversion). Also since the segmen-
tation did not use the Hue channel for k-means or EM, it
can now be potentially used by converting back from the
identiﬁed cluster segments in the RGB space. Results of
this process is shown in Figure 4. Here we can see that
in case of EM with four Gaussians, the diseased part in-
cludes small part of the stem and surrounding healthy
areas, while in case of k-means separation is more dis-
tinct. However, in case of k-means the area of the dis-
eased part is lower due to the hard separation. This was
actually preferred, because our feature is texture based
and we don’t want to include healthy portions of the leaf
with the diseased part.

2. Choosing the diseased segment

In order to select the segment containing the diseased im-
age, we average the hue portion of the non zeroed pixels
across each segmented image and select the image that
is farthest away from the hue value of green (0.3333 in
Matlab). While this method works on most images, this
might not work for leaves where the healthy color is not
green. In such cases we manually correct set diseased im-
age to correct segment. Since the number of such images
were limited, we were easily able to do this. This was also
an important step since we did not want to incorrectly
use healthy images to training disease classiﬁers.

Fig. 3. RGB vs HSV Color Spaces

6. Features

A. Feature Extraction

B.

Image segmentation

Since our dataset contained images having varying light-
ning conditions, we wanted to choose a color space that

We used Gray-Level Co-occurrence Matrix (GLCM)
based features on each HSV channel of the segmented
image containing diseased areas. A GLCM matrix shows
how often a pixel with the intensity (gray-level) value i

2

and Value channels each respectively, we wanted to se-
lect the subset of these 12 features (F1-F12) that mini-
mize the cross validation error. We tried multiple models
and found the quadratic-SVM gave us best results. As
seen from Fig. 5, We chose features [F5,F6,F9,F10,F11]
since this gave us the best results and also because it
completely eliminated the Hue channel from feature se-
lection. Eliminating the Hue channel is desirable since it
makes our features more resilient to varying color condi-
tions.

Fig. 5. Top ten feature combination using forward search

Features 5 and 9 seemed to be dominant in being able
to visually cluster the subset of our selected feature set.
As seen in Fig. 6, we are able to visually cluster the data
after making a scatter plot of F5, vs F9

Fig. 4. Segmentation using EM vs k-means (4 parts)

occurs in a speciﬁc spatial relationship to a pixel with
the value j. Features were thus deﬁned as follows:

• Contrast: Measures local variations in the gray-

level co-occurrence matrix.

|i − j|2p(i, j))

(cid:33)

(cid:33)

(cid:32)(cid:88)
(cid:32)(cid:88)

i,j

i,j

• Correlation: Measures joint probability occur-

rence.

(i − µi)(j − µj)p(i, j)

σiσj

• Energy Provides the sum of squared elements in

the GLCM.

• Homogeneity: Measures closeness of the distribu-
tion of elements in the GLCM to the GLCM diago-
nal.

(cid:32)(cid:88)

i,j

(cid:32)(cid:88)

i,j

(cid:33)

(cid:33)

p(i, j)2

p(i, j)

1 + |i − j|

We extracted these four features from each of Hue,
Saturation and Value channel, resulting in 12 featurs in
total. We wanted to ﬁrst start with these features to see
how the results were before deciding to modify them.
We used Matlab’s ’graycomatrix’ and ’graycoprops’ func-
tions to extract the features from the selected HSV seg-
mented image channels.

B. Feature Selection

Fig. 6. Scatter plot of F5 vs F9 (Contrast in S channel
vs Contrast in the V Channel

7. Models

We used SVM (Linear and Quadratic), K-Means and
LDA to train and compare classiﬁcation performance:

Given these 4 features(Contrast, Correlation, Energy
and Homogeneity in order) from the Hue, Saturation

SVM: An SVM classiﬁes data that has exactly two
classes by ﬁnding the best hyperplane that separates all

3

points of one class from the other class. The best margin
hyperplane that maximizes the margin between the two
classes is given by the following optimization problem:

minγ,w,b

||w||2 + C

1
2

i

m(cid:88)

i=1

s.t. y(i)(wT x(i) + h) ≥ 1 − i, i = 1, ..., m

i ≥ 0, i = 1, ..., m

For SVM, we used an L1 soft margin classiﬁer with

C=1.

In order to achieve multi-class classiﬁcation, we use
the One-vs-One approach which constructs one classi-
ﬁer per pair of classes. During prediction, the class which
received the most votes is selected. In the event of a tie
the class with the highest aggregate classiﬁcation conﬁ-
dence is selected. This method thus builds N (N − 1)/2
classiﬁers, where N is the number of classes.

We compared results across two kernel functions:

• Linear Kernel: The linear kernel has the form:

K(xi, xi) =

xijx(cid:48)

ij

p(cid:88)

j=1

p(cid:88)

• Quadratic Kernel: Is a polynomial kernel and has

a much more ﬂexible decision boundary:

K(xi, xi) = (1 +

xijx(cid:48)

ij)2

We also wanted to use discriminative models:

j=1

(cid:88)

• LDA: We used mixtures of Gaussians with a diag-
onal covariance matrix to model the parameters of
a Gaussian for each class. The prediction tries to
minimize the classiﬁcation cost given by:

y = argminy=1...K

KP (k|x)C(y|k)

k=1

Where, y is the predicted classiﬁcation, K is the
number of classes, P (k|x) is the posterior probabil-
ity of class k for observation x and C(y|k)
• k-means:We use K-means as a classiﬁcation and
also as a segmentation algorithm. For segmentation,
the points are labelled belonging to k=4 clusters,
and for classiﬁcation the point is classiﬁed based on
the closest cluster centroid.

8. Results

We used several classiﬁcation models with 5-fold cross
validation to compare learning algorithms:

We used Matlab to compare results across: k-means,
Linear Discriminative Analysis, Linear SVM and
Quadratic SVM. The optimized feature selection gave
us a 2% improvement over the previous set of results

4

Fig. 7. Overview of results comparing background seg-
mentation methods (EM and k-means) along with the
performance for various learning algorithms

(with all 12 features). All the models were trained
and compared with the optimized feature selection
[F5,F6,F9,F10,F11].

Fig. 7 shows us the overall accuracy numbers. We see
accuracy of 93.1% on Quadratic SVM with K=4 back-
ground removal. This makes sense for a texture based
feature set because we need the hard separation. Confu-
sion Matrices are shown in Fig 8 and 10. We see in case of
the Linear SVM the maximum miss-classiﬁcation seems
to be between Blight and Leaf Spot, which also makes
sense because they are visually similar as seen in Fig. 1
We see that LDA does not perform as well as other
models. In case of Gaussian mixture based segmenta-
tion, We see that the texture based classiﬁcation seems
sensitive to ”noise” in the texture based features. We
were able to visually conﬁrm (As seen in Fig.4) that
diseased portion of the images segmented using GM in-
cluded healthy areas as well.

9. Conclusion/Future Work

For the best performing model (Quadratic SVM with K-
means background separation with K=4), chosen with
optimized feature set, we see our accuracy is 93.1%. The
Precision, Recall and F1 scores for each classiﬁer are
shown in Fig. 9 are within 85% to 100%.

Since we have fairly high accuracy, our next step would
be to focus on recommendations to treat the disease. In
order to do this better, we would have to identify the
species and build a dataset having recommendations.

As seen from the EM case, our model is sensitive to
inaccuracies in background removal, we would thus focus
on making it robust to be able better select the diseased
cluster and ensuring the diseased cluster does not have
healthy areas. Given more time, we could train a classi-
ﬁer to just recognize diseased segments of the image to
make the background separation more robust.

Fig. 8. Confusion Matrix with k-means B/G separation
for (1: Leaf Spot), (2: Blight), (3: Mildew) and (4: Rust)

Fig. 10. Confusion Matrix with Gaussian Mixture B/G
separation for (1: Leaf Spot), (2: Blight), (3: Mildew)
and (4: Rust)

102-6 2013

2. Sastry, K. Subramanya, A. Zitter, Thomas. ”Manage-
ment of Virus and Viroid Diseases of Crops in the Trop-
ics” Springer (2014).

3. Neeraj Kumar and Peter N. Belhumeur and Arijit
Biswas and David W. Jacobs and W. John Kress and
Ida Lopez and Joo V. B. Soares ”Leafsnap: A Computer
Vision System for Automatic Plant Species Identiﬁca-
tion,” http://leafsnap.com/dataset/ (2012).

4. https://www.ﬂickr.com/photos/scotnelson .
5. HSV Color Space:

https://en.wikipedia.org/wiki/HSL and HSV.

6. Forcyth, Ponce. ”Computer Vision, a modern approach”

ISBN:0130851981 (2002)

7. H. Al-Hiary, S. Bani-Ahmad, M. Reyalat, M. Braik
and Z. ALRahamneh ”Fast and Accurate Detection and
Classiﬁcation of Plant Diseases” International Journal
of Computer Applications (0975 8887) Volume 17 No.1,
March 2011

8. Shi Yun1, Wang Xianfeng1, Zhang Shanwen1, Zhang
Chuanlei ”PNN based crop disease recognition with leaf
image features and meteorological data” Int J Agric Biol
Eng, Aug 2015

9. Jayme Garcia Arnal Barbedo1, Cludia Vieira Godoy
”Automatic Classiﬁcation of Soybean Diseases Based on
Digital Images of Leaf Symptoms ” SBI AGRO (Oct
2015)

10. Pydipati, R., T. F. Burks, and W. S. Lee. ”Statistical
and neural network classiﬁers for citrus disease detection
using machine vision.” TRANSACTIONS-AMERICAN
SOCIETY OF AGRICULTURAL ENGINEERS 48.5
(2005): 2007.

Fig. 9. Performance Results with k-means B/G separa-
tion for (1: Leaf Spot), (2: Blight), (3: Mildew) and (4:
Rust)

References

1. Martinez-Espinoza Alfredo, et al. ”GEORGIA PLANT
DISEASE LOSS ESTIMATES” UGA Extension AP

5

