Direct Data-Driven Methods for Decision Making under Uncertainty

Junjie Qin
Institute for Computational and Mathematical Engineering, Stanford, CA 94305 USA

JQIN@STANFORD.EDU

1. Introduction
We are constantly making decisions under uncertainty. A
widely used formulation for decision making under uncer-
tainty can be summarized by the following optimization
program

EP[f (u, X)],

u∈U

u(cid:63) = argmin

(1)
where the future cost f depends both on the decision u ∈ U
as well as the outcome of uncertain events, represented by
a random variable X ∈ X . Here the random variable X
follows a distribution P which is assumed to be known in
order to form the expectation in problem (1). Examples
includes making an inventory decision with uncertainty fu-
ture demand, purchasing stocks with uncertain information
about the future price, and deciding which PhD programs
to choose to go with uncertainty in research directions, ad-
visors and funding opportunities.
In practice, the distribution P is never readily available. In-
stead, practitioners often resort to the following two step
procedure:

Data
(Sn)

learning
−−−−−−→
methods

Model
uncertainty

of

(P)

stochastic
−−−−−−−−−→
optimization

Decision
(u(cid:63))

that is, given a historical data set Sn, one would ﬁrst apply
certain machine learning algorithms to obtain representa-
tions of the data, usually in the form of point prediction or
parameters for the distribution P, and then use these repre-
sentations to form the stochastic optimization program (1)
which in turn would lead to an “optimal” decision. This
procedure has many known issues. First of all, off-the-
shelf learning algorithms are derived using loss functions
that are mathematically convenient, but may have nothing
to do with the actual economic costs regarding the decision
that one is making. For instance, commonly used linear re-
gression algorithm assumes a quadratic error loss, whereas
the actual cost function may be a different function such
as a piecewise linear function in the inventory control ex-
ample. As such, the learning step in the above procedure
is sub-optimal with respect to the true economic cost. Fur-
thermore, as the stochastic optimization step sees the model
of uncertainty which is a summary of the data instead of the

data itself, it may make assumptions inconsistent with as-
sumptions made in the learning step. An example would be
using Gaussian error assumption in the stochastic optimiza-
tion step whereas a (cid:96)1-type regularization was used in the
learning step (which implies the assumption that the error
follows the Laplace distribution). Last but not the least, as
different assumptions and approximations may be used in
each step of the two-step procedure, it is usually very hard
to theoretically gauge the performance of this two-step pro-
cedure.
An attractive proposal is to integrate these two steps. A
couple of existing papers have explored this idea within
particular application domains. Liyanage & Shanthiku-
mar (2005) proposed the concept of operational statistics
that drives the optimal estimator for the newsvendor or-
dering target under uncertainty. Their methods assume the
functional form of the distribution for the uncertainty (e.g.
the net demand follows an exponential distribution) and
equivalence-type argument to reduce the hypothesis class
of all possible estimators. Kao et al. (2009) considers the
setting that the results of a regression are used for solving
decision problems whose cost function is an arbitrary con-
vex quadratic function.
It is shown in the paper that by
using a convex combination of the results produced by or-
dinary least squares and empirical minimization, the actual
cost generated by their algorithm is signiﬁcantly lower than
directly using the results of ordinary least squares. A few
important question still remains open. (i) What is a suit-
able general formulation for deriving methods that directly
identify the optimal decision from the data? (ii) Are there
algorithms that have provably guaranteed performances un-
der this general formulation?
This paper makes progresses in addressing these questions.
In particular, we adopt and modify the framework of statis-
tical decision theory, which is the root of all modern learn-
ing algorithms, to incorporate the actual economic costs in
Section 2. This leads to a risk minimization problem which
again depends on the unknown underlying data generating
distribution. We show that empirical risk minimization can
lead to a class of efﬁcient algorithms whose performance
can be theoretically analyzed. Section 3 then applies these
general consideration to a speciﬁc problem on dispatching

Direct Data-Driven Methods for Decision Making under Uncertainty

Junjie Qin
Institute for Computational and Mathematical Engineering, Stanford, CA 94305 USA

JQIN@STANFORD.EDU

1. Introduction
We are constantly making decisions under uncertainty. A
widely used formulation for decision making under uncer-
tainty can be summarized by the following optimization
program

EP[f (u, X)],

u∈U

u(cid:63) = argmin

(1)
where the future cost f depends both on the decision u ∈ U
as well as the outcome of uncertain events, represented by
a random variable X ∈ X . Here the random variable X
follows a distribution P which is assumed to be known in
order to form the expectation in problem (1). Examples
includes making an inventory decision with uncertainty fu-
ture demand, purchasing stocks with uncertain information
about the future price, and deciding which PhD programs
to choose to go with uncertainty in research directions, ad-
visors and funding opportunities.
In practice, the distribution P is never readily available. In-
stead, practitioners often resort to the following two step
procedure:

Data
(Sn)

learning
−−−−−−→
methods

Model
uncertainty

of

(P)

stochastic
−−−−−−−−−→
optimization

Decision
(u(cid:63))

that is, given a historical data set Sn, one would ﬁrst apply
certain machine learning algorithms to obtain representa-
tions of the data, usually in the form of point prediction or
parameters for the distribution P, and then use these repre-
sentations to form the stochastic optimization program (1)
which in turn would lead to an “optimal” decision. This
procedure has many known issues. First of all, off-the-
shelf learning algorithms are derived using loss functions
that are mathematically convenient, but may have nothing
to do with the actual economic costs regarding the decision
that one is making. For instance, commonly used linear re-
gression algorithm assumes a quadratic error loss, whereas
the actual cost function may be a different function such
as a piecewise linear function in the inventory control ex-
ample. As such, the learning step in the above procedure
is sub-optimal with respect to the true economic cost. Fur-
thermore, as the stochastic optimization step sees the model
of uncertainty which is a summary of the data instead of the

data itself, it may make assumptions inconsistent with as-
sumptions made in the learning step. An example would be
using Gaussian error assumption in the stochastic optimiza-
tion step whereas a (cid:96)1-type regularization was used in the
learning step (which implies the assumption that the error
follows the Laplace distribution). Last but not the least, as
different assumptions and approximations may be used in
each step of the two-step procedure, it is usually very hard
to theoretically gauge the performance of this two-step pro-
cedure.
An attractive proposal is to integrate these two steps. A
couple of existing papers have explored this idea within
particular application domains. Liyanage & Shanthiku-
mar (2005) proposed the concept of operational statistics
that drives the optimal estimator for the newsvendor or-
dering target under uncertainty. Their methods assume the
functional form of the distribution for the uncertainty (e.g.
the net demand follows an exponential distribution) and
equivalence-type argument to reduce the hypothesis class
of all possible estimators. Kao et al. (2009) considers the
setting that the results of a regression are used for solving
decision problems whose cost function is an arbitrary con-
vex quadratic function.
It is shown in the paper that by
using a convex combination of the results produced by or-
dinary least squares and empirical minimization, the actual
cost generated by their algorithm is signiﬁcantly lower than
directly using the results of ordinary least squares. A few
important question still remains open. (i) What is a suit-
able general formulation for deriving methods that directly
identify the optimal decision from the data? (ii) Are there
algorithms that have provably guaranteed performances un-
der this general formulation?
This paper makes progresses in addressing these questions.
In particular, we adopt and modify the framework of statis-
tical decision theory, which is the root of all modern learn-
ing algorithms, to incorporate the actual economic costs in
Section 2. This leads to a risk minimization problem which
again depends on the unknown underlying data generating
distribution. We show that empirical risk minimization can
lead to a class of efﬁcient algorithms whose performance
can be theoretically analyzed. Section 3 then applies these
general consideration to a speciﬁc problem on dispatching

energy generators to meet uncertain demand in the context
of renewable integration. We then propose algorithm that
follows empirical risk minimization paradigm as well as
variations of it. Theoretical guarantees are then derived fol-
lowed by empirical test results with data from BPA.

2. Formulation
Given a family of distributions P = {Pθ : θ ∈ Ω}, and
iid∼ Pθ, the goal of statistical decision
samples X1, . . . , Xn
theory is to identify a good procedure δ that maps the data
X = (X1, . . . , Xn) to a decision d ∈ D that has small risk.
The notion of risk is deﬁned as the expected value of a loss
function L(θ, d), i.e.,

R(θ, δ) = EPθ [L(θ, δ(X))],

where the loss function L(θ, d) assigns preference to de-
cisions given the value of the model parameter θ and d =
δ(X). This theory is usually used for the purpose of esti-
mating the parameter θ itself of some known function of θ
and so the resulting procedure δ is often called an estimator.
To cast our problem into the framework of decision theory,
we use the following speciﬁcation or modiﬁcation

• We make no assumption on the form of the distribu-
tion Pθ. That is, instead of say assuming the uncer-
tainty follows a normal distribution and then estimat-
ing its mean and variance, we allow arbitrary type of
distribution in the family P.1 In a sense, this forms a
nonparametric estimation problem in the classical ter-
minology. As such, we drop the index θ and use P
itself to refer to an arbitrary member of the family of
the unknown distribution P.

• We set the loss function to be the true economic cost

of the problem, that is

L(Xn+1, d) = f (d, Xn+1),

where Xn+1 ∼ P denotes the unobserved uncertainty
in when we are making the decision (i.e. X in (1)).
Notice that this modiﬁes the conventional loss func-
tion which is a deterministic function of the unknown
parameter θ and decision d to a function that depends
on the random realization of Xn+1. The resulting risk
function is

EPf (u, Xn+1),

where we modiﬁed the notation from estimator δ to
decision u.

1We would still have to make implicit technical assumptions

such as the mean of the loss function exists.

(1/n)(cid:80)n

instead,

The remaining problem is to design procedures that maps
the data to a good decision u that minimizes the risk. The
challenge is that since P is unknown, it is in general im-
possible to ﬁnd procedures that are uniformly optimal with
respect to all possible members P ∈ P. Thus the bulk of
the classical decision theory concerns about alternative no-
tations of optimality, which leads to uniformly minimal risk
unbiased estimators, uniformly minimal risk equivariant
estimators, optimal Bayes estimators, and minimax estima-
tors (cf. Lehmann & Casella (1998) for a good treatment of
this subject). However, none of the above optimality crite-
ria permits universal procedures to derive algorithms which
could identify the optimal decision. That is, calculation has
to be done based on the particularly assumed distribution,
and for different distributions the methods and results vary
signiﬁcantly.
We propose,

to minimize the empirical risk
i=1 f (u, Xi) within a pre-determined hypothesis2
class that contains functional forms for u. This would cer-
tainly generate efﬁcient algorithms if for examples the cost
function is convex and the hypothesis class is linear.
In
more complex situations, non-convex optimization proce-
dures may be deployed to identify the optimal hypothe-
sis in the hypothesis class. We will show by an applica-
tion in the next section that it is possible to prove theo-
retical performance guarantees for the resulting procedures
which suggests that the sub-optimality with respect to the
true risk R (which is deﬁned using the unknown distribu-
tion P) is bounded with large probability and the bound
approaches to zero with the number of samples increases
to inﬁnity. The application consists of a speciﬁc choice of
the cost function for a practical situation, and the hypothe-
sis class. But both the proposed algorithms and the perfor-
mance analysis could be generalized to other cost functions
and hypothesis classes.

3. Application: Electric Power Dispatch for

Renewable Integration

The rest of this paper concerns with an application that is
of an increasing importance both in the United States and
around the globe. As global warming becomes a growing
consensus, many countries around the world are pushing
deeper renewable penetration into their energy generation
portfolio and their electric power grids. This results in sig-
niﬁcant challenges in the operation of the grids as renew-
ables are intrinsically variable, i.e., they are intermittent,
uncontrollable and random. Figure 1 (a) depicts the wind
power generation in a BPA region over 20 days, and Fig-
ure 1 (b) gives common percentage forecast errors for the

2This use of the term of hypothesis follows leaning theory
instead of the literature of hypothesis testing, although they are
closely related.

Direct Data-Driven Methods for Decision Making under Uncertainty

Junjie Qin
Institute for Computational and Mathematical Engineering, Stanford, CA 94305 USA

JQIN@STANFORD.EDU

1. Introduction
We are constantly making decisions under uncertainty. A
widely used formulation for decision making under uncer-
tainty can be summarized by the following optimization
program

EP[f (u, X)],

u∈U

u(cid:63) = argmin

(1)
where the future cost f depends both on the decision u ∈ U
as well as the outcome of uncertain events, represented by
a random variable X ∈ X . Here the random variable X
follows a distribution P which is assumed to be known in
order to form the expectation in problem (1). Examples
includes making an inventory decision with uncertainty fu-
ture demand, purchasing stocks with uncertain information
about the future price, and deciding which PhD programs
to choose to go with uncertainty in research directions, ad-
visors and funding opportunities.
In practice, the distribution P is never readily available. In-
stead, practitioners often resort to the following two step
procedure:

Data
(Sn)

learning
−−−−−−→
methods

Model
uncertainty

of

(P)

stochastic
−−−−−−−−−→
optimization

Decision
(u(cid:63))

that is, given a historical data set Sn, one would ﬁrst apply
certain machine learning algorithms to obtain representa-
tions of the data, usually in the form of point prediction or
parameters for the distribution P, and then use these repre-
sentations to form the stochastic optimization program (1)
which in turn would lead to an “optimal” decision. This
procedure has many known issues. First of all, off-the-
shelf learning algorithms are derived using loss functions
that are mathematically convenient, but may have nothing
to do with the actual economic costs regarding the decision
that one is making. For instance, commonly used linear re-
gression algorithm assumes a quadratic error loss, whereas
the actual cost function may be a different function such
as a piecewise linear function in the inventory control ex-
ample. As such, the learning step in the above procedure
is sub-optimal with respect to the true economic cost. Fur-
thermore, as the stochastic optimization step sees the model
of uncertainty which is a summary of the data instead of the

data itself, it may make assumptions inconsistent with as-
sumptions made in the learning step. An example would be
using Gaussian error assumption in the stochastic optimiza-
tion step whereas a (cid:96)1-type regularization was used in the
learning step (which implies the assumption that the error
follows the Laplace distribution). Last but not the least, as
different assumptions and approximations may be used in
each step of the two-step procedure, it is usually very hard
to theoretically gauge the performance of this two-step pro-
cedure.
An attractive proposal is to integrate these two steps. A
couple of existing papers have explored this idea within
particular application domains. Liyanage & Shanthiku-
mar (2005) proposed the concept of operational statistics
that drives the optimal estimator for the newsvendor or-
dering target under uncertainty. Their methods assume the
functional form of the distribution for the uncertainty (e.g.
the net demand follows an exponential distribution) and
equivalence-type argument to reduce the hypothesis class
of all possible estimators. Kao et al. (2009) considers the
setting that the results of a regression are used for solving
decision problems whose cost function is an arbitrary con-
vex quadratic function.
It is shown in the paper that by
using a convex combination of the results produced by or-
dinary least squares and empirical minimization, the actual
cost generated by their algorithm is signiﬁcantly lower than
directly using the results of ordinary least squares. A few
important question still remains open. (i) What is a suit-
able general formulation for deriving methods that directly
identify the optimal decision from the data? (ii) Are there
algorithms that have provably guaranteed performances un-
der this general formulation?
This paper makes progresses in addressing these questions.
In particular, we adopt and modify the framework of statis-
tical decision theory, which is the root of all modern learn-
ing algorithms, to incorporate the actual economic costs in
Section 2. This leads to a risk minimization problem which
again depends on the unknown underlying data generating
distribution. We show that empirical risk minimization can
lead to a class of efﬁcient algorithms whose performance
can be theoretically analyzed. Section 3 then applies these
general consideration to a speciﬁc problem on dispatching

energy generators to meet uncertain demand in the context
of renewable integration. We then propose algorithm that
follows empirical risk minimization paradigm as well as
variations of it. Theoretical guarantees are then derived fol-
lowed by empirical test results with data from BPA.

2. Formulation
Given a family of distributions P = {Pθ : θ ∈ Ω}, and
iid∼ Pθ, the goal of statistical decision
samples X1, . . . , Xn
theory is to identify a good procedure δ that maps the data
X = (X1, . . . , Xn) to a decision d ∈ D that has small risk.
The notion of risk is deﬁned as the expected value of a loss
function L(θ, d), i.e.,

R(θ, δ) = EPθ [L(θ, δ(X))],

where the loss function L(θ, d) assigns preference to de-
cisions given the value of the model parameter θ and d =
δ(X). This theory is usually used for the purpose of esti-
mating the parameter θ itself of some known function of θ
and so the resulting procedure δ is often called an estimator.
To cast our problem into the framework of decision theory,
we use the following speciﬁcation or modiﬁcation

• We make no assumption on the form of the distribu-
tion Pθ. That is, instead of say assuming the uncer-
tainty follows a normal distribution and then estimat-
ing its mean and variance, we allow arbitrary type of
distribution in the family P.1 In a sense, this forms a
nonparametric estimation problem in the classical ter-
minology. As such, we drop the index θ and use P
itself to refer to an arbitrary member of the family of
the unknown distribution P.

• We set the loss function to be the true economic cost

of the problem, that is

L(Xn+1, d) = f (d, Xn+1),

where Xn+1 ∼ P denotes the unobserved uncertainty
in when we are making the decision (i.e. X in (1)).
Notice that this modiﬁes the conventional loss func-
tion which is a deterministic function of the unknown
parameter θ and decision d to a function that depends
on the random realization of Xn+1. The resulting risk
function is

EPf (u, Xn+1),

where we modiﬁed the notation from estimator δ to
decision u.

1We would still have to make implicit technical assumptions

such as the mean of the loss function exists.

(1/n)(cid:80)n

instead,

The remaining problem is to design procedures that maps
the data to a good decision u that minimizes the risk. The
challenge is that since P is unknown, it is in general im-
possible to ﬁnd procedures that are uniformly optimal with
respect to all possible members P ∈ P. Thus the bulk of
the classical decision theory concerns about alternative no-
tations of optimality, which leads to uniformly minimal risk
unbiased estimators, uniformly minimal risk equivariant
estimators, optimal Bayes estimators, and minimax estima-
tors (cf. Lehmann & Casella (1998) for a good treatment of
this subject). However, none of the above optimality crite-
ria permits universal procedures to derive algorithms which
could identify the optimal decision. That is, calculation has
to be done based on the particularly assumed distribution,
and for different distributions the methods and results vary
signiﬁcantly.
We propose,

to minimize the empirical risk
i=1 f (u, Xi) within a pre-determined hypothesis2
class that contains functional forms for u. This would cer-
tainly generate efﬁcient algorithms if for examples the cost
function is convex and the hypothesis class is linear.
In
more complex situations, non-convex optimization proce-
dures may be deployed to identify the optimal hypothe-
sis in the hypothesis class. We will show by an applica-
tion in the next section that it is possible to prove theo-
retical performance guarantees for the resulting procedures
which suggests that the sub-optimality with respect to the
true risk R (which is deﬁned using the unknown distribu-
tion P) is bounded with large probability and the bound
approaches to zero with the number of samples increases
to inﬁnity. The application consists of a speciﬁc choice of
the cost function for a practical situation, and the hypothe-
sis class. But both the proposed algorithms and the perfor-
mance analysis could be generalized to other cost functions
and hypothesis classes.

3. Application: Electric Power Dispatch for

Renewable Integration

The rest of this paper concerns with an application that is
of an increasing importance both in the United States and
around the globe. As global warming becomes a growing
consensus, many countries around the world are pushing
deeper renewable penetration into their energy generation
portfolio and their electric power grids. This results in sig-
niﬁcant challenges in the operation of the grids as renew-
ables are intrinsically variable, i.e., they are intermittent,
uncontrollable and random. Figure 1 (a) depicts the wind
power generation in a BPA region over 20 days, and Fig-
ure 1 (b) gives common percentage forecast errors for the

2This use of the term of hypothesis follows leaning theory
instead of the literature of hypothesis testing, although they are
closely related.

wind with different forecast horizons. It is evident that as
the forecast errors for the wind is signiﬁcant at day-ahead
(around 16% in Figure 1(b)), an explicit modeling of its un-
certainty and its impact is necessary. See (Qin et al., 2013a)
and (Qin et al., 2013b) for more backgrounds.

the temperature, wind speed, and other relevant informa-
tion about hour i, as well as some nonlinear transforma-
tions of the some of the features available. Denote the his-
torical data set by Sn = {(X1, D1), . . . , (Xn, Dn)}, where
Xi ∈ Rm. We are also given features regarding the deliv-
ery hour which we are making a dispatch decision about,
denoted as Xn+1. Now our goal is to ﬁnd a mapping from
Xn+1 to u that has small risk using data Sn. As in Section
2, the true population risk is deﬁned using economic cost
of the system, which coincides with the objective function
of the stochastic optimization (2), i.e.,

R = EP[cu + q(D − u)+].

(a) Wind generation for 20 days

(b) Forecast error (%) for wind

3.2. Algorithms

Figure 1. Renewable is variable and difﬁcult to forecast.

3.1. Problem Statement

The problem that we are concerning is the dispatch of con-
ventional generators, which are slow and have to be notiﬁed
and scheduled at 24 hours ahead of the delivery period, in
a grid with substantial amount of the renewables in the sys-
tem. This is a challenging problem in the sense that when
the decision regarding the conventional generator is made,
no precise information about the net demand, deﬁned as
the actual demand minus the renewable generation is avail-
able. We can formulate this problem as a speciﬁc instance
of the general decision-making under uncertainty problem
that we discussed in the previous sections. In particular,
if the distribution for the net demand is P, then one would
like to identify the optimal amount to be scheduled for the
conventional generators by solving the following stochastic
optimization

u(cid:63) = argmin

u∈U

EP[cu + q(D − u)+],

(2)

where u is the dispatched slow generator at day-ahead with
cost per unit generation being c dollars, D ∈ [Dmin, Dmax]
is the future net demand for the system, (D − u)+ =
max(D − u, 0) is the unserved demand with per unit
penalty being q dollars. In California, the average per unit
cost for slow generators (i.e. c) is around $50 per MW,
whereas the penalty for each unit of unserved demand (i.e.
q, also referred to as value of lost load) is in the range of
$500 ∼ 2000 per MW. So we assume that q > c.
As a matter of practice, the actual distribution for the net
demand D is unknown. Instead, we have observation of
the net demand over historical hours, together with other
relevant data that we refer to as features. For instance, for
a historical hour i, we may have records of the net demand
Di and a vector of features Xi with its entries recording

As the true population risk cannot be evaluated without the
knowledge about the underlying distribution P, we mini-
mize the empirical risk instead. Furthermore, we restrict
ourselves to the hypothesis class of linear functions of the
feature Xn+1 for tractability. Note that this does not reduce
the generality of our procedure a lot because as mentioned
before we can always add nonlinear transformed features
into the original list of features to capture any nonlinear
effects. Within the linear hypothesis class, the dispatch de-
cision u can be represented by a weight vector w ∈ Rm,

i.e., u =(cid:80)m

j=1 wjX j

n+1.

We proposes three algorithms listed as follows:

• Algorithm 1: Empirical Risk Minimization (ERM)

n(cid:88)

i=1

min

w

1
n

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+

with its solution denoted by wERM.

• Algorithm 2: ERM with Least Squares Regularization

cw(cid:62)Xi+q(Di−w(cid:62)Xi)++λLS(cid:107)D−Xw(cid:107)2,

n(cid:88)

i=1

min

w

1
n

n(cid:88)

i=1

min

w

1
n

with its solution denoted by wERM+LS.

• Algorithm 3: ERM with (cid:96)2 Regularization

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ + λ2(cid:107)w(cid:107)2,

with its solution denoted by wERM+(cid:96)2.

(cid:80)n
Here the ﬁrst algorithm is directly minimizes the empirical
i=1 cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ within the
risk ˆR = 1
n
hypothesis class. Algorithm 2 is proposed for the case that
some of the underlying data-generating features may not

05101520050010001500200025003000Time (hour)Wind power generation (MW) 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0 5 10 15 20 25Timehorizon(hour)ForecasterrorForecasterrorTypicaldispatchstagesDirect Data-Driven Methods for Decision Making under Uncertainty

Junjie Qin
Institute for Computational and Mathematical Engineering, Stanford, CA 94305 USA

JQIN@STANFORD.EDU

1. Introduction
We are constantly making decisions under uncertainty. A
widely used formulation for decision making under uncer-
tainty can be summarized by the following optimization
program

EP[f (u, X)],

u∈U

u(cid:63) = argmin

(1)
where the future cost f depends both on the decision u ∈ U
as well as the outcome of uncertain events, represented by
a random variable X ∈ X . Here the random variable X
follows a distribution P which is assumed to be known in
order to form the expectation in problem (1). Examples
includes making an inventory decision with uncertainty fu-
ture demand, purchasing stocks with uncertain information
about the future price, and deciding which PhD programs
to choose to go with uncertainty in research directions, ad-
visors and funding opportunities.
In practice, the distribution P is never readily available. In-
stead, practitioners often resort to the following two step
procedure:

Data
(Sn)

learning
−−−−−−→
methods

Model
uncertainty

of

(P)

stochastic
−−−−−−−−−→
optimization

Decision
(u(cid:63))

that is, given a historical data set Sn, one would ﬁrst apply
certain machine learning algorithms to obtain representa-
tions of the data, usually in the form of point prediction or
parameters for the distribution P, and then use these repre-
sentations to form the stochastic optimization program (1)
which in turn would lead to an “optimal” decision. This
procedure has many known issues. First of all, off-the-
shelf learning algorithms are derived using loss functions
that are mathematically convenient, but may have nothing
to do with the actual economic costs regarding the decision
that one is making. For instance, commonly used linear re-
gression algorithm assumes a quadratic error loss, whereas
the actual cost function may be a different function such
as a piecewise linear function in the inventory control ex-
ample. As such, the learning step in the above procedure
is sub-optimal with respect to the true economic cost. Fur-
thermore, as the stochastic optimization step sees the model
of uncertainty which is a summary of the data instead of the

data itself, it may make assumptions inconsistent with as-
sumptions made in the learning step. An example would be
using Gaussian error assumption in the stochastic optimiza-
tion step whereas a (cid:96)1-type regularization was used in the
learning step (which implies the assumption that the error
follows the Laplace distribution). Last but not the least, as
different assumptions and approximations may be used in
each step of the two-step procedure, it is usually very hard
to theoretically gauge the performance of this two-step pro-
cedure.
An attractive proposal is to integrate these two steps. A
couple of existing papers have explored this idea within
particular application domains. Liyanage & Shanthiku-
mar (2005) proposed the concept of operational statistics
that drives the optimal estimator for the newsvendor or-
dering target under uncertainty. Their methods assume the
functional form of the distribution for the uncertainty (e.g.
the net demand follows an exponential distribution) and
equivalence-type argument to reduce the hypothesis class
of all possible estimators. Kao et al. (2009) considers the
setting that the results of a regression are used for solving
decision problems whose cost function is an arbitrary con-
vex quadratic function.
It is shown in the paper that by
using a convex combination of the results produced by or-
dinary least squares and empirical minimization, the actual
cost generated by their algorithm is signiﬁcantly lower than
directly using the results of ordinary least squares. A few
important question still remains open. (i) What is a suit-
able general formulation for deriving methods that directly
identify the optimal decision from the data? (ii) Are there
algorithms that have provably guaranteed performances un-
der this general formulation?
This paper makes progresses in addressing these questions.
In particular, we adopt and modify the framework of statis-
tical decision theory, which is the root of all modern learn-
ing algorithms, to incorporate the actual economic costs in
Section 2. This leads to a risk minimization problem which
again depends on the unknown underlying data generating
distribution. We show that empirical risk minimization can
lead to a class of efﬁcient algorithms whose performance
can be theoretically analyzed. Section 3 then applies these
general consideration to a speciﬁc problem on dispatching

energy generators to meet uncertain demand in the context
of renewable integration. We then propose algorithm that
follows empirical risk minimization paradigm as well as
variations of it. Theoretical guarantees are then derived fol-
lowed by empirical test results with data from BPA.

2. Formulation
Given a family of distributions P = {Pθ : θ ∈ Ω}, and
iid∼ Pθ, the goal of statistical decision
samples X1, . . . , Xn
theory is to identify a good procedure δ that maps the data
X = (X1, . . . , Xn) to a decision d ∈ D that has small risk.
The notion of risk is deﬁned as the expected value of a loss
function L(θ, d), i.e.,

R(θ, δ) = EPθ [L(θ, δ(X))],

where the loss function L(θ, d) assigns preference to de-
cisions given the value of the model parameter θ and d =
δ(X). This theory is usually used for the purpose of esti-
mating the parameter θ itself of some known function of θ
and so the resulting procedure δ is often called an estimator.
To cast our problem into the framework of decision theory,
we use the following speciﬁcation or modiﬁcation

• We make no assumption on the form of the distribu-
tion Pθ. That is, instead of say assuming the uncer-
tainty follows a normal distribution and then estimat-
ing its mean and variance, we allow arbitrary type of
distribution in the family P.1 In a sense, this forms a
nonparametric estimation problem in the classical ter-
minology. As such, we drop the index θ and use P
itself to refer to an arbitrary member of the family of
the unknown distribution P.

• We set the loss function to be the true economic cost

of the problem, that is

L(Xn+1, d) = f (d, Xn+1),

where Xn+1 ∼ P denotes the unobserved uncertainty
in when we are making the decision (i.e. X in (1)).
Notice that this modiﬁes the conventional loss func-
tion which is a deterministic function of the unknown
parameter θ and decision d to a function that depends
on the random realization of Xn+1. The resulting risk
function is

EPf (u, Xn+1),

where we modiﬁed the notation from estimator δ to
decision u.

1We would still have to make implicit technical assumptions

such as the mean of the loss function exists.

(1/n)(cid:80)n

instead,

The remaining problem is to design procedures that maps
the data to a good decision u that minimizes the risk. The
challenge is that since P is unknown, it is in general im-
possible to ﬁnd procedures that are uniformly optimal with
respect to all possible members P ∈ P. Thus the bulk of
the classical decision theory concerns about alternative no-
tations of optimality, which leads to uniformly minimal risk
unbiased estimators, uniformly minimal risk equivariant
estimators, optimal Bayes estimators, and minimax estima-
tors (cf. Lehmann & Casella (1998) for a good treatment of
this subject). However, none of the above optimality crite-
ria permits universal procedures to derive algorithms which
could identify the optimal decision. That is, calculation has
to be done based on the particularly assumed distribution,
and for different distributions the methods and results vary
signiﬁcantly.
We propose,

to minimize the empirical risk
i=1 f (u, Xi) within a pre-determined hypothesis2
class that contains functional forms for u. This would cer-
tainly generate efﬁcient algorithms if for examples the cost
function is convex and the hypothesis class is linear.
In
more complex situations, non-convex optimization proce-
dures may be deployed to identify the optimal hypothe-
sis in the hypothesis class. We will show by an applica-
tion in the next section that it is possible to prove theo-
retical performance guarantees for the resulting procedures
which suggests that the sub-optimality with respect to the
true risk R (which is deﬁned using the unknown distribu-
tion P) is bounded with large probability and the bound
approaches to zero with the number of samples increases
to inﬁnity. The application consists of a speciﬁc choice of
the cost function for a practical situation, and the hypothe-
sis class. But both the proposed algorithms and the perfor-
mance analysis could be generalized to other cost functions
and hypothesis classes.

3. Application: Electric Power Dispatch for

Renewable Integration

The rest of this paper concerns with an application that is
of an increasing importance both in the United States and
around the globe. As global warming becomes a growing
consensus, many countries around the world are pushing
deeper renewable penetration into their energy generation
portfolio and their electric power grids. This results in sig-
niﬁcant challenges in the operation of the grids as renew-
ables are intrinsically variable, i.e., they are intermittent,
uncontrollable and random. Figure 1 (a) depicts the wind
power generation in a BPA region over 20 days, and Fig-
ure 1 (b) gives common percentage forecast errors for the

2This use of the term of hypothesis follows leaning theory
instead of the literature of hypothesis testing, although they are
closely related.

wind with different forecast horizons. It is evident that as
the forecast errors for the wind is signiﬁcant at day-ahead
(around 16% in Figure 1(b)), an explicit modeling of its un-
certainty and its impact is necessary. See (Qin et al., 2013a)
and (Qin et al., 2013b) for more backgrounds.

the temperature, wind speed, and other relevant informa-
tion about hour i, as well as some nonlinear transforma-
tions of the some of the features available. Denote the his-
torical data set by Sn = {(X1, D1), . . . , (Xn, Dn)}, where
Xi ∈ Rm. We are also given features regarding the deliv-
ery hour which we are making a dispatch decision about,
denoted as Xn+1. Now our goal is to ﬁnd a mapping from
Xn+1 to u that has small risk using data Sn. As in Section
2, the true population risk is deﬁned using economic cost
of the system, which coincides with the objective function
of the stochastic optimization (2), i.e.,

R = EP[cu + q(D − u)+].

(a) Wind generation for 20 days

(b) Forecast error (%) for wind

3.2. Algorithms

Figure 1. Renewable is variable and difﬁcult to forecast.

3.1. Problem Statement

The problem that we are concerning is the dispatch of con-
ventional generators, which are slow and have to be notiﬁed
and scheduled at 24 hours ahead of the delivery period, in
a grid with substantial amount of the renewables in the sys-
tem. This is a challenging problem in the sense that when
the decision regarding the conventional generator is made,
no precise information about the net demand, deﬁned as
the actual demand minus the renewable generation is avail-
able. We can formulate this problem as a speciﬁc instance
of the general decision-making under uncertainty problem
that we discussed in the previous sections. In particular,
if the distribution for the net demand is P, then one would
like to identify the optimal amount to be scheduled for the
conventional generators by solving the following stochastic
optimization

u(cid:63) = argmin

u∈U

EP[cu + q(D − u)+],

(2)

where u is the dispatched slow generator at day-ahead with
cost per unit generation being c dollars, D ∈ [Dmin, Dmax]
is the future net demand for the system, (D − u)+ =
max(D − u, 0) is the unserved demand with per unit
penalty being q dollars. In California, the average per unit
cost for slow generators (i.e. c) is around $50 per MW,
whereas the penalty for each unit of unserved demand (i.e.
q, also referred to as value of lost load) is in the range of
$500 ∼ 2000 per MW. So we assume that q > c.
As a matter of practice, the actual distribution for the net
demand D is unknown. Instead, we have observation of
the net demand over historical hours, together with other
relevant data that we refer to as features. For instance, for
a historical hour i, we may have records of the net demand
Di and a vector of features Xi with its entries recording

As the true population risk cannot be evaluated without the
knowledge about the underlying distribution P, we mini-
mize the empirical risk instead. Furthermore, we restrict
ourselves to the hypothesis class of linear functions of the
feature Xn+1 for tractability. Note that this does not reduce
the generality of our procedure a lot because as mentioned
before we can always add nonlinear transformed features
into the original list of features to capture any nonlinear
effects. Within the linear hypothesis class, the dispatch de-
cision u can be represented by a weight vector w ∈ Rm,

i.e., u =(cid:80)m

j=1 wjX j

n+1.

We proposes three algorithms listed as follows:

• Algorithm 1: Empirical Risk Minimization (ERM)

n(cid:88)

i=1

min

w

1
n

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+

with its solution denoted by wERM.

• Algorithm 2: ERM with Least Squares Regularization

cw(cid:62)Xi+q(Di−w(cid:62)Xi)++λLS(cid:107)D−Xw(cid:107)2,

n(cid:88)

i=1

min

w

1
n

n(cid:88)

i=1

min

w

1
n

with its solution denoted by wERM+LS.

• Algorithm 3: ERM with (cid:96)2 Regularization

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ + λ2(cid:107)w(cid:107)2,

with its solution denoted by wERM+(cid:96)2.

(cid:80)n
Here the ﬁrst algorithm is directly minimizes the empirical
i=1 cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ within the
risk ˆR = 1
n
hypothesis class. Algorithm 2 is proposed for the case that
some of the underlying data-generating features may not

05101520050010001500200025003000Time (hour)Wind power generation (MW) 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0 5 10 15 20 25Timehorizon(hour)ForecasterrorForecasterrorTypicaldispatchstagesbe included in the model. If the missing components can
be approximated with normal distribution (by the virtue of
the central limit theorem), the least square regularization
would improve ERM. The last algorithm is proposed for
the case that certain automatic feature selection is needed:
If the number of features is large, the (cid:96)2 regularization in
Algorithm 3 would be useful to reduce over-ﬁtting.

3.3. Performance Guarantees

We have the following guarantees on the performance of
wERM.
Theorem 1 (Uniform Convergence Bound). For i.i.d. data
(X1, D1), . . . , (Xn, Dn), suppose that we restrict to the
weights satisﬁying (cid:107)w(cid:107)2 ≤ W max and suppose that
E(cid:107)Xi(cid:107)2 ≤ (X max)2, then with probability at least 1 − δ,
the excess risk of ERM is bounded as

|R(wERM)−R(w(cid:63))| ≤ 4(q − c)W maxX max

√

n

+

2 log(2/δ)

n

,

(cid:114)

where w(cid:63) is the minimizer of the population risk R.
This result suggest that with probability 1 − δ, the excess
√
risk of ERM diminishes as O(1/
n), i.e., as the number of
samples grows to inﬁnity, the result of ERM is near-optimal
in the hypothesis class with large probability. One unsatis-
factory fact regarding the previous result is that it does not
show how the algorithm performs as the number of feature
m changes. Using tools from algorithmic stability theory,
the next results bounds the generalization error of Algo-
rithm 1 and explicit shows the dependence on the number
of features.
Theorem 2 (Algorithmic Stability Bound). Under assump-
tions of Theorem 1 and w.l.o.g. assume |Dmax| > |Dmin|,
with probability at least 1 − δ, the generalization error of
ERM is bounded as
|R(wERM) − ˆR(wERM)|
≤2γ(q − c)Dmax m
n
where γ = (q − c)/c.

+ (q − c)Dmax (4γm+1)

(cid:114)

log(2/δ)

2n

√
This result shows that generalization error scales as
n) (note the second term in the bound) so that
O(m/
when we have a large number of features, the sample size
has to grow much faster to ensure the same risk bound.
Note that the generalization error is different from the ex-
cess risk and is only the difference of between the popu-
lation risk and empirical risk both evaluated at the point
produced by the ERM algorithm. As the algorithmic stabil-
ity theory concerns the output of the particular algorithm,
it does not bound the risk difference with the true popula-
tion risk minimizer. However, we would expect the error

bounds in Theorem 2 to be informative as well, because
in general whenever the empirical risk and population risk
are close enough (which is ensured by the bound given),
the distance between their minimizers should not be far.

3.4. Numerical Results

We test all three algorithms with one year of hourly wind
and demand data from BPA (http://transmission.
bpa.gov/business/operations/wind/).
The
three proposed algorithms are compared with a benchmark
algorithm which is separated estimation and optimization
(SEO), that is the two-step procedure discussed in Section
1. Here since for the deterministic case of (2) the optimal
solution is clearly u = D, the SEO reduces to performs
a least square regression for the demand. We have tested
three sets of features. The ﬁrst set of features consists of the
last net demand observation and hour of the day, where the
hour of the day is used to capture seasonality. The second
set of features consists of the net demand over the last 24
hours and hour of the day. The last set of features includes
the net demand over the last 24 hours, order statistics3 of
the net demand and hour of the day. All three cases con-
tains a constant feature representing the intercept, so that
the number of features for these three cases are m = 3,
m = 26, and m = 50, respectively. The tests are con-
ducted in a rolling horizon fashion: for each hour in which
a dispatch decision has to be made, the data corresponding
to the past n hours are used as the sample data set. The
same procedure is repeatedly tested for all N − n hours,
where N = 24 × 365 = 8760 is the total number of hours
in the data set.4
The results for our experiments are shown in Table 1 in
the form of the percentage cost reduction compared to the
benchmark algorithm. From the results in the table, we can
observe that with small number of features (m = 3), the
cost saving of ERM increases slowly as the number of sam-
ples increases. While with more features (m = 50), the av-
erage cost saving grow dramatically as the number of sam-
ples grows. When the number of features is large ERM+L2
over-performs ERM which suggests that the automatic fea-
ture selection is beneﬁcial even with 50 features. In all our
3The set of all linear combinations form so-called L-statistics.
They are widely used as estimators of quantiles. Note that for
the problem of our interests, the optimal solution of the stochas-
tic optimization can be solved analytically if there is no feature,
and the optimal solution is a quantile of the unknown net demand
distribution.

4Although this is not a conventional learning problem, in the
learning language, we would say the training data set has size n
and for each of the N − n experiments the test data set has size 1.
Using a larger test set, i.e., deciding the optimal decision for more
than one future hours would not make sense in our application as
the most recent piece of information has the largest information
content regarding the optimal decision.

Direct Data-Driven Methods for Decision Making under Uncertainty

Junjie Qin
Institute for Computational and Mathematical Engineering, Stanford, CA 94305 USA

JQIN@STANFORD.EDU

1. Introduction
We are constantly making decisions under uncertainty. A
widely used formulation for decision making under uncer-
tainty can be summarized by the following optimization
program

EP[f (u, X)],

u∈U

u(cid:63) = argmin

(1)
where the future cost f depends both on the decision u ∈ U
as well as the outcome of uncertain events, represented by
a random variable X ∈ X . Here the random variable X
follows a distribution P which is assumed to be known in
order to form the expectation in problem (1). Examples
includes making an inventory decision with uncertainty fu-
ture demand, purchasing stocks with uncertain information
about the future price, and deciding which PhD programs
to choose to go with uncertainty in research directions, ad-
visors and funding opportunities.
In practice, the distribution P is never readily available. In-
stead, practitioners often resort to the following two step
procedure:

Data
(Sn)

learning
−−−−−−→
methods

Model
uncertainty

of

(P)

stochastic
−−−−−−−−−→
optimization

Decision
(u(cid:63))

that is, given a historical data set Sn, one would ﬁrst apply
certain machine learning algorithms to obtain representa-
tions of the data, usually in the form of point prediction or
parameters for the distribution P, and then use these repre-
sentations to form the stochastic optimization program (1)
which in turn would lead to an “optimal” decision. This
procedure has many known issues. First of all, off-the-
shelf learning algorithms are derived using loss functions
that are mathematically convenient, but may have nothing
to do with the actual economic costs regarding the decision
that one is making. For instance, commonly used linear re-
gression algorithm assumes a quadratic error loss, whereas
the actual cost function may be a different function such
as a piecewise linear function in the inventory control ex-
ample. As such, the learning step in the above procedure
is sub-optimal with respect to the true economic cost. Fur-
thermore, as the stochastic optimization step sees the model
of uncertainty which is a summary of the data instead of the

data itself, it may make assumptions inconsistent with as-
sumptions made in the learning step. An example would be
using Gaussian error assumption in the stochastic optimiza-
tion step whereas a (cid:96)1-type regularization was used in the
learning step (which implies the assumption that the error
follows the Laplace distribution). Last but not the least, as
different assumptions and approximations may be used in
each step of the two-step procedure, it is usually very hard
to theoretically gauge the performance of this two-step pro-
cedure.
An attractive proposal is to integrate these two steps. A
couple of existing papers have explored this idea within
particular application domains. Liyanage & Shanthiku-
mar (2005) proposed the concept of operational statistics
that drives the optimal estimator for the newsvendor or-
dering target under uncertainty. Their methods assume the
functional form of the distribution for the uncertainty (e.g.
the net demand follows an exponential distribution) and
equivalence-type argument to reduce the hypothesis class
of all possible estimators. Kao et al. (2009) considers the
setting that the results of a regression are used for solving
decision problems whose cost function is an arbitrary con-
vex quadratic function.
It is shown in the paper that by
using a convex combination of the results produced by or-
dinary least squares and empirical minimization, the actual
cost generated by their algorithm is signiﬁcantly lower than
directly using the results of ordinary least squares. A few
important question still remains open. (i) What is a suit-
able general formulation for deriving methods that directly
identify the optimal decision from the data? (ii) Are there
algorithms that have provably guaranteed performances un-
der this general formulation?
This paper makes progresses in addressing these questions.
In particular, we adopt and modify the framework of statis-
tical decision theory, which is the root of all modern learn-
ing algorithms, to incorporate the actual economic costs in
Section 2. This leads to a risk minimization problem which
again depends on the unknown underlying data generating
distribution. We show that empirical risk minimization can
lead to a class of efﬁcient algorithms whose performance
can be theoretically analyzed. Section 3 then applies these
general consideration to a speciﬁc problem on dispatching

energy generators to meet uncertain demand in the context
of renewable integration. We then propose algorithm that
follows empirical risk minimization paradigm as well as
variations of it. Theoretical guarantees are then derived fol-
lowed by empirical test results with data from BPA.

2. Formulation
Given a family of distributions P = {Pθ : θ ∈ Ω}, and
iid∼ Pθ, the goal of statistical decision
samples X1, . . . , Xn
theory is to identify a good procedure δ that maps the data
X = (X1, . . . , Xn) to a decision d ∈ D that has small risk.
The notion of risk is deﬁned as the expected value of a loss
function L(θ, d), i.e.,

R(θ, δ) = EPθ [L(θ, δ(X))],

where the loss function L(θ, d) assigns preference to de-
cisions given the value of the model parameter θ and d =
δ(X). This theory is usually used for the purpose of esti-
mating the parameter θ itself of some known function of θ
and so the resulting procedure δ is often called an estimator.
To cast our problem into the framework of decision theory,
we use the following speciﬁcation or modiﬁcation

• We make no assumption on the form of the distribu-
tion Pθ. That is, instead of say assuming the uncer-
tainty follows a normal distribution and then estimat-
ing its mean and variance, we allow arbitrary type of
distribution in the family P.1 In a sense, this forms a
nonparametric estimation problem in the classical ter-
minology. As such, we drop the index θ and use P
itself to refer to an arbitrary member of the family of
the unknown distribution P.

• We set the loss function to be the true economic cost

of the problem, that is

L(Xn+1, d) = f (d, Xn+1),

where Xn+1 ∼ P denotes the unobserved uncertainty
in when we are making the decision (i.e. X in (1)).
Notice that this modiﬁes the conventional loss func-
tion which is a deterministic function of the unknown
parameter θ and decision d to a function that depends
on the random realization of Xn+1. The resulting risk
function is

EPf (u, Xn+1),

where we modiﬁed the notation from estimator δ to
decision u.

1We would still have to make implicit technical assumptions

such as the mean of the loss function exists.

(1/n)(cid:80)n

instead,

The remaining problem is to design procedures that maps
the data to a good decision u that minimizes the risk. The
challenge is that since P is unknown, it is in general im-
possible to ﬁnd procedures that are uniformly optimal with
respect to all possible members P ∈ P. Thus the bulk of
the classical decision theory concerns about alternative no-
tations of optimality, which leads to uniformly minimal risk
unbiased estimators, uniformly minimal risk equivariant
estimators, optimal Bayes estimators, and minimax estima-
tors (cf. Lehmann & Casella (1998) for a good treatment of
this subject). However, none of the above optimality crite-
ria permits universal procedures to derive algorithms which
could identify the optimal decision. That is, calculation has
to be done based on the particularly assumed distribution,
and for different distributions the methods and results vary
signiﬁcantly.
We propose,

to minimize the empirical risk
i=1 f (u, Xi) within a pre-determined hypothesis2
class that contains functional forms for u. This would cer-
tainly generate efﬁcient algorithms if for examples the cost
function is convex and the hypothesis class is linear.
In
more complex situations, non-convex optimization proce-
dures may be deployed to identify the optimal hypothe-
sis in the hypothesis class. We will show by an applica-
tion in the next section that it is possible to prove theo-
retical performance guarantees for the resulting procedures
which suggests that the sub-optimality with respect to the
true risk R (which is deﬁned using the unknown distribu-
tion P) is bounded with large probability and the bound
approaches to zero with the number of samples increases
to inﬁnity. The application consists of a speciﬁc choice of
the cost function for a practical situation, and the hypothe-
sis class. But both the proposed algorithms and the perfor-
mance analysis could be generalized to other cost functions
and hypothesis classes.

3. Application: Electric Power Dispatch for

Renewable Integration

The rest of this paper concerns with an application that is
of an increasing importance both in the United States and
around the globe. As global warming becomes a growing
consensus, many countries around the world are pushing
deeper renewable penetration into their energy generation
portfolio and their electric power grids. This results in sig-
niﬁcant challenges in the operation of the grids as renew-
ables are intrinsically variable, i.e., they are intermittent,
uncontrollable and random. Figure 1 (a) depicts the wind
power generation in a BPA region over 20 days, and Fig-
ure 1 (b) gives common percentage forecast errors for the

2This use of the term of hypothesis follows leaning theory
instead of the literature of hypothesis testing, although they are
closely related.

wind with different forecast horizons. It is evident that as
the forecast errors for the wind is signiﬁcant at day-ahead
(around 16% in Figure 1(b)), an explicit modeling of its un-
certainty and its impact is necessary. See (Qin et al., 2013a)
and (Qin et al., 2013b) for more backgrounds.

the temperature, wind speed, and other relevant informa-
tion about hour i, as well as some nonlinear transforma-
tions of the some of the features available. Denote the his-
torical data set by Sn = {(X1, D1), . . . , (Xn, Dn)}, where
Xi ∈ Rm. We are also given features regarding the deliv-
ery hour which we are making a dispatch decision about,
denoted as Xn+1. Now our goal is to ﬁnd a mapping from
Xn+1 to u that has small risk using data Sn. As in Section
2, the true population risk is deﬁned using economic cost
of the system, which coincides with the objective function
of the stochastic optimization (2), i.e.,

R = EP[cu + q(D − u)+].

(a) Wind generation for 20 days

(b) Forecast error (%) for wind

3.2. Algorithms

Figure 1. Renewable is variable and difﬁcult to forecast.

3.1. Problem Statement

The problem that we are concerning is the dispatch of con-
ventional generators, which are slow and have to be notiﬁed
and scheduled at 24 hours ahead of the delivery period, in
a grid with substantial amount of the renewables in the sys-
tem. This is a challenging problem in the sense that when
the decision regarding the conventional generator is made,
no precise information about the net demand, deﬁned as
the actual demand minus the renewable generation is avail-
able. We can formulate this problem as a speciﬁc instance
of the general decision-making under uncertainty problem
that we discussed in the previous sections. In particular,
if the distribution for the net demand is P, then one would
like to identify the optimal amount to be scheduled for the
conventional generators by solving the following stochastic
optimization

u(cid:63) = argmin

u∈U

EP[cu + q(D − u)+],

(2)

where u is the dispatched slow generator at day-ahead with
cost per unit generation being c dollars, D ∈ [Dmin, Dmax]
is the future net demand for the system, (D − u)+ =
max(D − u, 0) is the unserved demand with per unit
penalty being q dollars. In California, the average per unit
cost for slow generators (i.e. c) is around $50 per MW,
whereas the penalty for each unit of unserved demand (i.e.
q, also referred to as value of lost load) is in the range of
$500 ∼ 2000 per MW. So we assume that q > c.
As a matter of practice, the actual distribution for the net
demand D is unknown. Instead, we have observation of
the net demand over historical hours, together with other
relevant data that we refer to as features. For instance, for
a historical hour i, we may have records of the net demand
Di and a vector of features Xi with its entries recording

As the true population risk cannot be evaluated without the
knowledge about the underlying distribution P, we mini-
mize the empirical risk instead. Furthermore, we restrict
ourselves to the hypothesis class of linear functions of the
feature Xn+1 for tractability. Note that this does not reduce
the generality of our procedure a lot because as mentioned
before we can always add nonlinear transformed features
into the original list of features to capture any nonlinear
effects. Within the linear hypothesis class, the dispatch de-
cision u can be represented by a weight vector w ∈ Rm,

i.e., u =(cid:80)m

j=1 wjX j

n+1.

We proposes three algorithms listed as follows:

• Algorithm 1: Empirical Risk Minimization (ERM)

n(cid:88)

i=1

min

w

1
n

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+

with its solution denoted by wERM.

• Algorithm 2: ERM with Least Squares Regularization

cw(cid:62)Xi+q(Di−w(cid:62)Xi)++λLS(cid:107)D−Xw(cid:107)2,

n(cid:88)

i=1

min

w

1
n

n(cid:88)

i=1

min

w

1
n

with its solution denoted by wERM+LS.

• Algorithm 3: ERM with (cid:96)2 Regularization

cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ + λ2(cid:107)w(cid:107)2,

with its solution denoted by wERM+(cid:96)2.

(cid:80)n
Here the ﬁrst algorithm is directly minimizes the empirical
i=1 cw(cid:62)Xi + q(Di − w(cid:62)Xi)+ within the
risk ˆR = 1
n
hypothesis class. Algorithm 2 is proposed for the case that
some of the underlying data-generating features may not

05101520050010001500200025003000Time (hour)Wind power generation (MW) 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0 5 10 15 20 25Timehorizon(hour)ForecasterrorForecasterrorTypicaldispatchstagesbe included in the model. If the missing components can
be approximated with normal distribution (by the virtue of
the central limit theorem), the least square regularization
would improve ERM. The last algorithm is proposed for
the case that certain automatic feature selection is needed:
If the number of features is large, the (cid:96)2 regularization in
Algorithm 3 would be useful to reduce over-ﬁtting.

3.3. Performance Guarantees

We have the following guarantees on the performance of
wERM.
Theorem 1 (Uniform Convergence Bound). For i.i.d. data
(X1, D1), . . . , (Xn, Dn), suppose that we restrict to the
weights satisﬁying (cid:107)w(cid:107)2 ≤ W max and suppose that
E(cid:107)Xi(cid:107)2 ≤ (X max)2, then with probability at least 1 − δ,
the excess risk of ERM is bounded as

|R(wERM)−R(w(cid:63))| ≤ 4(q − c)W maxX max

√

n

+

2 log(2/δ)

n

,

(cid:114)

where w(cid:63) is the minimizer of the population risk R.
This result suggest that with probability 1 − δ, the excess
√
risk of ERM diminishes as O(1/
n), i.e., as the number of
samples grows to inﬁnity, the result of ERM is near-optimal
in the hypothesis class with large probability. One unsatis-
factory fact regarding the previous result is that it does not
show how the algorithm performs as the number of feature
m changes. Using tools from algorithmic stability theory,
the next results bounds the generalization error of Algo-
rithm 1 and explicit shows the dependence on the number
of features.
Theorem 2 (Algorithmic Stability Bound). Under assump-
tions of Theorem 1 and w.l.o.g. assume |Dmax| > |Dmin|,
with probability at least 1 − δ, the generalization error of
ERM is bounded as
|R(wERM) − ˆR(wERM)|
≤2γ(q − c)Dmax m
n
where γ = (q − c)/c.

+ (q − c)Dmax (4γm+1)

(cid:114)

log(2/δ)

2n

√
This result shows that generalization error scales as
n) (note the second term in the bound) so that
O(m/
when we have a large number of features, the sample size
has to grow much faster to ensure the same risk bound.
Note that the generalization error is different from the ex-
cess risk and is only the difference of between the popu-
lation risk and empirical risk both evaluated at the point
produced by the ERM algorithm. As the algorithmic stabil-
ity theory concerns the output of the particular algorithm,
it does not bound the risk difference with the true popula-
tion risk minimizer. However, we would expect the error

bounds in Theorem 2 to be informative as well, because
in general whenever the empirical risk and population risk
are close enough (which is ensured by the bound given),
the distance between their minimizers should not be far.

3.4. Numerical Results

We test all three algorithms with one year of hourly wind
and demand data from BPA (http://transmission.
bpa.gov/business/operations/wind/).
The
three proposed algorithms are compared with a benchmark
algorithm which is separated estimation and optimization
(SEO), that is the two-step procedure discussed in Section
1. Here since for the deterministic case of (2) the optimal
solution is clearly u = D, the SEO reduces to performs
a least square regression for the demand. We have tested
three sets of features. The ﬁrst set of features consists of the
last net demand observation and hour of the day, where the
hour of the day is used to capture seasonality. The second
set of features consists of the net demand over the last 24
hours and hour of the day. The last set of features includes
the net demand over the last 24 hours, order statistics3 of
the net demand and hour of the day. All three cases con-
tains a constant feature representing the intercept, so that
the number of features for these three cases are m = 3,
m = 26, and m = 50, respectively. The tests are con-
ducted in a rolling horizon fashion: for each hour in which
a dispatch decision has to be made, the data corresponding
to the past n hours are used as the sample data set. The
same procedure is repeatedly tested for all N − n hours,
where N = 24 × 365 = 8760 is the total number of hours
in the data set.4
The results for our experiments are shown in Table 1 in
the form of the percentage cost reduction compared to the
benchmark algorithm. From the results in the table, we can
observe that with small number of features (m = 3), the
cost saving of ERM increases slowly as the number of sam-
ples increases. While with more features (m = 50), the av-
erage cost saving grow dramatically as the number of sam-
ples grows. When the number of features is large ERM+L2
over-performs ERM which suggests that the automatic fea-
ture selection is beneﬁcial even with 50 features. In all our
3The set of all linear combinations form so-called L-statistics.
They are widely used as estimators of quantiles. Note that for
the problem of our interests, the optimal solution of the stochas-
tic optimization can be solved analytically if there is no feature,
and the optimal solution is a quantile of the unknown net demand
distribution.

4Although this is not a conventional learning problem, in the
learning language, we would say the training data set has size n
and for each of the N − n experiments the test data set has size 1.
Using a larger test set, i.e., deciding the optimal decision for more
than one future hours would not make sense in our application as
the most recent piece of information has the largest information
content regarding the optimal decision.

Table 1. Percentage cost reduction for various number of samples and number of features.
m=3

m=26

m=50

m=3

m=3
ERM ERM+LS ERM+L2
29.1
28.4
31.7

26.1
24.1
27.0

18.9
17.0
16.2

m=26

m=26
ERM ERM+LS ERM+L2
22.2
27.7
27.7

22.9
24.4
24.7

18.7
16.9
15.8

n=100
n=200
n=300

m=50

m=50
ERM ERM+LS ERM+L2
8.2
22.7
25.0

26.9
28.6
26.8

14.3
16.6
15.0

(cid:112)2 log(2/δ)/n (Bousquet et al., 2004). For the linear hy-

√
pothesis class with bounded (cid:96)2 norm, the Rademacher com-
plexity is bounded by W maxX max/
n. The observation
that the loss function is Lipschitz continuous with coefﬁ-
cient q − c translates the Rademacher complexity of the
hypothesis class to that of the loss function class and com-
pletes the proof.

experiments, ERM+LS does not work well in general for
this application, especially comparing to ERM+L2.
As all the cost numbers vary signiﬁcantly from experiments
to experiments, Figure 2 gives the box-plots for two set-
tings, which suggests that all the proposed methods have
much smaller spread (variance) in the realized costs and
ERM has smallest over the three proposed algorithms.

Proof Sketch of Theorem 2. As routine algorithmic stabil-
ity proofs, we have to establish that the algorithm is sta-
ble (in fact uniformly stable). One can show (with very
tedious algebra) that for our problem and the ERM algo-
rithm, the stability coefﬁcient is α = Dmax(q−c)2m/(cn).
Furthermore, the cost function is uniformly bounded by
K = Dmax(q − c). Invoking a standard algorithmic sta-
bility theorem (Bousquet et al., 2004) gives the bound that

|R(wERM)− ˆR(wERM)| ≤ 2α+(4αn+K)(cid:112)log(2/δ)/2n,

(a) n = 100, m = 3

(b) n = 100, m = 26

Figure 2. Box-plots (spreads) of the costs for various methods and
scenarios.

and completes the proof.

4. Conclusion and Future Directions
This project proposes, theoretically analyzes, and empiri-
cally tests methods that directly solve stochastic optimiza-
tion using the data, instead of performing separated estima-
tion and optimization procedure. The application of gener-
ator dispatch with renewables is studied in depth to serve
as an example of general formulation and methods pro-
posed. Empirical results show that our algorithms lead to
great cost savings (∼ 20%) for the energy grid operator.
Future work that develops bounds for regularized version
of the algorithm, improves the theoretical understanding on
the effect of model mis-speciﬁcation, investigates how es-
timators from statistics and operational statistics can serve
as features and improve the performance. and tests exten-
sion of the algorithms such as kernelized versions are of
interest.

A. Proof Sketches
Proof Sketch of Theorem 1. This result relies on a theorem
that bounds the excess risk with the sum of 4 times of
the Rademacher complexity of the loss function class and

References
Bousquet, O., Boucheron, S., and Lugosi, G. Introduction
to statistical learning theory. In Advanced Lectures on
Machine Learning, pp. 169–207. Springer, 2004.

Kao, Y., Roy, B.V., and Yan, X. Directed regression. In
Proc. Advances in Neural Information Processing Sys-
tems, pp. 889–897, 2009.

Lehmann, Erich Leo and Casella, George. Theory of point

estimation, volume 31. Springer, 1998.

Liyanage, Liwan H. and Shanthikumar, J.George. A prac-
tical inventory control policy using operational statistics.
Operations Research Letters, 33(4):341 – 348, 2005.
ISSN 0167-6377.

Qin, J., Su, H., and Rajagopal, R. Storage in risk limiting
dispatch: Control and approximation. In Proc. American
Control Conference, 2013a.

Qin, J., Zhang, B., and Rajagopal, R. Risk limiting dis-
In Proc. IEEE Inter-
patch with ramping constraints.
national Conference on Smart Grid Communications
(SmartGridComm),, pp. 791–796, 2013b.

00.511.522.5x 104SEOERMERM+LSERM+L2cost00.511.522.5x 104SEOERMERM+LSERM+L2cost