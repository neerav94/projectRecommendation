Automatic Playlist Generation

Xingting Gong and Xu Chen

Stanford University
gongx@stanford.edu
xchen91@stanford.edu

I.

Introduction

Digital music applications have become an increasingly
popular means of listening to music. Applications such
as Spotify allows the user to add songs to his/her
playlist without downloading the song to his/her com-
puter. The user can also be recommended songs by
Spotify through Spotify’s “Discover" option. Pandora—
an online radio—generates a radio station based on
a single user-inputted artist, genre, or composer. For
these types of applications, applying algorithms to
learn user preferences is extremely important. In this
report, we explore two different methods to generate
automatic playlists based on user-input:
1. Gaussian Process Regression (GPR):
This method takes in a set of seed songs (which can
contain as little as a single song) inputted by the user to
train a preference function that predicts the user pref-
erence for a new song to be considered for the playlist.
2. SVM + HMM:
For this method, we assume that the user has gener-
ated a large number of seed songs (i.e. a user has liked
hundreds of songs are pandora throughout the course
of a year). For this method we also require a set of
low-preference songs (i.e. the user has skipped hun-
dreds of songs on pandora over a year). With a large
training set of labelled data, we can apply classiﬁcation
algorithms such as SVM to determine if a new song
will be liked or disliked by the user.
Because we believe timbre to be an important predic-
tor for music, we combine the SVM with an HMM to
model the timbre spectra.
These methods are described in much greater detail in
section IV.

mitigate the problem of a small training set. Instead of
designing a machine learning problem to train only on
the user-provided seeds, the Microsoft group gathered
174,577 songs from 14,198 albums as a kernel "meta"-
training set. The idea is that songs placed on the same
album are similar, and so it is appropriate to train the
similarity metric on the set of 174,577 songs. However,
their selection of musical features were mostly qualita-
tive, and consisted of: genre (i.e. jazz, rap), subgenera
(i.e. heavy metal), mood (i.e. angry, happy), style (i.e.
East coast rap, Gangsta rap) , rhythm type (i.e swing,
disco), rhythmic description (i.e. funky, lazy), and vo-
cal code (i.e. duet, instrumental). We felt that some of
these features were not very well deﬁned and seemed
redundant in the musical qualities they were trying to
capture. The example features classiﬁed under genre,
subgenera, and style, for example, seem extremely in-
terchangeable amongst the 3 categories. For our ﬁrst
method using GPR, we aim to expand upon the Mi-
crosoft group’s work by applying KMT to data from the
Million Song Dataset (described in section III). Brieﬂy,
the Million Song Dataset provides quantitative features
such as tempo in beats-per-minute, or loudness in deci-
bels, which we will instead use as features to train the
similarity metric.

Our second method falls into the more standard cat-
egory of binary classiﬁcation problems. More notably,
we want to expand upon a standard SVM by modeling
the timbre sequence as a HMM. There has been a lot
of research on using timbre to analyze complex instru-
mental textures and even rhythmic styles [2-4]. Due
to the importance of timbre in characterizing sound,
we believe that an SVM armed with HMM can be an
effective classiﬁer on large training sets.

II. Related Work

III. Dataset and Features

Automatic Playlist Generation can be a difﬁcult task
due to the fact that the user will often provide only
a few seed songs. With such a small training set, it
can be difﬁcult to train a sensible similarity metric. A
paper by Zheng et. al. at Microsoft Corporation de-
vised a novel "Kernel Meta-Training" (KMT) method to

We obtained our data from the Million Song Dataset, a
dataset compiled by Columbia University’s Laboratory
for the Recognition and Organization of Speech and
Audio and The Echo Nest. The entirety of this dataset
consists of audio features and metadata for a million
popular songs. For the sake of practicality, we down-

1

Automatic Playlist Generation

Xingting Gong and Xu Chen

Stanford University
gongx@stanford.edu
xchen91@stanford.edu

I.

Introduction

Digital music applications have become an increasingly
popular means of listening to music. Applications such
as Spotify allows the user to add songs to his/her
playlist without downloading the song to his/her com-
puter. The user can also be recommended songs by
Spotify through Spotify’s “Discover" option. Pandora—
an online radio—generates a radio station based on
a single user-inputted artist, genre, or composer. For
these types of applications, applying algorithms to
learn user preferences is extremely important. In this
report, we explore two different methods to generate
automatic playlists based on user-input:
1. Gaussian Process Regression (GPR):
This method takes in a set of seed songs (which can
contain as little as a single song) inputted by the user to
train a preference function that predicts the user pref-
erence for a new song to be considered for the playlist.
2. SVM + HMM:
For this method, we assume that the user has gener-
ated a large number of seed songs (i.e. a user has liked
hundreds of songs are pandora throughout the course
of a year). For this method we also require a set of
low-preference songs (i.e. the user has skipped hun-
dreds of songs on pandora over a year). With a large
training set of labelled data, we can apply classiﬁcation
algorithms such as SVM to determine if a new song
will be liked or disliked by the user.
Because we believe timbre to be an important predic-
tor for music, we combine the SVM with an HMM to
model the timbre spectra.
These methods are described in much greater detail in
section IV.

mitigate the problem of a small training set. Instead of
designing a machine learning problem to train only on
the user-provided seeds, the Microsoft group gathered
174,577 songs from 14,198 albums as a kernel "meta"-
training set. The idea is that songs placed on the same
album are similar, and so it is appropriate to train the
similarity metric on the set of 174,577 songs. However,
their selection of musical features were mostly qualita-
tive, and consisted of: genre (i.e. jazz, rap), subgenera
(i.e. heavy metal), mood (i.e. angry, happy), style (i.e.
East coast rap, Gangsta rap) , rhythm type (i.e swing,
disco), rhythmic description (i.e. funky, lazy), and vo-
cal code (i.e. duet, instrumental). We felt that some of
these features were not very well deﬁned and seemed
redundant in the musical qualities they were trying to
capture. The example features classiﬁed under genre,
subgenera, and style, for example, seem extremely in-
terchangeable amongst the 3 categories. For our ﬁrst
method using GPR, we aim to expand upon the Mi-
crosoft group’s work by applying KMT to data from the
Million Song Dataset (described in section III). Brieﬂy,
the Million Song Dataset provides quantitative features
such as tempo in beats-per-minute, or loudness in deci-
bels, which we will instead use as features to train the
similarity metric.

Our second method falls into the more standard cat-
egory of binary classiﬁcation problems. More notably,
we want to expand upon a standard SVM by modeling
the timbre sequence as a HMM. There has been a lot
of research on using timbre to analyze complex instru-
mental textures and even rhythmic styles [2-4]. Due
to the importance of timbre in characterizing sound,
we believe that an SVM armed with HMM can be an
effective classiﬁer on large training sets.

II. Related Work

III. Dataset and Features

Automatic Playlist Generation can be a difﬁcult task
due to the fact that the user will often provide only
a few seed songs. With such a small training set, it
can be difﬁcult to train a sensible similarity metric. A
paper by Zheng et. al. at Microsoft Corporation de-
vised a novel "Kernel Meta-Training" (KMT) method to

We obtained our data from the Million Song Dataset, a
dataset compiled by Columbia University’s Laboratory
for the Recognition and Organization of Speech and
Audio and The Echo Nest. The entirety of this dataset
consists of audio features and metadata for a million
popular songs. For the sake of practicality, we down-

1

loaded the 10,000 song subset.
The dataset contains approximately 54 features per
track. Of this set we hand selected a subset of 5 fea-
tures upon which to perform our analysis:

1. Genre: Each track can consist of anywhere from 0
to multiple user-supplied genre tags from the Mu-
sicBrainz website. To keep our analysis simple, we
randomly assigned each track to one its genre tags.
Each track is therefore labelled by an integer that
corresponds to a particular genre.

2. Tempo: The estimated tempo in BMP. To discretize
this feature, we binned the tempo values by incre-
ments of 20.

3. Loudness: The average loudness of the song in dB.

We binned these values by increments of 5 dB.

4. Decade: We included the decade in which the song
was released as a feature. The motivation behind
this is that songs produced in the same decade
sound similar in style.

5. Timbre: Timbre is represented as a 12 × N matrix
of Mel-frequency cepstral coefﬁcients, where N is
the number of segments. Each column of the matrix
is thus a 12 dimensional vector representing the 12
MFCCs of a particular time segment. We processed
timbre differently for each of our two methods:
GPR: For this method, we limited ourselves to tracks
with N ≥ 200 and randomly selected 200 rows of
the timbre matrix for these tracks.
SVM + HMM: Since each column of the timbre ma-
trix is obtained from a different time segment, it
makes more sense to represent the timbre matrix as
a hidden markov model. We trained an HMM for
each of the two song sets representing songs "liked"
and "disliked" by the user (i.e. added or not added
to the user’s Spotify playlist from the application’s
list of recommendations). The loglikelihoods of each
track given each of the HMM models are then used
as features for the SVM.

Table 1: Feature Vector Examples

Features
Genre

Tempo
Year

Avg. Loudness
Timbre (GPR)

Timbre (SVM+HM)

Example raw values

Discretized/Processed values

rock, indie, pop, hip-hop
country, jazz, metal, folk

rap, dance

130.861, 122.174, 80.149

1989, 1999, 2007

-13.366, -7.928, -15.367
12 ×N matrix of MFCCs
12 ×N matrix of MFCCs

Integer values 0 to 9

6, 6, 4

198, 199, 200

-2, -1, -3

randomly selected 200 rows

loglikelihoods under each HMM

2

IV. Methods

Gaussian Process Regression: The ﬁrst of our main
methods makes use of Gaussian Process Regression. In
a Gaussian process (GP), any ﬁnite subset of the points
in our domain space satisﬁes a multivariate Gaussian
distribution. For automatic playlist generation, our
domain space consists of the possible user preferences
f for some song which we wish to predict. To simplify
calculations, the mean of the GP is often assumed to be
0, which makes sense in our case since it is reasonable
to assume that in the space of all songs, a user will
probably not want to listen to most of them.

Let seedSongs = {xi}N

i=1 be the set of user-inputted
songs that serve as the "seed" for which we will gen-
erate a playlist around, where xi denotes the feature
vector for seed song i. Let fi denote the true user pref-
erence for these songs (though fi can in principle take
on any real value, for simplicity we assume it is approx-
imately 1 with noise σ if the user selects the song as a
seed). Let f∗ denote the user preference for some song
x∗ that we want to predict. Then the joint distribution

[ fi, f∗] is Gaussian:(cid:20) fi

(cid:21)

= N (0, K)

(1)

f∗

where K is the covariance matrix.
Since [ fi, f∗] is jointly Gaussian, the conditional dis-
tribution P( f∗| fi) is therefore also a Gaussian with
parameters:

P( f∗| fi) ∼ N (µ, Σ)
µ = K(xi, x∗)K(xi, xi) fi
Σ = K(x∗, x∗) − K(x, x∗)K(xi, xi)−1K(x∗, xi)

(2a)
(2b)
(2c)
The preference function f∗ is then obtained by tak-
ing the posterior mean of this conditional distribution,
resulting in:

f∗ =

N∑

i=1

αiK(xi, x∗)

(K(xi, xj) + σ2δij)−1

αi =

N∑

j=1

(3a)

(3b)

Lastly, since σ is the noise in our GP, it is obtained by
maximizing the log likelihood of obtaining the set of
seed songs:
log p( f|σ) = − 1
2
Thus, in order to learn the preference function we must
obtain a kernel K(x, y) that will serve as our similar-
ity metric between two songs x and y. Once we have

f TK−1 f − 1
2

log|K| − N
2

log 2π (4)

Automatic Playlist Generation

Xingting Gong and Xu Chen

Stanford University
gongx@stanford.edu
xchen91@stanford.edu

I.

Introduction

Digital music applications have become an increasingly
popular means of listening to music. Applications such
as Spotify allows the user to add songs to his/her
playlist without downloading the song to his/her com-
puter. The user can also be recommended songs by
Spotify through Spotify’s “Discover" option. Pandora—
an online radio—generates a radio station based on
a single user-inputted artist, genre, or composer. For
these types of applications, applying algorithms to
learn user preferences is extremely important. In this
report, we explore two different methods to generate
automatic playlists based on user-input:
1. Gaussian Process Regression (GPR):
This method takes in a set of seed songs (which can
contain as little as a single song) inputted by the user to
train a preference function that predicts the user pref-
erence for a new song to be considered for the playlist.
2. SVM + HMM:
For this method, we assume that the user has gener-
ated a large number of seed songs (i.e. a user has liked
hundreds of songs are pandora throughout the course
of a year). For this method we also require a set of
low-preference songs (i.e. the user has skipped hun-
dreds of songs on pandora over a year). With a large
training set of labelled data, we can apply classiﬁcation
algorithms such as SVM to determine if a new song
will be liked or disliked by the user.
Because we believe timbre to be an important predic-
tor for music, we combine the SVM with an HMM to
model the timbre spectra.
These methods are described in much greater detail in
section IV.

mitigate the problem of a small training set. Instead of
designing a machine learning problem to train only on
the user-provided seeds, the Microsoft group gathered
174,577 songs from 14,198 albums as a kernel "meta"-
training set. The idea is that songs placed on the same
album are similar, and so it is appropriate to train the
similarity metric on the set of 174,577 songs. However,
their selection of musical features were mostly qualita-
tive, and consisted of: genre (i.e. jazz, rap), subgenera
(i.e. heavy metal), mood (i.e. angry, happy), style (i.e.
East coast rap, Gangsta rap) , rhythm type (i.e swing,
disco), rhythmic description (i.e. funky, lazy), and vo-
cal code (i.e. duet, instrumental). We felt that some of
these features were not very well deﬁned and seemed
redundant in the musical qualities they were trying to
capture. The example features classiﬁed under genre,
subgenera, and style, for example, seem extremely in-
terchangeable amongst the 3 categories. For our ﬁrst
method using GPR, we aim to expand upon the Mi-
crosoft group’s work by applying KMT to data from the
Million Song Dataset (described in section III). Brieﬂy,
the Million Song Dataset provides quantitative features
such as tempo in beats-per-minute, or loudness in deci-
bels, which we will instead use as features to train the
similarity metric.

Our second method falls into the more standard cat-
egory of binary classiﬁcation problems. More notably,
we want to expand upon a standard SVM by modeling
the timbre sequence as a HMM. There has been a lot
of research on using timbre to analyze complex instru-
mental textures and even rhythmic styles [2-4]. Due
to the importance of timbre in characterizing sound,
we believe that an SVM armed with HMM can be an
effective classiﬁer on large training sets.

II. Related Work

III. Dataset and Features

Automatic Playlist Generation can be a difﬁcult task
due to the fact that the user will often provide only
a few seed songs. With such a small training set, it
can be difﬁcult to train a sensible similarity metric. A
paper by Zheng et. al. at Microsoft Corporation de-
vised a novel "Kernel Meta-Training" (KMT) method to

We obtained our data from the Million Song Dataset, a
dataset compiled by Columbia University’s Laboratory
for the Recognition and Organization of Speech and
Audio and The Echo Nest. The entirety of this dataset
consists of audio features and metadata for a million
popular songs. For the sake of practicality, we down-

1

loaded the 10,000 song subset.
The dataset contains approximately 54 features per
track. Of this set we hand selected a subset of 5 fea-
tures upon which to perform our analysis:

1. Genre: Each track can consist of anywhere from 0
to multiple user-supplied genre tags from the Mu-
sicBrainz website. To keep our analysis simple, we
randomly assigned each track to one its genre tags.
Each track is therefore labelled by an integer that
corresponds to a particular genre.

2. Tempo: The estimated tempo in BMP. To discretize
this feature, we binned the tempo values by incre-
ments of 20.

3. Loudness: The average loudness of the song in dB.

We binned these values by increments of 5 dB.

4. Decade: We included the decade in which the song
was released as a feature. The motivation behind
this is that songs produced in the same decade
sound similar in style.

5. Timbre: Timbre is represented as a 12 × N matrix
of Mel-frequency cepstral coefﬁcients, where N is
the number of segments. Each column of the matrix
is thus a 12 dimensional vector representing the 12
MFCCs of a particular time segment. We processed
timbre differently for each of our two methods:
GPR: For this method, we limited ourselves to tracks
with N ≥ 200 and randomly selected 200 rows of
the timbre matrix for these tracks.
SVM + HMM: Since each column of the timbre ma-
trix is obtained from a different time segment, it
makes more sense to represent the timbre matrix as
a hidden markov model. We trained an HMM for
each of the two song sets representing songs "liked"
and "disliked" by the user (i.e. added or not added
to the user’s Spotify playlist from the application’s
list of recommendations). The loglikelihoods of each
track given each of the HMM models are then used
as features for the SVM.

Table 1: Feature Vector Examples

Features
Genre

Tempo
Year

Avg. Loudness
Timbre (GPR)

Timbre (SVM+HM)

Example raw values

Discretized/Processed values

rock, indie, pop, hip-hop
country, jazz, metal, folk

rap, dance

130.861, 122.174, 80.149

1989, 1999, 2007

-13.366, -7.928, -15.367
12 ×N matrix of MFCCs
12 ×N matrix of MFCCs

Integer values 0 to 9

6, 6, 4

198, 199, 200

-2, -1, -3

randomly selected 200 rows

loglikelihoods under each HMM

2

IV. Methods

Gaussian Process Regression: The ﬁrst of our main
methods makes use of Gaussian Process Regression. In
a Gaussian process (GP), any ﬁnite subset of the points
in our domain space satisﬁes a multivariate Gaussian
distribution. For automatic playlist generation, our
domain space consists of the possible user preferences
f for some song which we wish to predict. To simplify
calculations, the mean of the GP is often assumed to be
0, which makes sense in our case since it is reasonable
to assume that in the space of all songs, a user will
probably not want to listen to most of them.

Let seedSongs = {xi}N

i=1 be the set of user-inputted
songs that serve as the "seed" for which we will gen-
erate a playlist around, where xi denotes the feature
vector for seed song i. Let fi denote the true user pref-
erence for these songs (though fi can in principle take
on any real value, for simplicity we assume it is approx-
imately 1 with noise σ if the user selects the song as a
seed). Let f∗ denote the user preference for some song
x∗ that we want to predict. Then the joint distribution

[ fi, f∗] is Gaussian:(cid:20) fi

(cid:21)

= N (0, K)

(1)

f∗

where K is the covariance matrix.
Since [ fi, f∗] is jointly Gaussian, the conditional dis-
tribution P( f∗| fi) is therefore also a Gaussian with
parameters:

P( f∗| fi) ∼ N (µ, Σ)
µ = K(xi, x∗)K(xi, xi) fi
Σ = K(x∗, x∗) − K(x, x∗)K(xi, xi)−1K(x∗, xi)

(2a)
(2b)
(2c)
The preference function f∗ is then obtained by tak-
ing the posterior mean of this conditional distribution,
resulting in:

f∗ =

N∑

i=1

αiK(xi, x∗)

(K(xi, xj) + σ2δij)−1

αi =

N∑

j=1

(3a)

(3b)

Lastly, since σ is the noise in our GP, it is obtained by
maximizing the log likelihood of obtaining the set of
seed songs:
log p( f|σ) = − 1
2
Thus, in order to learn the preference function we must
obtain a kernel K(x, y) that will serve as our similar-
ity metric between two songs x and y. Once we have

f TK−1 f − 1
2

log|K| − N
2

log 2π (4)

the preference function, selecting a playlist becomes as
easy as computing the preference of each song under
consideration and ranking the top M.

For our project we tried two kernels, the ﬁrst of
which must be learned (a method called "Kernel Meta
Training") and the second is a simple hamming kernel
to compare our results with.

Kernel Meta Training (KMT): The idea behind KMT
is to use pre-deﬁned playlists to learn a similarity met-
ric K between any two songs. In our case, we separated
the 10,000 songs from the Million Song Subset into a
kernel-meta-training set, a seed set, and a test set. The
test set consists of the set of "new" songs that will be
considered for the playlist generation. The KMT set
constitutes the largest fraction of our dataset and is
divided further into subsets based on some feature in
order to train K. In our case, we chose to paritition
the KMT set by genre.
In contrast, the seed set is
usually very small, containing as little as one song.
Thus, the advantage to kernel-meta-training is that we
can effectively meta-train on a much larger sample,
allowing us to obtain a more accurate similarity metric.
The kernel we chose to learn was inspired by the
one used in Zheng et. al. [1], and deﬁned as follows:

K(x, y) =

Nψ∑

n=1

βnψn(x, y)

(5)

where ψn is a family of Mercer kernels indexed by n,
and Nψ is deﬁned later. In order to describe ψn in the
least confusing manner, we ﬁrst make an observation
about the timbre feature. For the ﬁrst 4 features, a
direct comparison can be made between any of these
features (i.e. two songs have similar tempos if they fall
within the same increment of 20 BPM). However, the
timbre feature was processed into a still fairly large
matrix of dimensions 12 × 200. To compare two timbre
features x5 and y5, we take the frobeniums norm of the
difference between the two timbre matrices:

Norm(x5, y5) = Frobenius Norm(x5 − y5)

(6)

Two timbre matrices are then declared similar if their
norm is below a threshold value, which we computed
by taking the average norm of all tuples in the pre-
made playlists. Now we are ready to deﬁne ψn:

(7)
where the vector a is the binary representation of the
integer n. To understand this more intuitively, a can be

 1

0

ψn(x, y) =

if anl = 0 or xl = yl ∀l < 5 and

Norm(x5, y5) < threshold

otherwise

thought of as a mask that allows us to compare a subset
of features at a time. In other words, ψn evaluates to 1
only when the components of x and y are exactly equal
(or less than a threshold) whenever the component of a
is 1. Since we have 5 features, we therefore have a total
of 25 subsets of features to consider, and so n ranges
from 0 to Nψ = 25.

Finally, to train K we want to solve for the coefﬁ-
cients βn. We do so by minimizing the cost function:

βn = arg min

1
2

N∑

i,j=1

( ˆKij − Nψ∑

n=1

βnψn(xi, xj))2

(8)

where ˆKij is the empirical covariance given by

1

# genres = 1
9

0

if songs xi, xj are in same genre

otherwise

(9)

(cid:40)

ˆKij =

Generating the seed, test, and KMT sets:
Our KMT set consists of 7,000 randomly picked songs
from the Million Song Subset. To generate a seed set
of size N from the remaining 3,000 songs, we ﬁrst ran-
domly selected a single track to serve as the initial seed.
We then compared its features to other songs in the re-
maining set. If the initial seed song s0 either shares an
artist with a second song s, has 3 identical, non-timbre
features, or has 2 identical non-timbre features and the
timbre features are "similar" (i.e. Norm < threshold),
then s0 and s are declared "similar". However, in order
to accurately mimic user behavior, we also introduce
randomness into our seed generation. For every song
s we compare to s0, we also generate a random real
number random ∈ [0, 1]. If s and s0 are similar and
random ≥ 0.3, s is added to the seed set. If s and s0
are dissimilar and random < 0.3, s is also added to
the seed set. Finally, the remaining 3, 000 − N songs
comprise the test set.

Hamming Kernel: To compare the results we ob-
tain with the KMT method, we also applied a simple
Hamming kernel (no training required) to GPR:

Kham(x, y) =

1{xi = yi} + 1{Norm(x5, y5) < threshold}

4∑

i=1

(10)
This Kernel simply computes the number of matches
between the feature vectors (and for timbre, it com-
pares whether the two matrices are similar).

3

Automatic Playlist Generation

Xingting Gong and Xu Chen

Stanford University
gongx@stanford.edu
xchen91@stanford.edu

I.

Introduction

Digital music applications have become an increasingly
popular means of listening to music. Applications such
as Spotify allows the user to add songs to his/her
playlist without downloading the song to his/her com-
puter. The user can also be recommended songs by
Spotify through Spotify’s “Discover" option. Pandora—
an online radio—generates a radio station based on
a single user-inputted artist, genre, or composer. For
these types of applications, applying algorithms to
learn user preferences is extremely important. In this
report, we explore two different methods to generate
automatic playlists based on user-input:
1. Gaussian Process Regression (GPR):
This method takes in a set of seed songs (which can
contain as little as a single song) inputted by the user to
train a preference function that predicts the user pref-
erence for a new song to be considered for the playlist.
2. SVM + HMM:
For this method, we assume that the user has gener-
ated a large number of seed songs (i.e. a user has liked
hundreds of songs are pandora throughout the course
of a year). For this method we also require a set of
low-preference songs (i.e. the user has skipped hun-
dreds of songs on pandora over a year). With a large
training set of labelled data, we can apply classiﬁcation
algorithms such as SVM to determine if a new song
will be liked or disliked by the user.
Because we believe timbre to be an important predic-
tor for music, we combine the SVM with an HMM to
model the timbre spectra.
These methods are described in much greater detail in
section IV.

mitigate the problem of a small training set. Instead of
designing a machine learning problem to train only on
the user-provided seeds, the Microsoft group gathered
174,577 songs from 14,198 albums as a kernel "meta"-
training set. The idea is that songs placed on the same
album are similar, and so it is appropriate to train the
similarity metric on the set of 174,577 songs. However,
their selection of musical features were mostly qualita-
tive, and consisted of: genre (i.e. jazz, rap), subgenera
(i.e. heavy metal), mood (i.e. angry, happy), style (i.e.
East coast rap, Gangsta rap) , rhythm type (i.e swing,
disco), rhythmic description (i.e. funky, lazy), and vo-
cal code (i.e. duet, instrumental). We felt that some of
these features were not very well deﬁned and seemed
redundant in the musical qualities they were trying to
capture. The example features classiﬁed under genre,
subgenera, and style, for example, seem extremely in-
terchangeable amongst the 3 categories. For our ﬁrst
method using GPR, we aim to expand upon the Mi-
crosoft group’s work by applying KMT to data from the
Million Song Dataset (described in section III). Brieﬂy,
the Million Song Dataset provides quantitative features
such as tempo in beats-per-minute, or loudness in deci-
bels, which we will instead use as features to train the
similarity metric.

Our second method falls into the more standard cat-
egory of binary classiﬁcation problems. More notably,
we want to expand upon a standard SVM by modeling
the timbre sequence as a HMM. There has been a lot
of research on using timbre to analyze complex instru-
mental textures and even rhythmic styles [2-4]. Due
to the importance of timbre in characterizing sound,
we believe that an SVM armed with HMM can be an
effective classiﬁer on large training sets.

II. Related Work

III. Dataset and Features

Automatic Playlist Generation can be a difﬁcult task
due to the fact that the user will often provide only
a few seed songs. With such a small training set, it
can be difﬁcult to train a sensible similarity metric. A
paper by Zheng et. al. at Microsoft Corporation de-
vised a novel "Kernel Meta-Training" (KMT) method to

We obtained our data from the Million Song Dataset, a
dataset compiled by Columbia University’s Laboratory
for the Recognition and Organization of Speech and
Audio and The Echo Nest. The entirety of this dataset
consists of audio features and metadata for a million
popular songs. For the sake of practicality, we down-

1

loaded the 10,000 song subset.
The dataset contains approximately 54 features per
track. Of this set we hand selected a subset of 5 fea-
tures upon which to perform our analysis:

1. Genre: Each track can consist of anywhere from 0
to multiple user-supplied genre tags from the Mu-
sicBrainz website. To keep our analysis simple, we
randomly assigned each track to one its genre tags.
Each track is therefore labelled by an integer that
corresponds to a particular genre.

2. Tempo: The estimated tempo in BMP. To discretize
this feature, we binned the tempo values by incre-
ments of 20.

3. Loudness: The average loudness of the song in dB.

We binned these values by increments of 5 dB.

4. Decade: We included the decade in which the song
was released as a feature. The motivation behind
this is that songs produced in the same decade
sound similar in style.

5. Timbre: Timbre is represented as a 12 × N matrix
of Mel-frequency cepstral coefﬁcients, where N is
the number of segments. Each column of the matrix
is thus a 12 dimensional vector representing the 12
MFCCs of a particular time segment. We processed
timbre differently for each of our two methods:
GPR: For this method, we limited ourselves to tracks
with N ≥ 200 and randomly selected 200 rows of
the timbre matrix for these tracks.
SVM + HMM: Since each column of the timbre ma-
trix is obtained from a different time segment, it
makes more sense to represent the timbre matrix as
a hidden markov model. We trained an HMM for
each of the two song sets representing songs "liked"
and "disliked" by the user (i.e. added or not added
to the user’s Spotify playlist from the application’s
list of recommendations). The loglikelihoods of each
track given each of the HMM models are then used
as features for the SVM.

Table 1: Feature Vector Examples

Features
Genre

Tempo
Year

Avg. Loudness
Timbre (GPR)

Timbre (SVM+HM)

Example raw values

Discretized/Processed values

rock, indie, pop, hip-hop
country, jazz, metal, folk

rap, dance

130.861, 122.174, 80.149

1989, 1999, 2007

-13.366, -7.928, -15.367
12 ×N matrix of MFCCs
12 ×N matrix of MFCCs

Integer values 0 to 9

6, 6, 4

198, 199, 200

-2, -1, -3

randomly selected 200 rows

loglikelihoods under each HMM

2

IV. Methods

Gaussian Process Regression: The ﬁrst of our main
methods makes use of Gaussian Process Regression. In
a Gaussian process (GP), any ﬁnite subset of the points
in our domain space satisﬁes a multivariate Gaussian
distribution. For automatic playlist generation, our
domain space consists of the possible user preferences
f for some song which we wish to predict. To simplify
calculations, the mean of the GP is often assumed to be
0, which makes sense in our case since it is reasonable
to assume that in the space of all songs, a user will
probably not want to listen to most of them.

Let seedSongs = {xi}N

i=1 be the set of user-inputted
songs that serve as the "seed" for which we will gen-
erate a playlist around, where xi denotes the feature
vector for seed song i. Let fi denote the true user pref-
erence for these songs (though fi can in principle take
on any real value, for simplicity we assume it is approx-
imately 1 with noise σ if the user selects the song as a
seed). Let f∗ denote the user preference for some song
x∗ that we want to predict. Then the joint distribution

[ fi, f∗] is Gaussian:(cid:20) fi

(cid:21)

= N (0, K)

(1)

f∗

where K is the covariance matrix.
Since [ fi, f∗] is jointly Gaussian, the conditional dis-
tribution P( f∗| fi) is therefore also a Gaussian with
parameters:

P( f∗| fi) ∼ N (µ, Σ)
µ = K(xi, x∗)K(xi, xi) fi
Σ = K(x∗, x∗) − K(x, x∗)K(xi, xi)−1K(x∗, xi)

(2a)
(2b)
(2c)
The preference function f∗ is then obtained by tak-
ing the posterior mean of this conditional distribution,
resulting in:

f∗ =

N∑

i=1

αiK(xi, x∗)

(K(xi, xj) + σ2δij)−1

αi =

N∑

j=1

(3a)

(3b)

Lastly, since σ is the noise in our GP, it is obtained by
maximizing the log likelihood of obtaining the set of
seed songs:
log p( f|σ) = − 1
2
Thus, in order to learn the preference function we must
obtain a kernel K(x, y) that will serve as our similar-
ity metric between two songs x and y. Once we have

f TK−1 f − 1
2

log|K| − N
2

log 2π (4)

the preference function, selecting a playlist becomes as
easy as computing the preference of each song under
consideration and ranking the top M.

For our project we tried two kernels, the ﬁrst of
which must be learned (a method called "Kernel Meta
Training") and the second is a simple hamming kernel
to compare our results with.

Kernel Meta Training (KMT): The idea behind KMT
is to use pre-deﬁned playlists to learn a similarity met-
ric K between any two songs. In our case, we separated
the 10,000 songs from the Million Song Subset into a
kernel-meta-training set, a seed set, and a test set. The
test set consists of the set of "new" songs that will be
considered for the playlist generation. The KMT set
constitutes the largest fraction of our dataset and is
divided further into subsets based on some feature in
order to train K. In our case, we chose to paritition
the KMT set by genre.
In contrast, the seed set is
usually very small, containing as little as one song.
Thus, the advantage to kernel-meta-training is that we
can effectively meta-train on a much larger sample,
allowing us to obtain a more accurate similarity metric.
The kernel we chose to learn was inspired by the
one used in Zheng et. al. [1], and deﬁned as follows:

K(x, y) =

Nψ∑

n=1

βnψn(x, y)

(5)

where ψn is a family of Mercer kernels indexed by n,
and Nψ is deﬁned later. In order to describe ψn in the
least confusing manner, we ﬁrst make an observation
about the timbre feature. For the ﬁrst 4 features, a
direct comparison can be made between any of these
features (i.e. two songs have similar tempos if they fall
within the same increment of 20 BPM). However, the
timbre feature was processed into a still fairly large
matrix of dimensions 12 × 200. To compare two timbre
features x5 and y5, we take the frobeniums norm of the
difference between the two timbre matrices:

Norm(x5, y5) = Frobenius Norm(x5 − y5)

(6)

Two timbre matrices are then declared similar if their
norm is below a threshold value, which we computed
by taking the average norm of all tuples in the pre-
made playlists. Now we are ready to deﬁne ψn:

(7)
where the vector a is the binary representation of the
integer n. To understand this more intuitively, a can be

 1

0

ψn(x, y) =

if anl = 0 or xl = yl ∀l < 5 and

Norm(x5, y5) < threshold

otherwise

thought of as a mask that allows us to compare a subset
of features at a time. In other words, ψn evaluates to 1
only when the components of x and y are exactly equal
(or less than a threshold) whenever the component of a
is 1. Since we have 5 features, we therefore have a total
of 25 subsets of features to consider, and so n ranges
from 0 to Nψ = 25.

Finally, to train K we want to solve for the coefﬁ-
cients βn. We do so by minimizing the cost function:

βn = arg min

1
2

N∑

i,j=1

( ˆKij − Nψ∑

n=1

βnψn(xi, xj))2

(8)

where ˆKij is the empirical covariance given by

1

# genres = 1
9

0

if songs xi, xj are in same genre

otherwise

(9)

(cid:40)

ˆKij =

Generating the seed, test, and KMT sets:
Our KMT set consists of 7,000 randomly picked songs
from the Million Song Subset. To generate a seed set
of size N from the remaining 3,000 songs, we ﬁrst ran-
domly selected a single track to serve as the initial seed.
We then compared its features to other songs in the re-
maining set. If the initial seed song s0 either shares an
artist with a second song s, has 3 identical, non-timbre
features, or has 2 identical non-timbre features and the
timbre features are "similar" (i.e. Norm < threshold),
then s0 and s are declared "similar". However, in order
to accurately mimic user behavior, we also introduce
randomness into our seed generation. For every song
s we compare to s0, we also generate a random real
number random ∈ [0, 1]. If s and s0 are similar and
random ≥ 0.3, s is added to the seed set. If s and s0
are dissimilar and random < 0.3, s is also added to
the seed set. Finally, the remaining 3, 000 − N songs
comprise the test set.

Hamming Kernel: To compare the results we ob-
tain with the KMT method, we also applied a simple
Hamming kernel (no training required) to GPR:

Kham(x, y) =

1{xi = yi} + 1{Norm(x5, y5) < threshold}

4∑

i=1

(10)
This Kernel simply computes the number of matches
between the feature vectors (and for timbre, it com-
pares whether the two matrices are similar).

3

SVM + HMM: Our desire to give a more reason-
able treatment to the timbre feature led us to explore
a combined SVM and HMM model.
In the case of
having a very small seed set, training an HMM on a set
that can contain as little as a single song does not make
much sense. However, it is reasonable to suppose that
over time a user may have accumulated a large playlist
of preferential songs and also rejects other songs in the
process (i.e. from a recommended playlist on Spotify,
the user only chooses a fraction of the songs; or the
user either likes or skips a song on Pandora). In this
case we have two training sets: a set of "likes" and a
set of "dislikes". We can then train an HMM on each
of these sets and the log likelihood of a training song
under each HMM model become the timbre features
for the SVM.
Generating the Training Sets: In order to apply SVM
we must ﬁrst separate our training data into two sets:
one with the label "like" and the other with "dislike".
We denote these sets as SL and SD, respectively.

To obtain these playlists, we selected an initial seed
song s0 and compared its features to other songs in
the dataset. If a song s has 3 non-timbre features in
common with s0, then s is similar to s0. We also added
the same random component as with generating the
seed set for GPR. Thus the same rules apply for adding
s to SL or SD as for GPR.
Pre-processing Timbre: To make the size of the timbre
matrices uniform across all training songs, we averaged
consecutive columns to obtain a resulting "compressed"
timbre matrix of dimension 12 × 200. I.e. If the original
track had N = 612 segments, then the ﬁrst 199 columns
of the new matrix will consist of averaging 3 = (int) 612
200
consecutive columns. The last column will contain the
average of the last 15 columns.
Gaussian HMM: Since MFCCs do not take on discrete
values, we model the emission probability at each state
by a multivariate Gaussian, where µ has dimensions
12× 1 and the covariance matrix has dimension 12× 12.
We used a HMM toolkit for Matlab to train the
HMM [6]. We experimented with different numbers of
hidden states, and picked the state numbers Lhidden = 6
and Dhidden = 7 that maximized the log likelihoods of
the training sets SL and SD. We then obtained the
timbre features for a song x by computing the log
likelihoods log p(x|HMML) and log p(x|HMMD).

V. Results

GPR: We tested both the KMT and hamming kernel
on two seed sets, one containing a single seed and the
other containing 3 seeds. The results are tabulated

4

below:

Table 2: Top 5 Songs for GPR + KMT using 1 Seed

Seed

Playlist

Title

House of Pain

Artist

Van Halen

Tell Your Momma Come

Black Eyed Peas

October

Goin’ To The River

Don’t Waste My Time
On The Road Again

U2

Alice Cooper
John Mayall
The Sonics

Genre Decade
Rock
Pop
Rock
Rock
Pop
Pop

1980
2000
1980
1980
1970
1960

Tempo

Loudness

200
200
80
140
200
140

-10
-5
-5
-10
-10
-10

Table 3: Top 5 Songs for GPR + KMT using 3 Seeds

Seeds

Title

House of Pain
Harajuku Girls

Ease

Performance
Laser Show

Playlist

Looking for A Kiss

Artist

Van Halen

Gwen Stefani

Public Image Ltd
Happy Mondays

Fountains of Wayne

Sex Pistols

The End

My Chemical Romance

Till We Ain’t Strangers Anymore

Bon Jovi

Genre Decade
Rock
Pop
Rock
Rock
Rock
Rock
Pop
Metal

1980
2000
1980
1980
1990
1970
2000
2000

Tempo

Loudness

200
100
180
100
100
120
80
140

-10
-5
-10
-5
-5
-5
-5
-5

Table 4: Top 5 Songs for GPR + Hamming using 1 Seed

Seed

House of Pain

Title

Playlist

Out Of This World

Don’t Waste My Time

Stumble
Still a Fool

Goin’ to the River

Artist

Van Halen
Black Flag
John Mayall

R.E.M.

Groundhogs
Alice Cooper

Genre Decade
Rock
Rock
Pop
Rock
Pop
Rock

1980
1980
1970
1980
1960
1980

Tempo

Loudness

200
200
200
140
120
140

-10
-10
-10
-10
-10
-10

Table 5: Top 5 Songs for GPR + Hamming using 3 Seeds

Seeds

Playlist

Title

House of Pain
Harajuku Girls

Ease
You

Start Me Up
True Nature

Artist

Van Halen

Gwen Stefani

Public Image Ltd

Radiohead

The Rolling Stones
Jane’s Addiction

Armageddon’s Raid

Final Straw

Belphegor

R.E.M.

Genre Decade
Rock
Pop
Rock
Rock
Pop
Rock
Metal
Rock

1980
2000
1980
2000
1980
2000
2000
2000

Tempo

Loudness

200
100
180
100
120
80
100
100

-10
-5
-10
-10
0
0
0
-5

SVM + HMM In order to generates results with
SVM+HMM that can be comparable to those using
GPR, we generated the sets SL and SD based on the
same initial seed s0 used to generate the seed sets for
GPR. Thus, although SL constitutes a much larger set,
the idea is that most of the songs in SL are "similar" to
s0, and therefore to all the songs in the seed sets.

We trained our SVM and HMM on a set SL of
187 songs and a set SD of 416 songs. We then ap-
plied our trained SVM + HMM model to classify
the top 20 ranking songs in each of the four GPR
runs (GPR+KMT and GPR+Hamming with 1 seed,
GPR+KMT and GPR+Hamming with 3 seeds). Omit-
ting overlaps, this meant testing on a set of 71 songs.
Of these, only 3 were labelled as "like", and these songs
are listed in the table below:

Table 6: Classiﬁcation Using SVM+HMM

Automatic Playlist Generation

Xingting Gong and Xu Chen

Stanford University
gongx@stanford.edu
xchen91@stanford.edu

I.

Introduction

Digital music applications have become an increasingly
popular means of listening to music. Applications such
as Spotify allows the user to add songs to his/her
playlist without downloading the song to his/her com-
puter. The user can also be recommended songs by
Spotify through Spotify’s “Discover" option. Pandora—
an online radio—generates a radio station based on
a single user-inputted artist, genre, or composer. For
these types of applications, applying algorithms to
learn user preferences is extremely important. In this
report, we explore two different methods to generate
automatic playlists based on user-input:
1. Gaussian Process Regression (GPR):
This method takes in a set of seed songs (which can
contain as little as a single song) inputted by the user to
train a preference function that predicts the user pref-
erence for a new song to be considered for the playlist.
2. SVM + HMM:
For this method, we assume that the user has gener-
ated a large number of seed songs (i.e. a user has liked
hundreds of songs are pandora throughout the course
of a year). For this method we also require a set of
low-preference songs (i.e. the user has skipped hun-
dreds of songs on pandora over a year). With a large
training set of labelled data, we can apply classiﬁcation
algorithms such as SVM to determine if a new song
will be liked or disliked by the user.
Because we believe timbre to be an important predic-
tor for music, we combine the SVM with an HMM to
model the timbre spectra.
These methods are described in much greater detail in
section IV.

mitigate the problem of a small training set. Instead of
designing a machine learning problem to train only on
the user-provided seeds, the Microsoft group gathered
174,577 songs from 14,198 albums as a kernel "meta"-
training set. The idea is that songs placed on the same
album are similar, and so it is appropriate to train the
similarity metric on the set of 174,577 songs. However,
their selection of musical features were mostly qualita-
tive, and consisted of: genre (i.e. jazz, rap), subgenera
(i.e. heavy metal), mood (i.e. angry, happy), style (i.e.
East coast rap, Gangsta rap) , rhythm type (i.e swing,
disco), rhythmic description (i.e. funky, lazy), and vo-
cal code (i.e. duet, instrumental). We felt that some of
these features were not very well deﬁned and seemed
redundant in the musical qualities they were trying to
capture. The example features classiﬁed under genre,
subgenera, and style, for example, seem extremely in-
terchangeable amongst the 3 categories. For our ﬁrst
method using GPR, we aim to expand upon the Mi-
crosoft group’s work by applying KMT to data from the
Million Song Dataset (described in section III). Brieﬂy,
the Million Song Dataset provides quantitative features
such as tempo in beats-per-minute, or loudness in deci-
bels, which we will instead use as features to train the
similarity metric.

Our second method falls into the more standard cat-
egory of binary classiﬁcation problems. More notably,
we want to expand upon a standard SVM by modeling
the timbre sequence as a HMM. There has been a lot
of research on using timbre to analyze complex instru-
mental textures and even rhythmic styles [2-4]. Due
to the importance of timbre in characterizing sound,
we believe that an SVM armed with HMM can be an
effective classiﬁer on large training sets.

II. Related Work

III. Dataset and Features

Automatic Playlist Generation can be a difﬁcult task
due to the fact that the user will often provide only
a few seed songs. With such a small training set, it
can be difﬁcult to train a sensible similarity metric. A
paper by Zheng et. al. at Microsoft Corporation de-
vised a novel "Kernel Meta-Training" (KMT) method to

We obtained our data from the Million Song Dataset, a
dataset compiled by Columbia University’s Laboratory
for the Recognition and Organization of Speech and
Audio and The Echo Nest. The entirety of this dataset
consists of audio features and metadata for a million
popular songs. For the sake of practicality, we down-

1

loaded the 10,000 song subset.
The dataset contains approximately 54 features per
track. Of this set we hand selected a subset of 5 fea-
tures upon which to perform our analysis:

1. Genre: Each track can consist of anywhere from 0
to multiple user-supplied genre tags from the Mu-
sicBrainz website. To keep our analysis simple, we
randomly assigned each track to one its genre tags.
Each track is therefore labelled by an integer that
corresponds to a particular genre.

2. Tempo: The estimated tempo in BMP. To discretize
this feature, we binned the tempo values by incre-
ments of 20.

3. Loudness: The average loudness of the song in dB.

We binned these values by increments of 5 dB.

4. Decade: We included the decade in which the song
was released as a feature. The motivation behind
this is that songs produced in the same decade
sound similar in style.

5. Timbre: Timbre is represented as a 12 × N matrix
of Mel-frequency cepstral coefﬁcients, where N is
the number of segments. Each column of the matrix
is thus a 12 dimensional vector representing the 12
MFCCs of a particular time segment. We processed
timbre differently for each of our two methods:
GPR: For this method, we limited ourselves to tracks
with N ≥ 200 and randomly selected 200 rows of
the timbre matrix for these tracks.
SVM + HMM: Since each column of the timbre ma-
trix is obtained from a different time segment, it
makes more sense to represent the timbre matrix as
a hidden markov model. We trained an HMM for
each of the two song sets representing songs "liked"
and "disliked" by the user (i.e. added or not added
to the user’s Spotify playlist from the application’s
list of recommendations). The loglikelihoods of each
track given each of the HMM models are then used
as features for the SVM.

Table 1: Feature Vector Examples

Features
Genre

Tempo
Year

Avg. Loudness
Timbre (GPR)

Timbre (SVM+HM)

Example raw values

Discretized/Processed values

rock, indie, pop, hip-hop
country, jazz, metal, folk

rap, dance

130.861, 122.174, 80.149

1989, 1999, 2007

-13.366, -7.928, -15.367
12 ×N matrix of MFCCs
12 ×N matrix of MFCCs

Integer values 0 to 9

6, 6, 4

198, 199, 200

-2, -1, -3

randomly selected 200 rows

loglikelihoods under each HMM

2

IV. Methods

Gaussian Process Regression: The ﬁrst of our main
methods makes use of Gaussian Process Regression. In
a Gaussian process (GP), any ﬁnite subset of the points
in our domain space satisﬁes a multivariate Gaussian
distribution. For automatic playlist generation, our
domain space consists of the possible user preferences
f for some song which we wish to predict. To simplify
calculations, the mean of the GP is often assumed to be
0, which makes sense in our case since it is reasonable
to assume that in the space of all songs, a user will
probably not want to listen to most of them.

Let seedSongs = {xi}N

i=1 be the set of user-inputted
songs that serve as the "seed" for which we will gen-
erate a playlist around, where xi denotes the feature
vector for seed song i. Let fi denote the true user pref-
erence for these songs (though fi can in principle take
on any real value, for simplicity we assume it is approx-
imately 1 with noise σ if the user selects the song as a
seed). Let f∗ denote the user preference for some song
x∗ that we want to predict. Then the joint distribution

[ fi, f∗] is Gaussian:(cid:20) fi

(cid:21)

= N (0, K)

(1)

f∗

where K is the covariance matrix.
Since [ fi, f∗] is jointly Gaussian, the conditional dis-
tribution P( f∗| fi) is therefore also a Gaussian with
parameters:

P( f∗| fi) ∼ N (µ, Σ)
µ = K(xi, x∗)K(xi, xi) fi
Σ = K(x∗, x∗) − K(x, x∗)K(xi, xi)−1K(x∗, xi)

(2a)
(2b)
(2c)
The preference function f∗ is then obtained by tak-
ing the posterior mean of this conditional distribution,
resulting in:

f∗ =

N∑

i=1

αiK(xi, x∗)

(K(xi, xj) + σ2δij)−1

αi =

N∑

j=1

(3a)

(3b)

Lastly, since σ is the noise in our GP, it is obtained by
maximizing the log likelihood of obtaining the set of
seed songs:
log p( f|σ) = − 1
2
Thus, in order to learn the preference function we must
obtain a kernel K(x, y) that will serve as our similar-
ity metric between two songs x and y. Once we have

f TK−1 f − 1
2

log|K| − N
2

log 2π (4)

the preference function, selecting a playlist becomes as
easy as computing the preference of each song under
consideration and ranking the top M.

For our project we tried two kernels, the ﬁrst of
which must be learned (a method called "Kernel Meta
Training") and the second is a simple hamming kernel
to compare our results with.

Kernel Meta Training (KMT): The idea behind KMT
is to use pre-deﬁned playlists to learn a similarity met-
ric K between any two songs. In our case, we separated
the 10,000 songs from the Million Song Subset into a
kernel-meta-training set, a seed set, and a test set. The
test set consists of the set of "new" songs that will be
considered for the playlist generation. The KMT set
constitutes the largest fraction of our dataset and is
divided further into subsets based on some feature in
order to train K. In our case, we chose to paritition
the KMT set by genre.
In contrast, the seed set is
usually very small, containing as little as one song.
Thus, the advantage to kernel-meta-training is that we
can effectively meta-train on a much larger sample,
allowing us to obtain a more accurate similarity metric.
The kernel we chose to learn was inspired by the
one used in Zheng et. al. [1], and deﬁned as follows:

K(x, y) =

Nψ∑

n=1

βnψn(x, y)

(5)

where ψn is a family of Mercer kernels indexed by n,
and Nψ is deﬁned later. In order to describe ψn in the
least confusing manner, we ﬁrst make an observation
about the timbre feature. For the ﬁrst 4 features, a
direct comparison can be made between any of these
features (i.e. two songs have similar tempos if they fall
within the same increment of 20 BPM). However, the
timbre feature was processed into a still fairly large
matrix of dimensions 12 × 200. To compare two timbre
features x5 and y5, we take the frobeniums norm of the
difference between the two timbre matrices:

Norm(x5, y5) = Frobenius Norm(x5 − y5)

(6)

Two timbre matrices are then declared similar if their
norm is below a threshold value, which we computed
by taking the average norm of all tuples in the pre-
made playlists. Now we are ready to deﬁne ψn:

(7)
where the vector a is the binary representation of the
integer n. To understand this more intuitively, a can be

 1

0

ψn(x, y) =

if anl = 0 or xl = yl ∀l < 5 and

Norm(x5, y5) < threshold

otherwise

thought of as a mask that allows us to compare a subset
of features at a time. In other words, ψn evaluates to 1
only when the components of x and y are exactly equal
(or less than a threshold) whenever the component of a
is 1. Since we have 5 features, we therefore have a total
of 25 subsets of features to consider, and so n ranges
from 0 to Nψ = 25.

Finally, to train K we want to solve for the coefﬁ-
cients βn. We do so by minimizing the cost function:

βn = arg min

1
2

N∑

i,j=1

( ˆKij − Nψ∑

n=1

βnψn(xi, xj))2

(8)

where ˆKij is the empirical covariance given by

1

# genres = 1
9

0

if songs xi, xj are in same genre

otherwise

(9)

(cid:40)

ˆKij =

Generating the seed, test, and KMT sets:
Our KMT set consists of 7,000 randomly picked songs
from the Million Song Subset. To generate a seed set
of size N from the remaining 3,000 songs, we ﬁrst ran-
domly selected a single track to serve as the initial seed.
We then compared its features to other songs in the re-
maining set. If the initial seed song s0 either shares an
artist with a second song s, has 3 identical, non-timbre
features, or has 2 identical non-timbre features and the
timbre features are "similar" (i.e. Norm < threshold),
then s0 and s are declared "similar". However, in order
to accurately mimic user behavior, we also introduce
randomness into our seed generation. For every song
s we compare to s0, we also generate a random real
number random ∈ [0, 1]. If s and s0 are similar and
random ≥ 0.3, s is added to the seed set. If s and s0
are dissimilar and random < 0.3, s is also added to
the seed set. Finally, the remaining 3, 000 − N songs
comprise the test set.

Hamming Kernel: To compare the results we ob-
tain with the KMT method, we also applied a simple
Hamming kernel (no training required) to GPR:

Kham(x, y) =

1{xi = yi} + 1{Norm(x5, y5) < threshold}

4∑

i=1

(10)
This Kernel simply computes the number of matches
between the feature vectors (and for timbre, it com-
pares whether the two matrices are similar).

3

SVM + HMM: Our desire to give a more reason-
able treatment to the timbre feature led us to explore
a combined SVM and HMM model.
In the case of
having a very small seed set, training an HMM on a set
that can contain as little as a single song does not make
much sense. However, it is reasonable to suppose that
over time a user may have accumulated a large playlist
of preferential songs and also rejects other songs in the
process (i.e. from a recommended playlist on Spotify,
the user only chooses a fraction of the songs; or the
user either likes or skips a song on Pandora). In this
case we have two training sets: a set of "likes" and a
set of "dislikes". We can then train an HMM on each
of these sets and the log likelihood of a training song
under each HMM model become the timbre features
for the SVM.
Generating the Training Sets: In order to apply SVM
we must ﬁrst separate our training data into two sets:
one with the label "like" and the other with "dislike".
We denote these sets as SL and SD, respectively.

To obtain these playlists, we selected an initial seed
song s0 and compared its features to other songs in
the dataset. If a song s has 3 non-timbre features in
common with s0, then s is similar to s0. We also added
the same random component as with generating the
seed set for GPR. Thus the same rules apply for adding
s to SL or SD as for GPR.
Pre-processing Timbre: To make the size of the timbre
matrices uniform across all training songs, we averaged
consecutive columns to obtain a resulting "compressed"
timbre matrix of dimension 12 × 200. I.e. If the original
track had N = 612 segments, then the ﬁrst 199 columns
of the new matrix will consist of averaging 3 = (int) 612
200
consecutive columns. The last column will contain the
average of the last 15 columns.
Gaussian HMM: Since MFCCs do not take on discrete
values, we model the emission probability at each state
by a multivariate Gaussian, where µ has dimensions
12× 1 and the covariance matrix has dimension 12× 12.
We used a HMM toolkit for Matlab to train the
HMM [6]. We experimented with different numbers of
hidden states, and picked the state numbers Lhidden = 6
and Dhidden = 7 that maximized the log likelihoods of
the training sets SL and SD. We then obtained the
timbre features for a song x by computing the log
likelihoods log p(x|HMML) and log p(x|HMMD).

V. Results

GPR: We tested both the KMT and hamming kernel
on two seed sets, one containing a single seed and the
other containing 3 seeds. The results are tabulated

4

below:

Table 2: Top 5 Songs for GPR + KMT using 1 Seed

Seed

Playlist

Title

House of Pain

Artist

Van Halen

Tell Your Momma Come

Black Eyed Peas

October

Goin’ To The River

Don’t Waste My Time
On The Road Again

U2

Alice Cooper
John Mayall
The Sonics

Genre Decade
Rock
Pop
Rock
Rock
Pop
Pop

1980
2000
1980
1980
1970
1960

Tempo

Loudness

200
200
80
140
200
140

-10
-5
-5
-10
-10
-10

Table 3: Top 5 Songs for GPR + KMT using 3 Seeds

Seeds

Title

House of Pain
Harajuku Girls

Ease

Performance
Laser Show

Playlist

Looking for A Kiss

Artist

Van Halen

Gwen Stefani

Public Image Ltd
Happy Mondays

Fountains of Wayne

Sex Pistols

The End

My Chemical Romance

Till We Ain’t Strangers Anymore

Bon Jovi

Genre Decade
Rock
Pop
Rock
Rock
Rock
Rock
Pop
Metal

1980
2000
1980
1980
1990
1970
2000
2000

Tempo

Loudness

200
100
180
100
100
120
80
140

-10
-5
-10
-5
-5
-5
-5
-5

Table 4: Top 5 Songs for GPR + Hamming using 1 Seed

Seed

House of Pain

Title

Playlist

Out Of This World

Don’t Waste My Time

Stumble
Still a Fool

Goin’ to the River

Artist

Van Halen
Black Flag
John Mayall

R.E.M.

Groundhogs
Alice Cooper

Genre Decade
Rock
Rock
Pop
Rock
Pop
Rock

1980
1980
1970
1980
1960
1980

Tempo

Loudness

200
200
200
140
120
140

-10
-10
-10
-10
-10
-10

Table 5: Top 5 Songs for GPR + Hamming using 3 Seeds

Seeds

Playlist

Title

House of Pain
Harajuku Girls

Ease
You

Start Me Up
True Nature

Artist

Van Halen

Gwen Stefani

Public Image Ltd

Radiohead

The Rolling Stones
Jane’s Addiction

Armageddon’s Raid

Final Straw

Belphegor

R.E.M.

Genre Decade
Rock
Pop
Rock
Rock
Pop
Rock
Metal
Rock

1980
2000
1980
2000
1980
2000
2000
2000

Tempo

Loudness

200
100
180
100
120
80
100
100

-10
-5
-10
-10
0
0
0
-5

SVM + HMM In order to generates results with
SVM+HMM that can be comparable to those using
GPR, we generated the sets SL and SD based on the
same initial seed s0 used to generate the seed sets for
GPR. Thus, although SL constitutes a much larger set,
the idea is that most of the songs in SL are "similar" to
s0, and therefore to all the songs in the seed sets.

We trained our SVM and HMM on a set SL of
187 songs and a set SD of 416 songs. We then ap-
plied our trained SVM + HMM model to classify
the top 20 ranking songs in each of the four GPR
runs (GPR+KMT and GPR+Hamming with 1 seed,
GPR+KMT and GPR+Hamming with 3 seeds). Omit-
ting overlaps, this meant testing on a set of 71 songs.
Of these, only 3 were labelled as "like", and these songs
are listed in the table below:

Table 6: Classiﬁcation Using SVM+HMM

Title

Performance

Darling, I want to Destroy You

Stumble

Artist

Happy Mondays

AFI

R.E.M.

Genre Decade
Rock
Rock
Rock

1980
2000
1980

Tempo

Loudness

100
140
140

-5
0
-10

VI. Discussion

GPR: To compare the performance of different learn-
ing algorithms, we used standard collaborative ﬁltering
metric to score the generated playlist in each trial. The
score of the playlist from trial j is deﬁned as:

Rj =

Nj∑

i=1

tij

2(i−1)/(β−1)

(11)

Where tij = 1 if ith song in the generated playlist is
in pre-made playlist in trial j; 0 otherwise. Beta deter-
mines how fast user interest decays, and is set to 10. Nj
is the number of songs in the generated playlist. The
score is then summed and normalized as

Hamming kernel. On the other hand, treating songs
from the same artist as pre-deﬁned playlists results in
much better predictions of the user prefenrece. Based
on the observation above, KMT works well only with
well designed pre-deﬁned playlists, and can constantly
outperform GPR+Hamming.
SVM + HMM: Although we did not have enough time
to write a scoring algorithm for SVM, we note that 2 of
the 3 songs in Table 6 were ranked at top 10 by GPR+
KMT and GPR+ Hamming. Thus the two methods do
appear to overlap in terms of which songs they predict
the user might like. In general, however, SVM and GPR
are very different approaches to playlist generation and
therefore difﬁcult to compare. GPR is good for very
few seeds, but has an extremely simplistic way of deal-
ing with timbre. SVM depends on their being two large
training sets SL and SD, allowing us to train an HMM
for timbre for each of these sets. Thus each method has
their own unique advantages and determining which
method is best depends on the situation.

R = 100

1000∑

j=1

Rj

(cid:14) 1000∑

j=1

Rmax

j

(12)

VII. Conclusion/Future Work

j

Where Rmax
is the perfect score in trial j. R = 100
corresponds to perfect prediction and larger R values
indicate better performance.

Figure 1: Histogram of Scores of the Various Methods

All variations of GPR signiﬁcantly outperform the
randomly generated playlist. However, GPR+KMT
does not consistently win GPR+Hamming. How we
make the pre-deﬁned playlists is important. Treat-
ing all songs in the same genre as similar tends to
over-generalize and results in worse predictions than

There are a lot of interesting avenues to explore from
here. We could, for example, train our SVM + HMM
model using the more intricate kernel deﬁned in equa-
tion 5 rather than the linear kernel which we used for
this project. We could also expand upon the feature set
by including lyrical features—i.e.
judging the mean-
ing/content of the music rather than only its acoustic
features.

References

[1] Zheng et. al. (1996). Learning a Gaussian Process
Prior for Automatically Generating Music Playlists

[2] Sandler et. al. (2005). Timbre Models for Analysis

and Retrieval of Music Signals
IEEE Transactions on Multimedia, Vol 7, No. 6

[3] Zhang, X., Ras, Z., Dardzinska, A. (2005). Discrim-
inant Feature Analysis for Music Timbre Recogni-
tion and Automatic Indexing

[4] Platt, J. C. (2006). Auto playlist generation with

multiple seed songs

[5] Ebden, M. (2008). Gaussian Processes for Regres-

sion: A Quick Introduction

[6] Murphy, K. (1998). Hidden Markov Model (HMM)

Toolbox for Matlab

5

