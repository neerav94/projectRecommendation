Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

”liked” by researchers.

To address the shortcomings of CF, David
M. Blei and Chong Wang recently devel-
oped Collaborative Topic Regression (CTR)
[0]. Much like CF, CTR assigns latent features
to every user and item based on prior user-
item interactions. However, CTR diﬀers from
CF in its usage of Latent Dirichlet Allocation
(LDA) to construct topic distributions (drawn
from β = β1:K unique topics) for every item.
Rather than describing vj as an exclusively la-
tent factor-based vector, Blei et al.
choose
to describe the item vector as vj = θj + j,
where θj ∈ RK represents the LDA derived
topic distribution of item j, and j
is a la-
tent variable that captures ﬂuctuations away
from the topic distribution. These latent oﬀ-
sets augment the content similarity-based ap-
proach through the ﬂexibility that they aﬀord
the model to understand hidden features about
items and users. Since regularization for the
topic-enhanced items must inherently be dif-
ferent than that for pure-latent users, separate
parameters λu and λv are applied to user and
item feature vectors respectively. The resulting
log-likelihood function is intractable; a type of
Expectation Maxmization algorithm is there-
fore used to arrive upon the optimal parame-
ters.

(cid:80)
n log((cid:80)
(cid:80)

i uT

i ui − λv

(cid:80)
j(vj − θj)T (vj − θj)
2 (rij − uT

k θjkβk, wjn) −(cid:80)

cij

i,j

2

L = − λu

2

+(cid:80)

j

(4)

i vj)2

The derived update rules for u and v then

become:

ui ← (V CiV T + λuI)−1V CiPi
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(5)

ated: q(θ, z | γ, φ) = q(θ | γ)(cid:81)

Given u and v, the topic proportions are
learned by variational inference; a family of
distributions on the latent variables is gener-
n q(zn | φn) and
Jensen’s inequality is applied to ﬁnd the tight
lower bound for the log likelihood function be-
low.

3

+(cid:80)

n

(cid:80)

2 (vj − θj)T (vj − θj)

L ≥ − λv
k φjnk(logθjkβk, wjn − logφjkn)

(6)

The free variational parameters upon which
the distributions are generated are optimized
by minimizing the Kullback Leibler (KL) di-
vergence between the variational distribution
and the true posterior. The resulting update
equations, for determining θ and β are given
below

φni ∝ βiwnexp{Eq[logθi | γ]}

γi = αi +

φi

(cid:88)

(7)

(8)

n

The predicted rating variable ˆri,j

for in-

matrix predictions is then computed by:

ˆri,j = uT

i vj = uT

i (θj + j)

(9)

When an item is new and in-matrix pre-
diction is not possible, the rating variable is
computed ignoring the latent oﬀset:

ˆri,j = uT

i θj

(10)

Consequently, users are still represented by
latent factors but items are represented by a
combination of their topical distribution and a
latent factor oﬀset; the latter aiming to capture
variables conducive to a user-item interaction
that are not related to the item’s topic. CTR
was shown to perform better as a recommender
system than Collaborative Filtering using both
latent factor and content-based methods.

3 Collaborative Neighbors

Given the performance improvement CTR saw
by introducing topic modeling for the items, we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy. In this section we describe

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

”liked” by researchers.

To address the shortcomings of CF, David
M. Blei and Chong Wang recently devel-
oped Collaborative Topic Regression (CTR)
[0]. Much like CF, CTR assigns latent features
to every user and item based on prior user-
item interactions. However, CTR diﬀers from
CF in its usage of Latent Dirichlet Allocation
(LDA) to construct topic distributions (drawn
from β = β1:K unique topics) for every item.
Rather than describing vj as an exclusively la-
tent factor-based vector, Blei et al.
choose
to describe the item vector as vj = θj + j,
where θj ∈ RK represents the LDA derived
topic distribution of item j, and j
is a la-
tent variable that captures ﬂuctuations away
from the topic distribution. These latent oﬀ-
sets augment the content similarity-based ap-
proach through the ﬂexibility that they aﬀord
the model to understand hidden features about
items and users. Since regularization for the
topic-enhanced items must inherently be dif-
ferent than that for pure-latent users, separate
parameters λu and λv are applied to user and
item feature vectors respectively. The resulting
log-likelihood function is intractable; a type of
Expectation Maxmization algorithm is there-
fore used to arrive upon the optimal parame-
ters.

(cid:80)
n log((cid:80)
(cid:80)

i uT

i ui − λv

(cid:80)
j(vj − θj)T (vj − θj)
2 (rij − uT

k θjkβk, wjn) −(cid:80)

cij

i,j

2

L = − λu

2

+(cid:80)

j

(4)

i vj)2

The derived update rules for u and v then

become:

ui ← (V CiV T + λuI)−1V CiPi
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(5)

ated: q(θ, z | γ, φ) = q(θ | γ)(cid:81)

Given u and v, the topic proportions are
learned by variational inference; a family of
distributions on the latent variables is gener-
n q(zn | φn) and
Jensen’s inequality is applied to ﬁnd the tight
lower bound for the log likelihood function be-
low.

3

+(cid:80)

n

(cid:80)

2 (vj − θj)T (vj − θj)

L ≥ − λv
k φjnk(logθjkβk, wjn − logφjkn)

(6)

The free variational parameters upon which
the distributions are generated are optimized
by minimizing the Kullback Leibler (KL) di-
vergence between the variational distribution
and the true posterior. The resulting update
equations, for determining θ and β are given
below

φni ∝ βiwnexp{Eq[logθi | γ]}

γi = αi +

φi

(cid:88)

(7)

(8)

n

The predicted rating variable ˆri,j

for in-

matrix predictions is then computed by:

ˆri,j = uT

i vj = uT

i (θj + j)

(9)

When an item is new and in-matrix pre-
diction is not possible, the rating variable is
computed ignoring the latent oﬀset:

ˆri,j = uT

i θj

(10)

Consequently, users are still represented by
latent factors but items are represented by a
combination of their topical distribution and a
latent factor oﬀset; the latter aiming to capture
variables conducive to a user-item interaction
that are not related to the item’s topic. CTR
was shown to perform better as a recommender
system than Collaborative Filtering using both
latent factor and content-based methods.

3 Collaborative Neighbors

Given the performance improvement CTR saw
by introducing topic modeling for the items, we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy. In this section we describe

the resulting algorithm, Collaborative Neigh-
bors.

As in CTR, our users are I researchers and
our items are J scientiﬁc articles. The prefer-
ence variable pi,j ∈ 0, 1 indicates whether or
not user i cited article j. The preference vari-
able is computed from the predicted ratings as
in eq.
(1) and the predicted rating variable
remains ˆri,j = uT

i vj.

optimize for the topic distributions. The most
important diﬀerence is that our update rules
for ui, vj now become:

ui ← (V CiV T + λuI)−1(V CiPi + λuψi)
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(11)
Our algorithm then additionally has to incor-
porate topic modeling for the users in the same
way as CTR does it for the items.

4 Experimental Study

Dataset: A total of 1.2 millions articles were re-
trieved from the PubMed open access dataset.
We parsed the title, abstract, authors, key-
words and citations associated with each arti-
cle. We removed articles missing any one of the
ﬁelds of interest to obtain a dataset of 129,531
scientiﬁc articles.

Articles: For each article, we concatenated
its title, abstract and keywords into a docu-
ment. We then removed all english stop-words
and built a vocabulary consisting of the X
words that appeared in our corpus more than
once. Next, we used a Hierarchical Dirichlet
Process (HDP) model on our dataset to deter-
mine the number of K topics contained within,
and subsequently ran LDA to determine the
K-vector topic distribution for each article.

Users:

1.5 million unique authors were
identiﬁed in the initial open access dataset.
User-article interactions were generated by
mapping users to all the citations that they
had across all their publications. We removed
self citations (where an author cites their past
work) and ﬁltered out users that had cited
fewer than 10 papers in our dataset. Our ﬁnal
user item matrix consisted of 26,152 users by
129,531 thousand articles, with an average of
16.9 interactions (citations) per user and 12.5
publications per user. Lastly, we assigned a
topic distribution to each user by taking the
average topic distribution of all papers they
had co/authored. Because of computational

We now introduce a way to represent topic pro-
portions for both users and items. We denote
θj as the topic distribution for item j, where
each θj is drawn from β = β1:K unique topics.
Conversely, we introduce ψi as the topic distri-
bution for user i, each φi drawn from β(cid:48) = β1:L.
In our experiment, we chose ψi to be the av-
erage topic space of user i but there are sev-
eral other strategies one could use to represent
the user. Since Matrix Factorization requires
for u, v ∈ RK (the user and item factor ma-
trices have to align), both θ and ψ have to
be drawn from the same topic space or, alter-
natively, topic models of the same magnitude
(| β(cid:48) |=| β |). Since ﬁnding the optimal value
of ψ, θ, u and v given β, β(cid:48) becomes intractable,
our algorithm will only be tested in the case
where β = β(cid:48) so we can assume ψ ≈ θand
use the same EM-style algorithm as in CTR to

4

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

”liked” by researchers.

To address the shortcomings of CF, David
M. Blei and Chong Wang recently devel-
oped Collaborative Topic Regression (CTR)
[0]. Much like CF, CTR assigns latent features
to every user and item based on prior user-
item interactions. However, CTR diﬀers from
CF in its usage of Latent Dirichlet Allocation
(LDA) to construct topic distributions (drawn
from β = β1:K unique topics) for every item.
Rather than describing vj as an exclusively la-
tent factor-based vector, Blei et al.
choose
to describe the item vector as vj = θj + j,
where θj ∈ RK represents the LDA derived
topic distribution of item j, and j
is a la-
tent variable that captures ﬂuctuations away
from the topic distribution. These latent oﬀ-
sets augment the content similarity-based ap-
proach through the ﬂexibility that they aﬀord
the model to understand hidden features about
items and users. Since regularization for the
topic-enhanced items must inherently be dif-
ferent than that for pure-latent users, separate
parameters λu and λv are applied to user and
item feature vectors respectively. The resulting
log-likelihood function is intractable; a type of
Expectation Maxmization algorithm is there-
fore used to arrive upon the optimal parame-
ters.

(cid:80)
n log((cid:80)
(cid:80)

i uT

i ui − λv

(cid:80)
j(vj − θj)T (vj − θj)
2 (rij − uT

k θjkβk, wjn) −(cid:80)

cij

i,j

2

L = − λu

2

+(cid:80)

j

(4)

i vj)2

The derived update rules for u and v then

become:

ui ← (V CiV T + λuI)−1V CiPi
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(5)

ated: q(θ, z | γ, φ) = q(θ | γ)(cid:81)

Given u and v, the topic proportions are
learned by variational inference; a family of
distributions on the latent variables is gener-
n q(zn | φn) and
Jensen’s inequality is applied to ﬁnd the tight
lower bound for the log likelihood function be-
low.

3

+(cid:80)

n

(cid:80)

2 (vj − θj)T (vj − θj)

L ≥ − λv
k φjnk(logθjkβk, wjn − logφjkn)

(6)

The free variational parameters upon which
the distributions are generated are optimized
by minimizing the Kullback Leibler (KL) di-
vergence between the variational distribution
and the true posterior. The resulting update
equations, for determining θ and β are given
below

φni ∝ βiwnexp{Eq[logθi | γ]}

γi = αi +

φi

(cid:88)

(7)

(8)

n

The predicted rating variable ˆri,j

for in-

matrix predictions is then computed by:

ˆri,j = uT

i vj = uT

i (θj + j)

(9)

When an item is new and in-matrix pre-
diction is not possible, the rating variable is
computed ignoring the latent oﬀset:

ˆri,j = uT

i θj

(10)

Consequently, users are still represented by
latent factors but items are represented by a
combination of their topical distribution and a
latent factor oﬀset; the latter aiming to capture
variables conducive to a user-item interaction
that are not related to the item’s topic. CTR
was shown to perform better as a recommender
system than Collaborative Filtering using both
latent factor and content-based methods.

3 Collaborative Neighbors

Given the performance improvement CTR saw
by introducing topic modeling for the items, we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy. In this section we describe

the resulting algorithm, Collaborative Neigh-
bors.

As in CTR, our users are I researchers and
our items are J scientiﬁc articles. The prefer-
ence variable pi,j ∈ 0, 1 indicates whether or
not user i cited article j. The preference vari-
able is computed from the predicted ratings as
in eq.
(1) and the predicted rating variable
remains ˆri,j = uT

i vj.

optimize for the topic distributions. The most
important diﬀerence is that our update rules
for ui, vj now become:

ui ← (V CiV T + λuI)−1(V CiPi + λuψi)
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(11)
Our algorithm then additionally has to incor-
porate topic modeling for the users in the same
way as CTR does it for the items.

4 Experimental Study

Dataset: A total of 1.2 millions articles were re-
trieved from the PubMed open access dataset.
We parsed the title, abstract, authors, key-
words and citations associated with each arti-
cle. We removed articles missing any one of the
ﬁelds of interest to obtain a dataset of 129,531
scientiﬁc articles.

Articles: For each article, we concatenated
its title, abstract and keywords into a docu-
ment. We then removed all english stop-words
and built a vocabulary consisting of the X
words that appeared in our corpus more than
once. Next, we used a Hierarchical Dirichlet
Process (HDP) model on our dataset to deter-
mine the number of K topics contained within,
and subsequently ran LDA to determine the
K-vector topic distribution for each article.

Users:

1.5 million unique authors were
identiﬁed in the initial open access dataset.
User-article interactions were generated by
mapping users to all the citations that they
had across all their publications. We removed
self citations (where an author cites their past
work) and ﬁltered out users that had cited
fewer than 10 papers in our dataset. Our ﬁnal
user item matrix consisted of 26,152 users by
129,531 thousand articles, with an average of
16.9 interactions (citations) per user and 12.5
publications per user. Lastly, we assigned a
topic distribution to each user by taking the
average topic distribution of all papers they
had co/authored. Because of computational

We now introduce a way to represent topic pro-
portions for both users and items. We denote
θj as the topic distribution for item j, where
each θj is drawn from β = β1:K unique topics.
Conversely, we introduce ψi as the topic distri-
bution for user i, each φi drawn from β(cid:48) = β1:L.
In our experiment, we chose ψi to be the av-
erage topic space of user i but there are sev-
eral other strategies one could use to represent
the user. Since Matrix Factorization requires
for u, v ∈ RK (the user and item factor ma-
trices have to align), both θ and ψ have to
be drawn from the same topic space or, alter-
natively, topic models of the same magnitude
(| β(cid:48) |=| β |). Since ﬁnding the optimal value
of ψ, θ, u and v given β, β(cid:48) becomes intractable,
our algorithm will only be tested in the case
where β = β(cid:48) so we can assume ψ ≈ θand
use the same EM-style algorithm as in CTR to

4

constraints *(our tests routinely took up to 36
hours on Stanford’s Barley machines due to al-
sqr)* , all tests were run on a random fraction
of the original dataset consisting of 35,341 ar-
ticles.

4.1 Evaluation

Cross-Validation: The training and testing
sets for all tests were split as follows. From
the original M × N matrix containing all user
interactions, a total of m = M/20 user row
indices and n = N/20 item column indices
were randomly selected.
Interactions belong-
ing to these m randomly selected users were
separated into a diﬀerent m × N − n matrix
for user out-of matrix cross validation. Inter-
actions belonging to the n randomly selected
items were also separated, this time into a
M − m× n matrix for user out-of matrix cross
validation. Interactions in both the m selected
rows and n selected columns were discarded.
The remaining bulk of the interactions were
Assigned to a M − m× N − n matrix. Of these
interactions, 10% were randomly selected and
placed in a separate M − m × N − n for in-
matrix prediction cross-validating. The other
90% were used for training the models. The
user and item topic matrices were split and
distributed according to where their represen-
tative rows/columns were assigned during the
shuﬄe. We saw no signiﬁcant changes in our
training and testing recall values when imple-
menting multiple folds of this matrix shuﬄe
split.

In-matrix predictions: Following Blei and
Wang’s prior work, we established our mea-
sures of accuracy to be standard precision and
recall within the ﬁrst 1-200 highest-scored pre-
dictions. For in-matrix recommendations, re-
call consisted of the number of articles recom-
mended to a user that were also in the testing
set over the total number of articles in that
user’s testing set.

Out-of-matrix predictions:
For out-of-
matrix recommendations, recall consisted of
the number of articles recommended to a user
that were also in the out-of-matrix set over the
total number of articles in that user’s out-of-
matrix set.

4.2 Settings

Blei and Wang established that the indepen-
dence of the topic distributions θj relative to
user vectors allowed for the optimal topic dis-
tributions to be found before beginning to op-
timize for ui and vj = j + θj. Consequently,
we used HDP to ﬁnd an optimal topic number
of K = 200 and also set the dimensions of our
latent vectors equal to K. We set α = 1 and it-
erated for values of λv, λu ∈ {.01, .1, 1, 10, 100}
to ﬁnd that λv = 10,λu = .01 gave optimal
results for CTR using 25 training epochs. Val-
ues of λv = 10, λu = .1 gave optimal re-
sults for CN. As prior literature had already
shown CTR outperforms CF, we simply used
K = 200, λu = λv = 0.01 for our CTR iter-
ations to provide a point of reference without
optimizing the parameters.

4.3 Results:

Comparisons: Our algorithm performed bet-
ter than Collaborative Filtering and compa-
rable to Collaborative Topic Regression when
performing in-matrix recommendations. This
is consistent with prior research on the perfor-
mance of CTR. In our particular dataset, we
found that recall using CN was almost iden-
tical to that measured using CTR during the
ﬁrst predictions and consistently higher than
CTR in the ranges after 20 predictions. This
could mean that our algorithm generally per-
forms better in-matrix recommendations than
CTR but it could also be attributed to the
more direct topical connections of our dataset.

5

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

”liked” by researchers.

To address the shortcomings of CF, David
M. Blei and Chong Wang recently devel-
oped Collaborative Topic Regression (CTR)
[0]. Much like CF, CTR assigns latent features
to every user and item based on prior user-
item interactions. However, CTR diﬀers from
CF in its usage of Latent Dirichlet Allocation
(LDA) to construct topic distributions (drawn
from β = β1:K unique topics) for every item.
Rather than describing vj as an exclusively la-
tent factor-based vector, Blei et al.
choose
to describe the item vector as vj = θj + j,
where θj ∈ RK represents the LDA derived
topic distribution of item j, and j
is a la-
tent variable that captures ﬂuctuations away
from the topic distribution. These latent oﬀ-
sets augment the content similarity-based ap-
proach through the ﬂexibility that they aﬀord
the model to understand hidden features about
items and users. Since regularization for the
topic-enhanced items must inherently be dif-
ferent than that for pure-latent users, separate
parameters λu and λv are applied to user and
item feature vectors respectively. The resulting
log-likelihood function is intractable; a type of
Expectation Maxmization algorithm is there-
fore used to arrive upon the optimal parame-
ters.

(cid:80)
n log((cid:80)
(cid:80)

i uT

i ui − λv

(cid:80)
j(vj − θj)T (vj − θj)
2 (rij − uT

k θjkβk, wjn) −(cid:80)

cij

i,j

2

L = − λu

2

+(cid:80)

j

(4)

i vj)2

The derived update rules for u and v then

become:

ui ← (V CiV T + λuI)−1V CiPi
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(5)

ated: q(θ, z | γ, φ) = q(θ | γ)(cid:81)

Given u and v, the topic proportions are
learned by variational inference; a family of
distributions on the latent variables is gener-
n q(zn | φn) and
Jensen’s inequality is applied to ﬁnd the tight
lower bound for the log likelihood function be-
low.

3

+(cid:80)

n

(cid:80)

2 (vj − θj)T (vj − θj)

L ≥ − λv
k φjnk(logθjkβk, wjn − logφjkn)

(6)

The free variational parameters upon which
the distributions are generated are optimized
by minimizing the Kullback Leibler (KL) di-
vergence between the variational distribution
and the true posterior. The resulting update
equations, for determining θ and β are given
below

φni ∝ βiwnexp{Eq[logθi | γ]}

γi = αi +

φi

(cid:88)

(7)

(8)

n

The predicted rating variable ˆri,j

for in-

matrix predictions is then computed by:

ˆri,j = uT

i vj = uT

i (θj + j)

(9)

When an item is new and in-matrix pre-
diction is not possible, the rating variable is
computed ignoring the latent oﬀset:

ˆri,j = uT

i θj

(10)

Consequently, users are still represented by
latent factors but items are represented by a
combination of their topical distribution and a
latent factor oﬀset; the latter aiming to capture
variables conducive to a user-item interaction
that are not related to the item’s topic. CTR
was shown to perform better as a recommender
system than Collaborative Filtering using both
latent factor and content-based methods.

3 Collaborative Neighbors

Given the performance improvement CTR saw
by introducing topic modeling for the items, we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy. In this section we describe

the resulting algorithm, Collaborative Neigh-
bors.

As in CTR, our users are I researchers and
our items are J scientiﬁc articles. The prefer-
ence variable pi,j ∈ 0, 1 indicates whether or
not user i cited article j. The preference vari-
able is computed from the predicted ratings as
in eq.
(1) and the predicted rating variable
remains ˆri,j = uT

i vj.

optimize for the topic distributions. The most
important diﬀerence is that our update rules
for ui, vj now become:

ui ← (V CiV T + λuI)−1(V CiPi + λuψi)
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(11)
Our algorithm then additionally has to incor-
porate topic modeling for the users in the same
way as CTR does it for the items.

4 Experimental Study

Dataset: A total of 1.2 millions articles were re-
trieved from the PubMed open access dataset.
We parsed the title, abstract, authors, key-
words and citations associated with each arti-
cle. We removed articles missing any one of the
ﬁelds of interest to obtain a dataset of 129,531
scientiﬁc articles.

Articles: For each article, we concatenated
its title, abstract and keywords into a docu-
ment. We then removed all english stop-words
and built a vocabulary consisting of the X
words that appeared in our corpus more than
once. Next, we used a Hierarchical Dirichlet
Process (HDP) model on our dataset to deter-
mine the number of K topics contained within,
and subsequently ran LDA to determine the
K-vector topic distribution for each article.

Users:

1.5 million unique authors were
identiﬁed in the initial open access dataset.
User-article interactions were generated by
mapping users to all the citations that they
had across all their publications. We removed
self citations (where an author cites their past
work) and ﬁltered out users that had cited
fewer than 10 papers in our dataset. Our ﬁnal
user item matrix consisted of 26,152 users by
129,531 thousand articles, with an average of
16.9 interactions (citations) per user and 12.5
publications per user. Lastly, we assigned a
topic distribution to each user by taking the
average topic distribution of all papers they
had co/authored. Because of computational

We now introduce a way to represent topic pro-
portions for both users and items. We denote
θj as the topic distribution for item j, where
each θj is drawn from β = β1:K unique topics.
Conversely, we introduce ψi as the topic distri-
bution for user i, each φi drawn from β(cid:48) = β1:L.
In our experiment, we chose ψi to be the av-
erage topic space of user i but there are sev-
eral other strategies one could use to represent
the user. Since Matrix Factorization requires
for u, v ∈ RK (the user and item factor ma-
trices have to align), both θ and ψ have to
be drawn from the same topic space or, alter-
natively, topic models of the same magnitude
(| β(cid:48) |=| β |). Since ﬁnding the optimal value
of ψ, θ, u and v given β, β(cid:48) becomes intractable,
our algorithm will only be tested in the case
where β = β(cid:48) so we can assume ψ ≈ θand
use the same EM-style algorithm as in CTR to

4

constraints *(our tests routinely took up to 36
hours on Stanford’s Barley machines due to al-
sqr)* , all tests were run on a random fraction
of the original dataset consisting of 35,341 ar-
ticles.

4.1 Evaluation

Cross-Validation: The training and testing
sets for all tests were split as follows. From
the original M × N matrix containing all user
interactions, a total of m = M/20 user row
indices and n = N/20 item column indices
were randomly selected.
Interactions belong-
ing to these m randomly selected users were
separated into a diﬀerent m × N − n matrix
for user out-of matrix cross validation. Inter-
actions belonging to the n randomly selected
items were also separated, this time into a
M − m× n matrix for user out-of matrix cross
validation. Interactions in both the m selected
rows and n selected columns were discarded.
The remaining bulk of the interactions were
Assigned to a M − m× N − n matrix. Of these
interactions, 10% were randomly selected and
placed in a separate M − m × N − n for in-
matrix prediction cross-validating. The other
90% were used for training the models. The
user and item topic matrices were split and
distributed according to where their represen-
tative rows/columns were assigned during the
shuﬄe. We saw no signiﬁcant changes in our
training and testing recall values when imple-
menting multiple folds of this matrix shuﬄe
split.

In-matrix predictions: Following Blei and
Wang’s prior work, we established our mea-
sures of accuracy to be standard precision and
recall within the ﬁrst 1-200 highest-scored pre-
dictions. For in-matrix recommendations, re-
call consisted of the number of articles recom-
mended to a user that were also in the testing
set over the total number of articles in that
user’s testing set.

Out-of-matrix predictions:
For out-of-
matrix recommendations, recall consisted of
the number of articles recommended to a user
that were also in the out-of-matrix set over the
total number of articles in that user’s out-of-
matrix set.

4.2 Settings

Blei and Wang established that the indepen-
dence of the topic distributions θj relative to
user vectors allowed for the optimal topic dis-
tributions to be found before beginning to op-
timize for ui and vj = j + θj. Consequently,
we used HDP to ﬁnd an optimal topic number
of K = 200 and also set the dimensions of our
latent vectors equal to K. We set α = 1 and it-
erated for values of λv, λu ∈ {.01, .1, 1, 10, 100}
to ﬁnd that λv = 10,λu = .01 gave optimal
results for CTR using 25 training epochs. Val-
ues of λv = 10, λu = .1 gave optimal re-
sults for CN. As prior literature had already
shown CTR outperforms CF, we simply used
K = 200, λu = λv = 0.01 for our CTR iter-
ations to provide a point of reference without
optimizing the parameters.

4.3 Results:

Comparisons: Our algorithm performed bet-
ter than Collaborative Filtering and compa-
rable to Collaborative Topic Regression when
performing in-matrix recommendations. This
is consistent with prior research on the perfor-
mance of CTR. In our particular dataset, we
found that recall using CN was almost iden-
tical to that measured using CTR during the
ﬁrst predictions and consistently higher than
CTR in the ranges after 20 predictions. This
could mean that our algorithm generally per-
forms better in-matrix recommendations than
CTR but it could also be attributed to the
more direct topical connections of our dataset.

5

For item out-of-matrix predictions, our al-
gorithm demonstrated having considerably
higher recall ﬁgures compared to CTR, indi-
cating the value of our algorithm is strongest
when performing cold-start recommendations.
We attempted to perform user out-of-matrix
predictions multiple times with no more suc-
cess than random recommendations. We at-
tribute this failure to the strategy we used to
establish the user topic space as an averaging
of a user’s publications is likely to be similar
to too many publications without much speci-
ﬁcity.

Examining user Proﬁles: We can explicitly
analyze user proﬁles from the LDA representa-
tion of topics that were generated by averaging
the topic distribution across all their publica-
tions. With CN, we are able to extend the
analysis further by analyzing the magnitude of
each latent oﬀset from the authors topic dis-
tribution. These oﬀsets represent large devi-
ations of an author’s preferences, from their
core topics of research. For instance, a ﬁnan-
cial engineer might apply electrical engineering

6

signal processing techniques to ﬁlter time se-
ries data in his/her research. More generally,
these oﬀsets capture passive interests that can
allow recommender systems to make more in-
formed judgments on what to recommend. In
our dataset, we observe the topic associated
with words such as south, variation, india, asia,
geographic and madagascar exhibit the largest
oﬀsets.
Examining Article Characteristics: Sim-
ilarly CN allows us to understand which top-
ics attract a broad range of interest from re-
searchers from a diversity of ﬁelds. We ac-
complish this analysis by calculating the aver-
age magnitude of each item latent feature oﬀ-
set. Topics with a large oﬀsetting magnitudes
on the item side, tend to be topics that have
been cited by users in a variety of ﬁelds.
In
our dataset we observe topics associated with
words such as world, skin, biodiversity and
communities to have the largest oﬀsets.

5 Conclusions

We demonstrate in this study the ability of
Collaborative Neighbourhoods of predicting
the citations made by researchers in medical
literature. We obtain results that are supe-
rior to traditional Collaborative Filtering and
Collaborative Topic Regression in in-matrix
and out-of-matrix predictions. Furthermore,
we demonstrate the ability our model to de-
velop a semantic understanding of an author’s
preferences, as well as to identify the types of
articles that enjoy the most reception from a
variety of ﬁelds. Our method can be gener-
ally applied to any user-item recommendation
problem where there is suﬃcient information
about each user. Future work will focus on
eliciting further meaning from the latent fea-
tures derived, and augmenting the ability of
CN to recommend items to users whose prior
interactions have not been observed.

Collaborative Neighborhoods

Diego Represas, David Dindi

diegorep,ddindi@stanford.edu

December 13, 2014

Abstract

Finding relevant research publications is a growing problem for researchers across all
ﬁelds. Online platforms such as Mendeley and CiteULike have attempted to address
this need by providing researchers the ability to share relevant articles with one another.
These platforms have further sought to extend their capabilities by recommending articles
to users based on the user’s past interactions and preferences. The models that underlie
these methods, however, are unable to provide recommendations on an item for which
no prior interactions have been observed. To solve this issue, we propose Collaborative
Neighborhoods (CN). CN combines elements of Collaborative Topic Regression [0] and
Nearest Neighbor Models [1] to provide meaningful recommendations in both the pres-
ence and absence of past user interactions with items. We assess the performance of CN
on dataset of 129,531 articles sourced from PubMed, and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks.

1

Introduction

Researchers today are inundated with in-
formation; 2 million peer-reviewed articles are
published every year [2]. The diﬃculty in ﬁnd-
ing relevant articles amidst this abundance of
information has prompted citation manage-
ment platforms like Mendeley and CiteULike
to implement recommendation systems to aid
researchers in the search [13]. These systems
recommend articles based on implicit user pref-
erences learned from a user’s past article as-
sociations ( likes, shares or additions to one’s
personal archive.)

Several collaborative ﬁltering recommenda-
tion models have been proposed to aide in the
implicit learning of user preferences. Collabo-
rative Topic Regression (CTR) [0] has been the

most promising model thus far. CTR applies
topic modeling to augment the item feature
vector used in traditional collaborative ﬁlter-
ing. The limitation of CTR, however, is its rep-
resentation of users by latent features alone.
In the absence of information on past user-
article associations, these user latent features
cannot be accurately predicted. Consequently,
CTR performs poorly on users that have fewer
article associations.

We address CTRs shortcomings with CN.
CN not only applies topic modeling to augment
the latent feature representation of items, but
does so as well for the latent feature represen-
tation of users. We begin by representing users
and items by their associated topic distribu-
tions. We then proceed by learning latent vari-
ables that oﬀset these distributions using past

1

observations of user-article interactions. These
oﬀsets capture hidden interests that an author
may have in ﬁelds that are outside their main
area of research. Given that CN attributes
both explicit and implicit content features to
every user, it is capable both of understanding
hidden preferences , and providing recommen-
dations to users for whom there is insuﬃcient
information to learn implicit preferences.

2 Background

A basic approach to recommending text
items has been to do so based on content
similarity. Such methods employ probabilistic
models and similarity scoring to deﬁne an ar-
ticle’s content [3,4,5,6], or matrix factorization
methods such as content-based Collaborative
Filtering (CBCF) to provide recommendations
to users [7,8,9]. For our particular problem, an
article j’s content can be thought oﬀ as a topic
distribution vector, θj ∈ RK, across Ktopics.
When a new item is introduced, a similarity
function (e.g. cosine similarity) is used to de-
termine the k items that are most similar to
the new item. The new item is then recom-
mended to users who in the past have rated
any of the k items favourably

Despite their intuitive appeal, similarity
and neighborhood models (such as k-Nearest
Neighbors) are inadequate for providing rec-
ommendations in research literature. This in-
adequacy stems from the fact that content
similarity alone is not suﬃcient to determine
whether or not an author would cite an ar-
ticle. A neighborhood model,
for instance,
would recommend an article that is of little
intrinsic value to a user, solely because the
article contains topics that the user has ref-
erenced in the past. This dependence on ex-
plicit features prevents neighbourhood models
from capturing hidden preferences of a user.
Some of the most popular market recom-

mendation systems, including the one used by
Mendeley, are based on Collaborative Filter-
ing (CF) methods using latent factor models
[10,11,12,13,14].
In these models, the rating
that a user j attributes to item i can be pre-
dicted through the rating function ˆri,j = uT
i vj,
where ui ∈ RK is the latent factor vector for
user i and vj ∈ RK. An eﬀective approach for
implicit feedback datasets is to translate the
continuous-value rating into the implicit space
by setting the preference variable as follows [1,
12]:

(cid:26) 1 ˆri,j > 0

0 ˆri,j = 0

ˆpi,j =

(1)

Because not all values of ˆri,j > 0 are equally
likely to predict a user-item interaction, a con-
ﬁdence variable ci,j = 1+αf (ri,j) is introduced
to measure the conﬁdence of observing pi,j = 1.
The constant α is a learning rate constant and
f (ri,j) is an empirical function that depends
on the dataset. The latent factor vectors ui
and vj are then computed by minimizing the
objective function:

(cid:80)

min
u,v

i,j ci,j(pi,j − uT

i vj)2 + λ

(cid:16)(cid:80)
i (cid:107)ui(cid:107)2 +(cid:80)

j (cid:107)vj(cid:107)2(cid:17)

(2)
The following update rules for both latent vec-
tors are then derived from the objective func-
tion:

ui ← (V CiV T + λI)−1V CiPi
vj ← (U CjU T + λI)−1U CjPj

(3)

Where U, V are the user and item latent
factor matrices, C is the conﬁdence variable
matrix and P is the preference variable ma-
trix. Updates are thus performed through an
alternating least-squares model.

Recommender systems based on latent fac-
tor models have been shown to provide better
recommendations than neighborhood methods
[15,12]. However, because CF relies on observ-
ing prior user-item interactions to provide rec-
ommendations, it is unable to recommend ar-
ticles that have not been previously cited or

2

”liked” by researchers.

To address the shortcomings of CF, David
M. Blei and Chong Wang recently devel-
oped Collaborative Topic Regression (CTR)
[0]. Much like CF, CTR assigns latent features
to every user and item based on prior user-
item interactions. However, CTR diﬀers from
CF in its usage of Latent Dirichlet Allocation
(LDA) to construct topic distributions (drawn
from β = β1:K unique topics) for every item.
Rather than describing vj as an exclusively la-
tent factor-based vector, Blei et al.
choose
to describe the item vector as vj = θj + j,
where θj ∈ RK represents the LDA derived
topic distribution of item j, and j
is a la-
tent variable that captures ﬂuctuations away
from the topic distribution. These latent oﬀ-
sets augment the content similarity-based ap-
proach through the ﬂexibility that they aﬀord
the model to understand hidden features about
items and users. Since regularization for the
topic-enhanced items must inherently be dif-
ferent than that for pure-latent users, separate
parameters λu and λv are applied to user and
item feature vectors respectively. The resulting
log-likelihood function is intractable; a type of
Expectation Maxmization algorithm is there-
fore used to arrive upon the optimal parame-
ters.

(cid:80)
n log((cid:80)
(cid:80)

i uT

i ui − λv

(cid:80)
j(vj − θj)T (vj − θj)
2 (rij − uT

k θjkβk, wjn) −(cid:80)

cij

i,j

2

L = − λu

2

+(cid:80)

j

(4)

i vj)2

The derived update rules for u and v then

become:

ui ← (V CiV T + λuI)−1V CiPi
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(5)

ated: q(θ, z | γ, φ) = q(θ | γ)(cid:81)

Given u and v, the topic proportions are
learned by variational inference; a family of
distributions on the latent variables is gener-
n q(zn | φn) and
Jensen’s inequality is applied to ﬁnd the tight
lower bound for the log likelihood function be-
low.

3

+(cid:80)

n

(cid:80)

2 (vj − θj)T (vj − θj)

L ≥ − λv
k φjnk(logθjkβk, wjn − logφjkn)

(6)

The free variational parameters upon which
the distributions are generated are optimized
by minimizing the Kullback Leibler (KL) di-
vergence between the variational distribution
and the true posterior. The resulting update
equations, for determining θ and β are given
below

φni ∝ βiwnexp{Eq[logθi | γ]}

γi = αi +

φi

(cid:88)

(7)

(8)

n

The predicted rating variable ˆri,j

for in-

matrix predictions is then computed by:

ˆri,j = uT

i vj = uT

i (θj + j)

(9)

When an item is new and in-matrix pre-
diction is not possible, the rating variable is
computed ignoring the latent oﬀset:

ˆri,j = uT

i θj

(10)

Consequently, users are still represented by
latent factors but items are represented by a
combination of their topical distribution and a
latent factor oﬀset; the latter aiming to capture
variables conducive to a user-item interaction
that are not related to the item’s topic. CTR
was shown to perform better as a recommender
system than Collaborative Filtering using both
latent factor and content-based methods.

3 Collaborative Neighbors

Given the performance improvement CTR saw
by introducing topic modeling for the items, we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy. In this section we describe

the resulting algorithm, Collaborative Neigh-
bors.

As in CTR, our users are I researchers and
our items are J scientiﬁc articles. The prefer-
ence variable pi,j ∈ 0, 1 indicates whether or
not user i cited article j. The preference vari-
able is computed from the predicted ratings as
in eq.
(1) and the predicted rating variable
remains ˆri,j = uT

i vj.

optimize for the topic distributions. The most
important diﬀerence is that our update rules
for ui, vj now become:

ui ← (V CiV T + λuI)−1(V CiPi + λuψi)
vj ← (U CjU T + λvI)−1(U CjPj + λvθj)

(11)
Our algorithm then additionally has to incor-
porate topic modeling for the users in the same
way as CTR does it for the items.

4 Experimental Study

Dataset: A total of 1.2 millions articles were re-
trieved from the PubMed open access dataset.
We parsed the title, abstract, authors, key-
words and citations associated with each arti-
cle. We removed articles missing any one of the
ﬁelds of interest to obtain a dataset of 129,531
scientiﬁc articles.

Articles: For each article, we concatenated
its title, abstract and keywords into a docu-
ment. We then removed all english stop-words
and built a vocabulary consisting of the X
words that appeared in our corpus more than
once. Next, we used a Hierarchical Dirichlet
Process (HDP) model on our dataset to deter-
mine the number of K topics contained within,
and subsequently ran LDA to determine the
K-vector topic distribution for each article.

Users:

1.5 million unique authors were
identiﬁed in the initial open access dataset.
User-article interactions were generated by
mapping users to all the citations that they
had across all their publications. We removed
self citations (where an author cites their past
work) and ﬁltered out users that had cited
fewer than 10 papers in our dataset. Our ﬁnal
user item matrix consisted of 26,152 users by
129,531 thousand articles, with an average of
16.9 interactions (citations) per user and 12.5
publications per user. Lastly, we assigned a
topic distribution to each user by taking the
average topic distribution of all papers they
had co/authored. Because of computational

We now introduce a way to represent topic pro-
portions for both users and items. We denote
θj as the topic distribution for item j, where
each θj is drawn from β = β1:K unique topics.
Conversely, we introduce ψi as the topic distri-
bution for user i, each φi drawn from β(cid:48) = β1:L.
In our experiment, we chose ψi to be the av-
erage topic space of user i but there are sev-
eral other strategies one could use to represent
the user. Since Matrix Factorization requires
for u, v ∈ RK (the user and item factor ma-
trices have to align), both θ and ψ have to
be drawn from the same topic space or, alter-
natively, topic models of the same magnitude
(| β(cid:48) |=| β |). Since ﬁnding the optimal value
of ψ, θ, u and v given β, β(cid:48) becomes intractable,
our algorithm will only be tested in the case
where β = β(cid:48) so we can assume ψ ≈ θand
use the same EM-style algorithm as in CTR to

4

constraints *(our tests routinely took up to 36
hours on Stanford’s Barley machines due to al-
sqr)* , all tests were run on a random fraction
of the original dataset consisting of 35,341 ar-
ticles.

4.1 Evaluation

Cross-Validation: The training and testing
sets for all tests were split as follows. From
the original M × N matrix containing all user
interactions, a total of m = M/20 user row
indices and n = N/20 item column indices
were randomly selected.
Interactions belong-
ing to these m randomly selected users were
separated into a diﬀerent m × N − n matrix
for user out-of matrix cross validation. Inter-
actions belonging to the n randomly selected
items were also separated, this time into a
M − m× n matrix for user out-of matrix cross
validation. Interactions in both the m selected
rows and n selected columns were discarded.
The remaining bulk of the interactions were
Assigned to a M − m× N − n matrix. Of these
interactions, 10% were randomly selected and
placed in a separate M − m × N − n for in-
matrix prediction cross-validating. The other
90% were used for training the models. The
user and item topic matrices were split and
distributed according to where their represen-
tative rows/columns were assigned during the
shuﬄe. We saw no signiﬁcant changes in our
training and testing recall values when imple-
menting multiple folds of this matrix shuﬄe
split.

In-matrix predictions: Following Blei and
Wang’s prior work, we established our mea-
sures of accuracy to be standard precision and
recall within the ﬁrst 1-200 highest-scored pre-
dictions. For in-matrix recommendations, re-
call consisted of the number of articles recom-
mended to a user that were also in the testing
set over the total number of articles in that
user’s testing set.

Out-of-matrix predictions:
For out-of-
matrix recommendations, recall consisted of
the number of articles recommended to a user
that were also in the out-of-matrix set over the
total number of articles in that user’s out-of-
matrix set.

4.2 Settings

Blei and Wang established that the indepen-
dence of the topic distributions θj relative to
user vectors allowed for the optimal topic dis-
tributions to be found before beginning to op-
timize for ui and vj = j + θj. Consequently,
we used HDP to ﬁnd an optimal topic number
of K = 200 and also set the dimensions of our
latent vectors equal to K. We set α = 1 and it-
erated for values of λv, λu ∈ {.01, .1, 1, 10, 100}
to ﬁnd that λv = 10,λu = .01 gave optimal
results for CTR using 25 training epochs. Val-
ues of λv = 10, λu = .1 gave optimal re-
sults for CN. As prior literature had already
shown CTR outperforms CF, we simply used
K = 200, λu = λv = 0.01 for our CTR iter-
ations to provide a point of reference without
optimizing the parameters.

4.3 Results:

Comparisons: Our algorithm performed bet-
ter than Collaborative Filtering and compa-
rable to Collaborative Topic Regression when
performing in-matrix recommendations. This
is consistent with prior research on the perfor-
mance of CTR. In our particular dataset, we
found that recall using CN was almost iden-
tical to that measured using CTR during the
ﬁrst predictions and consistently higher than
CTR in the ranges after 20 predictions. This
could mean that our algorithm generally per-
forms better in-matrix recommendations than
CTR but it could also be attributed to the
more direct topical connections of our dataset.

5

For item out-of-matrix predictions, our al-
gorithm demonstrated having considerably
higher recall ﬁgures compared to CTR, indi-
cating the value of our algorithm is strongest
when performing cold-start recommendations.
We attempted to perform user out-of-matrix
predictions multiple times with no more suc-
cess than random recommendations. We at-
tribute this failure to the strategy we used to
establish the user topic space as an averaging
of a user’s publications is likely to be similar
to too many publications without much speci-
ﬁcity.

Examining user Proﬁles: We can explicitly
analyze user proﬁles from the LDA representa-
tion of topics that were generated by averaging
the topic distribution across all their publica-
tions. With CN, we are able to extend the
analysis further by analyzing the magnitude of
each latent oﬀset from the authors topic dis-
tribution. These oﬀsets represent large devi-
ations of an author’s preferences, from their
core topics of research. For instance, a ﬁnan-
cial engineer might apply electrical engineering

6

signal processing techniques to ﬁlter time se-
ries data in his/her research. More generally,
these oﬀsets capture passive interests that can
allow recommender systems to make more in-
formed judgments on what to recommend. In
our dataset, we observe the topic associated
with words such as south, variation, india, asia,
geographic and madagascar exhibit the largest
oﬀsets.
Examining Article Characteristics: Sim-
ilarly CN allows us to understand which top-
ics attract a broad range of interest from re-
searchers from a diversity of ﬁelds. We ac-
complish this analysis by calculating the aver-
age magnitude of each item latent feature oﬀ-
set. Topics with a large oﬀsetting magnitudes
on the item side, tend to be topics that have
been cited by users in a variety of ﬁelds.
In
our dataset we observe topics associated with
words such as world, skin, biodiversity and
communities to have the largest oﬀsets.

5 Conclusions

We demonstrate in this study the ability of
Collaborative Neighbourhoods of predicting
the citations made by researchers in medical
literature. We obtain results that are supe-
rior to traditional Collaborative Filtering and
Collaborative Topic Regression in in-matrix
and out-of-matrix predictions. Furthermore,
we demonstrate the ability our model to de-
velop a semantic understanding of an author’s
preferences, as well as to identify the types of
articles that enjoy the most reception from a
variety of ﬁelds. Our method can be gener-
ally applied to any user-item recommendation
problem where there is suﬃcient information
about each user. Future work will focus on
eliciting further meaning from the latent fea-
tures derived, and augmenting the ability of
CN to recommend items to users whose prior
interactions have not been observed.

References

[0] Wang, Chong and David M. Blei. ”Collaborative Topic Modeling for Recommending Scien-
tiﬁc Articles.” Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. New York, NY, USA: ACM, 2011, 448-456.

[1] Hu, Y., Y. Koren, and C. Volinsky. Collaborative ﬁltering for implicit feedback datasets.”

Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on. 2009

[2] ”STM International Association of Scientiﬁc, Technical and Medical Publishers.” STM.

N.p., n.d. Web. 13 Dec. 2014.

[3] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. Journal of Machine Learning

Research, 3:9931022, January 2003.

[4] J. Chang, J. Boyd-Graber, S. Gerrish, C. Wang, and D. Blei. Reading tea leaves: How
humans interpret topic models. In Y. Bengio, D. Schuurmans, J. Laﬀerty, C. K. I. Williams,
and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 288296,
2009.

[5] S. M. Gerrish and D. M. Blei. Predicting legislative roll calls from text. In Proceedings

of the 28th Annual International Conference on Machine Learning, ICML 11, 2011.

[6] D. Agarwal and B.-C. Chen. ﬂda: matrix factorization through latent Dirichlet allo-
In Proceedings of the third ACM international conference on Web search and data

cation.
mining, WSDM 10, pages 91100, New York, NY, USA, 2010. ACM.

[7] Content-Based Recommendation Systems Michael J. Pazzani, Daniel Billsus
[8] Burke, R.: Hybrid Web Recommender Systems. In: Brusilovsky, P., Kobsa, A., Nejdl,
W. (eds.) The Adaptive Web: Methods and Strategies of Web Personalization. LNCS, vol.
4321, pp. 377408. Springer, Heidelberg (2007)

[9] Mooney, R. J., and Roy, L. 2000. Content-based book recommending using learning for
text categorization. In Proceedings of the Fifth ACM Conference on Digital Libraries, 195204.
[10] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix factorization using
Markov chain Monte Carlo. In Proceedings of the 25th International Conference on Machine
learning, pages 880887. ACM, 2008.

[11] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. Advances in Neural

Information Processing Systems, 20:12571264, 2008.

[12] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender

systems. IEEE Computer, 42(8):3037, 2009.

[13] D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings
of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,
pages 1928, New York, NY, USA, 2009. ACM.

[14] K. Yu, J. Laﬀerty, S. Zhu, and Y. Gong. Large-scale collaborative prediction using a
nonparametric random eﬀects model. In Proceedings of the 26th Annual International Confer-
ence on Machine Learning, pages 11851192, New York, NY, USA, 2009. ACM.

[15] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework
for performing collaborative ﬁltering. In Proceedings of the 22nd annual international ACM
SIGIR conference on Research and development in information

7

