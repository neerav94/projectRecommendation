Matching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

Matching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

the  algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™ 
for black) from the handwriting sample image. 

 
 
 
 
 
 
 

Author A 

Author B 

Author C 

Fig. 2. Handwriting samples from authors A, B, and C 

IV.  IMAGE PREPROCESSING 

While  there  are  many  image  pre-processing  techniques 
depending  on  the  condition  of  scanned  handwriting,  we 
identified  the  following  three  preprocessing  techniques  as 
crucial to the functionality of handwriting matching algorithm: 

 
1.  Conversion of image to B/W â€“ each pixel will either be 

â€˜1â€™ (for white) or â€˜0â€™ (for black). 
2.  Handwriting size normalization. 
3.  Background removal 
 
We have implemented part 1 and part 2 of the preprocessing 
algorithm  in  MATLAB.  Conversion  to  black  and  white  is 
achieved  using  the  in-built  MATLAB  function  called 
â€˜rgb2grayâ€™.  This  function  uses  the  luminance  equation  to 
convert  RGB  pixels  to  grayscale  numbers.  The  equation 
used is: 
 

0.2989R + 0.5870G + 0.1140B   â€¦   (1) 

 

The  R,  G  and  B  in  the  above  equation  are  respective  color 
channel  values  for  any  given  pixel.  Once  the  image  is 
converted to grayscale, we use the bounding box method to 
normalize  our  image.  In  this,  the  algorithm  first  finds  a 
lower and upper, row and column bounds to fit the image in 
the smallest possible rectangle. The rectangle bounding box 
is  converted  to  a  square  by  expanding  the  smaller  side  to 
make  it  equal  to  the  larger  side.  The  new  pixels  that  get 
added as a result  of this  operation are initialized to â€˜whiteâ€™ 
color. Note that the smaller side is expanded  on  either side 
to automatically center the image. This bounded box image 
can  now  be  scaled  to  any  pixel  resolution  using  the 
MATLAB  function  â€˜imresizeâ€™.  The  default  algorithm  used 
by  â€˜imresizeâ€™  to  scale  the  image  is  bi-cubic  interpolation. 
There  are  other  options  available  as  well,  such  as,  nearest 
neighbor  and  bi-linear  interpolation.  Bi-cubic  interpolation 
performs  a  weighted  average  computation  in  a  4x4 
neighborhood  of  the  pixel  thus  resulting  in  a  more 
smoothened  edge  outputs  for  higher  scaling  factors  as 
compared  to  bilinear  interpolation  which  works  in  a  2x2 
neighborhood. Thus, it was our choice of algorithm.   
 

 
 

Fig.3. Bounding box based size normalization 

 

V.  NAÃVE BAYES ALGORITHM 

NaÃ¯ve  Bayes  algorithm  was  implemented  to  distinguish  the 
handwriting  samples  from  author  A  and  author  B.  We  varied 
the number  of training samples (half and half  from authors A 
and  B)  and  used  100  test  samples  (50  from  author  A  and  50 
from  author  B).  At  each  number  of  training  examples,  the 
average  generalization  error  was  obtained  by  averaging  the 
generalization  error  collected  over  100  runs,  where  each  run 
used different randomly picked training samples. 

To make a prediction on a new test sample, we compare the 

following equations (2) and (3): 
 

p(y = 1|x) =   ğ‘(ğ‘¥|ğ‘¦=1)ğ‘(ğ‘¦=1)

    â€¦   (2) 

ğ‘(ğ‘¥)

 

p(y = 0|x) =   ğ‘(ğ‘¥|ğ‘¦=0)ğ‘(ğ‘¦=0)

   â€¦   (3) 

ğ‘(ğ‘¥)

 
In the equations above, y = 1 means the author is A, and y = 0 
means the author is B. Since we always used half from author 
A  and  half  from  author  B  for  the  training  and  test  samples, 
p(y=0) = p(y=1) = 0.5. Also, 
 

p(x|y = 1) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)

ğ‘›
ğ‘–=1

   â€¦   (4) 

p(x|y = 0) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0)

ğ‘›
ğ‘–=1

   â€¦   (5) 

 

 

Here,  n  is  the  total  number  of  pixels  in  an  image  sample. 
Therefore,  in  a  sample  of  64x64  pixels  image,  n  =  64Ã—64  = 
4096,  which  implies  ğ‘¥ğ‘–  is  the  value  of  ğ‘–ğ‘¡â„  pixel.  To  calculate 
each  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0),  Laplace  smoothing  was 
used: 
 

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 1) =  

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 0) =  

âˆ‘

âˆ‘

ğ‘š
ğ‘–=1

ğ‘š
ğ‘–=1

1{ğ‘¦(ğ‘–)=1}+2

=1 Ë„ ğ‘¦(ğ‘–)=1}+1

(ğ‘–)
1{ğ‘¥ğ‘—
ğ‘š
âˆ‘
ğ‘–=1
 
(ğ‘–)=1 Ë„ ğ‘¦(ğ‘–)=0}+1
1{ğ‘¥ğ‘—
ğ‘š
1{ğ‘¦(ğ‘–)=0}+2
âˆ‘
ğ‘–=1
 

   â€¦   (6) 

   â€¦   (7) 

(ğ‘–)

In  equations  (6)  and  (7),  m  denotes  the  total  number  of 
 means the value of ğ‘—ğ‘¡â„ pixel in the ğ‘–ğ‘¡â„ 
training samples, so ğ‘¥ğ‘—
training sample. 
  To model p(x|y), the NaÃ¯ve Bayes assumption assumes that 
the ğ‘¥ğ‘–â€™s are conditionally independent given y [7]. This means 
that for example we are assuming given the author is A (or B), 
knowing  the  value  of  pixel  â€˜iâ€™  has  no  effect  of  our  beliefs 
about  the  values  of  pixel  â€˜jâ€™.  This  NaÃ¯ve  Bayes  assumption 
does not entirely hold true in this case. Because we know that 
for any handwriting, especially for the high resolution images, 
if a pixel is black so that itâ€™s part of the letter/number, then the 
adjacent  pixels  are  also  likely  to  be  part  of  the  letter/number. 
With 
the  NaÃ¯ve  Bayes  algorithm  was 
implemented  and 
the  generalization  error  results  were 
obtained. 
 

in  mind, 

this 

Matching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

the  algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™ 
for black) from the handwriting sample image. 

 
 
 
 
 
 
 

Author A 

Author B 

Author C 

Fig. 2. Handwriting samples from authors A, B, and C 

IV.  IMAGE PREPROCESSING 

While  there  are  many  image  pre-processing  techniques 
depending  on  the  condition  of  scanned  handwriting,  we 
identified  the  following  three  preprocessing  techniques  as 
crucial to the functionality of handwriting matching algorithm: 

 
1.  Conversion of image to B/W â€“ each pixel will either be 

â€˜1â€™ (for white) or â€˜0â€™ (for black). 
2.  Handwriting size normalization. 
3.  Background removal 
 
We have implemented part 1 and part 2 of the preprocessing 
algorithm  in  MATLAB.  Conversion  to  black  and  white  is 
achieved  using  the  in-built  MATLAB  function  called 
â€˜rgb2grayâ€™.  This  function  uses  the  luminance  equation  to 
convert  RGB  pixels  to  grayscale  numbers.  The  equation 
used is: 
 

0.2989R + 0.5870G + 0.1140B   â€¦   (1) 

 

The  R,  G  and  B  in  the  above  equation  are  respective  color 
channel  values  for  any  given  pixel.  Once  the  image  is 
converted to grayscale, we use the bounding box method to 
normalize  our  image.  In  this,  the  algorithm  first  finds  a 
lower and upper, row and column bounds to fit the image in 
the smallest possible rectangle. The rectangle bounding box 
is  converted  to  a  square  by  expanding  the  smaller  side  to 
make  it  equal  to  the  larger  side.  The  new  pixels  that  get 
added as a result  of this  operation are initialized to â€˜whiteâ€™ 
color. Note that the smaller side is expanded  on  either side 
to automatically center the image. This bounded box image 
can  now  be  scaled  to  any  pixel  resolution  using  the 
MATLAB  function  â€˜imresizeâ€™.  The  default  algorithm  used 
by  â€˜imresizeâ€™  to  scale  the  image  is  bi-cubic  interpolation. 
There  are  other  options  available  as  well,  such  as,  nearest 
neighbor  and  bi-linear  interpolation.  Bi-cubic  interpolation 
performs  a  weighted  average  computation  in  a  4x4 
neighborhood  of  the  pixel  thus  resulting  in  a  more 
smoothened  edge  outputs  for  higher  scaling  factors  as 
compared  to  bilinear  interpolation  which  works  in  a  2x2 
neighborhood. Thus, it was our choice of algorithm.   
 

 
 

Fig.3. Bounding box based size normalization 

 

V.  NAÃVE BAYES ALGORITHM 

NaÃ¯ve  Bayes  algorithm  was  implemented  to  distinguish  the 
handwriting  samples  from  author  A  and  author  B.  We  varied 
the number  of training samples (half and half  from authors A 
and  B)  and  used  100  test  samples  (50  from  author  A  and  50 
from  author  B).  At  each  number  of  training  examples,  the 
average  generalization  error  was  obtained  by  averaging  the 
generalization  error  collected  over  100  runs,  where  each  run 
used different randomly picked training samples. 

To make a prediction on a new test sample, we compare the 

following equations (2) and (3): 
 

p(y = 1|x) =   ğ‘(ğ‘¥|ğ‘¦=1)ğ‘(ğ‘¦=1)

    â€¦   (2) 

ğ‘(ğ‘¥)

 

p(y = 0|x) =   ğ‘(ğ‘¥|ğ‘¦=0)ğ‘(ğ‘¦=0)

   â€¦   (3) 

ğ‘(ğ‘¥)

 
In the equations above, y = 1 means the author is A, and y = 0 
means the author is B. Since we always used half from author 
A  and  half  from  author  B  for  the  training  and  test  samples, 
p(y=0) = p(y=1) = 0.5. Also, 
 

p(x|y = 1) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)

ğ‘›
ğ‘–=1

   â€¦   (4) 

p(x|y = 0) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0)

ğ‘›
ğ‘–=1

   â€¦   (5) 

 

 

Here,  n  is  the  total  number  of  pixels  in  an  image  sample. 
Therefore,  in  a  sample  of  64x64  pixels  image,  n  =  64Ã—64  = 
4096,  which  implies  ğ‘¥ğ‘–  is  the  value  of  ğ‘–ğ‘¡â„  pixel.  To  calculate 
each  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0),  Laplace  smoothing  was 
used: 
 

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 1) =  

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 0) =  

âˆ‘

âˆ‘

ğ‘š
ğ‘–=1

ğ‘š
ğ‘–=1

1{ğ‘¦(ğ‘–)=1}+2

=1 Ë„ ğ‘¦(ğ‘–)=1}+1

(ğ‘–)
1{ğ‘¥ğ‘—
ğ‘š
âˆ‘
ğ‘–=1
 
(ğ‘–)=1 Ë„ ğ‘¦(ğ‘–)=0}+1
1{ğ‘¥ğ‘—
ğ‘š
1{ğ‘¦(ğ‘–)=0}+2
âˆ‘
ğ‘–=1
 

   â€¦   (6) 

   â€¦   (7) 

(ğ‘–)

In  equations  (6)  and  (7),  m  denotes  the  total  number  of 
 means the value of ğ‘—ğ‘¡â„ pixel in the ğ‘–ğ‘¡â„ 
training samples, so ğ‘¥ğ‘—
training sample. 
  To model p(x|y), the NaÃ¯ve Bayes assumption assumes that 
the ğ‘¥ğ‘–â€™s are conditionally independent given y [7]. This means 
that for example we are assuming given the author is A (or B), 
knowing  the  value  of  pixel  â€˜iâ€™  has  no  effect  of  our  beliefs 
about  the  values  of  pixel  â€˜jâ€™.  This  NaÃ¯ve  Bayes  assumption 
does not entirely hold true in this case. Because we know that 
for any handwriting, especially for the high resolution images, 
if a pixel is black so that itâ€™s part of the letter/number, then the 
adjacent  pixels  are  also  likely  to  be  part  of  the  letter/number. 
With 
the  NaÃ¯ve  Bayes  algorithm  was 
implemented  and 
the  generalization  error  results  were 
obtained. 
 

in  mind, 

this 

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

W I T H O U T  S I Z E - N O R M A L I Z A T I O N

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

U S I N G   S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

40

35

30

25

20

15

10

5

0

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

45

40

35

30

25

20

15

10

5

0

0

20

40

60

80

100

0

20

40

60

80

100

120

NUMBER OF TRAINING SAMPLES

NUMBER OF TRAINING SAMPLES

 

(64x64 

samples 

 
Fig. 4. NaÃ¯ve Bayes generalization error without size-normalization and centering 
 
Refer  to  Fig.  4  for  the  generalization  error  of  NaÃ¯ve  Bayes 
without  size-normalization  and  centering.  The  16x16  images 
resulted in the lowest generalization  error of 5%, followed by 
32x32  (7%),  64x64  (9%),  8x8  (13%)  images.  The  higher 
resolution 
and  32x32)  had  higher 
generalization  error  compared  to  the  16x16  images  because 
the  number  of  training  samples  were  not  enough  to  generate 
an  accurate  result.  For  example  a  64x64  image  has  4096 
features (pixels), and 100 training samples were not sufficient 
compared  to  the  number  of  features  in  each  image.  For  the 
16x16 training images, the number of  feature is 16Ã—16 = 256, 
which  is  comparable  to  the  100  samples.  As  for  the  8x8 
samples,  the  performance  was  worse  than  16x16  images 
because  they  lost  too  much  of  the  original  characteristics  of 
the  handwriting.  However,  note  that  even  at  the  lowest 
resolution  of  8x8  pixels,  the  algorithm  still  achieved  13% 
generalization  error.  This  is  impressive  considering  that  an 
8x8  resolution image has such a low resolution that  it is hard 
to recognize even by human eyes, as shown in Fig. 1.  
 

 

 
Fig. 5. NaÃ¯ve Bayes generalization error using size-normalization and centering 
 
Refer  to  Fig.  5  for  the  generalization  error  of  NaÃ¯ve  Bayes 
using  size-normalization  and  centering.  The  results  were 
worse than without using size-normalization and centering for 
all image resolutions. Size-normalization and centering did not 
improve  the  performance  of  NaÃ¯ve  Bayes.  We  think  this  is 
because size-normalization and centering actually reduced the 
difference  of  the  writing  samples  from  the  two  authors.  For 
example,  if  one  author  generally  writes  big  and  the  other 
author  have  smaller  handwriting,  this  difference  will  be 
reflected in the  raw image. NaÃ¯ve  Bayes algorithm then picks 
up  this  difference  in  the  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0) 
calculation to make the prediction. However if the images are 
size-normalized,  then  the  writing  samples  from  the  two 
authors  will  be  scaled  to  similar  sizes,  and  they  will  become 
more  similar  compared  to  the  raw  images.  With  more 
similarity, the prediction will become less accurate, and this is 
why  the  generalization  of  NaÃ¯ve  Bayes  algorithm  increased 
when using the size-normalization and centering. 
 

Naive Bayes Effect of Size-normalization and Centering

)

%

Without size-normalization and centering

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

Using size-normalization and centering

15

9

9

7

16

5

20

13

20
15
10
5
0

64x64

32x32

16x16

8x8

Different resolutions using 100 training samples

Fig. 6. NaÃ¯ve Bayes effect of size-normalization and centering 

 

Matching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

the  algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™ 
for black) from the handwriting sample image. 

 
 
 
 
 
 
 

Author A 

Author B 

Author C 

Fig. 2. Handwriting samples from authors A, B, and C 

IV.  IMAGE PREPROCESSING 

While  there  are  many  image  pre-processing  techniques 
depending  on  the  condition  of  scanned  handwriting,  we 
identified  the  following  three  preprocessing  techniques  as 
crucial to the functionality of handwriting matching algorithm: 

 
1.  Conversion of image to B/W â€“ each pixel will either be 

â€˜1â€™ (for white) or â€˜0â€™ (for black). 
2.  Handwriting size normalization. 
3.  Background removal 
 
We have implemented part 1 and part 2 of the preprocessing 
algorithm  in  MATLAB.  Conversion  to  black  and  white  is 
achieved  using  the  in-built  MATLAB  function  called 
â€˜rgb2grayâ€™.  This  function  uses  the  luminance  equation  to 
convert  RGB  pixels  to  grayscale  numbers.  The  equation 
used is: 
 

0.2989R + 0.5870G + 0.1140B   â€¦   (1) 

 

The  R,  G  and  B  in  the  above  equation  are  respective  color 
channel  values  for  any  given  pixel.  Once  the  image  is 
converted to grayscale, we use the bounding box method to 
normalize  our  image.  In  this,  the  algorithm  first  finds  a 
lower and upper, row and column bounds to fit the image in 
the smallest possible rectangle. The rectangle bounding box 
is  converted  to  a  square  by  expanding  the  smaller  side  to 
make  it  equal  to  the  larger  side.  The  new  pixels  that  get 
added as a result  of this  operation are initialized to â€˜whiteâ€™ 
color. Note that the smaller side is expanded  on  either side 
to automatically center the image. This bounded box image 
can  now  be  scaled  to  any  pixel  resolution  using  the 
MATLAB  function  â€˜imresizeâ€™.  The  default  algorithm  used 
by  â€˜imresizeâ€™  to  scale  the  image  is  bi-cubic  interpolation. 
There  are  other  options  available  as  well,  such  as,  nearest 
neighbor  and  bi-linear  interpolation.  Bi-cubic  interpolation 
performs  a  weighted  average  computation  in  a  4x4 
neighborhood  of  the  pixel  thus  resulting  in  a  more 
smoothened  edge  outputs  for  higher  scaling  factors  as 
compared  to  bilinear  interpolation  which  works  in  a  2x2 
neighborhood. Thus, it was our choice of algorithm.   
 

 
 

Fig.3. Bounding box based size normalization 

 

V.  NAÃVE BAYES ALGORITHM 

NaÃ¯ve  Bayes  algorithm  was  implemented  to  distinguish  the 
handwriting  samples  from  author  A  and  author  B.  We  varied 
the number  of training samples (half and half  from authors A 
and  B)  and  used  100  test  samples  (50  from  author  A  and  50 
from  author  B).  At  each  number  of  training  examples,  the 
average  generalization  error  was  obtained  by  averaging  the 
generalization  error  collected  over  100  runs,  where  each  run 
used different randomly picked training samples. 

To make a prediction on a new test sample, we compare the 

following equations (2) and (3): 
 

p(y = 1|x) =   ğ‘(ğ‘¥|ğ‘¦=1)ğ‘(ğ‘¦=1)

    â€¦   (2) 

ğ‘(ğ‘¥)

 

p(y = 0|x) =   ğ‘(ğ‘¥|ğ‘¦=0)ğ‘(ğ‘¦=0)

   â€¦   (3) 

ğ‘(ğ‘¥)

 
In the equations above, y = 1 means the author is A, and y = 0 
means the author is B. Since we always used half from author 
A  and  half  from  author  B  for  the  training  and  test  samples, 
p(y=0) = p(y=1) = 0.5. Also, 
 

p(x|y = 1) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)

ğ‘›
ğ‘–=1

   â€¦   (4) 

p(x|y = 0) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0)

ğ‘›
ğ‘–=1

   â€¦   (5) 

 

 

Here,  n  is  the  total  number  of  pixels  in  an  image  sample. 
Therefore,  in  a  sample  of  64x64  pixels  image,  n  =  64Ã—64  = 
4096,  which  implies  ğ‘¥ğ‘–  is  the  value  of  ğ‘–ğ‘¡â„  pixel.  To  calculate 
each  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0),  Laplace  smoothing  was 
used: 
 

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 1) =  

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 0) =  

âˆ‘

âˆ‘

ğ‘š
ğ‘–=1

ğ‘š
ğ‘–=1

1{ğ‘¦(ğ‘–)=1}+2

=1 Ë„ ğ‘¦(ğ‘–)=1}+1

(ğ‘–)
1{ğ‘¥ğ‘—
ğ‘š
âˆ‘
ğ‘–=1
 
(ğ‘–)=1 Ë„ ğ‘¦(ğ‘–)=0}+1
1{ğ‘¥ğ‘—
ğ‘š
1{ğ‘¦(ğ‘–)=0}+2
âˆ‘
ğ‘–=1
 

   â€¦   (6) 

   â€¦   (7) 

(ğ‘–)

In  equations  (6)  and  (7),  m  denotes  the  total  number  of 
 means the value of ğ‘—ğ‘¡â„ pixel in the ğ‘–ğ‘¡â„ 
training samples, so ğ‘¥ğ‘—
training sample. 
  To model p(x|y), the NaÃ¯ve Bayes assumption assumes that 
the ğ‘¥ğ‘–â€™s are conditionally independent given y [7]. This means 
that for example we are assuming given the author is A (or B), 
knowing  the  value  of  pixel  â€˜iâ€™  has  no  effect  of  our  beliefs 
about  the  values  of  pixel  â€˜jâ€™.  This  NaÃ¯ve  Bayes  assumption 
does not entirely hold true in this case. Because we know that 
for any handwriting, especially for the high resolution images, 
if a pixel is black so that itâ€™s part of the letter/number, then the 
adjacent  pixels  are  also  likely  to  be  part  of  the  letter/number. 
With 
the  NaÃ¯ve  Bayes  algorithm  was 
implemented  and 
the  generalization  error  results  were 
obtained. 
 

in  mind, 

this 

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

W I T H O U T  S I Z E - N O R M A L I Z A T I O N

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

U S I N G   S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

40

35

30

25

20

15

10

5

0

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

45

40

35

30

25

20

15

10

5

0

0

20

40

60

80

100

0

20

40

60

80

100

120

NUMBER OF TRAINING SAMPLES

NUMBER OF TRAINING SAMPLES

 

(64x64 

samples 

 
Fig. 4. NaÃ¯ve Bayes generalization error without size-normalization and centering 
 
Refer  to  Fig.  4  for  the  generalization  error  of  NaÃ¯ve  Bayes 
without  size-normalization  and  centering.  The  16x16  images 
resulted in the lowest generalization  error of 5%, followed by 
32x32  (7%),  64x64  (9%),  8x8  (13%)  images.  The  higher 
resolution 
and  32x32)  had  higher 
generalization  error  compared  to  the  16x16  images  because 
the  number  of  training  samples  were  not  enough  to  generate 
an  accurate  result.  For  example  a  64x64  image  has  4096 
features (pixels), and 100 training samples were not sufficient 
compared  to  the  number  of  features  in  each  image.  For  the 
16x16 training images, the number of  feature is 16Ã—16 = 256, 
which  is  comparable  to  the  100  samples.  As  for  the  8x8 
samples,  the  performance  was  worse  than  16x16  images 
because  they  lost  too  much  of  the  original  characteristics  of 
the  handwriting.  However,  note  that  even  at  the  lowest 
resolution  of  8x8  pixels,  the  algorithm  still  achieved  13% 
generalization  error.  This  is  impressive  considering  that  an 
8x8  resolution image has such a low resolution that  it is hard 
to recognize even by human eyes, as shown in Fig. 1.  
 

 

 
Fig. 5. NaÃ¯ve Bayes generalization error using size-normalization and centering 
 
Refer  to  Fig.  5  for  the  generalization  error  of  NaÃ¯ve  Bayes 
using  size-normalization  and  centering.  The  results  were 
worse than without using size-normalization and centering for 
all image resolutions. Size-normalization and centering did not 
improve  the  performance  of  NaÃ¯ve  Bayes.  We  think  this  is 
because size-normalization and centering actually reduced the 
difference  of  the  writing  samples  from  the  two  authors.  For 
example,  if  one  author  generally  writes  big  and  the  other 
author  have  smaller  handwriting,  this  difference  will  be 
reflected in the  raw image. NaÃ¯ve  Bayes algorithm then picks 
up  this  difference  in  the  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0) 
calculation to make the prediction. However if the images are 
size-normalized,  then  the  writing  samples  from  the  two 
authors  will  be  scaled  to  similar  sizes,  and  they  will  become 
more  similar  compared  to  the  raw  images.  With  more 
similarity, the prediction will become less accurate, and this is 
why  the  generalization  of  NaÃ¯ve  Bayes  algorithm  increased 
when using the size-normalization and centering. 
 

Naive Bayes Effect of Size-normalization and Centering

)

%

Without size-normalization and centering

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

Using size-normalization and centering

15

9

9

7

16

5

20

13

20
15
10
5
0

64x64

32x32

16x16

8x8

Different resolutions using 100 training samples

Fig. 6. NaÃ¯ve Bayes effect of size-normalization and centering 

 

VI.  SUPPORT VECTOR MACHINE (SVM) ALGORITHM 

Since  we  are  evaluating  supervised  learning  algorithms,  a 
discussion  without  SVM  is  incomplete.  We  used  an  off-the 
shelf  SVM  training  algorithm  provided  by  MATLAB  to 
understand  if  we  can  classify  images  to  their  respective 
writers.  SVM  is  modelled  using  the  primal  optimization 
problem [7]: 

ğ‘šğ‘–ğ‘›
ğ›¾,ğœ”,ğ‘

1
2

ğ‘š

2

||ğœ”||

+ ğ¶ âˆ‘ ğœ‰ğ‘–

 

ğ‘–=1

ğ‘ . ğ‘¡. ğ‘¦(ğ‘–)(ğœ”ğ‘‡ğ‘¥(ğ‘–) + ğ‘) â‰¥ 1 âˆ’   ğœ‰ğ‘–, ğ‘– = 1, â€¦ , ğ‘š 

ğœ‰ğ‘– â‰¥ 0, ğ‘– = 1, â€¦ , ğ‘š 

 
Here,  ğœ”  denotes  the  weight  matrix,  ğ‘¥(ğ‘–)are  our  samples 
(images),  ğ‘¦(ğ‘–)  is  the  class  label,  C  is  a  parameter  that  does 
relative  weighting  of  the  twin  goals  of  minimizing  the 
functional  margin  and  ensuring 
that  all  samples  have 
functional margin of at least 1, and lastly, ğœ‰ğ‘– is the quantity by 
which  the  functional  margin  for  a  sample  may  be  less  than  1 
which  results  in  an  extra  cost  of  Cğœ‰ğ‘–.  After  writing  the 
Lagrangian  for  the  above  problem  and  setting  the  partial 
derivatives  of  Lagrangian  w.r.t  ğœ”  and  b  to  zero,  we  get  our 
dual optimization problem [7]: 
 

max

ğ›¼

ğ‘Š(ğ›¼) =   âˆ‘ ğ›¼ğ‘–

âˆ’  

ğ‘–=1

 

ğ‘š

1
2

ğ‘š
âˆ‘ ğ‘¦(ğ‘–)ğ‘¦(ğ‘—)ğ›¼ğ‘–ğ›¼ğ‘—âŒ©ğ‘¥(ğ‘–), ğ‘¥(ğ‘—)âŒª
 
ğ‘–,ğ‘—=1

ğ‘ . ğ‘¡  {

0  â‰¤ ğ›¼ğ‘– â‰¤ ğ¶, ğ‘– = 1, â€¦ , ğ‘š

ğ‘š
âˆ‘ ğ›¼ğ‘–ğ‘¦(ğ‘–)
ğ‘–=1

= 0

 

The  â€˜svmtrainâ€™  function  from  MATLAB  solves  the  above 
optimization  problem  and  calculates  the  values  of  all  the 
parameters.  We  used  a  linear  kernel  for  our  SVM  classifier. 
Again, we had 100 samples from each author which were split 
into  50  training  samples  and  50  test  samples.  We  have 
compared  the  performance  of  the  algorithm  over  various 
image resolutions. 

 

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

S V M   G E N E R A L I Z A T I O N  E R R O R  W I T H O U T  

S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

60
50
40
30
20
10
0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 
Fig.7. SVM generalization error without size-normalization and centering 

 
Fig.  7  shows  the  generalization  error  for  SVM  without  size-
normalization and centering. The 64x64 images had the lowest 
generalization  error  of  4%,  followed  by  32x32  (10%),  16x16 
(25%),  8x8  (51%).  The  64x64  images  had  the  lowest 
generalization error at 100 training samples, but the 32x32 and 
16x16 images had results flattening between 60 to 100 training 
samples.  For  the  16x16  and  8x8  images,  the  generalization 
error  was  too  high  and  the  results  were  not  useful  to  make  a 
meaningful prediction. This result is intuitive as well since we 
lose too much information as we reduce the image resolution. 
At  8x8  resolution,  the  information  loss  is  so  much  that  it  is 
impossible to distinguish between two images. 
 

S V M   G E N E R A L I Z A T I O N  E R R O R  U S I N G   S I Z E -

N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

60

50

40

30

20

10

0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 

Fig. 8. SVM generalization error with size-normalization and centering 

 
 
 
Fig.  8  shows  the  generalization  error  for  SVM  using  size-
normalization and  centering.  The performance was improved, 
especially for the low resolution images (16x16 and 8x8). The 
64x64 and 32x32 images showed slight improvement as well. 
The results may seem odd but the key point to note here is that 
size  normalization  and  centering  â€œbrings  uniformity  amongst 
chaosâ€  in  the  low  resolution  images.  When  compressing  the 
original  image,  there  is  no  control  over  how  the  pixel 
information is truncated. The compression may lead to loss of 
information  at  different  areas  in  the  training  and  test  image 
which will make it difficult for the test image to be identified. 
When size normalization is applied, this indeterminate loss of 
information  is  curbed  to  a  certain  extent  since  whatever  the 
dimensions  of  the  text,  we  center  it  and  then  scale  it.  This 
effect will be more pronounced in  the samples where the text 
is present near one of the corners or edge of the image. 
 

Matching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

the  algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™ 
for black) from the handwriting sample image. 

 
 
 
 
 
 
 

Author A 

Author B 

Author C 

Fig. 2. Handwriting samples from authors A, B, and C 

IV.  IMAGE PREPROCESSING 

While  there  are  many  image  pre-processing  techniques 
depending  on  the  condition  of  scanned  handwriting,  we 
identified  the  following  three  preprocessing  techniques  as 
crucial to the functionality of handwriting matching algorithm: 

 
1.  Conversion of image to B/W â€“ each pixel will either be 

â€˜1â€™ (for white) or â€˜0â€™ (for black). 
2.  Handwriting size normalization. 
3.  Background removal 
 
We have implemented part 1 and part 2 of the preprocessing 
algorithm  in  MATLAB.  Conversion  to  black  and  white  is 
achieved  using  the  in-built  MATLAB  function  called 
â€˜rgb2grayâ€™.  This  function  uses  the  luminance  equation  to 
convert  RGB  pixels  to  grayscale  numbers.  The  equation 
used is: 
 

0.2989R + 0.5870G + 0.1140B   â€¦   (1) 

 

The  R,  G  and  B  in  the  above  equation  are  respective  color 
channel  values  for  any  given  pixel.  Once  the  image  is 
converted to grayscale, we use the bounding box method to 
normalize  our  image.  In  this,  the  algorithm  first  finds  a 
lower and upper, row and column bounds to fit the image in 
the smallest possible rectangle. The rectangle bounding box 
is  converted  to  a  square  by  expanding  the  smaller  side  to 
make  it  equal  to  the  larger  side.  The  new  pixels  that  get 
added as a result  of this  operation are initialized to â€˜whiteâ€™ 
color. Note that the smaller side is expanded  on  either side 
to automatically center the image. This bounded box image 
can  now  be  scaled  to  any  pixel  resolution  using  the 
MATLAB  function  â€˜imresizeâ€™.  The  default  algorithm  used 
by  â€˜imresizeâ€™  to  scale  the  image  is  bi-cubic  interpolation. 
There  are  other  options  available  as  well,  such  as,  nearest 
neighbor  and  bi-linear  interpolation.  Bi-cubic  interpolation 
performs  a  weighted  average  computation  in  a  4x4 
neighborhood  of  the  pixel  thus  resulting  in  a  more 
smoothened  edge  outputs  for  higher  scaling  factors  as 
compared  to  bilinear  interpolation  which  works  in  a  2x2 
neighborhood. Thus, it was our choice of algorithm.   
 

 
 

Fig.3. Bounding box based size normalization 

 

V.  NAÃVE BAYES ALGORITHM 

NaÃ¯ve  Bayes  algorithm  was  implemented  to  distinguish  the 
handwriting  samples  from  author  A  and  author  B.  We  varied 
the number  of training samples (half and half  from authors A 
and  B)  and  used  100  test  samples  (50  from  author  A  and  50 
from  author  B).  At  each  number  of  training  examples,  the 
average  generalization  error  was  obtained  by  averaging  the 
generalization  error  collected  over  100  runs,  where  each  run 
used different randomly picked training samples. 

To make a prediction on a new test sample, we compare the 

following equations (2) and (3): 
 

p(y = 1|x) =   ğ‘(ğ‘¥|ğ‘¦=1)ğ‘(ğ‘¦=1)

    â€¦   (2) 

ğ‘(ğ‘¥)

 

p(y = 0|x) =   ğ‘(ğ‘¥|ğ‘¦=0)ğ‘(ğ‘¦=0)

   â€¦   (3) 

ğ‘(ğ‘¥)

 
In the equations above, y = 1 means the author is A, and y = 0 
means the author is B. Since we always used half from author 
A  and  half  from  author  B  for  the  training  and  test  samples, 
p(y=0) = p(y=1) = 0.5. Also, 
 

p(x|y = 1) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)

ğ‘›
ğ‘–=1

   â€¦   (4) 

p(x|y = 0) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0)

ğ‘›
ğ‘–=1

   â€¦   (5) 

 

 

Here,  n  is  the  total  number  of  pixels  in  an  image  sample. 
Therefore,  in  a  sample  of  64x64  pixels  image,  n  =  64Ã—64  = 
4096,  which  implies  ğ‘¥ğ‘–  is  the  value  of  ğ‘–ğ‘¡â„  pixel.  To  calculate 
each  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0),  Laplace  smoothing  was 
used: 
 

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 1) =  

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 0) =  

âˆ‘

âˆ‘

ğ‘š
ğ‘–=1

ğ‘š
ğ‘–=1

1{ğ‘¦(ğ‘–)=1}+2

=1 Ë„ ğ‘¦(ğ‘–)=1}+1

(ğ‘–)
1{ğ‘¥ğ‘—
ğ‘š
âˆ‘
ğ‘–=1
 
(ğ‘–)=1 Ë„ ğ‘¦(ğ‘–)=0}+1
1{ğ‘¥ğ‘—
ğ‘š
1{ğ‘¦(ğ‘–)=0}+2
âˆ‘
ğ‘–=1
 

   â€¦   (6) 

   â€¦   (7) 

(ğ‘–)

In  equations  (6)  and  (7),  m  denotes  the  total  number  of 
 means the value of ğ‘—ğ‘¡â„ pixel in the ğ‘–ğ‘¡â„ 
training samples, so ğ‘¥ğ‘—
training sample. 
  To model p(x|y), the NaÃ¯ve Bayes assumption assumes that 
the ğ‘¥ğ‘–â€™s are conditionally independent given y [7]. This means 
that for example we are assuming given the author is A (or B), 
knowing  the  value  of  pixel  â€˜iâ€™  has  no  effect  of  our  beliefs 
about  the  values  of  pixel  â€˜jâ€™.  This  NaÃ¯ve  Bayes  assumption 
does not entirely hold true in this case. Because we know that 
for any handwriting, especially for the high resolution images, 
if a pixel is black so that itâ€™s part of the letter/number, then the 
adjacent  pixels  are  also  likely  to  be  part  of  the  letter/number. 
With 
the  NaÃ¯ve  Bayes  algorithm  was 
implemented  and 
the  generalization  error  results  were 
obtained. 
 

in  mind, 

this 

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

W I T H O U T  S I Z E - N O R M A L I Z A T I O N

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

U S I N G   S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

40

35

30

25

20

15

10

5

0

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

45

40

35

30

25

20

15

10

5

0

0

20

40

60

80

100

0

20

40

60

80

100

120

NUMBER OF TRAINING SAMPLES

NUMBER OF TRAINING SAMPLES

 

(64x64 

samples 

 
Fig. 4. NaÃ¯ve Bayes generalization error without size-normalization and centering 
 
Refer  to  Fig.  4  for  the  generalization  error  of  NaÃ¯ve  Bayes 
without  size-normalization  and  centering.  The  16x16  images 
resulted in the lowest generalization  error of 5%, followed by 
32x32  (7%),  64x64  (9%),  8x8  (13%)  images.  The  higher 
resolution 
and  32x32)  had  higher 
generalization  error  compared  to  the  16x16  images  because 
the  number  of  training  samples  were  not  enough  to  generate 
an  accurate  result.  For  example  a  64x64  image  has  4096 
features (pixels), and 100 training samples were not sufficient 
compared  to  the  number  of  features  in  each  image.  For  the 
16x16 training images, the number of  feature is 16Ã—16 = 256, 
which  is  comparable  to  the  100  samples.  As  for  the  8x8 
samples,  the  performance  was  worse  than  16x16  images 
because  they  lost  too  much  of  the  original  characteristics  of 
the  handwriting.  However,  note  that  even  at  the  lowest 
resolution  of  8x8  pixels,  the  algorithm  still  achieved  13% 
generalization  error.  This  is  impressive  considering  that  an 
8x8  resolution image has such a low resolution that  it is hard 
to recognize even by human eyes, as shown in Fig. 1.  
 

 

 
Fig. 5. NaÃ¯ve Bayes generalization error using size-normalization and centering 
 
Refer  to  Fig.  5  for  the  generalization  error  of  NaÃ¯ve  Bayes 
using  size-normalization  and  centering.  The  results  were 
worse than without using size-normalization and centering for 
all image resolutions. Size-normalization and centering did not 
improve  the  performance  of  NaÃ¯ve  Bayes.  We  think  this  is 
because size-normalization and centering actually reduced the 
difference  of  the  writing  samples  from  the  two  authors.  For 
example,  if  one  author  generally  writes  big  and  the  other 
author  have  smaller  handwriting,  this  difference  will  be 
reflected in the  raw image. NaÃ¯ve  Bayes algorithm then picks 
up  this  difference  in  the  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0) 
calculation to make the prediction. However if the images are 
size-normalized,  then  the  writing  samples  from  the  two 
authors  will  be  scaled  to  similar  sizes,  and  they  will  become 
more  similar  compared  to  the  raw  images.  With  more 
similarity, the prediction will become less accurate, and this is 
why  the  generalization  of  NaÃ¯ve  Bayes  algorithm  increased 
when using the size-normalization and centering. 
 

Naive Bayes Effect of Size-normalization and Centering

)

%

Without size-normalization and centering

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

Using size-normalization and centering

15

9

9

7

16

5

20

13

20
15
10
5
0

64x64

32x32

16x16

8x8

Different resolutions using 100 training samples

Fig. 6. NaÃ¯ve Bayes effect of size-normalization and centering 

 

VI.  SUPPORT VECTOR MACHINE (SVM) ALGORITHM 

Since  we  are  evaluating  supervised  learning  algorithms,  a 
discussion  without  SVM  is  incomplete.  We  used  an  off-the 
shelf  SVM  training  algorithm  provided  by  MATLAB  to 
understand  if  we  can  classify  images  to  their  respective 
writers.  SVM  is  modelled  using  the  primal  optimization 
problem [7]: 

ğ‘šğ‘–ğ‘›
ğ›¾,ğœ”,ğ‘

1
2

ğ‘š

2

||ğœ”||

+ ğ¶ âˆ‘ ğœ‰ğ‘–

 

ğ‘–=1

ğ‘ . ğ‘¡. ğ‘¦(ğ‘–)(ğœ”ğ‘‡ğ‘¥(ğ‘–) + ğ‘) â‰¥ 1 âˆ’   ğœ‰ğ‘–, ğ‘– = 1, â€¦ , ğ‘š 

ğœ‰ğ‘– â‰¥ 0, ğ‘– = 1, â€¦ , ğ‘š 

 
Here,  ğœ”  denotes  the  weight  matrix,  ğ‘¥(ğ‘–)are  our  samples 
(images),  ğ‘¦(ğ‘–)  is  the  class  label,  C  is  a  parameter  that  does 
relative  weighting  of  the  twin  goals  of  minimizing  the 
functional  margin  and  ensuring 
that  all  samples  have 
functional margin of at least 1, and lastly, ğœ‰ğ‘– is the quantity by 
which  the  functional  margin  for  a  sample  may  be  less  than  1 
which  results  in  an  extra  cost  of  Cğœ‰ğ‘–.  After  writing  the 
Lagrangian  for  the  above  problem  and  setting  the  partial 
derivatives  of  Lagrangian  w.r.t  ğœ”  and  b  to  zero,  we  get  our 
dual optimization problem [7]: 
 

max

ğ›¼

ğ‘Š(ğ›¼) =   âˆ‘ ğ›¼ğ‘–

âˆ’  

ğ‘–=1

 

ğ‘š

1
2

ğ‘š
âˆ‘ ğ‘¦(ğ‘–)ğ‘¦(ğ‘—)ğ›¼ğ‘–ğ›¼ğ‘—âŒ©ğ‘¥(ğ‘–), ğ‘¥(ğ‘—)âŒª
 
ğ‘–,ğ‘—=1

ğ‘ . ğ‘¡  {

0  â‰¤ ğ›¼ğ‘– â‰¤ ğ¶, ğ‘– = 1, â€¦ , ğ‘š

ğ‘š
âˆ‘ ğ›¼ğ‘–ğ‘¦(ğ‘–)
ğ‘–=1

= 0

 

The  â€˜svmtrainâ€™  function  from  MATLAB  solves  the  above 
optimization  problem  and  calculates  the  values  of  all  the 
parameters.  We  used  a  linear  kernel  for  our  SVM  classifier. 
Again, we had 100 samples from each author which were split 
into  50  training  samples  and  50  test  samples.  We  have 
compared  the  performance  of  the  algorithm  over  various 
image resolutions. 

 

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

S V M   G E N E R A L I Z A T I O N  E R R O R  W I T H O U T  

S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

60
50
40
30
20
10
0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 
Fig.7. SVM generalization error without size-normalization and centering 

 
Fig.  7  shows  the  generalization  error  for  SVM  without  size-
normalization and centering. The 64x64 images had the lowest 
generalization  error  of  4%,  followed  by  32x32  (10%),  16x16 
(25%),  8x8  (51%).  The  64x64  images  had  the  lowest 
generalization error at 100 training samples, but the 32x32 and 
16x16 images had results flattening between 60 to 100 training 
samples.  For  the  16x16  and  8x8  images,  the  generalization 
error  was  too  high  and  the  results  were  not  useful  to  make  a 
meaningful prediction. This result is intuitive as well since we 
lose too much information as we reduce the image resolution. 
At  8x8  resolution,  the  information  loss  is  so  much  that  it  is 
impossible to distinguish between two images. 
 

S V M   G E N E R A L I Z A T I O N  E R R O R  U S I N G   S I Z E -

N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

60

50

40

30

20

10

0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 

Fig. 8. SVM generalization error with size-normalization and centering 

 
 
 
Fig.  8  shows  the  generalization  error  for  SVM  using  size-
normalization and  centering.  The performance was improved, 
especially for the low resolution images (16x16 and 8x8). The 
64x64 and 32x32 images showed slight improvement as well. 
The results may seem odd but the key point to note here is that 
size  normalization  and  centering  â€œbrings  uniformity  amongst 
chaosâ€  in  the  low  resolution  images.  When  compressing  the 
original  image,  there  is  no  control  over  how  the  pixel 
information is truncated. The compression may lead to loss of 
information  at  different  areas  in  the  training  and  test  image 
which will make it difficult for the test image to be identified. 
When size normalization is applied, this indeterminate loss of 
information  is  curbed  to  a  certain  extent  since  whatever  the 
dimensions  of  the  text,  we  center  it  and  then  scale  it.  This 
effect will be more pronounced in  the samples where the text 
is present near one of the corners or edge of the image. 
 

)

%

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

SVM Effect of Size-normalization and Centering

51

14

4

3

10

8

25

8

60

40

20

0

64x64

32x32

16x16

8x8

different resolutions using 100 training samples

Without size-normalization and centering

Legend 

Using size-normalization and centering

Fig. 9. SVM effect of size-normalization and centering 

 

VII.  SVM ALGORITHM FOR THREE AUTHORS 

 

Fig.11. The best algorithm at different number of training samples 
and image resolutions. 

 

SVMs  typically  classify  data  in  two  classes  using  a 
separating  hyperplane.  However,  the  handwriting  recognition 
is  a  multi-class  problem.  To  solve  this,  we  extend  the  SVM 
algorithm  to  a  multi-class  algorithm  [3]  by  computing  one 
classifier  for  each  class  by  pitting  that  class  against  all  other 
classes. Therefore, if we have â€˜kâ€™ classes in our sample space, 
we  would  need  to  compute  â€˜kâ€™  classifiers.  To  classify  a  new 
sample,  we  evaluate  the  new  sample  against  each  classifier 
and  choose  the  class  whose  corresponding  classifier  labels  it 
as â€˜1â€™. This is otherwise called one-against-all approach. 

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

20

15

10

5

0

GENERALIZATION ERROR (%)

16.667

6

6

7.333

64X64

32X32

16X16

8X8

IMAGE RESOLUTION

Fig.10. Multi-class SVM generalization error with size-normalization and 
 
centering 

 

 

VIII.  CONCLUSION 

 
We  compared  the  performance  of  the  four  combinations: 
NaÃ¯ve  Bayes/SVM,  with/without  size  normalization  and 
centering.  At  each  image  resolution  and  training  sample  size, 
the  combination  that  gives  the  lowest  generalization  error  is 
illustrated  in  Fig.  11.  Based  on  this  result,  if  the  handwriting 
image resolution is 32x32 pixels or lower, using NaÃ¯ve Bayes 
without  size-normalization  and  centering  generally  has  the 
best performance. 
 

At  8x8  resolution,  between  20  and  90  training  samples, 
SVM  performs  slightly  better  than  NaÃ¯ve  Bayes,  but  the 
difference  not  significant.  If  the  training  samples  have  high 
resolution  similar  to  64x64  pixels,  if  there  are  very  few 
training  samples  (<  10),  using  NaÃ¯ve  Bayes  without  size-
normalization  and  centering  is  still  the  best  option.  Only  for 
64x64  images  with  10  or  more  training  samples,  SVM 
outperforms NaÃ¯ve Bayes.  This result is synonymous with the 
results obtained in the class â€“ NaÃ¯ve Bayes is quicker to learn 
while  performance  of  SVM  improves  as  the  number  of 
training  samples  increases.  Although  SVM  had  a  narrower 
range  of  good  performance  compared  to  NaÃ¯ve  Bayes,  SVM 
achieved  the  absolute  lowest  generalization  error  of  3%  with 
64x64  training  samples  and  using  size  normalization  and 
centering.  

IX.  FUTURE WORK 

Handwriting matching algorithms, such as this, are typically 
used by banks and law  firms  for signature matching to detect 
potential  fraud  or  establish  authenticity.  Our  signatures 
typically do not reflect  our actual handwriting  â€“ i.e. there is a 
significant  difference  between  the  handwriting  style  of  a 
written  paragraph  and  a  signature  from  the  same  person.  In 
addition to this, the size of the signature varies from document 
to  document  which  adds  to  the  complexity  of  problem.  As 
future  work,  the  challenge  would  be  to  extend  this  algorithm 
to  signatures.  The  size  normalization  algorithm  introduced  in 
this  project  needs  to  be  modified  and  extended  to  normalize 
the  size  of  signatures  not  only  from  the  same  person,  but 
across different people as well. Another challenge would be to 
increase  the  learning  rate  â€“  that  is  lower  generalization  error 
for  lesser  number  of  samples  â€“  this  is  an  important  aspect 
because  typically  organizations  have  to  work  with  very  few 
samples to determine if the signature is authentic or not. 

 
In order to work with very few samples, it will be helpful to 
automatically  synthesize  a  large  number  of  training  samples 
based  on  the  real  signature  samples.  As  explored  in  [8],  an 
algorithm  can  be  developed  to  naturally  deform  the  original 
samples to generate many more training samples. 

# of Training Samples64x6432x3216x168x82468102030405060708090100NaÃ¯ve Bayes, no size-normalization and centeringNaÃ¯ve Bayes, with size-normalization and centeringSVM, no size-normalization and centeringSVM, with size-normalization and centeringMatching Handwriting with Its Author 

Ziran Jiang, Aditya R. Mundada 

ï€  

Abstractâ€”Handwriting matching is a useful feature to identify 
individuals and  is used for  many purposes including bank check 
authentication and forensic investigation. This paper implements, 
compares,  and  optimizes  handwriting  matching  using  two 
algorithms:  NaÃ¯ve  Bayes  and  Support  Vector  Machine  (SVM). 
Handwriting samples are collected  using the INKredible  app [1] 
to obtain realistic samples similar to handwritings on paper. 100 
writing  samples  are  collected  from  each  of  the  three  authors 
(authors A, B, and C), and each sample is scaled to four different 
image resolutions.  A preprocessing algorithm  is developed  using 
MATLAB  to  convert  the  collected  samples  to  black  and  white 
and normalize the size of the handwriting. NaÃ¯ve Bayes and SVM 
algorithms  are  implemented  using  MATLAB  to  distinguish 
between samples from authors A and B. SVM is also expanded to 
distinguish  samples  between  all  three  authors.  Performance  of 
NaÃ¯ve  Bayes  and  SVM  is  compared,  and  the  effect  of  image 
resolution and preprocessing is also analyzed. 

algorithms.  Unlike  typing  in  computer,  handwritings  requires 
manual  work,  and  generating  a  large  number  of  handwriting 
samples  is  very  time  consuming.  A  number  of  studies  have 
been done to create algorithms that will automatically generate 
many  artificial  handwriting  samples  based  on  some  original 
authentic samples written by human [11, 12, 13, 14]. [12] and 
[14]  only  require  one  original  sample,  and  use  a  deformation 
model  to  deform  the  original  sample  to  generate  many  new 
samples.  This  method  however  does  not  always  generate 
natural-looking  handwritings.  The  study  done  by  [11]  tries  to 
learn  the  natural  variation  from  multiple  authentic  samples, 
and  create  a  distribution  that  describes  the  variation.  It  then 
synthesizes  new  samples  from  this  distribution.  This  method 
requirs  many  original  handwritings  to  have  an  accurate 
distribution. 

III.  DATA ACQUISITION 

I.  INTRODUCTION 

E 

ach  person  has  a  unique  handwriting,  and  this  makes 
handwriting  a  useful  feature  to  identify  individuals  [10]. 
Handwriting matching is used by banks for check-writing 
and  signature  authentication.  In  forensic  science,  handwriting 
matching  algorithm  can  aid  handwriting  analysis  experts 
predict the author with more accuracy. The goal of this project 
is to manually implement and optimize handwriting matching, 
including:  1)  Data  Acquisition,  2)  Image  Preprocessing,  3) 
Algorithm Implementation (NaÃ¯ve Bayes, SVM, and SVM for 
three 
and 
Optimization.  The  input  to  the  Naive  Bayes  and  SVM 
algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™  for 
black)  from  the handwriting sample image.  The  output  of the 
algorithms is the prediction of the corresponding author. 

and  4)  Algorithm  Comparison 

authors), 

II.  RELATED WORK 

individual, 

Although  intuitively  we  know  that  handwriting  is  different 
for  every 
the  uniqueness  of  each  personâ€™s 
handwriting was studied and objectively validated by [10, 15] 
through  a  machine  learning  approach.  Handwriting  features 
can  be  divided  into  two  categories:  document  examiner 
features, and computational features [15]. Document examiner 
features,  such  as  handwriting  embellishments,  are  often  used 
by  forensic  handwriting  examiners  and  are  difficult  to  model 
using computers. [15] used these document  examiner  features 
and obtained promising results. Computational features can be 
easily  modeled  by  machine  learning  algorithms,  and  are  used 
in [16, 17]. 

Another  challenge  of  handwriting  matching  is  generating  a 
large  number  of  training  samples  for  machine  learning 

 
 

We  considered  using 

the  MNIST  Database  [2]  for 
handwriting  samples,  however  the  MNIST  Database  samples 
are  not  associated  with  the  corresponding  authors.  For 
handwriting matching, the algorithm needs to know the author 
for  each  training  samples,  so  the  MNIST  Database  could  not 
be  used  as  training  or  test  samples.  Instead,  as  a  temporary 
measure  at  the  initial  stage  of  algorithm  implementation,  MS 
Paint  was  used  to  generate  handwriting  samples.  Later  we 
switched to using an app called  INKredible  [1], which allows 
directly  writing  on  a  tablet  screen  using  stylus/finger.  The 
INKredible  app  enables  collecting  realistic  handwriting 
samples  similar  to  the  samples  written  on  paper.  Each 
handwriting  sample  was  scaled 
the  following  four 
resolutions  using  MATLAB:  64x64  pixels,  32x32  pixels, 
16x16 pixels, and 8x8 pixels.  

to 

 
 
 
 
 
 
 

 

64x64 

32x32 

16x16 

8x8 

Fig. 1. Handwriting samples at different resolutions 

100  handwriting  samples  were  collected  from  each  of  the 
three  authors  (authors  A,  B,  and  C),  and  each  sample  was 
scaled  to  the  four  different  resolutions  mentioned  above.  As 
shown  in  Fig.  2,  each  author  has  different  writing  style,  and 
the  algorithms  attempt  to  predict  the  author  based  on  these 
differences.  Fig.  2,  only  shows  one  sample  from  each  author, 
but within the 100 samples from the same author, there is also 
certain  variations  from  sample  to  sample.  This  sample-to-
sample  variation  reflects  the  real  world  situation  where  a 
person  writes  slightly  differently  each  time.  The  features  for 

the  algorithms  are  all  the  pixel  values  (â€˜1â€™  for  white,  and  â€˜0â€™ 
for black) from the handwriting sample image. 

 
 
 
 
 
 
 

Author A 

Author B 

Author C 

Fig. 2. Handwriting samples from authors A, B, and C 

IV.  IMAGE PREPROCESSING 

While  there  are  many  image  pre-processing  techniques 
depending  on  the  condition  of  scanned  handwriting,  we 
identified  the  following  three  preprocessing  techniques  as 
crucial to the functionality of handwriting matching algorithm: 

 
1.  Conversion of image to B/W â€“ each pixel will either be 

â€˜1â€™ (for white) or â€˜0â€™ (for black). 
2.  Handwriting size normalization. 
3.  Background removal 
 
We have implemented part 1 and part 2 of the preprocessing 
algorithm  in  MATLAB.  Conversion  to  black  and  white  is 
achieved  using  the  in-built  MATLAB  function  called 
â€˜rgb2grayâ€™.  This  function  uses  the  luminance  equation  to 
convert  RGB  pixels  to  grayscale  numbers.  The  equation 
used is: 
 

0.2989R + 0.5870G + 0.1140B   â€¦   (1) 

 

The  R,  G  and  B  in  the  above  equation  are  respective  color 
channel  values  for  any  given  pixel.  Once  the  image  is 
converted to grayscale, we use the bounding box method to 
normalize  our  image.  In  this,  the  algorithm  first  finds  a 
lower and upper, row and column bounds to fit the image in 
the smallest possible rectangle. The rectangle bounding box 
is  converted  to  a  square  by  expanding  the  smaller  side  to 
make  it  equal  to  the  larger  side.  The  new  pixels  that  get 
added as a result  of this  operation are initialized to â€˜whiteâ€™ 
color. Note that the smaller side is expanded  on  either side 
to automatically center the image. This bounded box image 
can  now  be  scaled  to  any  pixel  resolution  using  the 
MATLAB  function  â€˜imresizeâ€™.  The  default  algorithm  used 
by  â€˜imresizeâ€™  to  scale  the  image  is  bi-cubic  interpolation. 
There  are  other  options  available  as  well,  such  as,  nearest 
neighbor  and  bi-linear  interpolation.  Bi-cubic  interpolation 
performs  a  weighted  average  computation  in  a  4x4 
neighborhood  of  the  pixel  thus  resulting  in  a  more 
smoothened  edge  outputs  for  higher  scaling  factors  as 
compared  to  bilinear  interpolation  which  works  in  a  2x2 
neighborhood. Thus, it was our choice of algorithm.   
 

 
 

Fig.3. Bounding box based size normalization 

 

V.  NAÃVE BAYES ALGORITHM 

NaÃ¯ve  Bayes  algorithm  was  implemented  to  distinguish  the 
handwriting  samples  from  author  A  and  author  B.  We  varied 
the number  of training samples (half and half  from authors A 
and  B)  and  used  100  test  samples  (50  from  author  A  and  50 
from  author  B).  At  each  number  of  training  examples,  the 
average  generalization  error  was  obtained  by  averaging  the 
generalization  error  collected  over  100  runs,  where  each  run 
used different randomly picked training samples. 

To make a prediction on a new test sample, we compare the 

following equations (2) and (3): 
 

p(y = 1|x) =   ğ‘(ğ‘¥|ğ‘¦=1)ğ‘(ğ‘¦=1)

    â€¦   (2) 

ğ‘(ğ‘¥)

 

p(y = 0|x) =   ğ‘(ğ‘¥|ğ‘¦=0)ğ‘(ğ‘¦=0)

   â€¦   (3) 

ğ‘(ğ‘¥)

 
In the equations above, y = 1 means the author is A, and y = 0 
means the author is B. Since we always used half from author 
A  and  half  from  author  B  for  the  training  and  test  samples, 
p(y=0) = p(y=1) = 0.5. Also, 
 

p(x|y = 1) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)

ğ‘›
ğ‘–=1

   â€¦   (4) 

p(x|y = 0) =   âˆ ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0)

ğ‘›
ğ‘–=1

   â€¦   (5) 

 

 

Here,  n  is  the  total  number  of  pixels  in  an  image  sample. 
Therefore,  in  a  sample  of  64x64  pixels  image,  n  =  64Ã—64  = 
4096,  which  implies  ğ‘¥ğ‘–  is  the  value  of  ğ‘–ğ‘¡â„  pixel.  To  calculate 
each  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0),  Laplace  smoothing  was 
used: 
 

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 1) =  

ğ‘(ğ‘¥ğ‘—|ğ‘¦ = 0) =  

âˆ‘

âˆ‘

ğ‘š
ğ‘–=1

ğ‘š
ğ‘–=1

1{ğ‘¦(ğ‘–)=1}+2

=1 Ë„ ğ‘¦(ğ‘–)=1}+1

(ğ‘–)
1{ğ‘¥ğ‘—
ğ‘š
âˆ‘
ğ‘–=1
 
(ğ‘–)=1 Ë„ ğ‘¦(ğ‘–)=0}+1
1{ğ‘¥ğ‘—
ğ‘š
1{ğ‘¦(ğ‘–)=0}+2
âˆ‘
ğ‘–=1
 

   â€¦   (6) 

   â€¦   (7) 

(ğ‘–)

In  equations  (6)  and  (7),  m  denotes  the  total  number  of 
 means the value of ğ‘—ğ‘¡â„ pixel in the ğ‘–ğ‘¡â„ 
training samples, so ğ‘¥ğ‘—
training sample. 
  To model p(x|y), the NaÃ¯ve Bayes assumption assumes that 
the ğ‘¥ğ‘–â€™s are conditionally independent given y [7]. This means 
that for example we are assuming given the author is A (or B), 
knowing  the  value  of  pixel  â€˜iâ€™  has  no  effect  of  our  beliefs 
about  the  values  of  pixel  â€˜jâ€™.  This  NaÃ¯ve  Bayes  assumption 
does not entirely hold true in this case. Because we know that 
for any handwriting, especially for the high resolution images, 
if a pixel is black so that itâ€™s part of the letter/number, then the 
adjacent  pixels  are  also  likely  to  be  part  of  the  letter/number. 
With 
the  NaÃ¯ve  Bayes  algorithm  was 
implemented  and 
the  generalization  error  results  were 
obtained. 
 

in  mind, 

this 

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

W I T H O U T  S I Z E - N O R M A L I Z A T I O N

N A I V E   B A Y E S  G E N E R A L I Z A T I O N   E R R O R  

U S I N G   S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

40

35

30

25

20

15

10

5

0

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

45

40

35

30

25

20

15

10

5

0

0

20

40

60

80

100

0

20

40

60

80

100

120

NUMBER OF TRAINING SAMPLES

NUMBER OF TRAINING SAMPLES

 

(64x64 

samples 

 
Fig. 4. NaÃ¯ve Bayes generalization error without size-normalization and centering 
 
Refer  to  Fig.  4  for  the  generalization  error  of  NaÃ¯ve  Bayes 
without  size-normalization  and  centering.  The  16x16  images 
resulted in the lowest generalization  error of 5%, followed by 
32x32  (7%),  64x64  (9%),  8x8  (13%)  images.  The  higher 
resolution 
and  32x32)  had  higher 
generalization  error  compared  to  the  16x16  images  because 
the  number  of  training  samples  were  not  enough  to  generate 
an  accurate  result.  For  example  a  64x64  image  has  4096 
features (pixels), and 100 training samples were not sufficient 
compared  to  the  number  of  features  in  each  image.  For  the 
16x16 training images, the number of  feature is 16Ã—16 = 256, 
which  is  comparable  to  the  100  samples.  As  for  the  8x8 
samples,  the  performance  was  worse  than  16x16  images 
because  they  lost  too  much  of  the  original  characteristics  of 
the  handwriting.  However,  note  that  even  at  the  lowest 
resolution  of  8x8  pixels,  the  algorithm  still  achieved  13% 
generalization  error.  This  is  impressive  considering  that  an 
8x8  resolution image has such a low resolution that  it is hard 
to recognize even by human eyes, as shown in Fig. 1.  
 

 

 
Fig. 5. NaÃ¯ve Bayes generalization error using size-normalization and centering 
 
Refer  to  Fig.  5  for  the  generalization  error  of  NaÃ¯ve  Bayes 
using  size-normalization  and  centering.  The  results  were 
worse than without using size-normalization and centering for 
all image resolutions. Size-normalization and centering did not 
improve  the  performance  of  NaÃ¯ve  Bayes.  We  think  this  is 
because size-normalization and centering actually reduced the 
difference  of  the  writing  samples  from  the  two  authors.  For 
example,  if  one  author  generally  writes  big  and  the  other 
author  have  smaller  handwriting,  this  difference  will  be 
reflected in the  raw image. NaÃ¯ve  Bayes algorithm then picks 
up  this  difference  in  the  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 1)  and  ğ‘(ğ‘¥ğ‘–|ğ‘¦ = 0) 
calculation to make the prediction. However if the images are 
size-normalized,  then  the  writing  samples  from  the  two 
authors  will  be  scaled  to  similar  sizes,  and  they  will  become 
more  similar  compared  to  the  raw  images.  With  more 
similarity, the prediction will become less accurate, and this is 
why  the  generalization  of  NaÃ¯ve  Bayes  algorithm  increased 
when using the size-normalization and centering. 
 

Naive Bayes Effect of Size-normalization and Centering

)

%

Without size-normalization and centering

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

Using size-normalization and centering

15

9

9

7

16

5

20

13

20
15
10
5
0

64x64

32x32

16x16

8x8

Different resolutions using 100 training samples

Fig. 6. NaÃ¯ve Bayes effect of size-normalization and centering 

 

VI.  SUPPORT VECTOR MACHINE (SVM) ALGORITHM 

Since  we  are  evaluating  supervised  learning  algorithms,  a 
discussion  without  SVM  is  incomplete.  We  used  an  off-the 
shelf  SVM  training  algorithm  provided  by  MATLAB  to 
understand  if  we  can  classify  images  to  their  respective 
writers.  SVM  is  modelled  using  the  primal  optimization 
problem [7]: 

ğ‘šğ‘–ğ‘›
ğ›¾,ğœ”,ğ‘

1
2

ğ‘š

2

||ğœ”||

+ ğ¶ âˆ‘ ğœ‰ğ‘–

 

ğ‘–=1

ğ‘ . ğ‘¡. ğ‘¦(ğ‘–)(ğœ”ğ‘‡ğ‘¥(ğ‘–) + ğ‘) â‰¥ 1 âˆ’   ğœ‰ğ‘–, ğ‘– = 1, â€¦ , ğ‘š 

ğœ‰ğ‘– â‰¥ 0, ğ‘– = 1, â€¦ , ğ‘š 

 
Here,  ğœ”  denotes  the  weight  matrix,  ğ‘¥(ğ‘–)are  our  samples 
(images),  ğ‘¦(ğ‘–)  is  the  class  label,  C  is  a  parameter  that  does 
relative  weighting  of  the  twin  goals  of  minimizing  the 
functional  margin  and  ensuring 
that  all  samples  have 
functional margin of at least 1, and lastly, ğœ‰ğ‘– is the quantity by 
which  the  functional  margin  for  a  sample  may  be  less  than  1 
which  results  in  an  extra  cost  of  Cğœ‰ğ‘–.  After  writing  the 
Lagrangian  for  the  above  problem  and  setting  the  partial 
derivatives  of  Lagrangian  w.r.t  ğœ”  and  b  to  zero,  we  get  our 
dual optimization problem [7]: 
 

max

ğ›¼

ğ‘Š(ğ›¼) =   âˆ‘ ğ›¼ğ‘–

âˆ’  

ğ‘–=1

 

ğ‘š

1
2

ğ‘š
âˆ‘ ğ‘¦(ğ‘–)ğ‘¦(ğ‘—)ğ›¼ğ‘–ğ›¼ğ‘—âŒ©ğ‘¥(ğ‘–), ğ‘¥(ğ‘—)âŒª
 
ğ‘–,ğ‘—=1

ğ‘ . ğ‘¡  {

0  â‰¤ ğ›¼ğ‘– â‰¤ ğ¶, ğ‘– = 1, â€¦ , ğ‘š

ğ‘š
âˆ‘ ğ›¼ğ‘–ğ‘¦(ğ‘–)
ğ‘–=1

= 0

 

The  â€˜svmtrainâ€™  function  from  MATLAB  solves  the  above 
optimization  problem  and  calculates  the  values  of  all  the 
parameters.  We  used  a  linear  kernel  for  our  SVM  classifier. 
Again, we had 100 samples from each author which were split 
into  50  training  samples  and  50  test  samples.  We  have 
compared  the  performance  of  the  algorithm  over  various 
image resolutions. 

 

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

S V M   G E N E R A L I Z A T I O N  E R R O R  W I T H O U T  

S I Z E - N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

60
50
40
30
20
10
0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 
Fig.7. SVM generalization error without size-normalization and centering 

 
Fig.  7  shows  the  generalization  error  for  SVM  without  size-
normalization and centering. The 64x64 images had the lowest 
generalization  error  of  4%,  followed  by  32x32  (10%),  16x16 
(25%),  8x8  (51%).  The  64x64  images  had  the  lowest 
generalization error at 100 training samples, but the 32x32 and 
16x16 images had results flattening between 60 to 100 training 
samples.  For  the  16x16  and  8x8  images,  the  generalization 
error  was  too  high  and  the  results  were  not  useful  to  make  a 
meaningful prediction. This result is intuitive as well since we 
lose too much information as we reduce the image resolution. 
At  8x8  resolution,  the  information  loss  is  so  much  that  it  is 
impossible to distinguish between two images. 
 

S V M   G E N E R A L I Z A T I O N  E R R O R  U S I N G   S I Z E -

N O R M A L I Z A T I O N

% Error 64x64

% Error 32x32

% Error 16x16

% Error 8x8

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G
E
G
A
R
E
V
A

 

60

50

40

30

20

10

0

0

20

40

60

80

100

NUMBER OF TRAINING SAMPLES

 

Fig. 8. SVM generalization error with size-normalization and centering 

 
 
 
Fig.  8  shows  the  generalization  error  for  SVM  using  size-
normalization and  centering.  The performance was improved, 
especially for the low resolution images (16x16 and 8x8). The 
64x64 and 32x32 images showed slight improvement as well. 
The results may seem odd but the key point to note here is that 
size  normalization  and  centering  â€œbrings  uniformity  amongst 
chaosâ€  in  the  low  resolution  images.  When  compressing  the 
original  image,  there  is  no  control  over  how  the  pixel 
information is truncated. The compression may lead to loss of 
information  at  different  areas  in  the  training  and  test  image 
which will make it difficult for the test image to be identified. 
When size normalization is applied, this indeterminate loss of 
information  is  curbed  to  a  certain  extent  since  whatever  the 
dimensions  of  the  text,  we  center  it  and  then  scale  it.  This 
effect will be more pronounced in  the samples where the text 
is present near one of the corners or edge of the image. 
 

)

%

 

(
 
r
o
r
r
e
n
o
i
t
a
z
i
l

a
r
e
n
e
g

 

e
g
a
r
e
v
A

 
 

SVM Effect of Size-normalization and Centering

51

14

4

3

10

8

25

8

60

40

20

0

64x64

32x32

16x16

8x8

different resolutions using 100 training samples

Without size-normalization and centering

Legend 

Using size-normalization and centering

Fig. 9. SVM effect of size-normalization and centering 

 

VII.  SVM ALGORITHM FOR THREE AUTHORS 

 

Fig.11. The best algorithm at different number of training samples 
and image resolutions. 

 

SVMs  typically  classify  data  in  two  classes  using  a 
separating  hyperplane.  However,  the  handwriting  recognition 
is  a  multi-class  problem.  To  solve  this,  we  extend  the  SVM 
algorithm  to  a  multi-class  algorithm  [3]  by  computing  one 
classifier  for  each  class  by  pitting  that  class  against  all  other 
classes. Therefore, if we have â€˜kâ€™ classes in our sample space, 
we  would  need  to  compute  â€˜kâ€™  classifiers.  To  classify  a  new 
sample,  we  evaluate  the  new  sample  against  each  classifier 
and  choose  the  class  whose  corresponding  classifier  labels  it 
as â€˜1â€™. This is otherwise called one-against-all approach. 

)

%

 

(
 
R
O
R
R
E
N
O
I
T
A
Z
I
L
A
R
E
N
E
G

20

15

10

5

0

GENERALIZATION ERROR (%)

16.667

6

6

7.333

64X64

32X32

16X16

8X8

IMAGE RESOLUTION

Fig.10. Multi-class SVM generalization error with size-normalization and 
 
centering 

 

 

VIII.  CONCLUSION 

 
We  compared  the  performance  of  the  four  combinations: 
NaÃ¯ve  Bayes/SVM,  with/without  size  normalization  and 
centering.  At  each  image  resolution  and  training  sample  size, 
the  combination  that  gives  the  lowest  generalization  error  is 
illustrated  in  Fig.  11.  Based  on  this  result,  if  the  handwriting 
image resolution is 32x32 pixels or lower, using NaÃ¯ve Bayes 
without  size-normalization  and  centering  generally  has  the 
best performance. 
 

At  8x8  resolution,  between  20  and  90  training  samples, 
SVM  performs  slightly  better  than  NaÃ¯ve  Bayes,  but  the 
difference  not  significant.  If  the  training  samples  have  high 
resolution  similar  to  64x64  pixels,  if  there  are  very  few 
training  samples  (<  10),  using  NaÃ¯ve  Bayes  without  size-
normalization  and  centering  is  still  the  best  option.  Only  for 
64x64  images  with  10  or  more  training  samples,  SVM 
outperforms NaÃ¯ve Bayes.  This result is synonymous with the 
results obtained in the class â€“ NaÃ¯ve Bayes is quicker to learn 
while  performance  of  SVM  improves  as  the  number  of 
training  samples  increases.  Although  SVM  had  a  narrower 
range  of  good  performance  compared  to  NaÃ¯ve  Bayes,  SVM 
achieved  the  absolute  lowest  generalization  error  of  3%  with 
64x64  training  samples  and  using  size  normalization  and 
centering.  

IX.  FUTURE WORK 

Handwriting matching algorithms, such as this, are typically 
used by banks and law  firms  for signature matching to detect 
potential  fraud  or  establish  authenticity.  Our  signatures 
typically do not reflect  our actual handwriting  â€“ i.e. there is a 
significant  difference  between  the  handwriting  style  of  a 
written  paragraph  and  a  signature  from  the  same  person.  In 
addition to this, the size of the signature varies from document 
to  document  which  adds  to  the  complexity  of  problem.  As 
future  work,  the  challenge  would  be  to  extend  this  algorithm 
to  signatures.  The  size  normalization  algorithm  introduced  in 
this  project  needs  to  be  modified  and  extended  to  normalize 
the  size  of  signatures  not  only  from  the  same  person,  but 
across different people as well. Another challenge would be to 
increase  the  learning  rate  â€“  that  is  lower  generalization  error 
for  lesser  number  of  samples  â€“  this  is  an  important  aspect 
because  typically  organizations  have  to  work  with  very  few 
samples to determine if the signature is authentic or not. 

 
In order to work with very few samples, it will be helpful to 
automatically  synthesize  a  large  number  of  training  samples 
based  on  the  real  signature  samples.  As  explored  in  [8],  an 
algorithm  can  be  developed  to  naturally  deform  the  original 
samples to generate many more training samples. 

# of Training Samples64x6432x3216x168x82468102030405060708090100NaÃ¯ve Bayes, no size-normalization and centeringNaÃ¯ve Bayes, with size-normalization and centeringSVM, no size-normalization and centeringSVM, with size-normalization and centeringREFERENCES 

INKredible [online]. Available: http://inkredibleapp.com/ 

[1] 
[2]  THE  MNIST  DATABASE  of  handwritten  digits  [online].  Available: 

http://yann.lecun.com/exdb/mnist/ 

on  multi-class 

support 

[3]  Literature 

- 
http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html 
Ideas  on  how  to  implement  multi-class  support  vector  machines  - 
http://www.codeproject.com/Articles/106583/Handwriting-Recognition-
Revisited-Kernel-Support-V 

vector  machines 

[4] 

[5]  https://en.wikipedia.org/wiki/Edge_detection 

- 

Image 

boundary 

detection and isolation. 

[6]  â€œBackground Subtraction Techniques: a reviewâ€, Massimo Piccardi 
[7]  A. Ng, â€œCS229 Lecture notesâ€, in CS229 (Machine Learning) class 
[8]  Zheng, Y., & Doermann, D. (2005, August). Handwriting  matching and 
its  application  to  handwriting  synthesis.  In  Document  Analysis  and 
Recognition, 2005. Proceedings. Eighth International Conference on (pp. 
861-865). IEEE. 

[9]  Srihari, S., Zhang, B.,  Tomai, C.,  Lee, S., Shi, Z., & Shin, Y. C. (2003, 
April).  A  system  for  handwriting  matching  and  recognition.  In  Proc. 
Symposium  on  Document  Image  Understanding  Technology  (pp.  67-
75). 

[10]  Srihari,  S.  N.,  Cha,  S.  H.,  Arora,  H.,  &  Lee,  S. (2002).  Individuality  of 

handwriting. Journal of Forensic Sciences, 47(4), 856-872. 

[11]  Wang, J., Wu, C., Xu, Y. Q., & Shum, H. Y. (2005). Combining  shape 
synthesis. 
and  physical  modelsfor  online  cursive  handwriting 
International  Journal  of  Document  Analysis  and  Recognition  (IJDAR), 
7(4), 219-227. 

[12]  Bunke,  H.  (2003,  August).  Generation  of  synthetic  training  data  for  an 

HMM-based handwriting recognition system. In null (p. 618). IEEE. 

[13]  Mori,  M.,  Suzuki,  A.,  Shio,  A.,  Ohtsuka,  S.,  Schomaker,  L.  R.  B.,  & 
Vuurpijl,  L.  G.  (2000,  September).  Generating  new  samples  from 
handwritten  numerals  based  on  point  correspondence.  In  Proc.  7th  Int. 
Workshop on Frontiers in Handwriting Recognition (pp. 281-290). 

[14]  Chui, H., & Rangarajan, A. (2003). A new point matching algorithm for 
non-rigid  registration.  Computer  Vision  and  Image  Understanding, 
89(2), 114-141. 

[15]  Pervouchine,  V.,  &  Leedham,  G.  (2007).  Extraction  and  analysis  of 
forensic  document  examiner  features  used  for  writer  identification. 
Pattern Recognition, 40(3), 1004-1013. 

[16]  Srikantan,  G.,  Lam,  S.  W.,  &  Srihari,  S.  N.  (1996).  Gradient-based 
contour  encoding  for  character  recognition.  Pattern  Recognition,  29(7), 
1147-1160. 

[17]  Cha, S. H., & Srihari, S. (2000, September). Multiple feature integration 
for  writer  verification.  In  Proc.  7th  Int.  Workshop  on  Frontiers  in 
Handwriting Recognition (pp. 333-342). 

[18]  Statistics and Machine Learning Toolbox, MATLAB. 
 
 

