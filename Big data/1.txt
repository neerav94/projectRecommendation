Large-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

Large-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

2

•

Chou et al.

These “movie features” or “character features” are matrices that
summarize the characteristics of each movie or character.

To create the feature, we ﬁrst generated a “timeline” that repre-
sents the entire duration of each movie. We separated the timeline
into 30-second time bins. Then we ﬁlled each time bin with the
scene segments that appear in it. For example, as shown in Fig-
ure 1, House and character 1 appeared in the ﬁrst time bin. House
and character 1 continued to appear in the second time bin, in ad-
dition to Gun and character 2. We repeat this for the entire duration
of each movie, so we can obtain a discretized timeline that cap-
tures the appearance, disappearance, and co-occurrence of objects,
characters, and actions.

To build movie features from our timeline, we took the concept
of w-shingling in text mining [3]. We created three types of shingles
for each timeline: 1-shingle, 2-shingle vertical, and 2-shingle hori-
zontal. 1-shingle is just a histogram of counts for all the items that
appear in each movie. For example, in Figure 1, House appeared 3
times, Gun appeared once, character 1 appeared twice, and so on.
2-shingle vertical counts all the doublets of items that appear within
each time bin, which captures the co-occurrence of items. For ex-
ample, the ﬁrst time bin has the combination (House, 1); the second
time bin has the combinations (House, Gun), (House, 1), (House,
2), (Gun, 1)... etc. Note that the order of items in these shingles
does not matter here. Similarly, we built a histogram of counts for
all these 2-shingles as our feature. 2-shingle horizontal is similar to
2-shingle vertical, but we counted the doublets of items that appear
in two consecutive time bins. For example, the ﬁrst two time bins
have the combinations (House, House), (House, Gun), (House, 1),
(House, 2), (1, House)... etc. Again, we constructed a histogram of
counts for all these 2-shingles. This feature captures the appearance
and disappearance of items in consecutive time bins. It is important
to note that the order of these shingles does matter. The three types
of histogram features were then concatenated to create the ﬁnal fea-
ture used in this work.

The character features were created in a similar fashion. Instead
of counting all possible shingles in each movie, we just used the
time bins that the target character appears. For example, character
1 shows up in time bins 1 and 2, but not 3. So for the feature of
character 1, we just used 1-shingles and 2-shingles in the ﬁrst two
time bins.

Finally, to normalize the importance of each shingle properly, we
applied TF-IDF (term frequencyinverse document frequency) [6], a
commonly used normalization scheme in text mining, to our feature
matrix. The feature for each movie/character is further normalized
to have a unit norm.

3.2 Initial attempts in character classiﬁcation
Using the character features created using the method above, we
ﬁrst attempted to classify characters into different categories. How-
ever, a major difﬁculty is that the characters are not labeled, mak-
ing it impossible for supervised learning. Unsupervised clustering
is also difﬁcult since we did not have a proper distance metric that
would work for our features, which have 20,000 dimensions. In ad-
dition, it is quite difﬁcult to interpret the meaning of each cluster in
such a high-dimensional space. We have tested a few common dis-
tance metrics (Euclidean distance, cosine distance, etc.), but with-
out much success.

We have also tried to manually label a few characters and classi-
ﬁed characters in this small labeled dataset. For example, we man-
ually labeled a few “superheros” such as Batman, Iron Man, Super-
man, Spider man, etc., and classiﬁed the characters as superhero or
non-superhero by logistic regression, SVM, or random forest clas-

CS341 Final Report

Table I. Summary of Genre Classiﬁcation Statistics

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

Accuracy

Precision

0.73
0.76
0.79
0.88
0.88
0.84
0.90
0.92
0.89
0.97
0.91
0.92
0.92
0.99
0.96
0.96
0.95
0.97
0.96
0.96
0.97
0.97
0.98
0.98
0.99
0.99

0.41
0.40
0.34
0.48
0.44
0.16
0.32
0.33
0.20
0.66
0.23
0.23
0.12
0.75
0.14
0.23
0.13
0.28
0.23
0.03
0.16
0.04
0.35
0.06

0

0.16

Recall
0.51
0.50
0.49
0.63
0.52
0.28
0.43
0.44
0.39
0.85
0.38
0.37
0.20
0.84
0.2
0.44
0.26
0.46
0.53
0.04
0.38
0.08
0.60
0.10

0
0.5

Number of movies

4817
4320
3121
2401
2167
1672
1440
1133
1130
24
1078
980
764
444
456
369
370
250
356
335
153
204
167
169
81
42

siﬁer. However, these classiﬁers performed poorly when applied to
the full dataset. For example, Batman and the Joker were both clas-
siﬁed as superhero, although the Joker is actually a vallain. Due to
the limited training data, the classiﬁer could only give a crude pic-
ture of the characters. For example, the previous Batman and Joker
case can be explained intuitively since both batman and joker are
“action”-type characters, and the classiﬁer was probably just clas-
sifying based on “action” rather than “superheros”. An additional
complexity of these methods is that since most characters are from
movies not widely watched, it is difﬁcult to manually label the bulk
of characters in our dataset.

3.3 Movie genre classiﬁcation
Due to the failure in our initial attempt on character proﬁling, we
took a step back to work on movie genre classiﬁcation, since movie
genres are already labeled in the dataset. These movie genre clas-
siﬁcations were then used to help classifying the characters, as dis-
cussed in sections below. We took the movie features, with each
movie labeled with its genres (note that movies may have multiple
genres), to do supervised classiﬁcation. For each genre, we did a
binary classiﬁcation using logistic regression classiﬁer, to predict
if a movie is in the target genre. We also tested SVM and random
forest classiﬁers; the results were similar and worse than logistic
regression. For each genre, we trained the classiﬁer with 90% of
the data, and tested the performance with the remaining 10% of
data. To prevent imbalance between number of positive (movies in
target genre) and negative training examples, we oversampled the
target genre movies in the training set to ensure a 1:1 ratio between
positive and negative data points in our training set. We then apply
the classiﬁer to the test set to determine the accuracy, precision, and
recall of the classiﬁer, as summarized in Table I.

For each genre, we found that the accuracy is usually quite high,
with a good precision and a good recall, especially for the top few

Large-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

2

•

Chou et al.

These “movie features” or “character features” are matrices that
summarize the characteristics of each movie or character.

To create the feature, we ﬁrst generated a “timeline” that repre-
sents the entire duration of each movie. We separated the timeline
into 30-second time bins. Then we ﬁlled each time bin with the
scene segments that appear in it. For example, as shown in Fig-
ure 1, House and character 1 appeared in the ﬁrst time bin. House
and character 1 continued to appear in the second time bin, in ad-
dition to Gun and character 2. We repeat this for the entire duration
of each movie, so we can obtain a discretized timeline that cap-
tures the appearance, disappearance, and co-occurrence of objects,
characters, and actions.

To build movie features from our timeline, we took the concept
of w-shingling in text mining [3]. We created three types of shingles
for each timeline: 1-shingle, 2-shingle vertical, and 2-shingle hori-
zontal. 1-shingle is just a histogram of counts for all the items that
appear in each movie. For example, in Figure 1, House appeared 3
times, Gun appeared once, character 1 appeared twice, and so on.
2-shingle vertical counts all the doublets of items that appear within
each time bin, which captures the co-occurrence of items. For ex-
ample, the ﬁrst time bin has the combination (House, 1); the second
time bin has the combinations (House, Gun), (House, 1), (House,
2), (Gun, 1)... etc. Note that the order of items in these shingles
does not matter here. Similarly, we built a histogram of counts for
all these 2-shingles as our feature. 2-shingle horizontal is similar to
2-shingle vertical, but we counted the doublets of items that appear
in two consecutive time bins. For example, the ﬁrst two time bins
have the combinations (House, House), (House, Gun), (House, 1),
(House, 2), (1, House)... etc. Again, we constructed a histogram of
counts for all these 2-shingles. This feature captures the appearance
and disappearance of items in consecutive time bins. It is important
to note that the order of these shingles does matter. The three types
of histogram features were then concatenated to create the ﬁnal fea-
ture used in this work.

The character features were created in a similar fashion. Instead
of counting all possible shingles in each movie, we just used the
time bins that the target character appears. For example, character
1 shows up in time bins 1 and 2, but not 3. So for the feature of
character 1, we just used 1-shingles and 2-shingles in the ﬁrst two
time bins.

Finally, to normalize the importance of each shingle properly, we
applied TF-IDF (term frequencyinverse document frequency) [6], a
commonly used normalization scheme in text mining, to our feature
matrix. The feature for each movie/character is further normalized
to have a unit norm.

3.2 Initial attempts in character classiﬁcation
Using the character features created using the method above, we
ﬁrst attempted to classify characters into different categories. How-
ever, a major difﬁculty is that the characters are not labeled, mak-
ing it impossible for supervised learning. Unsupervised clustering
is also difﬁcult since we did not have a proper distance metric that
would work for our features, which have 20,000 dimensions. In ad-
dition, it is quite difﬁcult to interpret the meaning of each cluster in
such a high-dimensional space. We have tested a few common dis-
tance metrics (Euclidean distance, cosine distance, etc.), but with-
out much success.

We have also tried to manually label a few characters and classi-
ﬁed characters in this small labeled dataset. For example, we man-
ually labeled a few “superheros” such as Batman, Iron Man, Super-
man, Spider man, etc., and classiﬁed the characters as superhero or
non-superhero by logistic regression, SVM, or random forest clas-

CS341 Final Report

Table I. Summary of Genre Classiﬁcation Statistics

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

Accuracy

Precision

0.73
0.76
0.79
0.88
0.88
0.84
0.90
0.92
0.89
0.97
0.91
0.92
0.92
0.99
0.96
0.96
0.95
0.97
0.96
0.96
0.97
0.97
0.98
0.98
0.99
0.99

0.41
0.40
0.34
0.48
0.44
0.16
0.32
0.33
0.20
0.66
0.23
0.23
0.12
0.75
0.14
0.23
0.13
0.28
0.23
0.03
0.16
0.04
0.35
0.06

0

0.16

Recall
0.51
0.50
0.49
0.63
0.52
0.28
0.43
0.44
0.39
0.85
0.38
0.37
0.20
0.84
0.2
0.44
0.26
0.46
0.53
0.04
0.38
0.08
0.60
0.10

0
0.5

Number of movies

4817
4320
3121
2401
2167
1672
1440
1133
1130
24
1078
980
764
444
456
369
370
250
356
335
153
204
167
169
81
42

siﬁer. However, these classiﬁers performed poorly when applied to
the full dataset. For example, Batman and the Joker were both clas-
siﬁed as superhero, although the Joker is actually a vallain. Due to
the limited training data, the classiﬁer could only give a crude pic-
ture of the characters. For example, the previous Batman and Joker
case can be explained intuitively since both batman and joker are
“action”-type characters, and the classiﬁer was probably just clas-
sifying based on “action” rather than “superheros”. An additional
complexity of these methods is that since most characters are from
movies not widely watched, it is difﬁcult to manually label the bulk
of characters in our dataset.

3.3 Movie genre classiﬁcation
Due to the failure in our initial attempt on character proﬁling, we
took a step back to work on movie genre classiﬁcation, since movie
genres are already labeled in the dataset. These movie genre clas-
siﬁcations were then used to help classifying the characters, as dis-
cussed in sections below. We took the movie features, with each
movie labeled with its genres (note that movies may have multiple
genres), to do supervised classiﬁcation. For each genre, we did a
binary classiﬁcation using logistic regression classiﬁer, to predict
if a movie is in the target genre. We also tested SVM and random
forest classiﬁers; the results were similar and worse than logistic
regression. For each genre, we trained the classiﬁer with 90% of
the data, and tested the performance with the remaining 10% of
data. To prevent imbalance between number of positive (movies in
target genre) and negative training examples, we oversampled the
target genre movies in the training set to ensure a 1:1 ratio between
positive and negative data points in our training set. We then apply
the classiﬁer to the test set to determine the accuracy, precision, and
recall of the classiﬁer, as summarized in Table I.

For each genre, we found that the accuracy is usually quite high,
with a good precision and a good recall, especially for the top few

Large-scale Proﬁling of Movie Scenes and Character Types

•

3

Fig. 1. Example movie feature and timeline. The timeline is separated into 30 second time bins, and the scene segments that appear in each time bin is
counted. Then, 1-shingles, 2-shingle horizontal, and 2-shingle vertical features can be constructed from the timeline.

Table II. Selected examples of features
Genre
Action

Selected Positive Features

(Attacking, Jumping, vertical)
(Running, Riding, horizontal)

Drama

(Car, Hotel/motel/inn, horizontal)

(Exploding, Ship, horizontal)
(School, Weapon, vertical)

(Street/Road, Bedroom, horizontal)
(Dining Room, Field, horizontal)
(Magazines, Bags, horizontal)

(House, Porch, vertical)

(House, Smoking, vertical)

genres (which appears more often and is more critical). For the
bottom genres, due to the limited number of examples in the data,
the recall and precision were quite low. Furthermore, Western, a
unique genre in our data, had very high accuracy, precision, and
recall (>0.7) at the same time. For other more common genres, e.g.
action, horror, and drama, the accuracies were limited to around 0.7
to 0.9 with precisions and recalls around 0.5. This is due to many
movies of these types often cross multiple genres.

To understand what shingles are signatures for each genre classi-
ﬁer, we extracted the important feature components for each genre
classiﬁer, as shown in Table II. The features make sense. For ex-
ample, for Action movies, the critical features involve combina-
tions between actions like attacking, jumping, exploding, and ob-
jects like weapon and car. Drama movies, on the other hand, have
important features involving bedroom, dining room, house, porch,
etc.

3.4 Attempts to improve the movie and character

features

Since now we have a good benchmark, we can try to optimize our
features. It is possible that not only the items that appear in each
time bin that is important, but the difference of items between each
consecutive time bins can also important. We incorporated these
“difference features” in addition to the 1-shingle and 2-shingles

described above and ran feature selection with the genre classiﬁer.
However, the addition of these difference features did not signiﬁ-
cantly improve the performance of the genre classiﬁer.

Furthermore, to test the importance of different single types, we
also repeated the experiment with only 1-shingle, and the accuracy
is general decreased around 0.2. Thus, this indicates the addition of
the 2-shingles are crucial.

3.5 Analyzing characters
We proceeded with our original movie and character features with-
out the incorporation of the difference features and feature selec-
tions to keep things simple. With our previous results in movie
classiﬁcation, we applied the logistic regression classiﬁers for each
genre, trained with the movie features, to each character feature.
We then calculated the probability that each character exhibits a
particular genre type. Essentially, we are mapping the character
feature onto each movie genre. One example is shown in Table III,
which analyzed Batman and Joker from the movie The Dark Knight
(2008). As expected, Batman exhibits high scores in Thriller (0.96),
Action (0.37), Adventure (0.97) and Crime Drama (0.74). Batman
also has a high score in Science Fiction (0.99), probably due to his
extraordinary powers and technology. As portrayed throughout the
movie, Batman has a high level of mystery, as indicated by his high
score in Mystery (0.87). Thus, the analysis of Batman makes intu-
itive sense. If we compare the Joker from the same movie, we can
see that many of the scores are similar. Though, it is interesting to
note that while Batman has a very low Horror score, the Joker has a
very high score (0.96). Moreover, Batman has a very high score in
Mystery (0.87), while the Joker has a relatively low score (0.002).
Thus, our character proﬁling method is not just picking out the gen-
res of the movies where the characters belong to; instead, we are
able to separate out characters of different types within the same
movie.

CS341 Final Report

GunChar 1Char 2Char 3HouseHouse1HouseGun12House231-shingle: {(House): 3, (Gun): 1, (1): 2, (2): 2, (3): 1}2-shingle horizontal: {(House, House): 2, (House, Gun): 1, (House, 1): 1, (House, 2): 2……..}Order matters2-shingle vertical: {(House, 1): 2, (House, Gun): 1, (House, 2): 2, (Gun, 1): 1……..}Order  does not matterLarge-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

2

•

Chou et al.

These “movie features” or “character features” are matrices that
summarize the characteristics of each movie or character.

To create the feature, we ﬁrst generated a “timeline” that repre-
sents the entire duration of each movie. We separated the timeline
into 30-second time bins. Then we ﬁlled each time bin with the
scene segments that appear in it. For example, as shown in Fig-
ure 1, House and character 1 appeared in the ﬁrst time bin. House
and character 1 continued to appear in the second time bin, in ad-
dition to Gun and character 2. We repeat this for the entire duration
of each movie, so we can obtain a discretized timeline that cap-
tures the appearance, disappearance, and co-occurrence of objects,
characters, and actions.

To build movie features from our timeline, we took the concept
of w-shingling in text mining [3]. We created three types of shingles
for each timeline: 1-shingle, 2-shingle vertical, and 2-shingle hori-
zontal. 1-shingle is just a histogram of counts for all the items that
appear in each movie. For example, in Figure 1, House appeared 3
times, Gun appeared once, character 1 appeared twice, and so on.
2-shingle vertical counts all the doublets of items that appear within
each time bin, which captures the co-occurrence of items. For ex-
ample, the ﬁrst time bin has the combination (House, 1); the second
time bin has the combinations (House, Gun), (House, 1), (House,
2), (Gun, 1)... etc. Note that the order of items in these shingles
does not matter here. Similarly, we built a histogram of counts for
all these 2-shingles as our feature. 2-shingle horizontal is similar to
2-shingle vertical, but we counted the doublets of items that appear
in two consecutive time bins. For example, the ﬁrst two time bins
have the combinations (House, House), (House, Gun), (House, 1),
(House, 2), (1, House)... etc. Again, we constructed a histogram of
counts for all these 2-shingles. This feature captures the appearance
and disappearance of items in consecutive time bins. It is important
to note that the order of these shingles does matter. The three types
of histogram features were then concatenated to create the ﬁnal fea-
ture used in this work.

The character features were created in a similar fashion. Instead
of counting all possible shingles in each movie, we just used the
time bins that the target character appears. For example, character
1 shows up in time bins 1 and 2, but not 3. So for the feature of
character 1, we just used 1-shingles and 2-shingles in the ﬁrst two
time bins.

Finally, to normalize the importance of each shingle properly, we
applied TF-IDF (term frequencyinverse document frequency) [6], a
commonly used normalization scheme in text mining, to our feature
matrix. The feature for each movie/character is further normalized
to have a unit norm.

3.2 Initial attempts in character classiﬁcation
Using the character features created using the method above, we
ﬁrst attempted to classify characters into different categories. How-
ever, a major difﬁculty is that the characters are not labeled, mak-
ing it impossible for supervised learning. Unsupervised clustering
is also difﬁcult since we did not have a proper distance metric that
would work for our features, which have 20,000 dimensions. In ad-
dition, it is quite difﬁcult to interpret the meaning of each cluster in
such a high-dimensional space. We have tested a few common dis-
tance metrics (Euclidean distance, cosine distance, etc.), but with-
out much success.

We have also tried to manually label a few characters and classi-
ﬁed characters in this small labeled dataset. For example, we man-
ually labeled a few “superheros” such as Batman, Iron Man, Super-
man, Spider man, etc., and classiﬁed the characters as superhero or
non-superhero by logistic regression, SVM, or random forest clas-

CS341 Final Report

Table I. Summary of Genre Classiﬁcation Statistics

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

Accuracy

Precision

0.73
0.76
0.79
0.88
0.88
0.84
0.90
0.92
0.89
0.97
0.91
0.92
0.92
0.99
0.96
0.96
0.95
0.97
0.96
0.96
0.97
0.97
0.98
0.98
0.99
0.99

0.41
0.40
0.34
0.48
0.44
0.16
0.32
0.33
0.20
0.66
0.23
0.23
0.12
0.75
0.14
0.23
0.13
0.28
0.23
0.03
0.16
0.04
0.35
0.06

0

0.16

Recall
0.51
0.50
0.49
0.63
0.52
0.28
0.43
0.44
0.39
0.85
0.38
0.37
0.20
0.84
0.2
0.44
0.26
0.46
0.53
0.04
0.38
0.08
0.60
0.10

0
0.5

Number of movies

4817
4320
3121
2401
2167
1672
1440
1133
1130
24
1078
980
764
444
456
369
370
250
356
335
153
204
167
169
81
42

siﬁer. However, these classiﬁers performed poorly when applied to
the full dataset. For example, Batman and the Joker were both clas-
siﬁed as superhero, although the Joker is actually a vallain. Due to
the limited training data, the classiﬁer could only give a crude pic-
ture of the characters. For example, the previous Batman and Joker
case can be explained intuitively since both batman and joker are
“action”-type characters, and the classiﬁer was probably just clas-
sifying based on “action” rather than “superheros”. An additional
complexity of these methods is that since most characters are from
movies not widely watched, it is difﬁcult to manually label the bulk
of characters in our dataset.

3.3 Movie genre classiﬁcation
Due to the failure in our initial attempt on character proﬁling, we
took a step back to work on movie genre classiﬁcation, since movie
genres are already labeled in the dataset. These movie genre clas-
siﬁcations were then used to help classifying the characters, as dis-
cussed in sections below. We took the movie features, with each
movie labeled with its genres (note that movies may have multiple
genres), to do supervised classiﬁcation. For each genre, we did a
binary classiﬁcation using logistic regression classiﬁer, to predict
if a movie is in the target genre. We also tested SVM and random
forest classiﬁers; the results were similar and worse than logistic
regression. For each genre, we trained the classiﬁer with 90% of
the data, and tested the performance with the remaining 10% of
data. To prevent imbalance between number of positive (movies in
target genre) and negative training examples, we oversampled the
target genre movies in the training set to ensure a 1:1 ratio between
positive and negative data points in our training set. We then apply
the classiﬁer to the test set to determine the accuracy, precision, and
recall of the classiﬁer, as summarized in Table I.

For each genre, we found that the accuracy is usually quite high,
with a good precision and a good recall, especially for the top few

Large-scale Proﬁling of Movie Scenes and Character Types

•

3

Fig. 1. Example movie feature and timeline. The timeline is separated into 30 second time bins, and the scene segments that appear in each time bin is
counted. Then, 1-shingles, 2-shingle horizontal, and 2-shingle vertical features can be constructed from the timeline.

Table II. Selected examples of features
Genre
Action

Selected Positive Features

(Attacking, Jumping, vertical)
(Running, Riding, horizontal)

Drama

(Car, Hotel/motel/inn, horizontal)

(Exploding, Ship, horizontal)
(School, Weapon, vertical)

(Street/Road, Bedroom, horizontal)
(Dining Room, Field, horizontal)
(Magazines, Bags, horizontal)

(House, Porch, vertical)

(House, Smoking, vertical)

genres (which appears more often and is more critical). For the
bottom genres, due to the limited number of examples in the data,
the recall and precision were quite low. Furthermore, Western, a
unique genre in our data, had very high accuracy, precision, and
recall (>0.7) at the same time. For other more common genres, e.g.
action, horror, and drama, the accuracies were limited to around 0.7
to 0.9 with precisions and recalls around 0.5. This is due to many
movies of these types often cross multiple genres.

To understand what shingles are signatures for each genre classi-
ﬁer, we extracted the important feature components for each genre
classiﬁer, as shown in Table II. The features make sense. For ex-
ample, for Action movies, the critical features involve combina-
tions between actions like attacking, jumping, exploding, and ob-
jects like weapon and car. Drama movies, on the other hand, have
important features involving bedroom, dining room, house, porch,
etc.

3.4 Attempts to improve the movie and character

features

Since now we have a good benchmark, we can try to optimize our
features. It is possible that not only the items that appear in each
time bin that is important, but the difference of items between each
consecutive time bins can also important. We incorporated these
“difference features” in addition to the 1-shingle and 2-shingles

described above and ran feature selection with the genre classiﬁer.
However, the addition of these difference features did not signiﬁ-
cantly improve the performance of the genre classiﬁer.

Furthermore, to test the importance of different single types, we
also repeated the experiment with only 1-shingle, and the accuracy
is general decreased around 0.2. Thus, this indicates the addition of
the 2-shingles are crucial.

3.5 Analyzing characters
We proceeded with our original movie and character features with-
out the incorporation of the difference features and feature selec-
tions to keep things simple. With our previous results in movie
classiﬁcation, we applied the logistic regression classiﬁers for each
genre, trained with the movie features, to each character feature.
We then calculated the probability that each character exhibits a
particular genre type. Essentially, we are mapping the character
feature onto each movie genre. One example is shown in Table III,
which analyzed Batman and Joker from the movie The Dark Knight
(2008). As expected, Batman exhibits high scores in Thriller (0.96),
Action (0.37), Adventure (0.97) and Crime Drama (0.74). Batman
also has a high score in Science Fiction (0.99), probably due to his
extraordinary powers and technology. As portrayed throughout the
movie, Batman has a high level of mystery, as indicated by his high
score in Mystery (0.87). Thus, the analysis of Batman makes intu-
itive sense. If we compare the Joker from the same movie, we can
see that many of the scores are similar. Though, it is interesting to
note that while Batman has a very low Horror score, the Joker has a
very high score (0.96). Moreover, Batman has a very high score in
Mystery (0.87), while the Joker has a relatively low score (0.002).
Thus, our character proﬁling method is not just picking out the gen-
res of the movies where the characters belong to; instead, we are
able to separate out characters of different types within the same
movie.

CS341 Final Report

GunChar 1Char 2Char 3HouseHouse1HouseGun12House231-shingle: {(House): 3, (Gun): 1, (1): 2, (2): 2, (3): 1}2-shingle horizontal: {(House, House): 2, (House, Gun): 1, (House, 1): 1, (House, 2): 2……..}Order matters2-shingle vertical: {(House, 1): 2, (House, Gun): 1, (House, 2): 2, (Gun, 1): 1……..}Order  does not matter4

•

Chou et al.

Table III. Example Character Analysis of the Dark Knight
Dark Knight/Joker

Dark Knight/Batman

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

0.005083
0.376786
0.961771
0.365348
0.001306
0.036339
0.971452
0.997813
0.744358
0.000039
0.000000
0.385773
0.001062
0.000182
0.000002
0.000016
0.000423
0.062279
0.000011
0.868754
0.000138
0.000628
0.002699
0.000004
0.009716
0.000000

0.001103
0.034829
0.991281
0.992663
0.959315
0.000007
0.788594
0.372594
0.001417
0.000000
0.000000
0.984121
0.000100
0.000550
0.003090
0.000000
0.000005
0.001833
0.000045
0.002359
0.000002
0.000000
0.031714
0.000000
0.000000
0.000145

3.6 Validation: statistical analysis and trending of

character types

Though manually picking out interesting characters, the character
proﬁle seems to make intuitive sense. However, we need a method
to statistically validate our method and results, using the entire
dataset instead of just observing individual examples. In follow-
ing paragraphs, we will describe two comprehensive analysis of all
characters in our dataset, by analyzing the distribution of types of
characters in each movie genre, and by analyzing the frequency of
combinations of character types in different movie genres.

To gain more insight into the results, we plotted the histogram of
the probability scores for each character types for different movie
genres, as shown in Figure 2. The ﬁgure shows that in a certain
movie genre, the distributions of genre types are different. For ex-
ample, in Horror movies, the characters typically have high Thriller
scores and low Action scores. Moreover, we can see that the distri-
bution of types varies with the movie genres. For instance, charac-
ters in Drama movies have a quite uniform distribution in Drama
type; on the other hand, the characters in other genres, such as Ac-
tion and Horror, tends to be less ”Dramatic”, with distributions
peaking near zero. It is important to note that the y-axis is log-
scale. Furthermore, there are two clear peaks in some distributions,
indicating that in the some movie genre, many characters have high
tendency to a certain type while many others have low tendency.
Take Action movies for example, some characters seem to be very
”Horror” but some are very ”non Horror”, and this might be a use-
ful feature for separating the characters.

Second, we analyzed the character dataset to see if any particu-
lar combination of character types in the same movie appears much
more frequently in each movie genre. For each character, we se-
lected the top three genres with highest probability scores as the
“characteristic types” of the character. The genres of the movie that

CS341 Final Report

the character is from were excluded, as it is used in training our
character genre classiﬁer. For each pair of characters in the same
movie, we then extract all pairs of character types. For example,
suppose we have a character Alice, with types Drama, Fantasy and
Thriller, and another character Bob in the same movie classiﬁed as
Action, Horror and Thriller, we then have character type pairs such
as (Drama, Action), (Fantasy, Action), (Drama, Horror), etc. We
ﬁrst generated the baseline by computing histogram of character
genre pairs for all possible character pairs in our dataset. For each
movie genre, we counted the number of character type pairs for ev-
ery pair of characters in the same movie, to see if different movie
genres will give different distributions of commonly appeared char-
acter genre pairs. As shown in Fig. 3, indeed many combinations
of character types appear more often than the baseline values for
different movie genres. Table IV summarizes the top combina-
tions appear in different genres. For example, Action genre movies
tend to have character combinations of (Horror, Science Fiction),
(Science Fiction, Crime Drama)...etc. Drama movies, on the other
hand, tend to have combinations of (Comedy drama, Romance),
(Comedy drama, Biography),...etc. Due to space limitations, we
only showed a few examples, but this analysis works across all the
different genre types. Thus, different movie genres tend to have
different character type combinations, as expected. In Table V, we
showed a few movie examples with characters of different types
in the same movie. We have the example described before: Bat-
man from the Dark Knight is a Science Fiction (or Crime Drama
or Mystery), while the Joker is mainly Horror. From the result, we
found that our character type assignments give statistically signif-
icant difference to the baseline across all the movie data. The ob-
tained character type combinations also gave additional insights on
the combination of character types preferred in different movie gen-
res.

3.7 Impediments and difﬁculties
The main difﬁculty in doing character analysis is the lack of labeled
data, in addition to limited knowledge of sufﬁcient number of char-
acters to do manual labeling. Thus, it is difﬁcult to do a straightfor-
ward unsupervised clustering or supervised learning. Furthermore,
there is usually a very broad spectrum of character types, so even
if we have an appropriate distance metric, we may not be able to
cluster the characters in a very meaningful way. Another difﬁculty
is the lack of detailed scene annotations. Even though each scene
is annotated, the tags are quite general (for example, car, explo-
sion, vehicle, house...etc). If the tags can be more detailed, more
insight can probably be mined from the data. Finally, although we
were able to use the co-occurrence, appearance and disappearance
of items to capture their correlation, the exact association between
items can be ambiguous. For example, suppose we have two char-
acters Alice and Bob and a gun appeared together in a scene, it
may represent various scenes, such as (1) Alice shooting Bob with
the gun, (2) Bob shooting Alice with the gun, (3) Bob holding a
gun to guard Alice, etc. Since these scenarios lead to very differ-
ent interpretations of the types of the characters, it is challenging to
correctly proﬁle each character with the data.

4. FUTURE WORK
Although we have developed a method to do large-scale proﬁl-
ing for character analysis, more work can be done. The movie
and character features can be further improved by including addi-
tional information, for example the actor(s), year, director...etc for
each movie or character. Furthermore, the scene annotations actu-

Large-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

2

•

Chou et al.

These “movie features” or “character features” are matrices that
summarize the characteristics of each movie or character.

To create the feature, we ﬁrst generated a “timeline” that repre-
sents the entire duration of each movie. We separated the timeline
into 30-second time bins. Then we ﬁlled each time bin with the
scene segments that appear in it. For example, as shown in Fig-
ure 1, House and character 1 appeared in the ﬁrst time bin. House
and character 1 continued to appear in the second time bin, in ad-
dition to Gun and character 2. We repeat this for the entire duration
of each movie, so we can obtain a discretized timeline that cap-
tures the appearance, disappearance, and co-occurrence of objects,
characters, and actions.

To build movie features from our timeline, we took the concept
of w-shingling in text mining [3]. We created three types of shingles
for each timeline: 1-shingle, 2-shingle vertical, and 2-shingle hori-
zontal. 1-shingle is just a histogram of counts for all the items that
appear in each movie. For example, in Figure 1, House appeared 3
times, Gun appeared once, character 1 appeared twice, and so on.
2-shingle vertical counts all the doublets of items that appear within
each time bin, which captures the co-occurrence of items. For ex-
ample, the ﬁrst time bin has the combination (House, 1); the second
time bin has the combinations (House, Gun), (House, 1), (House,
2), (Gun, 1)... etc. Note that the order of items in these shingles
does not matter here. Similarly, we built a histogram of counts for
all these 2-shingles as our feature. 2-shingle horizontal is similar to
2-shingle vertical, but we counted the doublets of items that appear
in two consecutive time bins. For example, the ﬁrst two time bins
have the combinations (House, House), (House, Gun), (House, 1),
(House, 2), (1, House)... etc. Again, we constructed a histogram of
counts for all these 2-shingles. This feature captures the appearance
and disappearance of items in consecutive time bins. It is important
to note that the order of these shingles does matter. The three types
of histogram features were then concatenated to create the ﬁnal fea-
ture used in this work.

The character features were created in a similar fashion. Instead
of counting all possible shingles in each movie, we just used the
time bins that the target character appears. For example, character
1 shows up in time bins 1 and 2, but not 3. So for the feature of
character 1, we just used 1-shingles and 2-shingles in the ﬁrst two
time bins.

Finally, to normalize the importance of each shingle properly, we
applied TF-IDF (term frequencyinverse document frequency) [6], a
commonly used normalization scheme in text mining, to our feature
matrix. The feature for each movie/character is further normalized
to have a unit norm.

3.2 Initial attempts in character classiﬁcation
Using the character features created using the method above, we
ﬁrst attempted to classify characters into different categories. How-
ever, a major difﬁculty is that the characters are not labeled, mak-
ing it impossible for supervised learning. Unsupervised clustering
is also difﬁcult since we did not have a proper distance metric that
would work for our features, which have 20,000 dimensions. In ad-
dition, it is quite difﬁcult to interpret the meaning of each cluster in
such a high-dimensional space. We have tested a few common dis-
tance metrics (Euclidean distance, cosine distance, etc.), but with-
out much success.

We have also tried to manually label a few characters and classi-
ﬁed characters in this small labeled dataset. For example, we man-
ually labeled a few “superheros” such as Batman, Iron Man, Super-
man, Spider man, etc., and classiﬁed the characters as superhero or
non-superhero by logistic regression, SVM, or random forest clas-

CS341 Final Report

Table I. Summary of Genre Classiﬁcation Statistics

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

Accuracy

Precision

0.73
0.76
0.79
0.88
0.88
0.84
0.90
0.92
0.89
0.97
0.91
0.92
0.92
0.99
0.96
0.96
0.95
0.97
0.96
0.96
0.97
0.97
0.98
0.98
0.99
0.99

0.41
0.40
0.34
0.48
0.44
0.16
0.32
0.33
0.20
0.66
0.23
0.23
0.12
0.75
0.14
0.23
0.13
0.28
0.23
0.03
0.16
0.04
0.35
0.06

0

0.16

Recall
0.51
0.50
0.49
0.63
0.52
0.28
0.43
0.44
0.39
0.85
0.38
0.37
0.20
0.84
0.2
0.44
0.26
0.46
0.53
0.04
0.38
0.08
0.60
0.10

0
0.5

Number of movies

4817
4320
3121
2401
2167
1672
1440
1133
1130
24
1078
980
764
444
456
369
370
250
356
335
153
204
167
169
81
42

siﬁer. However, these classiﬁers performed poorly when applied to
the full dataset. For example, Batman and the Joker were both clas-
siﬁed as superhero, although the Joker is actually a vallain. Due to
the limited training data, the classiﬁer could only give a crude pic-
ture of the characters. For example, the previous Batman and Joker
case can be explained intuitively since both batman and joker are
“action”-type characters, and the classiﬁer was probably just clas-
sifying based on “action” rather than “superheros”. An additional
complexity of these methods is that since most characters are from
movies not widely watched, it is difﬁcult to manually label the bulk
of characters in our dataset.

3.3 Movie genre classiﬁcation
Due to the failure in our initial attempt on character proﬁling, we
took a step back to work on movie genre classiﬁcation, since movie
genres are already labeled in the dataset. These movie genre clas-
siﬁcations were then used to help classifying the characters, as dis-
cussed in sections below. We took the movie features, with each
movie labeled with its genres (note that movies may have multiple
genres), to do supervised classiﬁcation. For each genre, we did a
binary classiﬁcation using logistic regression classiﬁer, to predict
if a movie is in the target genre. We also tested SVM and random
forest classiﬁers; the results were similar and worse than logistic
regression. For each genre, we trained the classiﬁer with 90% of
the data, and tested the performance with the remaining 10% of
data. To prevent imbalance between number of positive (movies in
target genre) and negative training examples, we oversampled the
target genre movies in the training set to ensure a 1:1 ratio between
positive and negative data points in our training set. We then apply
the classiﬁer to the test set to determine the accuracy, precision, and
recall of the classiﬁer, as summarized in Table I.

For each genre, we found that the accuracy is usually quite high,
with a good precision and a good recall, especially for the top few

Large-scale Proﬁling of Movie Scenes and Character Types

•

3

Fig. 1. Example movie feature and timeline. The timeline is separated into 30 second time bins, and the scene segments that appear in each time bin is
counted. Then, 1-shingles, 2-shingle horizontal, and 2-shingle vertical features can be constructed from the timeline.

Table II. Selected examples of features
Genre
Action

Selected Positive Features

(Attacking, Jumping, vertical)
(Running, Riding, horizontal)

Drama

(Car, Hotel/motel/inn, horizontal)

(Exploding, Ship, horizontal)
(School, Weapon, vertical)

(Street/Road, Bedroom, horizontal)
(Dining Room, Field, horizontal)
(Magazines, Bags, horizontal)

(House, Porch, vertical)

(House, Smoking, vertical)

genres (which appears more often and is more critical). For the
bottom genres, due to the limited number of examples in the data,
the recall and precision were quite low. Furthermore, Western, a
unique genre in our data, had very high accuracy, precision, and
recall (>0.7) at the same time. For other more common genres, e.g.
action, horror, and drama, the accuracies were limited to around 0.7
to 0.9 with precisions and recalls around 0.5. This is due to many
movies of these types often cross multiple genres.

To understand what shingles are signatures for each genre classi-
ﬁer, we extracted the important feature components for each genre
classiﬁer, as shown in Table II. The features make sense. For ex-
ample, for Action movies, the critical features involve combina-
tions between actions like attacking, jumping, exploding, and ob-
jects like weapon and car. Drama movies, on the other hand, have
important features involving bedroom, dining room, house, porch,
etc.

3.4 Attempts to improve the movie and character

features

Since now we have a good benchmark, we can try to optimize our
features. It is possible that not only the items that appear in each
time bin that is important, but the difference of items between each
consecutive time bins can also important. We incorporated these
“difference features” in addition to the 1-shingle and 2-shingles

described above and ran feature selection with the genre classiﬁer.
However, the addition of these difference features did not signiﬁ-
cantly improve the performance of the genre classiﬁer.

Furthermore, to test the importance of different single types, we
also repeated the experiment with only 1-shingle, and the accuracy
is general decreased around 0.2. Thus, this indicates the addition of
the 2-shingles are crucial.

3.5 Analyzing characters
We proceeded with our original movie and character features with-
out the incorporation of the difference features and feature selec-
tions to keep things simple. With our previous results in movie
classiﬁcation, we applied the logistic regression classiﬁers for each
genre, trained with the movie features, to each character feature.
We then calculated the probability that each character exhibits a
particular genre type. Essentially, we are mapping the character
feature onto each movie genre. One example is shown in Table III,
which analyzed Batman and Joker from the movie The Dark Knight
(2008). As expected, Batman exhibits high scores in Thriller (0.96),
Action (0.37), Adventure (0.97) and Crime Drama (0.74). Batman
also has a high score in Science Fiction (0.99), probably due to his
extraordinary powers and technology. As portrayed throughout the
movie, Batman has a high level of mystery, as indicated by his high
score in Mystery (0.87). Thus, the analysis of Batman makes intu-
itive sense. If we compare the Joker from the same movie, we can
see that many of the scores are similar. Though, it is interesting to
note that while Batman has a very low Horror score, the Joker has a
very high score (0.96). Moreover, Batman has a very high score in
Mystery (0.87), while the Joker has a relatively low score (0.002).
Thus, our character proﬁling method is not just picking out the gen-
res of the movies where the characters belong to; instead, we are
able to separate out characters of different types within the same
movie.

CS341 Final Report

GunChar 1Char 2Char 3HouseHouse1HouseGun12House231-shingle: {(House): 3, (Gun): 1, (1): 2, (2): 2, (3): 1}2-shingle horizontal: {(House, House): 2, (House, Gun): 1, (House, 1): 1, (House, 2): 2……..}Order matters2-shingle vertical: {(House, 1): 2, (House, Gun): 1, (House, 2): 2, (Gun, 1): 1……..}Order  does not matter4

•

Chou et al.

Table III. Example Character Analysis of the Dark Knight
Dark Knight/Joker

Dark Knight/Batman

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

0.005083
0.376786
0.961771
0.365348
0.001306
0.036339
0.971452
0.997813
0.744358
0.000039
0.000000
0.385773
0.001062
0.000182
0.000002
0.000016
0.000423
0.062279
0.000011
0.868754
0.000138
0.000628
0.002699
0.000004
0.009716
0.000000

0.001103
0.034829
0.991281
0.992663
0.959315
0.000007
0.788594
0.372594
0.001417
0.000000
0.000000
0.984121
0.000100
0.000550
0.003090
0.000000
0.000005
0.001833
0.000045
0.002359
0.000002
0.000000
0.031714
0.000000
0.000000
0.000145

3.6 Validation: statistical analysis and trending of

character types

Though manually picking out interesting characters, the character
proﬁle seems to make intuitive sense. However, we need a method
to statistically validate our method and results, using the entire
dataset instead of just observing individual examples. In follow-
ing paragraphs, we will describe two comprehensive analysis of all
characters in our dataset, by analyzing the distribution of types of
characters in each movie genre, and by analyzing the frequency of
combinations of character types in different movie genres.

To gain more insight into the results, we plotted the histogram of
the probability scores for each character types for different movie
genres, as shown in Figure 2. The ﬁgure shows that in a certain
movie genre, the distributions of genre types are different. For ex-
ample, in Horror movies, the characters typically have high Thriller
scores and low Action scores. Moreover, we can see that the distri-
bution of types varies with the movie genres. For instance, charac-
ters in Drama movies have a quite uniform distribution in Drama
type; on the other hand, the characters in other genres, such as Ac-
tion and Horror, tends to be less ”Dramatic”, with distributions
peaking near zero. It is important to note that the y-axis is log-
scale. Furthermore, there are two clear peaks in some distributions,
indicating that in the some movie genre, many characters have high
tendency to a certain type while many others have low tendency.
Take Action movies for example, some characters seem to be very
”Horror” but some are very ”non Horror”, and this might be a use-
ful feature for separating the characters.

Second, we analyzed the character dataset to see if any particu-
lar combination of character types in the same movie appears much
more frequently in each movie genre. For each character, we se-
lected the top three genres with highest probability scores as the
“characteristic types” of the character. The genres of the movie that

CS341 Final Report

the character is from were excluded, as it is used in training our
character genre classiﬁer. For each pair of characters in the same
movie, we then extract all pairs of character types. For example,
suppose we have a character Alice, with types Drama, Fantasy and
Thriller, and another character Bob in the same movie classiﬁed as
Action, Horror and Thriller, we then have character type pairs such
as (Drama, Action), (Fantasy, Action), (Drama, Horror), etc. We
ﬁrst generated the baseline by computing histogram of character
genre pairs for all possible character pairs in our dataset. For each
movie genre, we counted the number of character type pairs for ev-
ery pair of characters in the same movie, to see if different movie
genres will give different distributions of commonly appeared char-
acter genre pairs. As shown in Fig. 3, indeed many combinations
of character types appear more often than the baseline values for
different movie genres. Table IV summarizes the top combina-
tions appear in different genres. For example, Action genre movies
tend to have character combinations of (Horror, Science Fiction),
(Science Fiction, Crime Drama)...etc. Drama movies, on the other
hand, tend to have combinations of (Comedy drama, Romance),
(Comedy drama, Biography),...etc. Due to space limitations, we
only showed a few examples, but this analysis works across all the
different genre types. Thus, different movie genres tend to have
different character type combinations, as expected. In Table V, we
showed a few movie examples with characters of different types
in the same movie. We have the example described before: Bat-
man from the Dark Knight is a Science Fiction (or Crime Drama
or Mystery), while the Joker is mainly Horror. From the result, we
found that our character type assignments give statistically signif-
icant difference to the baseline across all the movie data. The ob-
tained character type combinations also gave additional insights on
the combination of character types preferred in different movie gen-
res.

3.7 Impediments and difﬁculties
The main difﬁculty in doing character analysis is the lack of labeled
data, in addition to limited knowledge of sufﬁcient number of char-
acters to do manual labeling. Thus, it is difﬁcult to do a straightfor-
ward unsupervised clustering or supervised learning. Furthermore,
there is usually a very broad spectrum of character types, so even
if we have an appropriate distance metric, we may not be able to
cluster the characters in a very meaningful way. Another difﬁculty
is the lack of detailed scene annotations. Even though each scene
is annotated, the tags are quite general (for example, car, explo-
sion, vehicle, house...etc). If the tags can be more detailed, more
insight can probably be mined from the data. Finally, although we
were able to use the co-occurrence, appearance and disappearance
of items to capture their correlation, the exact association between
items can be ambiguous. For example, suppose we have two char-
acters Alice and Bob and a gun appeared together in a scene, it
may represent various scenes, such as (1) Alice shooting Bob with
the gun, (2) Bob shooting Alice with the gun, (3) Bob holding a
gun to guard Alice, etc. Since these scenarios lead to very differ-
ent interpretations of the types of the characters, it is challenging to
correctly proﬁle each character with the data.

4. FUTURE WORK
Although we have developed a method to do large-scale proﬁl-
ing for character analysis, more work can be done. The movie
and character features can be further improved by including addi-
tional information, for example the actor(s), year, director...etc for
each movie or character. Furthermore, the scene annotations actu-

Large-scale Proﬁling of Movie Scenes and Character Types

•

5

Fig. 2. Histogram of character genre feature in different movie genres. The ﬁgure only shows the histograms of the ﬁrst 6 types in 5 different movie genres.
The x-axis is the probability from 0 to 1, divided into 10 bins in the histograms, and the y-axis plots the counts of each bin in log scale.

Fig. 3. Histogram of genre pairs for characters from four selected movie genres. The x-axis plots the genre pairs, with each pair indexed as an integer (not
shown). Also the genre pairs are sorted based on their probability in the baseline (blue). The y-axis plots the frequency of each genre pair. The green line plots
the histogram for the genre pairs from the particular genre. The blue line plots the base line when movies are randomly selected from any genre. Since the
x-axis is sorted based on the blue line, the blue line monotonically decreases.

CS341 Final Report

Probability for each genreCountLarge-scale Proﬁling of Movie Scenes and Character Types

FANG-CHIEH CHOU
Department of Biochemistry, Stanford University. fcchou@stanford.edu
and
JIN CHEN
Department of Applied Physics, Stanford University. jchen77@stanford.edu
and
YU-WEI LIN
Department of Electrical Engineering, Stanford University. yuweilin@stanford.edu

Past efforts in analyzing movies have been focused on recommending
movies to users, but little has been done on proﬁling the movie and charac-
ter types to ﬁnd combinations or trends. Using the movie dataset, we have
developed a method to proﬁle characters from movie scenes. By applying
text mining techniques to a dataset of nearly 10,000 movies with each scene
annotated, we can build a movie timeline and movie and character features
through 1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative occur-
rence frequencies of each item. We ﬁrst created logistic classiﬁers to do
binary classiﬁcations on the movie genres, which are labeled. Our logistic
classiﬁers proved to be quite successful in classifying our movie features
into the respective genres. We then applied the classiﬁers to our character
features, mapping the characters onto each genre. From this, we were able
to determine the character “types” based on the different genres and to ana-
lyze the frequent combinations of character types in each movie genre. Our
method is easily applicable and extendable to study trending scenes and
character combinations, in addition to performing recommendation based
on actors and characters.

INTRODUCTION

1.
Past efforts of machine learning and data mining in analyzing
movies have been focused on recommending movies to users [4].
The algorithms mainly ﬁnd similarities between users and movies
for recommending movies, which focuses more on the user and
very general categorizations of movies. The implementation of
Latent factors, collaborative ﬁltering, content-based ﬁltering,...etc.
have been proven to be quite successful in user-movie recommen-
dations (for example, the Netﬂix challenge, [1]). However, little has
been done on analysis and proﬁling of characters within movies,
and comparing characters across different movies [5]. Analyzing
characters and movie scenes are important, as it provides insights
into the trending character types, trending scenes, and frequently
appeared combinations of character types in movie genres. This
could add an extra layer of information to the current recommen-
dation systems that only focuses on users and movies.

Character proﬁling and personality analysis have traditionally
been a ﬁeld of study in psychology and social science, which focus
on just one or several movies [7]. Character theory has been used
to study the roles of the characters in each movie. However, these
previous theories are based on the analysis of small datasets and
on stereotypes [2]. It is therefore particularly useful to apply sta-
tistical learning methods to large movie datasets to understand the
characters’ proﬁles, which provides correlations and trends within
characters that is more informative than just stereotypical analysis.
In this report, we analyzed a dataset of annotated movie scenes
of nearly 10,000 movies to proﬁle each character based on the ac-

tions, objects, and other characters that appear within each scene
with them. From this analysis, we were able to classify not only
the type of movie genres, but also the type of characters, in addi-
tion to trends and combinations of characters that often appear in
a movie. This can be further applied to proﬁle the types of scenes,
movies, and characters that particular actors are good at or are bet-
ter received. This type of proﬁling can be used for future recom-
mendations of a new script to an actor, for recommending actors
to directors, or for recommending movie types and character types
for directors and script writers. Another aatural extension is making
recommendations to users based on a speciﬁc plot, character, or ac-
tor. With a large amount of movie data available, including IMDB
and Rotten Tomato reviews, ratings, and information, as well as
the annotated movie scene information, it is now possible to mine
this data to create a comprehensive proﬁle of each character of the
movies.

2. THE DATA
In order to proﬁle movies and characters, we used the movie scenes
dataset provided by Professor Jure Leskovec. The dataset contains
8,933 movies from 1918 to 2013, with every scene manually anno-
tated. Each data ﬁle consists of an unique identiﬁer for the movie
and the movie metadata. The metadata consists of the movie name,
year, a short description, the language, the director(s), the cast
(which consists of actor names and character names), and the movie
genres. In addition, there are Rotten Tomato identiﬁers and scores.
The bulk of the dataset, and the most useful information from
the dataset, are the scene annotations. Every scene of each movie
is marked with the start and end time of each segment, and anno-
tated with (1) actions (for example, ﬁghting, attacking, ﬂying), (2)
locations (for example garage, airport, gym), (3) objects (for exam-
ple animal, drinks, books, drugs) and (4) appearances (for exam-
ple, character, actor). There is one segment for each action, object,
location, and appearance, and the segments can be overlapping, in-
dicating the simultaneous appearance of the objects, characters, or
actions. This can be analyzed to determine how long each object,
character, or action last, as well as how they overlap in time.

The data is organized in a JSON format, so it can be easily parsed

using Python.

3. RESULTS
3.1 Movie and character features
In order to analyze the movies and the characters, we must ﬁrst
create features that represent each movie or character to capture the
appearances and correlations of the characters, objects, and actions.

CS341 Final Report

2

•

Chou et al.

These “movie features” or “character features” are matrices that
summarize the characteristics of each movie or character.

To create the feature, we ﬁrst generated a “timeline” that repre-
sents the entire duration of each movie. We separated the timeline
into 30-second time bins. Then we ﬁlled each time bin with the
scene segments that appear in it. For example, as shown in Fig-
ure 1, House and character 1 appeared in the ﬁrst time bin. House
and character 1 continued to appear in the second time bin, in ad-
dition to Gun and character 2. We repeat this for the entire duration
of each movie, so we can obtain a discretized timeline that cap-
tures the appearance, disappearance, and co-occurrence of objects,
characters, and actions.

To build movie features from our timeline, we took the concept
of w-shingling in text mining [3]. We created three types of shingles
for each timeline: 1-shingle, 2-shingle vertical, and 2-shingle hori-
zontal. 1-shingle is just a histogram of counts for all the items that
appear in each movie. For example, in Figure 1, House appeared 3
times, Gun appeared once, character 1 appeared twice, and so on.
2-shingle vertical counts all the doublets of items that appear within
each time bin, which captures the co-occurrence of items. For ex-
ample, the ﬁrst time bin has the combination (House, 1); the second
time bin has the combinations (House, Gun), (House, 1), (House,
2), (Gun, 1)... etc. Note that the order of items in these shingles
does not matter here. Similarly, we built a histogram of counts for
all these 2-shingles as our feature. 2-shingle horizontal is similar to
2-shingle vertical, but we counted the doublets of items that appear
in two consecutive time bins. For example, the ﬁrst two time bins
have the combinations (House, House), (House, Gun), (House, 1),
(House, 2), (1, House)... etc. Again, we constructed a histogram of
counts for all these 2-shingles. This feature captures the appearance
and disappearance of items in consecutive time bins. It is important
to note that the order of these shingles does matter. The three types
of histogram features were then concatenated to create the ﬁnal fea-
ture used in this work.

The character features were created in a similar fashion. Instead
of counting all possible shingles in each movie, we just used the
time bins that the target character appears. For example, character
1 shows up in time bins 1 and 2, but not 3. So for the feature of
character 1, we just used 1-shingles and 2-shingles in the ﬁrst two
time bins.

Finally, to normalize the importance of each shingle properly, we
applied TF-IDF (term frequencyinverse document frequency) [6], a
commonly used normalization scheme in text mining, to our feature
matrix. The feature for each movie/character is further normalized
to have a unit norm.

3.2 Initial attempts in character classiﬁcation
Using the character features created using the method above, we
ﬁrst attempted to classify characters into different categories. How-
ever, a major difﬁculty is that the characters are not labeled, mak-
ing it impossible for supervised learning. Unsupervised clustering
is also difﬁcult since we did not have a proper distance metric that
would work for our features, which have 20,000 dimensions. In ad-
dition, it is quite difﬁcult to interpret the meaning of each cluster in
such a high-dimensional space. We have tested a few common dis-
tance metrics (Euclidean distance, cosine distance, etc.), but with-
out much success.

We have also tried to manually label a few characters and classi-
ﬁed characters in this small labeled dataset. For example, we man-
ually labeled a few “superheros” such as Batman, Iron Man, Super-
man, Spider man, etc., and classiﬁed the characters as superhero or
non-superhero by logistic regression, SVM, or random forest clas-

CS341 Final Report

Table I. Summary of Genre Classiﬁcation Statistics

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

Accuracy

Precision

0.73
0.76
0.79
0.88
0.88
0.84
0.90
0.92
0.89
0.97
0.91
0.92
0.92
0.99
0.96
0.96
0.95
0.97
0.96
0.96
0.97
0.97
0.98
0.98
0.99
0.99

0.41
0.40
0.34
0.48
0.44
0.16
0.32
0.33
0.20
0.66
0.23
0.23
0.12
0.75
0.14
0.23
0.13
0.28
0.23
0.03
0.16
0.04
0.35
0.06

0

0.16

Recall
0.51
0.50
0.49
0.63
0.52
0.28
0.43
0.44
0.39
0.85
0.38
0.37
0.20
0.84
0.2
0.44
0.26
0.46
0.53
0.04
0.38
0.08
0.60
0.10

0
0.5

Number of movies

4817
4320
3121
2401
2167
1672
1440
1133
1130
24
1078
980
764
444
456
369
370
250
356
335
153
204
167
169
81
42

siﬁer. However, these classiﬁers performed poorly when applied to
the full dataset. For example, Batman and the Joker were both clas-
siﬁed as superhero, although the Joker is actually a vallain. Due to
the limited training data, the classiﬁer could only give a crude pic-
ture of the characters. For example, the previous Batman and Joker
case can be explained intuitively since both batman and joker are
“action”-type characters, and the classiﬁer was probably just clas-
sifying based on “action” rather than “superheros”. An additional
complexity of these methods is that since most characters are from
movies not widely watched, it is difﬁcult to manually label the bulk
of characters in our dataset.

3.3 Movie genre classiﬁcation
Due to the failure in our initial attempt on character proﬁling, we
took a step back to work on movie genre classiﬁcation, since movie
genres are already labeled in the dataset. These movie genre clas-
siﬁcations were then used to help classifying the characters, as dis-
cussed in sections below. We took the movie features, with each
movie labeled with its genres (note that movies may have multiple
genres), to do supervised classiﬁcation. For each genre, we did a
binary classiﬁcation using logistic regression classiﬁer, to predict
if a movie is in the target genre. We also tested SVM and random
forest classiﬁers; the results were similar and worse than logistic
regression. For each genre, we trained the classiﬁer with 90% of
the data, and tested the performance with the remaining 10% of
data. To prevent imbalance between number of positive (movies in
target genre) and negative training examples, we oversampled the
target genre movies in the training set to ensure a 1:1 ratio between
positive and negative data points in our training set. We then apply
the classiﬁer to the test set to determine the accuracy, precision, and
recall of the classiﬁer, as summarized in Table I.

For each genre, we found that the accuracy is usually quite high,
with a good precision and a good recall, especially for the top few

Large-scale Proﬁling of Movie Scenes and Character Types

•

3

Fig. 1. Example movie feature and timeline. The timeline is separated into 30 second time bins, and the scene segments that appear in each time bin is
counted. Then, 1-shingles, 2-shingle horizontal, and 2-shingle vertical features can be constructed from the timeline.

Table II. Selected examples of features
Genre
Action

Selected Positive Features

(Attacking, Jumping, vertical)
(Running, Riding, horizontal)

Drama

(Car, Hotel/motel/inn, horizontal)

(Exploding, Ship, horizontal)
(School, Weapon, vertical)

(Street/Road, Bedroom, horizontal)
(Dining Room, Field, horizontal)
(Magazines, Bags, horizontal)

(House, Porch, vertical)

(House, Smoking, vertical)

genres (which appears more often and is more critical). For the
bottom genres, due to the limited number of examples in the data,
the recall and precision were quite low. Furthermore, Western, a
unique genre in our data, had very high accuracy, precision, and
recall (>0.7) at the same time. For other more common genres, e.g.
action, horror, and drama, the accuracies were limited to around 0.7
to 0.9 with precisions and recalls around 0.5. This is due to many
movies of these types often cross multiple genres.

To understand what shingles are signatures for each genre classi-
ﬁer, we extracted the important feature components for each genre
classiﬁer, as shown in Table II. The features make sense. For ex-
ample, for Action movies, the critical features involve combina-
tions between actions like attacking, jumping, exploding, and ob-
jects like weapon and car. Drama movies, on the other hand, have
important features involving bedroom, dining room, house, porch,
etc.

3.4 Attempts to improve the movie and character

features

Since now we have a good benchmark, we can try to optimize our
features. It is possible that not only the items that appear in each
time bin that is important, but the difference of items between each
consecutive time bins can also important. We incorporated these
“difference features” in addition to the 1-shingle and 2-shingles

described above and ran feature selection with the genre classiﬁer.
However, the addition of these difference features did not signiﬁ-
cantly improve the performance of the genre classiﬁer.

Furthermore, to test the importance of different single types, we
also repeated the experiment with only 1-shingle, and the accuracy
is general decreased around 0.2. Thus, this indicates the addition of
the 2-shingles are crucial.

3.5 Analyzing characters
We proceeded with our original movie and character features with-
out the incorporation of the difference features and feature selec-
tions to keep things simple. With our previous results in movie
classiﬁcation, we applied the logistic regression classiﬁers for each
genre, trained with the movie features, to each character feature.
We then calculated the probability that each character exhibits a
particular genre type. Essentially, we are mapping the character
feature onto each movie genre. One example is shown in Table III,
which analyzed Batman and Joker from the movie The Dark Knight
(2008). As expected, Batman exhibits high scores in Thriller (0.96),
Action (0.37), Adventure (0.97) and Crime Drama (0.74). Batman
also has a high score in Science Fiction (0.99), probably due to his
extraordinary powers and technology. As portrayed throughout the
movie, Batman has a high level of mystery, as indicated by his high
score in Mystery (0.87). Thus, the analysis of Batman makes intu-
itive sense. If we compare the Joker from the same movie, we can
see that many of the scores are similar. Though, it is interesting to
note that while Batman has a very low Horror score, the Joker has a
very high score (0.96). Moreover, Batman has a very high score in
Mystery (0.87), while the Joker has a relatively low score (0.002).
Thus, our character proﬁling method is not just picking out the gen-
res of the movies where the characters belong to; instead, we are
able to separate out characters of different types within the same
movie.

CS341 Final Report

GunChar 1Char 2Char 3HouseHouse1HouseGun12House231-shingle: {(House): 3, (Gun): 1, (1): 2, (2): 2, (3): 1}2-shingle horizontal: {(House, House): 2, (House, Gun): 1, (House, 1): 1, (House, 2): 2……..}Order matters2-shingle vertical: {(House, 1): 2, (House, Gun): 1, (House, 2): 2, (Gun, 1): 1……..}Order  does not matter4

•

Chou et al.

Table III. Example Character Analysis of the Dark Knight
Dark Knight/Joker

Dark Knight/Batman

Genre
Drama
Comedy
Thriller
Action
Horror

Comedy drama

Adventure

Science ﬁction
Crime drama
Documentary

Romantic comedy

Fantasy
Romance
Western

Historical drama

War

Biography
Animated
Musical
Mystery
Children
Docudrama
Martial arts

Musical comedy

Dark comedy

Music

0.005083
0.376786
0.961771
0.365348
0.001306
0.036339
0.971452
0.997813
0.744358
0.000039
0.000000
0.385773
0.001062
0.000182
0.000002
0.000016
0.000423
0.062279
0.000011
0.868754
0.000138
0.000628
0.002699
0.000004
0.009716
0.000000

0.001103
0.034829
0.991281
0.992663
0.959315
0.000007
0.788594
0.372594
0.001417
0.000000
0.000000
0.984121
0.000100
0.000550
0.003090
0.000000
0.000005
0.001833
0.000045
0.002359
0.000002
0.000000
0.031714
0.000000
0.000000
0.000145

3.6 Validation: statistical analysis and trending of

character types

Though manually picking out interesting characters, the character
proﬁle seems to make intuitive sense. However, we need a method
to statistically validate our method and results, using the entire
dataset instead of just observing individual examples. In follow-
ing paragraphs, we will describe two comprehensive analysis of all
characters in our dataset, by analyzing the distribution of types of
characters in each movie genre, and by analyzing the frequency of
combinations of character types in different movie genres.

To gain more insight into the results, we plotted the histogram of
the probability scores for each character types for different movie
genres, as shown in Figure 2. The ﬁgure shows that in a certain
movie genre, the distributions of genre types are different. For ex-
ample, in Horror movies, the characters typically have high Thriller
scores and low Action scores. Moreover, we can see that the distri-
bution of types varies with the movie genres. For instance, charac-
ters in Drama movies have a quite uniform distribution in Drama
type; on the other hand, the characters in other genres, such as Ac-
tion and Horror, tends to be less ”Dramatic”, with distributions
peaking near zero. It is important to note that the y-axis is log-
scale. Furthermore, there are two clear peaks in some distributions,
indicating that in the some movie genre, many characters have high
tendency to a certain type while many others have low tendency.
Take Action movies for example, some characters seem to be very
”Horror” but some are very ”non Horror”, and this might be a use-
ful feature for separating the characters.

Second, we analyzed the character dataset to see if any particu-
lar combination of character types in the same movie appears much
more frequently in each movie genre. For each character, we se-
lected the top three genres with highest probability scores as the
“characteristic types” of the character. The genres of the movie that

CS341 Final Report

the character is from were excluded, as it is used in training our
character genre classiﬁer. For each pair of characters in the same
movie, we then extract all pairs of character types. For example,
suppose we have a character Alice, with types Drama, Fantasy and
Thriller, and another character Bob in the same movie classiﬁed as
Action, Horror and Thriller, we then have character type pairs such
as (Drama, Action), (Fantasy, Action), (Drama, Horror), etc. We
ﬁrst generated the baseline by computing histogram of character
genre pairs for all possible character pairs in our dataset. For each
movie genre, we counted the number of character type pairs for ev-
ery pair of characters in the same movie, to see if different movie
genres will give different distributions of commonly appeared char-
acter genre pairs. As shown in Fig. 3, indeed many combinations
of character types appear more often than the baseline values for
different movie genres. Table IV summarizes the top combina-
tions appear in different genres. For example, Action genre movies
tend to have character combinations of (Horror, Science Fiction),
(Science Fiction, Crime Drama)...etc. Drama movies, on the other
hand, tend to have combinations of (Comedy drama, Romance),
(Comedy drama, Biography),...etc. Due to space limitations, we
only showed a few examples, but this analysis works across all the
different genre types. Thus, different movie genres tend to have
different character type combinations, as expected. In Table V, we
showed a few movie examples with characters of different types
in the same movie. We have the example described before: Bat-
man from the Dark Knight is a Science Fiction (or Crime Drama
or Mystery), while the Joker is mainly Horror. From the result, we
found that our character type assignments give statistically signif-
icant difference to the baseline across all the movie data. The ob-
tained character type combinations also gave additional insights on
the combination of character types preferred in different movie gen-
res.

3.7 Impediments and difﬁculties
The main difﬁculty in doing character analysis is the lack of labeled
data, in addition to limited knowledge of sufﬁcient number of char-
acters to do manual labeling. Thus, it is difﬁcult to do a straightfor-
ward unsupervised clustering or supervised learning. Furthermore,
there is usually a very broad spectrum of character types, so even
if we have an appropriate distance metric, we may not be able to
cluster the characters in a very meaningful way. Another difﬁculty
is the lack of detailed scene annotations. Even though each scene
is annotated, the tags are quite general (for example, car, explo-
sion, vehicle, house...etc). If the tags can be more detailed, more
insight can probably be mined from the data. Finally, although we
were able to use the co-occurrence, appearance and disappearance
of items to capture their correlation, the exact association between
items can be ambiguous. For example, suppose we have two char-
acters Alice and Bob and a gun appeared together in a scene, it
may represent various scenes, such as (1) Alice shooting Bob with
the gun, (2) Bob shooting Alice with the gun, (3) Bob holding a
gun to guard Alice, etc. Since these scenarios lead to very differ-
ent interpretations of the types of the characters, it is challenging to
correctly proﬁle each character with the data.

4. FUTURE WORK
Although we have developed a method to do large-scale proﬁl-
ing for character analysis, more work can be done. The movie
and character features can be further improved by including addi-
tional information, for example the actor(s), year, director...etc for
each movie or character. Furthermore, the scene annotations actu-

Large-scale Proﬁling of Movie Scenes and Character Types

•

5

Fig. 2. Histogram of character genre feature in different movie genres. The ﬁgure only shows the histograms of the ﬁrst 6 types in 5 different movie genres.
The x-axis is the probability from 0 to 1, divided into 10 bins in the histograms, and the y-axis plots the counts of each bin in log scale.

Fig. 3. Histogram of genre pairs for characters from four selected movie genres. The x-axis plots the genre pairs, with each pair indexed as an integer (not
shown). Also the genre pairs are sorted based on their probability in the baseline (blue). The y-axis plots the frequency of each genre pair. The green line plots
the histogram for the genre pairs from the particular genre. The blue line plots the base line when movies are randomly selected from any genre. Since the
x-axis is sorted based on the blue line, the blue line monotonically decreases.

CS341 Final Report

Probability for each genreCount6

•

Chou et al.

Table IV. Character genre pairs with highest probability compare to the baseline in different movie genres.

Drama

(Comedy drama, Biography)
(Comedy, Comedy drama)
(Comedy drama, Romance)
(Comedy, Romantic comedy)

(Comedy drama, Musical)
(Comedy drama, Fantasy)

(Fantasy, Biography)

Comedy

Thriller

(Comedy drama, Romantic comedy)

(Crime drama, Mystery)

(Drama, Comedy drama)
(Drama, Romantic comedy)
(Comedy drama, Children)

(Fantasy, Musical)
(Fantasy, Children)
(Adventure, Children)

(Horror, Mystery)
(Drama, Mystery)

(Action, Crime drama)

(Comedy, Mystery)

(Action, Science ﬁction)

(Science ﬁction, Crime drama)

Action

(Horror, Science ﬁction)

(Science ﬁction, Crime drama)

(Horror, Crime drama)
(Thriller, Science ﬁction)
(Thriller, Crime drama)
(Comedy, Science ﬁction)
(Adventure, Science ﬁction)

Table V. Examples of character combinations in movies

Movie

Character (genre)

Character (genre)

Pirates of the Caribbean: Dead Man’s Chest

Capt. Jack Sparrow (Horror)

Elizabeth Swann (Musical)

The Dark Knight

Spider-Man 2

Bruce Wayne/Batman (Science Fiction)

Spiderman (Science Fiction)

The Joker (Horror)

Harry Osborn (Horror)

Sherlock Holmes: A Game of Shadows

Sherlock Holmes (Science Fiction)

Dr. John Watson (Comedy)

Thor

RoboCop

Jane Foster (Romance)

RoboCop (Thriller)

Odin (Horror)

Dick Jones (Crime Drama)

each movie genre. Our method is easily applicable and extendable
to study trending scenes and character combinations, in addition to
performing recommendation based on actors and characters.

ACKNOWLEDGMENTS
We want to thank Professor Jeffrey Ullman for his continuous guid-
ance and support. We also would like to thank the CS341 staff,
Jure Leskovec, Anand Rajaraman, and Rok Sosic for organizing
this course.

REFERENCES

BELL, R. M., AND KOREN, Y. Lessons from the netﬂix prize challenge.

SIGKDD Explor. Newsl. 9, 2 (Dec. 2007), 75–79.

HINTON, P. R. Stereotypes, cognition and culture. Psychology Press, 2013.
MANBER, U. Finding similar ﬁles in a large ﬁle system. In Proceedings of
the USENIX Winter 1994 Technical Conference on USENIX Winter 1994
Technical Conference (Berkeley, CA, USA, 1994), WTEC’94, USENIX
Association, pp. 2–2.

MELVILLE, P., MOONEY, R. J., AND NAGARAJAN, R. Content-boosted
In AAAI/IAAI

collaborative ﬁltering for improved recommendations.
(2002), pp. 187–192.

PARK, S.-B., OH, K.-J., AND JO, G.-S. Social network analysis in a
movie using character-net. Multimedia Tools and Applications 59, 2
(2012), 601–627.

RAJARAMAN, ANAND, J. D. U. Cambridge University Press, 2011.
WEDDING, D., AND BOYD, M. Movies & Mental Illness: Using Films to

Understand Psychopathology. McGraw-Hill, 1999.

ally contain “captions”, which include some of the lines spoken in
each movie. However, since the captions are not labeled with which
character actually spoke the line, and analyzing lines require natu-
ral language processing, it is beyond what we can accomplish in a
quarter.

Currently, we only focused on the analysis of characters with
respect to each genre type. It is possible to combine this analysis
with IMDB scores and Rotten Tomato scores to analyze the popular
and most well-received character types and character combinations
within a movie. Furthermore, adding the actor information would
allow us to proﬁle the type of scenes, movies, and characters that
a particular actor is good at or is the best received (as mentioned
in the Introduction). This type of proﬁling can be used for future
recommendations of a new script to an actor, or for recommending
actors to directors, or for recommending movie types and character
types for directors and script writers. Natural extension of this is
make recommendations to users based on a speciﬁc plot, character,
or actor.

Other ideas that are easily extended with our method, but is not
directly related to character analysis, is to analyze trending scenes.
Currently, we analyzed all the movies together. However, we can
parse the movies with respect to their year, and try to ﬁnd corre-
lations between the years to determine if there are any trending
scenes or character combinations that have become popular in re-
cent years.

5. CONCLUSION
In conclusion, we have developed a method to proﬁle charac-
ters from movie scenes. By applying text mining techniques to a
dataset of nearly 10,000 movies with each scene annotated, we can
build a movie timeline and movie and character features through
1-shingles and 2-shingles that capture the appearance and disap-
pearance of objects, actions, and characters, as well as the relative
occurrence frequencies of each item. Although a direct analysis on
the character features proved to be difﬁcult due to unlabeled char-
acters, we ﬁrst created a logistic classiﬁer to do binary classiﬁca-
tions on the movie genres, which is labeled. Our logistic classiﬁer
proved to be quite successful in classifying our movie features into
the respective genres. We then applied this to classify our charac-
ter features and map the characters onto each genre. From this, we
were able to determine the character “types” based on the differ-
ent genres and analyze the frequent combinations of characters in

CS341 Final Report

