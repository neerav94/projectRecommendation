Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
2. SYSTEM DESIGN 

Utilizing  available  cloud  computing  and  storage  resources,  we  expect  a  heterogeneous  set  of  Cloud 
Mobile  Media  services  and  applications  to  emerge,  with  different  types  of  consumer  experiences  and 
advantages enabled. In this section, we first describe the typical end-to-end control and data flow architecture 
of CMM applications. Next, we categorize the existing and expected CMM applications, and analyze for each 
category the cloud infrastructure and platform needs, advantages and user experiences enabled, and challenges 
to make the applications successful. Fig.1 shows the overall architecture, including end-to-end flow of control 
and data between the mobile devices and the Internet cloud servers, for a typical CMM application. A typical 
CMM  application  has  a  small  footprint  client  on  the  mobile  device,  which  provides  the  appropriate  user 
interfaces (gesture, touchscreen, voice, text based) Subsequently, the multimedia data produced by the cloud, 
either  as  a  result  of  processing  using  the  cloud  computing  resources,  and/or  retrieval  from  cloud  storage 
resources, is transmitted downlink through the CN and RAN back to the mobile device. 

 The CMM client then decodes and displays the results on the mobile device display. From the above 
description, and as shown in Fig. 1, a typical CMM application will be highly interactive, with some types of 
applications  needing  near  real-time  response  times.  Note  that  for  certain  types  of  CMM  applications,  the 
control and data flow may deviate from that shown in Fig. 1. For example, for CMM applications like Cloud 
based  Media  Analytics  described  later,  the  application  may  not  always  be  initiated  by  a  mobile  CMM  client 
(like  in  Fig.  1),  and  may  collect  data  from  both  the  client  and  the  cloud  to  provide  analytics  to  other  CMM 
applications.  This  summarizes  the  different  categories  of  mobile  multimedia  applications  that  already  are,  or 
can  potentially  be,  driven  by  the  use  of  the  cloud,  including  storage,  download  and  synchronization 
applications,  audio  and  video  streaming  applications,  interactive  applications  like  multi-way  video 
Conferencing,  interactive  advertisements,  and  mobile  remote  desktop,  rich  rendering  based  applications  like 
mobile  multi-user  gaming  and  augmented  reality,  and  cloud  based  media  analytics  that  will  provide  better 
understanding of user preferences and experiences, and drive personalized mobile services. For each category 
of  CMM  applications,  we  list  the  IaaS  and  PaaS  features  that  will  be  needed,  including  some  which  are 
available  today,  and  some  that  need  to  be  developed.  We  also  list  the  advantages  of  each  category  of  CMM 
applications, including what multimedia experience can be enabled that cannot be supported currently, and the 
challenges that need to be addressed to make the application category successful. 

As  discussed  before,  Mobile  Cloud  Storage  is  the  most  commonly  used  category  of  CMM 
application/service  today,  with  offerings  from  Amazon,  Apple,  Dropbox,  Funambol,  and  Google,  among 
others.  These  services  provide  diverse  capabilities,  including  storing  documents,  photos,  music  and  video  in 
the  cloud,  accessing  media  from  any  device  anywhere  irrespective  of  the  source  of  the  media  and/or  the 
device/platform  used  to  generate  the  media,  and  synchronizing  data/media  across  multiple  devices  a  typical 
user owns. 

 

 

Figure 1.Cloud Mobile Impact of Wireless Network Factors on User Experience 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        66 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
2. SYSTEM DESIGN 

Utilizing  available  cloud  computing  and  storage  resources,  we  expect  a  heterogeneous  set  of  Cloud 
Mobile  Media  services  and  applications  to  emerge,  with  different  types  of  consumer  experiences  and 
advantages enabled. In this section, we first describe the typical end-to-end control and data flow architecture 
of CMM applications. Next, we categorize the existing and expected CMM applications, and analyze for each 
category the cloud infrastructure and platform needs, advantages and user experiences enabled, and challenges 
to make the applications successful. Fig.1 shows the overall architecture, including end-to-end flow of control 
and data between the mobile devices and the Internet cloud servers, for a typical CMM application. A typical 
CMM  application  has  a  small  footprint  client  on  the  mobile  device,  which  provides  the  appropriate  user 
interfaces (gesture, touchscreen, voice, text based) Subsequently, the multimedia data produced by the cloud, 
either  as  a  result  of  processing  using  the  cloud  computing  resources,  and/or  retrieval  from  cloud  storage 
resources, is transmitted downlink through the CN and RAN back to the mobile device. 

 The CMM client then decodes and displays the results on the mobile device display. From the above 
description, and as shown in Fig. 1, a typical CMM application will be highly interactive, with some types of 
applications  needing  near  real-time  response  times.  Note  that  for  certain  types  of  CMM  applications,  the 
control and data flow may deviate from that shown in Fig. 1. For example, for CMM applications like Cloud 
based  Media  Analytics  described  later,  the  application  may  not  always  be  initiated  by  a  mobile  CMM  client 
(like  in  Fig.  1),  and  may  collect  data  from  both  the  client  and  the  cloud  to  provide  analytics  to  other  CMM 
applications.  This  summarizes  the  different  categories  of  mobile  multimedia  applications  that  already  are,  or 
can  potentially  be,  driven  by  the  use  of  the  cloud,  including  storage,  download  and  synchronization 
applications,  audio  and  video  streaming  applications,  interactive  applications  like  multi-way  video 
Conferencing,  interactive  advertisements,  and  mobile  remote  desktop,  rich  rendering  based  applications  like 
mobile  multi-user  gaming  and  augmented  reality,  and  cloud  based  media  analytics  that  will  provide  better 
understanding of user preferences and experiences, and drive personalized mobile services. For each category 
of  CMM  applications,  we  list  the  IaaS  and  PaaS  features  that  will  be  needed,  including  some  which  are 
available  today,  and  some  that  need  to  be  developed.  We  also  list  the  advantages  of  each  category  of  CMM 
applications, including what multimedia experience can be enabled that cannot be supported currently, and the 
challenges that need to be addressed to make the application category successful. 

As  discussed  before,  Mobile  Cloud  Storage  is  the  most  commonly  used  category  of  CMM 
application/service  today,  with  offerings  from  Amazon,  Apple,  Dropbox,  Funambol,  and  Google,  among 
others.  These  services  provide  diverse  capabilities,  including  storing  documents,  photos,  music  and  video  in 
the  cloud,  accessing  media  from  any  device  anywhere  irrespective  of  the  source  of  the  media  and/or  the 
device/platform  used  to  generate  the  media,  and  synchronizing  data/media  across  multiple  devices  a  typical 
user owns. 

 

 

Figure 1.Cloud Mobile Impact of Wireless Network Factors on User Experience 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        66 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

To  study  the  impact  of  wireless  networks  on  the  quality  of  CMM  applications,  we  conducted 
experiments  with  a  Cloud  Mobile  Gaming  (CMG)  application  we  have  developed,  which  as  described  in 
Section II is a highly interactive cloud based rendering application: gaming commands are transmitted uplink 
from the mobile device to the cloud servers, and the rendered video needs to be streamed downlink from the 
server  to  the  mobile  client  in  near  real  time.  Since  this  application  is  highly  sensitive  to  response  time,  we 
measured uplink delay, downlink delay, and round-trip response time. The experiments were conducted under 
different network conditions data samples collected under three different conditions: when the network was not 
loaded  (data  collected  at  mid  night),  when  the  network  was  loaded  (data  collected  at  5  pm),  and  when  the 
network was loaded and the signal conditions were not strong (data collected at 6 pm, and inside a building). 
Media architecture, showing control and data flows. 

 

3. ADAPTIVE RENDERING PARAMETERS AND SETTINGS 

The first step in enabling dynamic game rendering adaptation in the CMG approach is to identify the 
adaptive  rendering  parameters  and  adaptive  rendering  settings.  A  game  may  have  many  different  rendering 
parameters,  but  only  a  few  of  them  have  obvious  impacts  on  CommC  or  CompC.  An  ―adaptive  rendering 
parameter‖ must be able to adapt at least one of CommC or CompC. An ―adaptive rendering setting‖ is a set of 
values  for the adaptive rendering parameters  which affect  CommC,  CompC or both. As discussed in  Section 
IV-A,  reducing  the  number  of  objects  in  the  graphic  scene  file  or  reducing  the  complexity  of  rendering 
operations could lead to the decreases in CommC and CompC. Based on the above principles, we identify four 
common parameters which we believe are suitable for rendering adaptation in most 3D games 

 3.1 REALISTIC EFFECT  

Realistic  effect  basically  includes  four  parameters:  color  depth,  anti-aliasing,  texture  filtering,  and 
lighting  mode.  Each  of  the  four  parameters  only  affects  part  of  graphic  rendering.  Varying  any  one  of  them 
may not reduce the graphic rendering load. Thus when we reduce/increase the realistic effect, we vary all four 
parameters. 

3.2 TEXTURE DETAIL  

This is also known as Level of Detail (LOD). It refers to how large and how many textures are used to 
present objects. The lower texture detail level, the lower resolution the textures have the surfaces of objects get 
blurred as we decrease the texture detail. 

3.3 VIEW DISTANCE 

 This parameter determines which objects in the camera view will be included in the resulting frame, 

and thereby should be sent to the display list for graphic rendering. 

3.4 ENVIRONMENT DETAIL  

Many  objects  and  effects  (grass,  flowers,  and  weather)  are  applied  in  modern  games,  to  make  the 
virtual world look more realistic. However they are not really necessary for users playing the game. Therefore, 
we could eliminate some of these objects or effects to reduce CommC and CompC if needed.  

 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        67 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
2. SYSTEM DESIGN 

Utilizing  available  cloud  computing  and  storage  resources,  we  expect  a  heterogeneous  set  of  Cloud 
Mobile  Media  services  and  applications  to  emerge,  with  different  types  of  consumer  experiences  and 
advantages enabled. In this section, we first describe the typical end-to-end control and data flow architecture 
of CMM applications. Next, we categorize the existing and expected CMM applications, and analyze for each 
category the cloud infrastructure and platform needs, advantages and user experiences enabled, and challenges 
to make the applications successful. Fig.1 shows the overall architecture, including end-to-end flow of control 
and data between the mobile devices and the Internet cloud servers, for a typical CMM application. A typical 
CMM  application  has  a  small  footprint  client  on  the  mobile  device,  which  provides  the  appropriate  user 
interfaces (gesture, touchscreen, voice, text based) Subsequently, the multimedia data produced by the cloud, 
either  as  a  result  of  processing  using  the  cloud  computing  resources,  and/or  retrieval  from  cloud  storage 
resources, is transmitted downlink through the CN and RAN back to the mobile device. 

 The CMM client then decodes and displays the results on the mobile device display. From the above 
description, and as shown in Fig. 1, a typical CMM application will be highly interactive, with some types of 
applications  needing  near  real-time  response  times.  Note  that  for  certain  types  of  CMM  applications,  the 
control and data flow may deviate from that shown in Fig. 1. For example, for CMM applications like Cloud 
based  Media  Analytics  described  later,  the  application  may  not  always  be  initiated  by  a  mobile  CMM  client 
(like  in  Fig.  1),  and  may  collect  data  from  both  the  client  and  the  cloud  to  provide  analytics  to  other  CMM 
applications.  This  summarizes  the  different  categories  of  mobile  multimedia  applications  that  already  are,  or 
can  potentially  be,  driven  by  the  use  of  the  cloud,  including  storage,  download  and  synchronization 
applications,  audio  and  video  streaming  applications,  interactive  applications  like  multi-way  video 
Conferencing,  interactive  advertisements,  and  mobile  remote  desktop,  rich  rendering  based  applications  like 
mobile  multi-user  gaming  and  augmented  reality,  and  cloud  based  media  analytics  that  will  provide  better 
understanding of user preferences and experiences, and drive personalized mobile services. For each category 
of  CMM  applications,  we  list  the  IaaS  and  PaaS  features  that  will  be  needed,  including  some  which  are 
available  today,  and  some  that  need  to  be  developed.  We  also  list  the  advantages  of  each  category  of  CMM 
applications, including what multimedia experience can be enabled that cannot be supported currently, and the 
challenges that need to be addressed to make the application category successful. 

As  discussed  before,  Mobile  Cloud  Storage  is  the  most  commonly  used  category  of  CMM 
application/service  today,  with  offerings  from  Amazon,  Apple,  Dropbox,  Funambol,  and  Google,  among 
others.  These  services  provide  diverse  capabilities,  including  storing  documents,  photos,  music  and  video  in 
the  cloud,  accessing  media  from  any  device  anywhere  irrespective  of  the  source  of  the  media  and/or  the 
device/platform  used  to  generate  the  media,  and  synchronizing  data/media  across  multiple  devices  a  typical 
user owns. 

 

 

Figure 1.Cloud Mobile Impact of Wireless Network Factors on User Experience 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        66 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

To  study  the  impact  of  wireless  networks  on  the  quality  of  CMM  applications,  we  conducted 
experiments  with  a  Cloud  Mobile  Gaming  (CMG)  application  we  have  developed,  which  as  described  in 
Section II is a highly interactive cloud based rendering application: gaming commands are transmitted uplink 
from the mobile device to the cloud servers, and the rendered video needs to be streamed downlink from the 
server  to  the  mobile  client  in  near  real  time.  Since  this  application  is  highly  sensitive  to  response  time,  we 
measured uplink delay, downlink delay, and round-trip response time. The experiments were conducted under 
different network conditions data samples collected under three different conditions: when the network was not 
loaded  (data  collected  at  mid  night),  when  the  network  was  loaded  (data  collected  at  5  pm),  and  when  the 
network was loaded and the signal conditions were not strong (data collected at 6 pm, and inside a building). 
Media architecture, showing control and data flows. 

 

3. ADAPTIVE RENDERING PARAMETERS AND SETTINGS 

The first step in enabling dynamic game rendering adaptation in the CMG approach is to identify the 
adaptive  rendering  parameters  and  adaptive  rendering  settings.  A  game  may  have  many  different  rendering 
parameters,  but  only  a  few  of  them  have  obvious  impacts  on  CommC  or  CompC.  An  ―adaptive  rendering 
parameter‖ must be able to adapt at least one of CommC or CompC. An ―adaptive rendering setting‖ is a set of 
values  for the adaptive rendering parameters  which affect  CommC,  CompC or both. As discussed in  Section 
IV-A,  reducing  the  number  of  objects  in  the  graphic  scene  file  or  reducing  the  complexity  of  rendering 
operations could lead to the decreases in CommC and CompC. Based on the above principles, we identify four 
common parameters which we believe are suitable for rendering adaptation in most 3D games 

 3.1 REALISTIC EFFECT  

Realistic  effect  basically  includes  four  parameters:  color  depth,  anti-aliasing,  texture  filtering,  and 
lighting  mode.  Each  of  the  four  parameters  only  affects  part  of  graphic  rendering.  Varying  any  one  of  them 
may not reduce the graphic rendering load. Thus when we reduce/increase the realistic effect, we vary all four 
parameters. 

3.2 TEXTURE DETAIL  

This is also known as Level of Detail (LOD). It refers to how large and how many textures are used to 
present objects. The lower texture detail level, the lower resolution the textures have the surfaces of objects get 
blurred as we decrease the texture detail. 

3.3 VIEW DISTANCE 

 This parameter determines which objects in the camera view will be included in the resulting frame, 

and thereby should be sent to the display list for graphic rendering. 

3.4 ENVIRONMENT DETAIL  

Many  objects  and  effects  (grass,  flowers,  and  weather)  are  applied  in  modern  games,  to  make  the 
virtual world look more realistic. However they are not really necessary for users playing the game. Therefore, 
we could eliminate some of these objects or effects to reduce CommC and CompC if needed.  

 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        67 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

Figure 2.Derivation of the Complexity Model (C) 

 

Having defined adaptive rendering parameters and settings, we next use the game Planeshift (PS) as 
an  example  to  explain  how  to  derive  the  complexity  model,  where  we  have  also  elaborately  studied  how 
different  adaptive  rendering  settings  affect  the  CommC  and  CompC.  Subsequently,  we  also  have  studied  the 
impacts on CommC and CompC when video encoding setting, or video resolution, or server GPU is changed. 
This  will  help  to  demonstrate  that  the  key  concept  that  communication  complexity  and  computation 
complexity can be affected by different rendering settings is broadly applicable, no matter what kind of video 
resolution or video encoding setting, and no matter what kind of graphic GPU is used. 

4. CHARACTERIZ ING CommC AND CompC 

Four  adaptive  rendering  parameters  are  selected  for  game  PS,  with  their  possible.  We  conduct 
experiments to characterize CommC and CompC for every possible rendering setting obtained using the values 
of parameters. The experiments are conducted on a desktop server which integrates a NVIDIA  Geforce 8300 
graphic card. Video resolution used is VGA. The video codec used is X264, and its encoding method is set to 
Variable Bit Rate (VBR). The Quantization Parameter (QP) is 25, while the encoding frame rate is 15 fps and 
the size of Group of Pictures (GOP) is 30. We have randomly selected several different gaming scenes. In each 
test scene, for each rendering setting, we let the game avatar roam in the gaming world along the same route. 
We measure the average compressed video bit rate and GPU utilization in each experiment test to calculate the 
CommC and CompC. 

5. CONCLUSION 

The complexity model we presented above was derived using a certain video encoding setting, video 
resolution, and GPU. We next investigate the impact of using different video encoding and resolution settings, 
and  different  GPUs,  on  the  complexity  model.  We  have  conducted  experiments  and  measured  CommC  and 
CompC of each rendering setting in three test cases: a) using various encoding settings (different QP and GOP 
settings), b) using three different resolutions (QVGA, CIF, and VGA), and c) using three different GPUs (Intel 
GMA4500,  NVIDIA  8300,  and  NVIDIA  GTX580).  Absolute  error  distribution  and  standard  deviations  of 
measured CommC and CompC in these test cases. We can observe that the overall variations of CommC and 
CompC in these different test cases are not significant. Hence, we can conclude that the offline modeling step 
does  not  need  to  characterize  the  CommC  and  CompC  and  create  different  complexity  models  for  different 
video resolutions, or video encoding settings, or different platforms. 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        68 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
2. SYSTEM DESIGN 

Utilizing  available  cloud  computing  and  storage  resources,  we  expect  a  heterogeneous  set  of  Cloud 
Mobile  Media  services  and  applications  to  emerge,  with  different  types  of  consumer  experiences  and 
advantages enabled. In this section, we first describe the typical end-to-end control and data flow architecture 
of CMM applications. Next, we categorize the existing and expected CMM applications, and analyze for each 
category the cloud infrastructure and platform needs, advantages and user experiences enabled, and challenges 
to make the applications successful. Fig.1 shows the overall architecture, including end-to-end flow of control 
and data between the mobile devices and the Internet cloud servers, for a typical CMM application. A typical 
CMM  application  has  a  small  footprint  client  on  the  mobile  device,  which  provides  the  appropriate  user 
interfaces (gesture, touchscreen, voice, text based) Subsequently, the multimedia data produced by the cloud, 
either  as  a  result  of  processing  using  the  cloud  computing  resources,  and/or  retrieval  from  cloud  storage 
resources, is transmitted downlink through the CN and RAN back to the mobile device. 

 The CMM client then decodes and displays the results on the mobile device display. From the above 
description, and as shown in Fig. 1, a typical CMM application will be highly interactive, with some types of 
applications  needing  near  real-time  response  times.  Note  that  for  certain  types  of  CMM  applications,  the 
control and data flow may deviate from that shown in Fig. 1. For example, for CMM applications like Cloud 
based  Media  Analytics  described  later,  the  application  may  not  always  be  initiated  by  a  mobile  CMM  client 
(like  in  Fig.  1),  and  may  collect  data  from  both  the  client  and  the  cloud  to  provide  analytics  to  other  CMM 
applications.  This  summarizes  the  different  categories  of  mobile  multimedia  applications  that  already  are,  or 
can  potentially  be,  driven  by  the  use  of  the  cloud,  including  storage,  download  and  synchronization 
applications,  audio  and  video  streaming  applications,  interactive  applications  like  multi-way  video 
Conferencing,  interactive  advertisements,  and  mobile  remote  desktop,  rich  rendering  based  applications  like 
mobile  multi-user  gaming  and  augmented  reality,  and  cloud  based  media  analytics  that  will  provide  better 
understanding of user preferences and experiences, and drive personalized mobile services. For each category 
of  CMM  applications,  we  list  the  IaaS  and  PaaS  features  that  will  be  needed,  including  some  which  are 
available  today,  and  some  that  need  to  be  developed.  We  also  list  the  advantages  of  each  category  of  CMM 
applications, including what multimedia experience can be enabled that cannot be supported currently, and the 
challenges that need to be addressed to make the application category successful. 

As  discussed  before,  Mobile  Cloud  Storage  is  the  most  commonly  used  category  of  CMM 
application/service  today,  with  offerings  from  Amazon,  Apple,  Dropbox,  Funambol,  and  Google,  among 
others.  These  services  provide  diverse  capabilities,  including  storing  documents,  photos,  music  and  video  in 
the  cloud,  accessing  media  from  any  device  anywhere  irrespective  of  the  source  of  the  media  and/or  the 
device/platform  used  to  generate  the  media,  and  synchronizing  data/media  across  multiple  devices  a  typical 
user owns. 

 

 

Figure 1.Cloud Mobile Impact of Wireless Network Factors on User Experience 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        66 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

To  study  the  impact  of  wireless  networks  on  the  quality  of  CMM  applications,  we  conducted 
experiments  with  a  Cloud  Mobile  Gaming  (CMG)  application  we  have  developed,  which  as  described  in 
Section II is a highly interactive cloud based rendering application: gaming commands are transmitted uplink 
from the mobile device to the cloud servers, and the rendered video needs to be streamed downlink from the 
server  to  the  mobile  client  in  near  real  time.  Since  this  application  is  highly  sensitive  to  response  time,  we 
measured uplink delay, downlink delay, and round-trip response time. The experiments were conducted under 
different network conditions data samples collected under three different conditions: when the network was not 
loaded  (data  collected  at  mid  night),  when  the  network  was  loaded  (data  collected  at  5  pm),  and  when  the 
network was loaded and the signal conditions were not strong (data collected at 6 pm, and inside a building). 
Media architecture, showing control and data flows. 

 

3. ADAPTIVE RENDERING PARAMETERS AND SETTINGS 

The first step in enabling dynamic game rendering adaptation in the CMG approach is to identify the 
adaptive  rendering  parameters  and  adaptive  rendering  settings.  A  game  may  have  many  different  rendering 
parameters,  but  only  a  few  of  them  have  obvious  impacts  on  CommC  or  CompC.  An  ―adaptive  rendering 
parameter‖ must be able to adapt at least one of CommC or CompC. An ―adaptive rendering setting‖ is a set of 
values  for the adaptive rendering parameters  which affect  CommC,  CompC or both. As discussed in  Section 
IV-A,  reducing  the  number  of  objects  in  the  graphic  scene  file  or  reducing  the  complexity  of  rendering 
operations could lead to the decreases in CommC and CompC. Based on the above principles, we identify four 
common parameters which we believe are suitable for rendering adaptation in most 3D games 

 3.1 REALISTIC EFFECT  

Realistic  effect  basically  includes  four  parameters:  color  depth,  anti-aliasing,  texture  filtering,  and 
lighting  mode.  Each  of  the  four  parameters  only  affects  part  of  graphic  rendering.  Varying  any  one  of  them 
may not reduce the graphic rendering load. Thus when we reduce/increase the realistic effect, we vary all four 
parameters. 

3.2 TEXTURE DETAIL  

This is also known as Level of Detail (LOD). It refers to how large and how many textures are used to 
present objects. The lower texture detail level, the lower resolution the textures have the surfaces of objects get 
blurred as we decrease the texture detail. 

3.3 VIEW DISTANCE 

 This parameter determines which objects in the camera view will be included in the resulting frame, 

and thereby should be sent to the display list for graphic rendering. 

3.4 ENVIRONMENT DETAIL  

Many  objects  and  effects  (grass,  flowers,  and  weather)  are  applied  in  modern  games,  to  make  the 
virtual world look more realistic. However they are not really necessary for users playing the game. Therefore, 
we could eliminate some of these objects or effects to reduce CommC and CompC if needed.  

 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        67 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

Figure 2.Derivation of the Complexity Model (C) 

 

Having defined adaptive rendering parameters and settings, we next use the game Planeshift (PS) as 
an  example  to  explain  how  to  derive  the  complexity  model,  where  we  have  also  elaborately  studied  how 
different  adaptive  rendering  settings  affect  the  CommC  and  CompC.  Subsequently,  we  also  have  studied  the 
impacts on CommC and CompC when video encoding setting, or video resolution, or server GPU is changed. 
This  will  help  to  demonstrate  that  the  key  concept  that  communication  complexity  and  computation 
complexity can be affected by different rendering settings is broadly applicable, no matter what kind of video 
resolution or video encoding setting, and no matter what kind of graphic GPU is used. 

4. CHARACTERIZ ING CommC AND CompC 

Four  adaptive  rendering  parameters  are  selected  for  game  PS,  with  their  possible.  We  conduct 
experiments to characterize CommC and CompC for every possible rendering setting obtained using the values 
of parameters. The experiments are conducted on a desktop server which integrates a NVIDIA  Geforce 8300 
graphic card. Video resolution used is VGA. The video codec used is X264, and its encoding method is set to 
Variable Bit Rate (VBR). The Quantization Parameter (QP) is 25, while the encoding frame rate is 15 fps and 
the size of Group of Pictures (GOP) is 30. We have randomly selected several different gaming scenes. In each 
test scene, for each rendering setting, we let the game avatar roam in the gaming world along the same route. 
We measure the average compressed video bit rate and GPU utilization in each experiment test to calculate the 
CommC and CompC. 

5. CONCLUSION 

The complexity model we presented above was derived using a certain video encoding setting, video 
resolution, and GPU. We next investigate the impact of using different video encoding and resolution settings, 
and  different  GPUs,  on  the  complexity  model.  We  have  conducted  experiments  and  measured  CommC  and 
CompC of each rendering setting in three test cases: a) using various encoding settings (different QP and GOP 
settings), b) using three different resolutions (QVGA, CIF, and VGA), and c) using three different GPUs (Intel 
GMA4500,  NVIDIA  8300,  and  NVIDIA  GTX580).  Absolute  error  distribution  and  standard  deviations  of 
measured CommC and CompC in these test cases. We can observe that the overall variations of CommC and 
CompC in these different test cases are not significant. Hence, we can conclude that the offline modeling step 
does  not  need  to  characterize  the  CommC  and  CompC  and  create  different  complexity  models  for  different 
video resolutions, or video encoding settings, or different platforms. 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        68 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
REFERENCES 

 

[1] Adaptive Mobile Cloud Computing to Enable  Rich Mobile Multimedia Applications  Shaoxuan Wang and Sujit Dey, 
Senior  Member, IEEE  
 
[2]  Canalys,Smart  PhonesOvertakeClient  PCs,  Feb.  2011.  [Online].Available:  http://www.canalys.com/newsroom/smart-
phones-overtakeclient-pcs-2011. 
 
[3]  IDC,  More  Mobile  Internet  Users  Than  Wireline  Users  in  the  U.S.  by  2015,  Sep.  2011.  [Online].  Available: 
http://www.idc.com/getdoc.jsp?containerId=prUS23028711. 
 
[4]  Juniper  Research,  Mobile  Cloud:  Smart  Device  Strategies  for  Enterprise  &  Consumer  Markets  2011-2016,  Jul. 2011.  
Online]. Available:http://juniperresearch.com/. 
 
[5]  MarketsAndMarkets,  World  Mobile  Applications  Market—Advanced  Technologies,  Global  Forecast  (2010-2015), 
Aug. 2010. [Online].Available: http://www.marketsandmarkets.com/. 
 
[6] GSMA OneAPI. [Online]. Available: https://gsma.securespsite.com/ access/ Access 20API 20 Wiki/Home.aspx. 
 
[7]  S.Wang  and  S.  Dey,  ―Rendering  adaptation  to  address  communication  and  computation  constraints  in  cloud  mobile 
gaming,‖ in Proc. IEEE GLOBECOM, Miami, FL, USA, Dec. 2010. 
 
[8] ARCchart, The Mobile Cloud: Market Analysis and Forecasts, 2011.  
 
[9] Cisco, Cisco Visual Networking Index: Forecast and Methodology, 2011-2016, 2012. 
 
[10]3D Game System Requirements. [Online]. Available: http://www.game-debate.com. 
 
[11] Anandtechiphone Performance Reviews. [Online]. Available: http:// www. anandtech. com. 
 
[12] S.Wang and S. Dey, ―Cloud mobile gaming: Modeling and measuring user experience in mobile wireless networks,‖ 
in Proc. ACM SIGMOBILE MC2R, 2012, vol. 16, no. 1, pp. 10–21. 
 
[13] S. Wang and S. Dey, ―Modeling and characterizing user experience in a cloud server based mobile gaming approach,‖ 
in Proc. IEEE GLOBECOM, Honolulu, HI, USA, Dec. 2009. 
 
 [14] Y.-T. Lee et al., ―World of warcraft avatar history dataset,‖ in Proc. ACM Multimedia Syst., 2011. 
[15]  Asia  Times,  Game  still  on  at  Tencent,  Mar.  2010.  [Online].  Available:    http://www.atimes.com/  atimes/ 
China_Business/ LC24Cb01.html. 
 
[16] Planeshift. [Online]. Available: http://www.planeshift.it/. 
 
[17] S. Wang and S. Dey, ―Addressing response time and video quality in remote server based internet mobile gaming,‖ in 
Proc. IEEE WCNC, Sydney, Australia, Mar. 2010. 
 
[18] H. Ahlehagh and S. Dey, ―Video caching in radio access network,‖ in Proc. IEEE WCNC, Paris, France, Apr. 2012. 
 
[19] H. Ahlehagh and S.Dey,  ―Hierarchical video caching in  wireless cloud: Approaches and algorithms,‖ in Proc. IEEE 
ICC Workshop on Realizing Advanced Video  Optimized Wireless Networks, Ottawa, ON, 
Canada, Jun. 2012. 
 
[20]  G.  Lee,  B.  Chun,  and  R.  Katz,  ―Heterogeneity-aware  resource  allocation  and  scheduling  in  the  cloud,‖  in Proc.  3rd 
USENIX Workshop Hot Topics in Cloud Comput., Jun. 2011. 
 
[21]  R.  Bossche,  K.  Vanmechelen,  and  J.  Broeckhove,  ―Cost-optimal  scheduling  in  hybrid  IaaS  clouds  for  deadline 
constrained workload,‖ in Proc. IEEE Int. Conf. Cloud Comput., Miami, FL, USA, Jul. 2010. 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        69 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

A MOBILE MULTIMEDIA CLOUD 

COMPUTING ON THE WEB 

Gayathri V1, Priyadarsini K2 

 

1Department of CSE, SRM University, gayathrivmca@gmail.com  
2Department of CSE, SRM University, priyadarsinikk@gmail.com 

 

 

Abstract 

The  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud  computing  infrastructure  to  develop  and 
creasing array of online personal health record (PHR) systems. Although these systems provide the technical capacity 
to store and retrieve medical data in various multimedia formats, including images, ideas, voice, and text, individual 
patient use remains limited by the lack of intuitive data representation and visualization techniques. As such, further 
research is necessary to better visualize and present these records, in ways that make the complex medical data more 
intuitive.  In  this  study,  we  present  a  web-based  PHR  visualization  system,  called  the  3D  medical  graphical  avatar 
(MGA),  which  was  designed  to  explore  web-based  delivery  of  a  wide  array  of  medical  data  types  including  multi-
dimensional  medical  images;  medical  videos;  text-based  data;  and  spatial  annotations.  Mapping  information  was 
extracted  from  each  of  the  data  types  and  was  used  to  embed  spatial  and  textual  annotations,  such  as  regions  of 
interest (ROIs) and time-based video annotations. Our MGA itself is built from clinical patient imaging studies, when 
available. We have taken advantage of the emerging web technologies of HTML5 and WebGL to make our application 
available to a wider base of users and devices. We analyzed the performance of our proof-of-concept prototype system 
on mobile and desktop consumer devices. Our initial experiments indicate that our system can render the medical data 
in a fashion that enables interactive navigation of the MGA 

Keywords: Medical Graphical  Avatar (MGA), Regions of  Interest (ROIs), Personal Health Record (PHR), 
Cloud Mobile Gaming (CMG) 

 

 
1. INTRODUCTION 

          In  existing  system  the  healthcare  industry  has  begun  to  utilize  web-based  systems  and  cloud 
computing  infrastructure  to  develop  an  increasing  array  of  online  personal  health  record  (PHR)  systems. 
Although these systems provide the technical capacity to store and retrieve medical data in various multimedia 
formats, including images, videos, voice, and text, individual patient use remains. Limited by lack of intuitive 
data representation and visualization techniques. As such, further research is necessary to better visualize and 
present  these  records,  in  ways  that  make  the  complex  medical  data  more  intuitive.  In  proposed  system  the 
systems  provide  the  technical  capacity  to  store  and          retrieve  medical  data  in  various  multimedia  formats, 
including images, videos, and voice, and text, individual patient  use remains  Limited by the lack of intuitive 
data  representation  and      visualization  techniques.      The  healthcare  industry  has  begun  to  utilize  web-based 
systems and cloud computing infrastructure to develop a creasing array of online personal health record (PHR) 
system.  Our  data  indicate  that  our  MGA  is  able  to  display  spatial  and  temporal  contextual  information, 
available  in  all  forms  of  medical  data.  The  patients  are  provided  with  such  data.    Recent  PHRs  have  been 
designed  to  serve  as  user-friendly,  patient-facing  digital  repositories  that  consolidate  an  individual’s  medical 
history and provide tools for communication. 

 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        65 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
2. SYSTEM DESIGN 

Utilizing  available  cloud  computing  and  storage  resources,  we  expect  a  heterogeneous  set  of  Cloud 
Mobile  Media  services  and  applications  to  emerge,  with  different  types  of  consumer  experiences  and 
advantages enabled. In this section, we first describe the typical end-to-end control and data flow architecture 
of CMM applications. Next, we categorize the existing and expected CMM applications, and analyze for each 
category the cloud infrastructure and platform needs, advantages and user experiences enabled, and challenges 
to make the applications successful. Fig.1 shows the overall architecture, including end-to-end flow of control 
and data between the mobile devices and the Internet cloud servers, for a typical CMM application. A typical 
CMM  application  has  a  small  footprint  client  on  the  mobile  device,  which  provides  the  appropriate  user 
interfaces (gesture, touchscreen, voice, text based) Subsequently, the multimedia data produced by the cloud, 
either  as  a  result  of  processing  using  the  cloud  computing  resources,  and/or  retrieval  from  cloud  storage 
resources, is transmitted downlink through the CN and RAN back to the mobile device. 

 The CMM client then decodes and displays the results on the mobile device display. From the above 
description, and as shown in Fig. 1, a typical CMM application will be highly interactive, with some types of 
applications  needing  near  real-time  response  times.  Note  that  for  certain  types  of  CMM  applications,  the 
control and data flow may deviate from that shown in Fig. 1. For example, for CMM applications like Cloud 
based  Media  Analytics  described  later,  the  application  may  not  always  be  initiated  by  a  mobile  CMM  client 
(like  in  Fig.  1),  and  may  collect  data  from  both  the  client  and  the  cloud  to  provide  analytics  to  other  CMM 
applications.  This  summarizes  the  different  categories  of  mobile  multimedia  applications  that  already  are,  or 
can  potentially  be,  driven  by  the  use  of  the  cloud,  including  storage,  download  and  synchronization 
applications,  audio  and  video  streaming  applications,  interactive  applications  like  multi-way  video 
Conferencing,  interactive  advertisements,  and  mobile  remote  desktop,  rich  rendering  based  applications  like 
mobile  multi-user  gaming  and  augmented  reality,  and  cloud  based  media  analytics  that  will  provide  better 
understanding of user preferences and experiences, and drive personalized mobile services. For each category 
of  CMM  applications,  we  list  the  IaaS  and  PaaS  features  that  will  be  needed,  including  some  which  are 
available  today,  and  some  that  need  to  be  developed.  We  also  list  the  advantages  of  each  category  of  CMM 
applications, including what multimedia experience can be enabled that cannot be supported currently, and the 
challenges that need to be addressed to make the application category successful. 

As  discussed  before,  Mobile  Cloud  Storage  is  the  most  commonly  used  category  of  CMM 
application/service  today,  with  offerings  from  Amazon,  Apple,  Dropbox,  Funambol,  and  Google,  among 
others.  These  services  provide  diverse  capabilities,  including  storing  documents,  photos,  music  and  video  in 
the  cloud,  accessing  media  from  any  device  anywhere  irrespective  of  the  source  of  the  media  and/or  the 
device/platform  used  to  generate  the  media,  and  synchronizing  data/media  across  multiple  devices  a  typical 
user owns. 

 

 

Figure 1.Cloud Mobile Impact of Wireless Network Factors on User Experience 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        66 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

To  study  the  impact  of  wireless  networks  on  the  quality  of  CMM  applications,  we  conducted 
experiments  with  a  Cloud  Mobile  Gaming  (CMG)  application  we  have  developed,  which  as  described  in 
Section II is a highly interactive cloud based rendering application: gaming commands are transmitted uplink 
from the mobile device to the cloud servers, and the rendered video needs to be streamed downlink from the 
server  to  the  mobile  client  in  near  real  time.  Since  this  application  is  highly  sensitive  to  response  time,  we 
measured uplink delay, downlink delay, and round-trip response time. The experiments were conducted under 
different network conditions data samples collected under three different conditions: when the network was not 
loaded  (data  collected  at  mid  night),  when  the  network  was  loaded  (data  collected  at  5  pm),  and  when  the 
network was loaded and the signal conditions were not strong (data collected at 6 pm, and inside a building). 
Media architecture, showing control and data flows. 

 

3. ADAPTIVE RENDERING PARAMETERS AND SETTINGS 

The first step in enabling dynamic game rendering adaptation in the CMG approach is to identify the 
adaptive  rendering  parameters  and  adaptive  rendering  settings.  A  game  may  have  many  different  rendering 
parameters,  but  only  a  few  of  them  have  obvious  impacts  on  CommC  or  CompC.  An  ―adaptive  rendering 
parameter‖ must be able to adapt at least one of CommC or CompC. An ―adaptive rendering setting‖ is a set of 
values  for the adaptive rendering parameters  which affect  CommC,  CompC or both. As discussed in  Section 
IV-A,  reducing  the  number  of  objects  in  the  graphic  scene  file  or  reducing  the  complexity  of  rendering 
operations could lead to the decreases in CommC and CompC. Based on the above principles, we identify four 
common parameters which we believe are suitable for rendering adaptation in most 3D games 

 3.1 REALISTIC EFFECT  

Realistic  effect  basically  includes  four  parameters:  color  depth,  anti-aliasing,  texture  filtering,  and 
lighting  mode.  Each  of  the  four  parameters  only  affects  part  of  graphic  rendering.  Varying  any  one  of  them 
may not reduce the graphic rendering load. Thus when we reduce/increase the realistic effect, we vary all four 
parameters. 

3.2 TEXTURE DETAIL  

This is also known as Level of Detail (LOD). It refers to how large and how many textures are used to 
present objects. The lower texture detail level, the lower resolution the textures have the surfaces of objects get 
blurred as we decrease the texture detail. 

3.3 VIEW DISTANCE 

 This parameter determines which objects in the camera view will be included in the resulting frame, 

and thereby should be sent to the display list for graphic rendering. 

3.4 ENVIRONMENT DETAIL  

Many  objects  and  effects  (grass,  flowers,  and  weather)  are  applied  in  modern  games,  to  make  the 
virtual world look more realistic. However they are not really necessary for users playing the game. Therefore, 
we could eliminate some of these objects or effects to reduce CommC and CompC if needed.  

 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        67 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 

Figure 2.Derivation of the Complexity Model (C) 

 

Having defined adaptive rendering parameters and settings, we next use the game Planeshift (PS) as 
an  example  to  explain  how  to  derive  the  complexity  model,  where  we  have  also  elaborately  studied  how 
different  adaptive  rendering  settings  affect  the  CommC  and  CompC.  Subsequently,  we  also  have  studied  the 
impacts on CommC and CompC when video encoding setting, or video resolution, or server GPU is changed. 
This  will  help  to  demonstrate  that  the  key  concept  that  communication  complexity  and  computation 
complexity can be affected by different rendering settings is broadly applicable, no matter what kind of video 
resolution or video encoding setting, and no matter what kind of graphic GPU is used. 

4. CHARACTERIZ ING CommC AND CompC 

Four  adaptive  rendering  parameters  are  selected  for  game  PS,  with  their  possible.  We  conduct 
experiments to characterize CommC and CompC for every possible rendering setting obtained using the values 
of parameters. The experiments are conducted on a desktop server which integrates a NVIDIA  Geforce 8300 
graphic card. Video resolution used is VGA. The video codec used is X264, and its encoding method is set to 
Variable Bit Rate (VBR). The Quantization Parameter (QP) is 25, while the encoding frame rate is 15 fps and 
the size of Group of Pictures (GOP) is 30. We have randomly selected several different gaming scenes. In each 
test scene, for each rendering setting, we let the game avatar roam in the gaming world along the same route. 
We measure the average compressed video bit rate and GPU utilization in each experiment test to calculate the 
CommC and CompC. 

5. CONCLUSION 

The complexity model we presented above was derived using a certain video encoding setting, video 
resolution, and GPU. We next investigate the impact of using different video encoding and resolution settings, 
and  different  GPUs,  on  the  complexity  model.  We  have  conducted  experiments  and  measured  CommC  and 
CompC of each rendering setting in three test cases: a) using various encoding settings (different QP and GOP 
settings), b) using three different resolutions (QVGA, CIF, and VGA), and c) using three different GPUs (Intel 
GMA4500,  NVIDIA  8300,  and  NVIDIA  GTX580).  Absolute  error  distribution  and  standard  deviations  of 
measured CommC and CompC in these test cases. We can observe that the overall variations of CommC and 
CompC in these different test cases are not significant. Hence, we can conclude that the offline modeling step 
does  not  need  to  characterize  the  CommC  and  CompC  and  create  different  complexity  models  for  different 
video resolutions, or video encoding settings, or different platforms. 

 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        68 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
REFERENCES 

 

[1] Adaptive Mobile Cloud Computing to Enable  Rich Mobile Multimedia Applications  Shaoxuan Wang and Sujit Dey, 
Senior  Member, IEEE  
 
[2]  Canalys,Smart  PhonesOvertakeClient  PCs,  Feb.  2011.  [Online].Available:  http://www.canalys.com/newsroom/smart-
phones-overtakeclient-pcs-2011. 
 
[3]  IDC,  More  Mobile  Internet  Users  Than  Wireline  Users  in  the  U.S.  by  2015,  Sep.  2011.  [Online].  Available: 
http://www.idc.com/getdoc.jsp?containerId=prUS23028711. 
 
[4]  Juniper  Research,  Mobile  Cloud:  Smart  Device  Strategies  for  Enterprise  &  Consumer  Markets  2011-2016,  Jul. 2011.  
Online]. Available:http://juniperresearch.com/. 
 
[5]  MarketsAndMarkets,  World  Mobile  Applications  Market—Advanced  Technologies,  Global  Forecast  (2010-2015), 
Aug. 2010. [Online].Available: http://www.marketsandmarkets.com/. 
 
[6] GSMA OneAPI. [Online]. Available: https://gsma.securespsite.com/ access/ Access 20API 20 Wiki/Home.aspx. 
 
[7]  S.Wang  and  S.  Dey,  ―Rendering  adaptation  to  address  communication  and  computation  constraints  in  cloud  mobile 
gaming,‖ in Proc. IEEE GLOBECOM, Miami, FL, USA, Dec. 2010. 
 
[8] ARCchart, The Mobile Cloud: Market Analysis and Forecasts, 2011.  
 
[9] Cisco, Cisco Visual Networking Index: Forecast and Methodology, 2011-2016, 2012. 
 
[10]3D Game System Requirements. [Online]. Available: http://www.game-debate.com. 
 
[11] Anandtechiphone Performance Reviews. [Online]. Available: http:// www. anandtech. com. 
 
[12] S.Wang and S. Dey, ―Cloud mobile gaming: Modeling and measuring user experience in mobile wireless networks,‖ 
in Proc. ACM SIGMOBILE MC2R, 2012, vol. 16, no. 1, pp. 10–21. 
 
[13] S. Wang and S. Dey, ―Modeling and characterizing user experience in a cloud server based mobile gaming approach,‖ 
in Proc. IEEE GLOBECOM, Honolulu, HI, USA, Dec. 2009. 
 
 [14] Y.-T. Lee et al., ―World of warcraft avatar history dataset,‖ in Proc. ACM Multimedia Syst., 2011. 
[15]  Asia  Times,  Game  still  on  at  Tencent,  Mar.  2010.  [Online].  Available:    http://www.atimes.com/  atimes/ 
China_Business/ LC24Cb01.html. 
 
[16] Planeshift. [Online]. Available: http://www.planeshift.it/. 
 
[17] S. Wang and S. Dey, ―Addressing response time and video quality in remote server based internet mobile gaming,‖ in 
Proc. IEEE WCNC, Sydney, Australia, Mar. 2010. 
 
[18] H. Ahlehagh and S. Dey, ―Video caching in radio access network,‖ in Proc. IEEE WCNC, Paris, France, Apr. 2012. 
 
[19] H. Ahlehagh and S.Dey,  ―Hierarchical video caching in  wireless cloud: Approaches and algorithms,‖ in Proc. IEEE 
ICC Workshop on Realizing Advanced Video  Optimized Wireless Networks, Ottawa, ON, 
Canada, Jun. 2012. 
 
[20]  G.  Lee,  B.  Chun,  and  R.  Katz,  ―Heterogeneity-aware  resource  allocation  and  scheduling  in  the  cloud,‖  in Proc.  3rd 
USENIX Workshop Hot Topics in Cloud Comput., Jun. 2011. 
 
[21]  R.  Bossche,  K.  Vanmechelen,  and  J.  Broeckhove,  ―Cost-optimal  scheduling  in  hybrid  IaaS  clouds  for  deadline 
constrained workload,‖ in Proc. IEEE Int. Conf. Cloud Comput., Miami, FL, USA, Jul. 2010. 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        69 
 
 

Gayathri V et al, International Journal of Computer Science and Mobile Applications, 

 

Vol.2 Issue. 4, April- 2014, pg. 65-70                              ISSN: 2321-8363 

 
[22]  S.Wang,  Y.  Liu,  and  S.  Dey,  ―Wireless  network  aware  cloud  scheduler  for  scalable  cloud  mobile  gaming,‖  in Proc. 
IEEE ICC, Ottawa, ON, Canada, Jun. 2012. 
 
[23] WoW Basic Demographics. [Online]. Available: http://www.nickyee.com/ Daedalus/  archives-/001365.php. 

 

A Brief Author Biography  
 
1Gayathri V –Gayathri is pursuing MTECH CSE in SRM University who is interested in Cloud Computing research. She 
holds MCA and working in a software concern.  
 
2Priyadarsini  K  –  Priyadarsini  is  working  as  an  Asst.  Professor  in  SRM  University,  who  is  currently  doing  research  in 
Cloud computing. 
 
 

©2014, IJCSMA All Rights Reserved, www.ijcsma.com                                                                        70 
 
 

