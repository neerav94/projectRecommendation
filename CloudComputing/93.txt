Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

166 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

Figure 5.    Green Cloud Architecture 

Table 3.    Carbon Emission Related Parameter of a Datacenter 

 

 

 
In  order  to  validate  our  framework  and  to  prove  that  it 
achieves better efficiency  in terms of carbon emission,  we 
have  studied  five  policies  (Green  and  profit-oriented) 
employed for scheduling by Green Broker. 

a.  Greedy Minimum Carbon Emission (GMCE): In this 
policy,  user  applications  are  assigned  to  Cloud 
providers  in  greedy  manner  based  on  their  carbon 
emission.   

b.  Minimum  Carbon  Emission  -  Minimum  Carbon 
Emission  (MCE-MCE):  This  is  a  double  greedy 
policy where applications are assigned to the Cloud 

 

providers  with  minimum  Carbon  emission  due  to 
their datacenter location and Carbon emission due to 
application execution. 

c.  Greedy Maximum Profit (GMP): In this policy, user 
applications  are  assigned  in  greedy  manner  to  a 
provider who execute the application fastest and get 
maximum profit. .   

d.  Maximum Profit - Maximum Profit (MP-MP): This is 
double  greedy  policy  considering  profit  made  by 
Cloud  providers  and  application  finishes  by  its 
deadline.   

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

166 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

Figure 5.    Green Cloud Architecture 

Table 3.    Carbon Emission Related Parameter of a Datacenter 

 

 

 
In  order  to  validate  our  framework  and  to  prove  that  it 
achieves better efficiency  in terms of carbon emission,  we 
have  studied  five  policies  (Green  and  profit-oriented) 
employed for scheduling by Green Broker. 

a.  Greedy Minimum Carbon Emission (GMCE): In this 
policy,  user  applications  are  assigned  to  Cloud 
providers  in  greedy  manner  based  on  their  carbon 
emission.   

b.  Minimum  Carbon  Emission  -  Minimum  Carbon 
Emission  (MCE-MCE):  This  is  a  double  greedy 
policy where applications are assigned to the Cloud 

 

providers  with  minimum  Carbon  emission  due  to 
their datacenter location and Carbon emission due to 
application execution. 

c.  Greedy Maximum Profit (GMP): In this policy, user 
applications  are  assigned  in  greedy  manner  to  a 
provider who execute the application fastest and get 
maximum profit. .   

d.  Maximum Profit - Maximum Profit (MP-MP): This is 
double  greedy  policy  considering  profit  made  by 
Cloud  providers  and  application  finishes  by  its 
deadline.   

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

167 

e.  Minimising Carbon Emission and Maximising Profit 
(MCE-MP):  In  this  policy,  the  broker  tries  to 
schedule  the  applications  to  those  providers  which 
results in minimization of total carbon emission and 
maximization of profit.   

Above  GMCE,  MCE-MCE  and  MCE-MP  are  “Green” 
policies while MP-MP and GMP are profit-oriented policies. 
A more extensive detail on modeling of energy efficiency of 
a Cloud datacenter, experimental data and results is available 
in  previous  work  [47].  Here,  we  present  some  important 
results to illustrate the validity of our presented framework. 
Figure 6 shows the course of experiments conducted with 
varying user‟s urgency for executing his application and job 
arrival rate. The metrics of total carbon emission and total 
profit are used since the resource provider needs to know the 
collective loss in carbon emission and gain in profit across all 
datacenters. From these results three main inferences can be 
made. 

-  Green policies reduce the carbon emission by almost 

20%  in  comparison  to  profit  based  policies.  This 
observation  emphasizes  the  inclusion  of  overall 
carbon  efficiency  of  all  the  Cloud  providers  in 
scheduling decisions.   

-  With the increase in  user‟s  urgency to execute the 
application,  the  gain  in  carbon  emission  reduces 
almost linearly. This clearly shows how important is 
the  role  of  user  in  making  Cloud  computing  in 
general  “Green”.  If  users  are  more  patient  and 
schedule  the  applications  when  the  datacenters  are 
running at higher energy efficiency, more energy and 
carbon gain can be made. Thus, in our framework, 
we introduce the need of Green Cloud Offers from 
providers.   
The green policies also have minimal effect on the 
provider‟s profit. This clearly shows that by using 
energy  efficient  solutions  such  as  Green  Cloud 
Framework  both  Cloud  providers  and  users  can 
benefit.   

- 

(a) Carbon Emission VS Urgency                                                                                (b) Carbon Emission VS Arrival Rate 

 

 

(c) Profit VS Urgency                                                                                              (d) Profit VS Arrival Rate 

Figure 6.    Carbon Emission and Profit of Provider Using Green Cloud Framework 

 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

166 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

Figure 5.    Green Cloud Architecture 

Table 3.    Carbon Emission Related Parameter of a Datacenter 

 

 

 
In  order  to  validate  our  framework  and  to  prove  that  it 
achieves better efficiency  in terms of carbon emission,  we 
have  studied  five  policies  (Green  and  profit-oriented) 
employed for scheduling by Green Broker. 

a.  Greedy Minimum Carbon Emission (GMCE): In this 
policy,  user  applications  are  assigned  to  Cloud 
providers  in  greedy  manner  based  on  their  carbon 
emission.   

b.  Minimum  Carbon  Emission  -  Minimum  Carbon 
Emission  (MCE-MCE):  This  is  a  double  greedy 
policy where applications are assigned to the Cloud 

 

providers  with  minimum  Carbon  emission  due  to 
their datacenter location and Carbon emission due to 
application execution. 

c.  Greedy Maximum Profit (GMP): In this policy, user 
applications  are  assigned  in  greedy  manner  to  a 
provider who execute the application fastest and get 
maximum profit. .   

d.  Maximum Profit - Maximum Profit (MP-MP): This is 
double  greedy  policy  considering  profit  made  by 
Cloud  providers  and  application  finishes  by  its 
deadline.   

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

167 

e.  Minimising Carbon Emission and Maximising Profit 
(MCE-MP):  In  this  policy,  the  broker  tries  to 
schedule  the  applications  to  those  providers  which 
results in minimization of total carbon emission and 
maximization of profit.   

Above  GMCE,  MCE-MCE  and  MCE-MP  are  “Green” 
policies while MP-MP and GMP are profit-oriented policies. 
A more extensive detail on modeling of energy efficiency of 
a Cloud datacenter, experimental data and results is available 
in  previous  work  [47].  Here,  we  present  some  important 
results to illustrate the validity of our presented framework. 
Figure 6 shows the course of experiments conducted with 
varying user‟s urgency for executing his application and job 
arrival rate. The metrics of total carbon emission and total 
profit are used since the resource provider needs to know the 
collective loss in carbon emission and gain in profit across all 
datacenters. From these results three main inferences can be 
made. 

-  Green policies reduce the carbon emission by almost 

20%  in  comparison  to  profit  based  policies.  This 
observation  emphasizes  the  inclusion  of  overall 
carbon  efficiency  of  all  the  Cloud  providers  in 
scheduling decisions.   

-  With the increase in  user‟s  urgency to execute the 
application,  the  gain  in  carbon  emission  reduces 
almost linearly. This clearly shows how important is 
the  role  of  user  in  making  Cloud  computing  in 
general  “Green”.  If  users  are  more  patient  and 
schedule  the  applications  when  the  datacenters  are 
running at higher energy efficiency, more energy and 
carbon gain can be made. Thus, in our framework, 
we introduce the need of Green Cloud Offers from 
providers.   
The green policies also have minimal effect on the 
provider‟s profit. This clearly shows that by using 
energy  efficient  solutions  such  as  Green  Cloud 
Framework  both  Cloud  providers  and  users  can 
benefit.   

- 

(a) Carbon Emission VS Urgency                                                                                (b) Carbon Emission VS Arrival Rate 

 

 

(c) Profit VS Urgency                                                                                              (d) Profit VS Arrival Rate 

Figure 6.    Carbon Emission and Profit of Provider Using Green Cloud Framework 

 

168 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

8. Conclusions and Future Directions   

Cloud  computing  business  potential  and  contribution  to 
already aggravating carbon emission from ICT, has lead to a 
series of discussion whether Cloud computing is really green. 
It  is  forecasted  that  the  environmental  footprint  from  data 
centers will triple between 2002 and 2020, which is currently 
7.8 billion tons of CO2 per year. There are reports on Green 
IT analysis of Clouds and datacenters that show that Cloud 
computing is “Green”, while others show that it will lead to 
alarming increase in Carbon emission. Thus, in this chapter, 
we first analyzed the benefits offered by Cloud computing by 
studying  its  fundamental  definitions  and  benefits,  the 
services  it  offers  to  end  users,  and  its  deployment  model. 
Then,  we  discussed 
that 
contribute to carbon emission and the features of Clouds that 
make it “Green”. We also discussed several research efforts 
and  technologies  that  increase  the  energy  efficiency  of 
various  aspects  of  Clouds.  For  this  study,  we  identified 
several  unexplored  areas  that  can  help  in  maximizing  the 
energy  efficiency  of  Clouds  from  a  holistic  perspective. 
After  analyzing  the  shortcoming  of  previous  solutions,  we 
proposed  a  Green  Cloud  Framework  and  presented  some 
results  for  its  validation.  Even  though  our  Green  Cloud 
to  make  Cloud 
framework  embeds  various  features 
computing  much  more  Green, 
there  are  still  many 
technological solutions are required to make it a reality: 

the  components  of  Clouds 

levels 

First  efforts  are  required  in  designing  software  at 
various 
(OS,  compiler,  algorithm  and 
application)  that  facilitates  system  wide  energy 
efficiency.  Although  SaaS  providers  may  still  use 
already implemented software, they need to analyze 
the  runtime  behavior  of  applications.  The  gathered 
empirical  data  can  be  used  in  energy  efficient 
scheduling and resource provisioning. The compiler 
and operating systems need to be designed in such a 
way  that  resources  can  be  allocated  to  application 
based on the required level of performance, and thus 
performance versus energy consumption tradeoff can 
be managed.   
To  enable  the  green  Cloud  datacenters,  the  Cloud 
providers need to understand and  measure existing 
datacenter  power  and  cooling  designs,  power 
consumptions  of 
their  cooling 
requirements, and equipment resource utilization to 
achieve maximum efficiency. In addition, modeling 
tools are required to measure the energy usage of all 
the components and services of Cloud, from user PC 
to datacenter where Cloud services are hosted. 
For designing the holistic solutions in the scheduling 
and resource provisioning of applications within the 
datacenter, all the factors such as cooling, network, 
memory,  and  CPU  should  be  considered.  For 
instance,  consolidation  of  VMs  even 
though 
effective technique to minimize overall power usage 
of  datacenter,  also  raises  the  issue  related  to 
necessary  redundancy  and  placement  geo-diversity 

servers  and 

- 

- 

- 

 

- 

required to be maintained to fulfill SLAs with users. 
It is obvious that last thing Cloud provider will want 
is  to  lose  their  reputation  by  their  bad  service  or 
violation of promised service requirements. 
Last but not the least, the responsibility also goes to 
both  providers  and  customers  to  make  sure  that 
emerging  technologies  do  not  bring  irreversible 
changes  which  can  bring  threat  to  the  health  of 
human society. The way end users interact with the 
application also has a very real cost and impact. For 
example,  purging  of  unsolicited  emails  can 
eliminates  energy  wasted  in  storage  and  network. 
Similarly, if Cloud providers want to provide a truly 
green and renewable Cloud, they must deploy their 
datacenters  near  renewable  energy  sources  and 
maximize  the  Green  energy  usage  in  their  already 
established  datacenters.  Before 
adding  new 
technologies  such  as  virtualization,  proper  analysis 
of overhead should be done real benefit in terms of 
energy efficiency.   

In  conclusion,  by  simply  improving  the  efficiency  of 
equipment, Cloud computing cannot be claimed to be Green. 
What is important is to make its usage more carbon efficient 
both from user and provider‟s perspective. Cloud Providers 
need  to  reduce  the  electricity  demand  of  Clouds  and  take 
major  steps  in  using  renewable  energy  sources  rather  than 
just looking for cost minimization. 

 

REFERENCES 
[1]  Gleeson,  E.  2009.  Computing  industry  set  for  a  shocking 
change. 
from 
http://www.moneyweek.com/investment-advice/computing-i
ndustry-set-for-a-shocking-change-43226.aspx   

Retrieved 

January 

2010 

10, 

[2]  Buyya,  R.,  Yeo,  C.S.  and  Venugopal,  S.  2008. 
Market-oriented Cloud computing: Vision, hype, and reality 
for delivering it services as computing utilities. Proceedings 
of 
the  10th  IEEE  International  Conference  on  High 
Performance Computing and Communications, Los Alamitos, 
CA, USA.   

[3]  New Datacenter Locations. 2008. http://royal.pingdom.com/

2008/04/11/map-of-all-google-data-center-locations/   

[4]  Bianchini,  R.,  and  Rajamony,  R.  2004,  Power  and  energy 

management for server systems, Computer, 37 (11) 68-74.   

[5]  Rivoire, S., Shah, M. A., Ranganathan, P., and Kozyrakis, C. 
2007.  Joulesort:  a  balanced  energy-efficiency  benchmark, 
Proceedings  of  the  2007  ACM  SIGMOD  International 
Conference on Management of Data, NY, USA.   

[6]  Greenpeace 

International. 
http://www.greenpeace.org/ 
international/en/publications/reports/make-it-green-Cloudco
mputing/   

2010.  Make 

IT  Green 

[7]  Accenture  Microsoft  Report.  2010.  Cloud  computing  and 
Sustainability: The Environmental Benefits of Moving to the 
Cloud, http://www.wspenvironmental.com/media/docs/news

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

166 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

Figure 5.    Green Cloud Architecture 

Table 3.    Carbon Emission Related Parameter of a Datacenter 

 

 

 
In  order  to  validate  our  framework  and  to  prove  that  it 
achieves better efficiency  in terms of carbon emission,  we 
have  studied  five  policies  (Green  and  profit-oriented) 
employed for scheduling by Green Broker. 

a.  Greedy Minimum Carbon Emission (GMCE): In this 
policy,  user  applications  are  assigned  to  Cloud 
providers  in  greedy  manner  based  on  their  carbon 
emission.   

b.  Minimum  Carbon  Emission  -  Minimum  Carbon 
Emission  (MCE-MCE):  This  is  a  double  greedy 
policy where applications are assigned to the Cloud 

 

providers  with  minimum  Carbon  emission  due  to 
their datacenter location and Carbon emission due to 
application execution. 

c.  Greedy Maximum Profit (GMP): In this policy, user 
applications  are  assigned  in  greedy  manner  to  a 
provider who execute the application fastest and get 
maximum profit. .   

d.  Maximum Profit - Maximum Profit (MP-MP): This is 
double  greedy  policy  considering  profit  made  by 
Cloud  providers  and  application  finishes  by  its 
deadline.   

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

167 

e.  Minimising Carbon Emission and Maximising Profit 
(MCE-MP):  In  this  policy,  the  broker  tries  to 
schedule  the  applications  to  those  providers  which 
results in minimization of total carbon emission and 
maximization of profit.   

Above  GMCE,  MCE-MCE  and  MCE-MP  are  “Green” 
policies while MP-MP and GMP are profit-oriented policies. 
A more extensive detail on modeling of energy efficiency of 
a Cloud datacenter, experimental data and results is available 
in  previous  work  [47].  Here,  we  present  some  important 
results to illustrate the validity of our presented framework. 
Figure 6 shows the course of experiments conducted with 
varying user‟s urgency for executing his application and job 
arrival rate. The metrics of total carbon emission and total 
profit are used since the resource provider needs to know the 
collective loss in carbon emission and gain in profit across all 
datacenters. From these results three main inferences can be 
made. 

-  Green policies reduce the carbon emission by almost 

20%  in  comparison  to  profit  based  policies.  This 
observation  emphasizes  the  inclusion  of  overall 
carbon  efficiency  of  all  the  Cloud  providers  in 
scheduling decisions.   

-  With the increase in  user‟s  urgency to execute the 
application,  the  gain  in  carbon  emission  reduces 
almost linearly. This clearly shows how important is 
the  role  of  user  in  making  Cloud  computing  in 
general  “Green”.  If  users  are  more  patient  and 
schedule  the  applications  when  the  datacenters  are 
running at higher energy efficiency, more energy and 
carbon gain can be made. Thus, in our framework, 
we introduce the need of Green Cloud Offers from 
providers.   
The green policies also have minimal effect on the 
provider‟s profit. This clearly shows that by using 
energy  efficient  solutions  such  as  Green  Cloud 
Framework  both  Cloud  providers  and  users  can 
benefit.   

- 

(a) Carbon Emission VS Urgency                                                                                (b) Carbon Emission VS Arrival Rate 

 

 

(c) Profit VS Urgency                                                                                              (d) Profit VS Arrival Rate 

Figure 6.    Carbon Emission and Profit of Provider Using Green Cloud Framework 

 

168 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

8. Conclusions and Future Directions   

Cloud  computing  business  potential  and  contribution  to 
already aggravating carbon emission from ICT, has lead to a 
series of discussion whether Cloud computing is really green. 
It  is  forecasted  that  the  environmental  footprint  from  data 
centers will triple between 2002 and 2020, which is currently 
7.8 billion tons of CO2 per year. There are reports on Green 
IT analysis of Clouds and datacenters that show that Cloud 
computing is “Green”, while others show that it will lead to 
alarming increase in Carbon emission. Thus, in this chapter, 
we first analyzed the benefits offered by Cloud computing by 
studying  its  fundamental  definitions  and  benefits,  the 
services  it  offers  to  end  users,  and  its  deployment  model. 
Then,  we  discussed 
that 
contribute to carbon emission and the features of Clouds that 
make it “Green”. We also discussed several research efforts 
and  technologies  that  increase  the  energy  efficiency  of 
various  aspects  of  Clouds.  For  this  study,  we  identified 
several  unexplored  areas  that  can  help  in  maximizing  the 
energy  efficiency  of  Clouds  from  a  holistic  perspective. 
After  analyzing  the  shortcoming  of  previous  solutions,  we 
proposed  a  Green  Cloud  Framework  and  presented  some 
results  for  its  validation.  Even  though  our  Green  Cloud 
to  make  Cloud 
framework  embeds  various  features 
computing  much  more  Green, 
there  are  still  many 
technological solutions are required to make it a reality: 

the  components  of  Clouds 

levels 

First  efforts  are  required  in  designing  software  at 
various 
(OS,  compiler,  algorithm  and 
application)  that  facilitates  system  wide  energy 
efficiency.  Although  SaaS  providers  may  still  use 
already implemented software, they need to analyze 
the  runtime  behavior  of  applications.  The  gathered 
empirical  data  can  be  used  in  energy  efficient 
scheduling and resource provisioning. The compiler 
and operating systems need to be designed in such a 
way  that  resources  can  be  allocated  to  application 
based on the required level of performance, and thus 
performance versus energy consumption tradeoff can 
be managed.   
To  enable  the  green  Cloud  datacenters,  the  Cloud 
providers need to understand and  measure existing 
datacenter  power  and  cooling  designs,  power 
consumptions  of 
their  cooling 
requirements, and equipment resource utilization to 
achieve maximum efficiency. In addition, modeling 
tools are required to measure the energy usage of all 
the components and services of Cloud, from user PC 
to datacenter where Cloud services are hosted. 
For designing the holistic solutions in the scheduling 
and resource provisioning of applications within the 
datacenter, all the factors such as cooling, network, 
memory,  and  CPU  should  be  considered.  For 
instance,  consolidation  of  VMs  even 
though 
effective technique to minimize overall power usage 
of  datacenter,  also  raises  the  issue  related  to 
necessary  redundancy  and  placement  geo-diversity 

servers  and 

- 

- 

- 

 

- 

required to be maintained to fulfill SLAs with users. 
It is obvious that last thing Cloud provider will want 
is  to  lose  their  reputation  by  their  bad  service  or 
violation of promised service requirements. 
Last but not the least, the responsibility also goes to 
both  providers  and  customers  to  make  sure  that 
emerging  technologies  do  not  bring  irreversible 
changes  which  can  bring  threat  to  the  health  of 
human society. The way end users interact with the 
application also has a very real cost and impact. For 
example,  purging  of  unsolicited  emails  can 
eliminates  energy  wasted  in  storage  and  network. 
Similarly, if Cloud providers want to provide a truly 
green and renewable Cloud, they must deploy their 
datacenters  near  renewable  energy  sources  and 
maximize  the  Green  energy  usage  in  their  already 
established  datacenters.  Before 
adding  new 
technologies  such  as  virtualization,  proper  analysis 
of overhead should be done real benefit in terms of 
energy efficiency.   

In  conclusion,  by  simply  improving  the  efficiency  of 
equipment, Cloud computing cannot be claimed to be Green. 
What is important is to make its usage more carbon efficient 
both from user and provider‟s perspective. Cloud Providers 
need  to  reduce  the  electricity  demand  of  Clouds  and  take 
major  steps  in  using  renewable  energy  sources  rather  than 
just looking for cost minimization. 

 

REFERENCES 
[1]  Gleeson,  E.  2009.  Computing  industry  set  for  a  shocking 
change. 
from 
http://www.moneyweek.com/investment-advice/computing-i
ndustry-set-for-a-shocking-change-43226.aspx   

Retrieved 

January 

2010 

10, 

[2]  Buyya,  R.,  Yeo,  C.S.  and  Venugopal,  S.  2008. 
Market-oriented Cloud computing: Vision, hype, and reality 
for delivering it services as computing utilities. Proceedings 
of 
the  10th  IEEE  International  Conference  on  High 
Performance Computing and Communications, Los Alamitos, 
CA, USA.   

[3]  New Datacenter Locations. 2008. http://royal.pingdom.com/

2008/04/11/map-of-all-google-data-center-locations/   

[4]  Bianchini,  R.,  and  Rajamony,  R.  2004,  Power  and  energy 

management for server systems, Computer, 37 (11) 68-74.   

[5]  Rivoire, S., Shah, M. A., Ranganathan, P., and Kozyrakis, C. 
2007.  Joulesort:  a  balanced  energy-efficiency  benchmark, 
Proceedings  of  the  2007  ACM  SIGMOD  International 
Conference on Management of Data, NY, USA.   

[6]  Greenpeace 

International. 
http://www.greenpeace.org/ 
international/en/publications/reports/make-it-green-Cloudco
mputing/   

2010.  Make 

IT  Green 

[7]  Accenture  Microsoft  Report.  2010.  Cloud  computing  and 
Sustainability: The Environmental Benefits of Moving to the 
Cloud, http://www.wspenvironmental.com/media/docs/news

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

169 

room/Cloud_computing_and_Sustainability_-_Whitepaper_-
_Nov_2010.pdf.   

[24]  Saxe, E. 2008. Power Efficient Software. Communication of 

the ACM. 53(2) 44-48.   

[8]  Mell, P. and Grance, T. 2009. The NIST Definition of Cloud 
computing, National Institute of Standards and Technology.   
[9]  Google App Engine. 2010. http://code.google.com/appengin

e/.   

[10]  Vecchiola,  C.,  Chu,  X.  and  Buyya,  R.  2009.  Aneka:  A 
Software Platform for .NET-based Cloud Computing. In High 
Performance & Large Scale computing, Advances in Parallel 
Computing, ed. W. Gentzsch, L. Grandinetti and G. Joubert, 
IOS Press.   

[11]  Microsoft Azure. 2011. www.microsoft.com/windowsazure/   
[12]  Charrington, S. 2010, Characteristics of Platform as a Service, 
Cloud Pulse blog, http://Cloudpulseblog.com/2010/02/the-es
sential-characteristics-of-paas.   

[13]  Cherkasova,  L.  and  Gardner,  R.  2005,  Measuring  CPU 
overhead  for  I/O  processing  in  the  Xen  virtual  machine 
monitor. Proceeding of  2005  Annual  Technical  Conference 
on USENIX, Anaheim, CA, USA.   

[14]  Sarokin,  D.  2007.  Question:  Energy  use  of  Internet, 

http://uclue.com/?xq=724.   

[15]  Baliga J., Ayre R., Hinton K., and Tucker R. S. 2010. Green 
Cloud  computing:  Balancing  energy  in  processing,  storage 
and transport. Proceedings of the IEEE, 99(1) 149-167.   

[16]  Chabarek, J., Sommers, J., Barford, P., Estan, C., Tsiang, D., 
and Wright, S. 2008. Power Awareness in Network Design 
and Routing. Proceedings of 27th IEEE INFOCOM, Pheonix, 
AZ, USA.   

[17]  Ranganathan  P,  2010,  Recipe  for  efficiency:  principles  of 
ACM, 

Communication. 

computing. 

power-aware 
53(4):60–67.   

[25]  Großschädl,  Avanzi  R.M.,  Savas  E.,  and  Tillich  S.  2005. 
Energy-efficient  software  implementation  of  long  integer 
modular  arithmetic,  Proceedings  of  7th  Workshop  on 
Cryptographic Hardware and Embedded Systems, Edinburg, 
Scotland.   

[26]  Srikantaiah, S., Kansal, A., and Zhao, F. 2008. Energy aware 
consolidation 
for  Cloud  computing.  Proceedings  of 
HotPower  ’08  Workshop  on  Power  Aware  computing  and 
Systems, San Diego, CA, USA.   

[27]  Chase, J.S., Anderson, D.C., Thakar, P.N., Vahdat, A.M., and 
Doyle, R.P. 2001. Managing energy and server resources in 
hosting  centers.  Proceedings  of  18th  ACM  Symposium  on 
Operating Systems Principles (SOSP ’01), Banff, Canada.   

[28]  Nathuji, R. and Schwan, K. 2007. VirtualPower: coordinated 
power  management 
in  virtualized  enterprise  systems. 
Proceedings of 21st ACM SIGOPS Symposium on Operating 
Systems Principles, Stevenson, WA, USA.   

[29]  Kephart, J. O., Chan, H., Das, R., Levine, D. W., Tesauro, G., 
Rawson,  F.,  and  Lefurgy,  C.  2007.  Coordinating  multiple 
autonomic managers to achieve specified power-performance 
tradeoffs.  Proceedings  of  4th  International  Conference  on 
Autonomic Computing, Florida, USA.   

[30]  Song, Y., Sun, Y., Wang, H., and Song, X. 2007. An adaptive 
resource flowing scheme amongst VMs in a VM-based utility 
computing. Proceedings of IEEE International Conference on 
Computer and Information Technology, Fukushima, Japan.   
[31]  Abdelsalam, H., Maly, K., Mukkamala, R., Zubair, M., and 
Kaminsky,  D.  2009.  Towards  energy  efficient  change 
management in a Cloud computing environment, Proceedings 
of 
on  Autonomous 
Infrastructure, Management and Security, The Netherlands.   

International  Conference 

3rd 

[18]  Greenberg, S., Mills, E., Tschudi, B., Rumsey, P., and Myatt, 
B., 2008, Best Practices for Data Centers: Lessons Learned 
from Benchmarking 22 Data Centers. ACEEE Summer Study 
on  Energy  Efficiency  in  Buildings.  Retrieved  September  4, 
2008, fromhttp://eetd.lbl.gov/emills/PUBS/PDF/ACEEE-dat
acenters.pdf   

[19]  Rawson,  A.,  Pfleuger,  J.,  and  Cader,  T.,  2008.  Green  Grid 
Data  Center  Power  Efficiency  Metrics.  Consortium  Green 
Grid.   

[20]  Smith,  J.  and  Nair,  R.  2003.  Virtual  Machines:  Versatile 
Platforms  for  Systems  and  Processes.  Morgan  Kaufmann: 
Los Altos, CA.   

[21]  IBM. 2008. ”Take the tennis to 1.9 billion viewersworldwide? 
Done.,” 04/05/08, 2008; http://www- 07.ibm.com/innovation
/au/ausopen/pdf/CaseStudy 01.pdf   

[32]  Kaushik, R. T., Cherkasova, L., Campbell, R., and Nahrstedt, 
K.,  2010.  Lightning:  self-adaptive,  energy-conserving, 
multi-zoned,  commodity  green  Cloud  storage  system.  In 
Proceedings of  the 19th  ACM  International Symposium  on 
High Performance Distributed computing (HPDC '10). ACM, 
New York, NY, USA.   

[33]  Verma, A., Koller, R., Useche, L., and Rangaswami, R., 2010. 
SRCMap:  energy  proportional  storage  using  dynamic 
consolidation.  2010,  Proceedings  of  the  8th  USENIX 
conference on File and storage technologies (FAST'10), San 
Jose, California   

[34]  Soror,  A.  A.,  Minhas,  U.  F.,  Aboulnaga,  A.,  Salem,  K., 
Kokosielis,  P.,  and  Kamath,  S.  2008.  Automatic  virtual 
machine configuration for database  workloads. Proceedings 
of ACM SIGMOD International Conference on Management 
of data, Vancouver, Canada   

[22]  Freeh, V. W., Pan, F., Kappiah, N., Lowenthal, D. K., and 
Springer,  R.  2005.  Exploring  the  energy-time  trade-off  in 
MPI programs on a power-scalable cluster, Proceedings of the 
19th IEEE International Parallel and Distributed Processing 
Symposium, CA, USA.   

[35]  Moore,  J.  D.,  Chase,  J.  S.,  and  Ranganathan,  P.  2006. 
Weatherman:  Automated,  online  and  predictive  thermal 
mapping and management for datacenters, Proceedings of the 
3rd  International  Conference  on  Autonomic  computing, 
Dublin, Ireland.   

[23]  Mayo, R. N. and Ranganathan P., 2005. Energy consumption 
in  mobile 
need 
requirements-aware  energy  scale-down.  Proceedings  of  3rd 
International Workshop on Power-Aware Computer Systems, 
San Diego, CA, USA.   

devices:  Why 

systems 

future 

[36]  Bash,  C.  and  Forman,  G.  2007.  Cool  job  allocation: 
Measuring 
jobs  at 
cooling-efficient  locations  in  the  datacenter,  Proceeding  of 
2007 Annual Technical Conference on USENIX, Santa Clara, 
CA, USA.   

savings  of  placing 

the  power 

 

Environment and Ecology Research 2(4): 153-170, 2014 
DOI: 10.13189/eer.2014.020401 

http://www.hrpub.org 

A Strategic Model for Adopting Energy Efficient Cloud 
Computing Infrastructure for Sustainable Environment 

Muhammad Adeel Javaid 

Member Vendor Advisory Council, CompTIA 
*Corresponding Author: ajaviad@gmail.com 

Copyright © 2014 Horizon Research Publishing All rights reserved. 

Abstract    In general, cloud computing focus on the data 
computing  efficiency;  green  cloud  computing  is  a  new 
thinking which is based on cloud computing architecture and 
focuses on the energy efficiency of device and computing. 
Although it is widely claimed that cloud computing is “green” 
because  of  its  better  energy  efficiency,  we  are  going  to 
examine this thesis more carefully via an analytic approach 
in this paper. We discuss a hierarchical structure to build the 
virtual network for facilitating management. 
Keywords    Green  IT,  Green  Computing,  Environment 
Protection, Environment Sustainability 

 

1. Introduction 

networks, 

previously 

it  melded 

The emergence of the Internet and the World Wide Web 
were technological triumphs of the late 20th Century. When 
this  common  architecture  for  digital  information  and 
communications  became  wedded  to  broadband  fixed  and 
mobile 
distinct 
communications  markets  for  data,  voice  and  broadcast 
content.  This  marriage  also  allows  society  to  take  full 
advantage  of  a  new  generation  of  computer  architectures 
enabled by the very large arrays of cheap data storage and 
processors that are popularly described as the “Cloud.” As 
the Cloud becomes fundamental to the world of information 
and communications technology (ICT), it will deliver major 
benefits for both low and high income countries. This report 
examines  these  benefits  and  the  public  policies  needed  to 
achieve them. 

Cloud  architectures  permit  users  to  decouple  the  main 
computing  power  and  storage  for  applications  from  the 
capabilities  of  particular  end  users  or  even  end  user 
organizations.  This  both  lowers  the  cost  of  information 
applications and allows them to operate ubiquitously, largely 
unconstrained  by  geography  wherever  broadband  network 
capacity is available.   

The Cloud’s advantages for bringing ICT to low income 
countries  are  easy  to  grasp.  There  are  both  short  and 
medium-term efficiencies with very large payoffs, as well as 
 

the possibility of medium and long-term expansion of local 
innovation capacity. Previously, for example, the purchase 
price of software was only a small component of the overall 
cost  of  ownership;  the  costs  of  hardware,  upgrades,  and 
supporting  personnel  often  dwarfed  the  purchase  price. 
Cloud  computing  shifts  these  costs  to  remote  data  centers 
which benefit from significant economies of scale and scope. 
It also allows significant flexibility in the choice of terminal 
device  linking  the  user  to  information  applications.  You 
don’t  need a PC to have data intensive applications in the 
middle of a farm field. This is why applications ranging from 
email to mobile enabled health care in developing nations are 
shifting  to  Cloud-based  delivery.  Doing  so  creates  cost 
savings,  improves  speed  of  service,  expands  operational 
flexibility  for  users  and  reduces  risks  in  information 
technology (IT) deployment.   

information  between 

These  Cloud  benefits  require  the  effective  and  efficient 
movement  of  Internet-based 
the 
customer and the Cloud service provider. This cannot occur 
without  three  key  technological  capabilities.  First,  while 
some  Cloud  supported  applications  can  be  delivered  on 
narrow  band  networks  (such  as  simple,  mobile  enabled 
health applications), the biggest payoffs from the Cloud arise 
when  high  speed  communications  service  (often  called 
“Broadband”) 
is  available.  Second,  Cloud  computing 
requires  the  unrestricted  flow  of  information  between 
customer and service provider. Third, Cloud data centers can 
only be fully effective if they achieve significant economies 
of  scale  and  scope,  and  can  respond  dynamically  to  their 
customers’ needs wherever they arise and with whatever data 
they need. This implies freedom to locate and operate data 
centers on the basis of efficiency considerations, and to scale 
data centers by handling cross- border data needs. And, as a 
surprising  corollary,  the  deployment  of  an  effective  Cloud 
infrastructure  improves  the  economic  case  for  creating 
broadband networks in low-or middle- income countries by 
enabling  the  national  broadband  connection  to  provide 
global services almost the instant it is connected. 

The  US  National  Institute  of  Science  and  Technology, 
NIST, defines Cloud computing as “…a model for enabling 
ubiquitous,  convenient,  on-demand  network  access  to  a 
shared  pool  of  configurable  computing  resources  (e.g., 

154 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

networks,  servers,  storage,  applications,  and  services)  that 
can  be  rapidly  provisioned  and  released  with  minimal 
management effort or service provider interaction.” Simply 
stated, the Cloud allows users to access computing resources 
on-demand and pay for only what they use.   

The  key  to  the  Cloud’s  architecture  is  the  separation  of 
suppliers  and  users  and  the  dynamic  allocation  of  ICT 
resources  along  with  some  form  of  metering  for  reporting 
and  billing  (NIST  2011).  Given  this  architecture,  the 
economics of the Cloud depend on the way it is deployed and 
the delivery model for its capabilities. 

Clouds  are  essentially  virtualized  datacenters  and 
applications offered as services on a subscription basis. They 
require  high  energy  usage  for  its  operation  [4].  Today,  a 
typical  datacenter  with  1000  racks  need  10  Megawatt  of 
power to operate [5], which results in higher operational cost. 
Thus,  for  a  datacenter,  the  energy  cost  is  a  significant 
component of its operating and up-front costs. In addition, in 
April  2007,  Gartner  estimated  that  the  Information  and 
Communication  Technologies  (ICT)  industry  generates 
about 2% of the total global CO2 emissions, which is equal to 
the aviation industry [5]. According to a report published by 
the  European  Union,  a  decrease  in  emission  volume  of 
15%–30% is required before year 2020 to keep the global 
temperature increase below 2 0C. Thus, energy consumption 
and carbon emission by Cloud infrastructures has become a 
key environmental concern. 

The Cloud can be deployed in one of three configurations. 
It can be the private capability of a single organization, as in 
some global banks. It can be a shared private resource of a 
consortium of users, such as is found in parts of the utility 
industry. Or, it can be a public commercial resource that is 
owned and managed by a private entity and is available to 
any user on commercial terms. (Obviously, hybrid  models 
are  also  possible)  (NIST  2011).  In  theory,  the  largest 
economic  savings  derive  from  provision  by  a  public 
commercial resource, which is not always feasible, thereby 
making  hybrid  strategies  attractive  (Centre  for  Economics 
and Business Research, 2010). 

The other critical dimension of Cloud capabilities is the 
service model. Software as a Service (SaaS), exemplified by 
Google  Applications  or  Microsoft  360  email,  is  the  most 
common  service  model  used  by  end  users.  The  user  or 
user-organization does not manage or control the underlying 
infrastructure and does not create the basic application. The 
applications  are  accessible  from  various  client  devices 
through either a thin client interface, such as a web browser 
(e.g.,  web-based  email),  or  a  dedicated  program  interface 
(e.g.  Outlook).  In  contrast,  with  the  Platform  as  a  Service 
(PaaS)  model,  the  end  application  is  created  by  the  user, 
leveraging  the  Cloud  provider’s  offer,  which  includes 
software  tools  to  help  the  user  access  the  underlying 
hardware. Examples of software tools include programming 
languages, program libraries, services, and development and 
collaboration tools. In India, for instance, Naadhi’s realized 
that 
project 
monitoring-and-reporting application to the Cloud to enable 
 

to  move 

needed 

their 

they 

prospective  customers  to  try  it  before  they  made  a  full 
commitment to the service. Finally, with Infrastructure as a 
Service  (IaaS)  the  user  can  access  machine  and  network 
resources dynamically and remotely and use them as needed. 
This is the lowest level of Cloud services. The user does not 
control  the  underlying  infrastructure  but  controls  what  is 
loaded onto the infrastructure, such as operating systems and 
deployed applications. 

The advantages of green cloud computing are many: lower 
costs, faster updates and simpler maintenance. And there’s 
also a nod to the socially conscious because it’s less taxing 
on  the  environment  due  to  lower  carbon  emissions.  IT’s 
carbon  footprint  has  been  expanding.  The  table  1  given 
below provides a comparison of significant cloud datacenters 
with  an  estimated  power  usage  and  carbon  and  other 
emissions. 

Table 1.    Comparison of Significant Cloud Datacenters [6] 

Cloud 

datacenters  Location 

Estimated power 

usage 

Effectiveness 

Google 

Lenoir 

1.21 

Apple, 
NC 

Apple 
Microsoft  Chicago, 
La Vista, 

IL 

Yahoo 

NE 

 

1.22 

1.16 

% of Dirty 

Energy 

Generation 
50.5% Coal, 
38.7% Nuclear 
50.5% Coal, 
38.7% Nuclear 
72.8% Coal, 
22.3% Nuclear 
73.1% Coal, 
14.6% Nuclear 

% of 

Renewable 
Electricity 

3.8% 

3.8% 

1.1% 

7% 

In  summary,  Cloud  computing,  being  an  emerging 
technology  also  raises  significant  questions  about  its 
environmental  sustainability.  While  financial  benefits  of 
Cloud computing have been analyzed widely in the literature, 
the energy efficiency of Cloud computing as a whole has not 
been analyzed. Through the use of large shared virtualized 
datacenters Cloud computing can offer large energy savings. 
However,  Cloud  services  can  also  further  increase  the 
internet traffic and its growing information database which 
could  decrease  such  energy  savings.  Thus,  this  paper 
explores 
sustainability  of  Cloud 
computing  by  analyzing  various 
technologies  and 
mechanism that support this goal. Our analysis is important 
for  users  and  organization  that  are  looking  at  Cloud 
computing  as  a 
their  administrative, 
infrastructural and management problems. Finally, we also 
propose  and  recommend  a  Green  Cloud  framework  for 
reducing its carbon footprint in wholesome manner without 
sacrificing 
(performance, 
responsiveness  and  availability)  offered  by  the  multiple 
Cloud providers. 

the  environmental 

solution 

service 

quality 

the 

for 

of 

2. What is Cloud Computing? 

Cloud  computing  is  an  evolving  paradigm  which  is 
enabling  outsourcing  of  all  IT  needs  such  as  storage, 
computation and software such as office and ERP, through 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

155 

large  Internet.  The  shift  toward  such  service-oriented 
computing is driven primarily by ease of management and 
administration process involving software upgrades and bug 
fixes. It also allows fast application development and testing 
for small IT companies that cannot afford large investments 
on  infrastructure.  Most  important  advantage  offered  by 
Clouds  is  in  terms  of  economics  of  scale;  that  is,  when 
thousands of users share same facility, cost per user and the 
server utilization. To enable such facilities, Cloud computing 
encompasses  many  technologies  and  concepts  such  as 
virtualization,  utility computing, pay as  you  go, no capital 
investment, elasticity, scalability, provisioning on demand, 
and IT outsourcing. 

Due to such varying properties of Cloud computing, there 
are many informal definitions, none of which fully describes 
it.  The  literary  meaning  of  “Cloud  computing”  can  be 
“computing  achieved  using  collection  of  networked 
resources,  which  are  offered  on  subscription”.  In  terms  of 
qualities of real  “Clouds,”  which do not  have any definite 
shape or position, Cloud computing is also called “Cloud” 
since a Cloud server can have any configuration and can be 
located  anywhere  in  the  world.  Internet  is  a  fundamental 
medium  through  which  these  Cloud  services  are  made 
accessible and delivered to end user. 

The  growing  popularity  of  Cloud  computing  has  led  to 
several  proposal  defining  its  characteristics.  Some  of  the 
definitions  given  by  many  well  known  scientists  and 
organizations include: 
A.  Buyya et al.[2] define the Cloud computing in terms of 
its utility to end user: “A Cloud is a market-oriented 
distributed  computing  system  consisting  of  a 
collection of interconnected and virtualized computers 
that are dynamically provisioned and presented as one 
or  more  unified  computing  resource(s)  based  on 
service-level 
through 
negotiation  between 
the  service  provider  and 
consumers.”   

agreements 

established 

B.  National Institute of Standards and Technology (NIST) 
[8]  defines  Cloud  computing  as  follows:“Cloud 
computing  is  a  model  for  enabling  convenient, 
on-demand  network  access  to  a  shared  pool  of 
configurable  computing  resources  (e.g.,  networks, 
servers, storage, applications, and services) that can be 
rapidly  provisioned  and  released  with  minimal 
management  effort  or  service  provider  interaction. 
This  Cloud  model  promotes  availability  and  is 
composed  of  five  essential  characteristics,  three 
service models, and four deployment models.” 

The  characteristics  of  Clouds 

include  on-demand 
self-service, broad network access, resource pooling, rapid 
elasticity,  and  measured  service.  The  available  service 
models are classified as SaaS (Software-as-a-Service), PaaS 
(Platform-as-a-Service), 
IaaS 
(Infrastructure-as-a-Service).  The  deployment  models  is 
categorised  into  public,  private,  community,  and  hybrid 
Clouds. 

and 

 

2.1. Cloud Computing Characteristics 

The key characteristics exhibited by Clouds are shown in 

Figure 1 and they are discussed below. 

Figure 1.    Characteristics of Cloud computing 

 

- 

is 

-  Virtualized:  Resources  (i.e.  compute,  storage,  and 
network capacity) in Clouds are virtualized and it is 
achieved  at  various  levels  including  VM  (Virtual 
Machine) and Platform levels. The most basic one is 
at  Virtual  Machine  (VM)  level  where  different 
applications can be executed within their containers 
or operating systems running on the same physical 
machine.  Platform  level  enables  seamless  mapping 
of applications to one or more resources offered by 
different Cloud infrastructure providers.   
Service-Oriented:  Cloud 
implemented  using 
Service-Oriented  Architecture  model  where  all  the 
capabilities/components  are  available  over 
the 
network  as  a  service.  Whether  it  is  software, 
platform or infrastructure everything is offered as a 
service.   

-  Elastic:  Resources  (i.e.  compute,  storage,  and 
network  capacity)  required  for  Cloud  applications 
can  be  dynamically  provisioned  and  varied  i.e., 
increase  or  decrease  at  runtime  depending  on  user 
QoS  requirements.  Major  Cloud  providers  such  as 
Amazon  even  provide  services  for  automatic 
scale-out  and  scale-in  based  on  hosted  application 
requirements.   

-  Dynamic  and  Distributed:  Although  Cloud 
resources are virtualised, they are often distributed to 
enable  the  delivery  of  high-performance  and/or 
reliable Cloud services.   

These resources are flexible and can be adapted according 
to  customer ‟ s  requirements  such  as  software,  network 
configuration, etc.   

- 

Shared  (Economy  of  Scale):  Clouds  are  shared 
resources  serve  multiple 
infrastructure  where 
customers with dynamic allocation according to their 

156 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

infrastructure  in  the  form  of  customized  virtual  machines. 
Depending  on 
the  virtualized 
infrastructure 
and 
programming environment,  what saves time  for users  who 
do not need to build their system from scratch. 

the  end  user  needs, 
is  pre-configured  with 

storage 

Even though IaaS gives access to physical resources with 
some software configuration, for designing new applications 
user requires advanced tools such as Map Reduce etc. These 
services constitute another layer called Platform as a Service 
(PaaS),  offering  Cloud  users  a  development  platform  to 
build their applications. Google AppEngine [9], Aneka [10], 
and Microsoft Azure [11] are some of the most prominent 
example of PaaS Clouds. In general, PaaS includes the lower 
layer (IaaS) as well that is bundled with the offered service. 
In general, pure PaaS offers only the user level middleware, 
which allows development and deployment of applications 
on any Cloud infrastructure. As noted by Appistry.com [12], 
the 
a 
Platform-as-a-Service solution include: 

characteristics 

essential 

identify 

that 

• 

• 

• 

end-user 

executes 

framework 

Runtime  framework:  It  represents  the  “software 
stack”  of  the  PaaS  model  and  the  most  intuitive 
aspect  that  comes  to  the  mind  of  people  when 
referring  to  Platform-as-a-  Service  solutions.  The 
runtime 
code 
according to the service level policies set by the user 
and the provider.   
Abstraction: PaaS solutions are distinguished by the 
higher  level  abstraction  that  they  provide.  Unlike 
IaaS  solutions  the  focus  is  on  delivering  “raw” 
access  to  virtual  or  physical  infrastructure.  In  the 
case  of  PaaS  the  focus  is  on  the  applications  the 
Cloud must support. This means that PaaS solutions 
offer a way to deploy and manage applications on the 
Cloud rather than a bunch of virtual machines on top 
of which the IT infrastructure is built and configured.   
Cloud  services:  PaaS  offerings  provide  developers 
and architects with services and APIs helping them 
to  simplify  delivering  of  elastically  scalable  and 
highly available Cloud applications. These services 
are  the  key  differentiators  among  competing  PaaS 
solutions and generally include specific component 
for  developing  applications,  advanced  services  for 
application monitoring, management, and reporting. 

application‟s  demand.  This  sharing  model  is  also 
termed  as  “multi-tenant”  model.  In  general,  the 
customers  neither  have  any  direct  control  over 
physical resources nor they are aware of the resource 
location and with whom they are being shared.   

-  Market-Oriented  (Pay  as  you  go):  In  Cloud 
computing,  customers  pay  for  services  on  a 
pay-per-use  (or  pay-as-you-go)  basis.  The  pricing 
model can vary depending on the QoS expectation of 
application.  Cloud  IaaS  providers  such  as  Amazon 
price  resources  using  market  models  such  as 
commodity  or  on-spot  pricing  models.  A  pricing 
model proposed by Allenofor & Thulasiram [49] for 
grid  resources  could  be  used  as  a  base  for  cloud 
resources.  This  characteristic  addresses  the  utility 
dimension of cloud computing. That means, Cloud 
services  are  offered  as  “metered”  services  where 
providers have an accounting model for  measuring 
the use of the services, which helps in development 
of  different  pricing  plans  and  models.  The 
accounting  model  helps 
in 
the  control  and 
optimization of resource usage. 

-  Autonomic:  To  provide  highly  reliable  services, 
Clouds  exhibit  autonomic  behaviour  by  managing 
themselves  in  case  of  failures  or  the  performance 
degradation.   

2.2. Components of Cloud Computing   

Cloud  computing  is  mainly  composed  of  three  layers 
which  cover  all  the  computing  stack  of  a  system.  Each  of 
these layers offers different set of services to end users as 
described in Figure 3. At the lowest layer, Cloud offerings 
are  named  as  Infrastructure-as-a-Service  (IaaS)  which 
consists of virtual machines or physical machines, storage, 
and clusters. Cloud infrastructures can also be heterogeneous, 
integrating  clusters,  PCs  and  workstations.  Moreover,  the 
system infrastructure can also include database management 
systems  and  other  storage  services.  The  infrastructure  in 
general  is  managed  by  an  upper  management  layer  that 
guarantees runtime environment customization, application 
isolation,  accounting  and  quality  of 
service.  The 
virtualization tools, such as hypervisors, also sit in this layer 
to  manage  the  resource  pool  and  to  partition  physical 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

157 

Figure 2.    Cloud computing Architecture 

 

The  major  advantage  of  PaaS  is  the  cost  saving  in 
development,  deployment,  and  management  cycle  of  new 
applications.  The  PaaS  providers  reduces  risk  in  terms  of 
upgrade cost of underlying platforms and allow Cloud users 
to concentrate on the application development. 

On  topmost  layer  of  Cloud  computing  Architecture,  the 
Cloud  services  (Figure  2)  are  referred  as  Software  as  a 
Service (SaaS) which is a software delivery model providing 
on-demand  access  to  applications.  The  most  common 
examples of such service are CRM and ERPF applications 
that  are  commonly  used  in  almost  all  the  enterprises  from 
small,  to  large  business.  In  general,  SaaS  providers  also 
constitute  other  layers  of  Cloud  computing  and  thus, 
maintain  the  customer  data  and  configure  the  applications 
according  to  customer  need.  This  scenario  results  in 
considerable  reduction  in  upfront  cost  of  purchasing  new 
software  and  infrastructure.  The  customers  do  not  have  to 
maintain  any  infrastructure  or  install  anything  within  their 
premises. They just require high speed network to get instant 
access to their applications. 

the  effort  of  managing 

Multi-tenancy is another core feature of SaaS compared to 
to 
traditional  packaged  software,  allowing  providers 
outsource 
large  hardware 
infrastructure, maintaining and upgrading applications, and 
optimizing resources by sharing the costs among the large 
user base. Therefore, SaaS  model is particularly appealing 
for  companies  who  get  access  to  softwares  configured 
according  to  their  specific  needs  and  shared  between 
multiple  users.  On  the  customer  side,  only  costs  that  will 

incur are the monthly software usage fee. 

2.3. Cloud Computing Deployment Models 

From above discussions, we can say that Cloud computing 
is a paradigm of offering on-demand services to end users. 
Clouds are deployed on physical infrastructure where Cloud 
middleware  is  implemented  for  delivering  service  to 
customers. Such an infrastructure and middleware differ in 
their  services,  administrative  domain  and  access  to  users. 
Therefore, the Cloud deployments are classified mainly into 
three types: Public Cloud, Private Cloud and Hybrid Cloud 
(Figure 3). 

2.3.1. Public Clouds 

Public  Cloud  is  the  most  common  deployment  model 
where  services  are  available  to  anyone  on  Internet.  To 
support thousand of public domain  users, datacenters built 
by  public  Cloud  providers  are  quite  large  comprising  of 
thousands of servers with high speed network. Some of the 
famous  public  Clouds  are  Amazon  Web  Services  (AWS), 
Google  AppEngine,  and  Microsoft  Azure. 
this 
deployment, Cloud services are made available to the public 
in a pay-as-you-go-manner. A public Cloud can offer any of 
the  three  kinds  of  services:  IaaS,  PaaS,  and  SaaS.  For 
instance,  Amazon  EC2  is  a  public  Cloud  providing 
infrastructure  as  a  service,  Google  AppEngine  is  a  public 
Cloud providing an application development platform as  a 
service,  and  Salesforce.com  is  public  Cloud  providing 

In 

 

158 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

software  as  a  service.  Public  Cloud  offers  very  good 
solutions  to  the  customers  having  small  enterprise  or  with 
infrequent infrastructure usage, since these Clouds provide a 
very  good  option  to  handle  peak  loads  on  the  local 
infrastructure  and  for  an  effective  capacity  planning.  The 
fundamental  characteristic  of  public  Clouds 
its 
multi-tenancy,  which 
is  essentially  achieved  using 
sophisticated virtualization at various level of the software 
stack. Being public Clouds, Quality of Service and security 
are  the  main  issues  that  need  to  be  ensured  in  their 
management.  Thus,  a  significant  portion  of  the  software 
infrastructure is devoted to monitor Cloud resources, to bill 
them according to the contract  made  with the  user, and to 
keep  a  complete  history  of  the  Cloud  usage  for  each 
customer. 

is 

2.3.2. Private Clouds 

While  public  Clouds  are  quite  appealing  and  provide  a 
viable  solution  for  cutting  IT  costs  such  as  administration 
and  infrastructure,  there  are  still  many  scenarios  where 
organization  may  want  to  maintain  their  own  specialized 
Clouds  catering  to  their  particular  needs.  For  instance,  the 
health  care  industry  maintains  many  confidential  medical 
data which cannot be stored in public infrastructure. Thus, 
private  Clouds  are  deployed  within  the  premise  of  an 
organization to provide IT services to its internal users. The 

private  Cloud  services  offer  greater  control  over  the 
infrastructure,  improving  security  and  service  resilience 
because its access is restricted to one or few organizations. 
Such private deployment poses an inherent limitation to end 
user applications i.e. inability to scale elastically on demand 
as can be done using pubic Cloud services. An organization 
can buy more machines according to expanding needs of its 
users, but this cannot be done as fast and seamlessly as with 
public  Clouds.  This  resulted  in  the  emergence  of  hybrid 
deployments  for  Clouds  where  the  advantages  of  both 
private  and  public  Clouds  are  made  available  to  the 
organization. 

2.3.3. Hybrid Clouds 

Hybrid Clouds is the deployment which emerged due to 
diffusion of both public and private Clouds‟  advantages. In 
this model, organizations outsource non-critical information 
and  processing  to the public  Cloud,  while  keeping critical 
services and data in their control. Therefore, organizations 
can  utilize  their  existing  IT  infrastructure  for  maintaining 
sensitive  information  within  the  premises,  and  whenever 
require  auto-scaling  their  resources  using  public  Clouds. 
These resources or services are temporarily leased in peak 
load times and then released. The hybrid Cloud, in general, 
applies  to  services  related  to  IT  infrastructure  rather  than 
software services See Figure 3. 

Figure 3.    Deployment Models for Clouds 

 

 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

159 

Figure 4.    Cloud Usage Model. 

 

3. Cloud Computing and Energy Usage 

Model: A Typical Example 
In this section, through a typical Cloud usage scenario we 
will  analyze  various  elements  of  Clouds  and  their  energy 
efficiency.  Figure  4  shows  an  end  user  accessing  Cloud 
services such as SaaS, PaaS, or IaaS over Internet. User data 
pass  from  his  own  device  through  an  Internet  service 
provider ‟s  router,  which  in  turn  connects  to  a  Gateway 
router  within  a  Cloud  datacenter.  Within  datacenters,  data 
goes  through  a  local  area  network  and  are  processed  on 
virtual machines, hosting Cloud services, which may access 
storage  servers.  Each  of  these  computing  and  network 
devices  that  are  directly  accessed  to  serve  Cloud  users 
contribute  to  energy  consumption.  In  addition,  within  a 
Cloud  datacenter,  there  are  many  other  devices,  such  as 
cooling and electrical devicies, that consume power. These 
devices even though do not directly help in providing Cloud 
service, are the major contributors to the power consumption 
of a Cloud datacenter. In the following section, we discuss in 
detail  the  energy  consumption  of  these  devices  and 
applications. 

3.1. User/Cloud Software Applications 

The first factor that contributes to energy consumption is 
the way software applications are designed and implemented. 
The Cloud computing can be used for running applications 
owned by individual user or offered by the Cloud provider 
using SaaS. In both cases, the energy consumption depends 
on the application itself. If application is long running with 
high CPU and memory requirements then its execution will 
result 
in  high  energy  consumption.  Thus,  energy 
consumption will be directly proportional to the application‟
s profile. The allocation of resources based on the maximum 
level of CPU and memory usage will result in much higher 
energy  consumption  than  actually  required.  The  energy 
inefficiency  in  execution  of  an  application  emanates  from 
 

inaccurate  design  and  implementation.  The  application 
inefficiencies, such as suboptimal algorithms and inefficient 
usage of shared resources causing contention lead to higher 
CPU  usage  and,  therefore,  higher  energy  consumption. 
However,  factors  such  as  energy  efficiency  are  not 
considered during the design of an application in most of the 
application  domains  other  than  for  example  embedded 
devices such as mobile phone. 

3.2. Cloud Software Stack for SaaS, PaaS, IaaS Level 

The  Cloud  software  stack  leads  to  an  extra  overhead  in 
execution  of  end  user  applications.  For  instance,  it  is  well 
known  that  a  physical  server  has  higher  performance 
efficiency  than  a  virtual  machine  and  IaaS  providers  offer 
generally access to a virtual machine to its end users [13]. In 
addition, the management process in the form of accounting 
and  monitoring  requires  some  CPU  power.  Being  profit 
oriented,  service  providers  regularly  have  to  adhere  to 
Service  Level  Agreements  (SLA)  with  their  clients.  These 
SLAs may take the form of time commitment for a task to be 
completed. Thus, Cloud provider for meeting certain level of 
service  quality  and  availability,  provision  extra  resources 
than  generally required. For instance, to avoid failure, fast 
recovery and reduction in response time, providers have to 
maintain  several  storage  replicas  across  many  datacenters. 
Since workflow in Web applications require several sites to 
give  better  response  time  to  its  end  user,  their  data  is 
replicated on many servers across the world. Therefore, it is 
important 
the  relationships  among  Cloud 
components  and  the  tradeoffs  between  QoS  and  energy 
consumption. 

to  explore 

3.3. Network Devices 

The  network  system  is  another  area  of  concern  which 
consumes  a  non-negligible  fraction  of  the  total  power 
consumption.  The  ICT  energy  consumption  estimates  [14] 

160 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

just for Vodafone Group radio access network was nearly 3 
TWh  in  2006.  In  Cloud  computing,  since  resources  are 
accessed  through  Internet,  both  applications  and  data  are 
needed to be transferred to the compute node. Therefore, it 
requires much more data communication bandwidth between 
user‟s PC to the Cloud resources than require the application 
execution requirements. In some cases, if data is really large, 
then it may turn out to be cheaper and more carbon emission 
efficient  to  send  the  data  by  mail  than  to  transfer  through 
Internet. 

In Cloud computing, the user data travels through many 
devices before it reaches a datacenter. In  general, the  user 
computer  is  connected  to  Ethernet  switch  of  his/her  ISP 
where traffic is aggregated. The BNG (Broadband Network 
Gateway)  network  performs 
traffic  management  and 
authentication functions on the packets received by Ethernet 
switches.  These  BNG  routers  connect  to  other  Internet 
routers through provider's edge routers. The core network is 
further  comprised  of  many  large  routers.  Each  of  these 
devices  consumes  power  according  to  the  traffic  volume. 
According  to  the  study  conducted  by  Tucker  [15],  public 
Cloud is estimated to consume about 2.7 J/b in transmission 
and switching in comparison to 0.46J/b for a private Cloud. 
They  found  out  that  power  consumption  in  transport 
represents  a  significant  proportion  of  the  total  power 
consumption for Cloud storage services at medium and high 
usage rates. Even typical network usage can result in three to 
four times more energy consumption in public Cloud storage 
than  one's  own  storage  infrastructure.  Therefore,  with  the 
growth of Cloud computing usage, it is expected that energy 
efficiency of switches and routers will play a very significant 
role in what since they need to provide capacity of hundreds 
of terabits of bandwidth. 

In the network infrastructure, the energy consumption [16] 
depends especially on the power efficiency and awareness of 
wired  network,  namely  the  network  equipments  or  system 
design, topology design, and network protocol design. Most 
of the energy in network devices is wasted because they are 
designed  to  handle  worst  case  scenario.  Therefore,  the 
energy  consumption  of  these  devices  remains  almost  the 
same  during  both  peak 
idle  state.  Many 
improvements are required to get high energy efficiency in 
these  devices.  For  example  during  low  utilization  periods, 
Ethernet links can be turned off and packets can be routed 
around  them.  Further  energy  savings  are  possible  at  the 
hardware level of the routers through appropriate selection 
and  optimization  of  the  layout  of  various  internal  router 
components (i.e. buffers, links, etc.). 

time  and 

3.4. Datacenter 

The Cloud datacenters are quite different from traditional 
hosting  facilities.  A  cloud  datacenter  could  comprise  of 
many hundreds or thousands of networked computers with 
their  corresponding  storage  and  networking  subsystems, 
power distribution and conditioning equipment, and cooling 
infrastructures.  Due 
large  number  of  equipments, 
 

to 

datacenters can consume massive energy consumption and 
emit large amount of carbon. According to 2007 report on 
computing  datacenters  by  US  Environmental  Protection 
Agency (EPA), the datacenters in US consumed about 1.5% 
of  total  energy,  which  costs  about  $4.5  billon.  This  high 
usage  also  translates  to  very  high  carbon  emissions  which 
was estimated to be about 80-116 Metric Megatons each year. 
Table 2 lists equipments typically used in datacenters with 
their contribution to energy consumption. It can be clearly 
observed that servers and storage systems are not the only 
infrastructure  that  consumes  energy  in  the  datacenter.  In 
reality, the cooling equipments consume equivalent amount 
of energy as the IT systems themselves. Ranganathan [17] 
suggests  that  for  every  dollar  spent  on  electricity  costs  in 
large-scale datacenters another dollar is spent on cooling. 

Table 2.    Percent of Power Consumption by Each Datacenter Device 

Cooling device (Chiller, Computer Room Air 

33%+9% 

Conditioning (CRAC)) 

IT Equipment 

Electrical Equipments(UPS, Power 
Distribution Units (PDUs), lighting) 

 

 

30% 
28% 

Further energy consumption occurs due to lighting, loss in 
the power distribution, and other electrical equipment such 
as UPS. In other words, the majority of power usage within a 
datacenter is used for other purposes than actual IT services. 
Thus,  to  achieve  the  maximum  efficiency  in  power 
consumption and CO2 emissions, each of these devices need 
to be designed and used efficiently while ensuring that their 
carbon footprint is reduced. 

A  key  factor  in  achieving  the  reduction  in  power 
consumption of a datacenter is to calculate how much energy 
is  consumed  in  cooling  and  other  overheads.  Standard 
metrics  are  emerging  such  as  Power  Usage  Effectiveness 
(PUE)  [19]  which  can  be  used  to  benchmark  how  much 
energy is being usefully deployed versus how much is spent 
on overhead. The PUE of a datacenter is defined as the ratio 
of  the  total  power  consumption  of  a  facility  (data  or 
switching  center)  to  the  total  power  consumption  of  IT 
equipment (servers, storage, routers, etc.). PUE varies from 
datacenters  depending  on  the  place  where  datacenter  is 
located and devices used in its construction. Research from 
the  Lawrence  Berkley  National  Labs  [18]  shows  that  22 
datacenters measured in 2008 have PUE Values in the range 
1.3  to  3.0.  PUE  of  datacenter  can  be  useful  in  measuring 
power  efficiency  of  datacenters  and 
thus  provide  a 
motivation to improve its efficiency. 

4. Features of Clouds Enabling Green 

Computing 
Even though there is a great concern in the community that 
Cloud computing can result in higher energy usage by the 
datacenters, the Cloud computing has a green lining. There 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

161 

are  several  technologies  and  concepts  employed  by  Cloud 
providers  to  achieve  better  utilization  and  efficiency  than 
traditional  computing.  Therefore,  comparatively 
lower 
carbon  emission  is  expected  in  Cloud  computing  due  to 
highly energy efficient infrastructure and reduction in the IT 
infrastructure  itself  by  multi-tenancy.  The  key  driver 
technology  for  energy  efficient  Clouds  is  “Virtualization,” 
which allows significant improvement in energy efficiency 
of  Cloud  providers  by  leveraging  the  economies  of  scale 
associated  with  large  number  of  organizations  sharing  the 
same 
the  process  of 
presenting  a  logical  grouping  or  subset  of  computing 
resources  so  that  they  can  be  accessed  in  ways  that  give 
benefits  over 
[20].  By 
consolidation of underutilized servers in the form of multiple 
virtual  machines  sharing  same  physical  server  at  higher 
utilization, companies can gain high savings in the form of 
space, management, and energy. 

infrastructure.  Virtualization 

the  original  configuration 

According  to  Accenture  Report  [7],  there  are  following 
four key factors that have enabled the Cloud computing to 
lower energy usage and carbon emissions from ICT. Due to 
these  Cloud  features,  organizations  can  reduce  carbon 
emissions  by  atleast  30%  per  user  by  moving  their 
applications to the Cloud. These savings are driven by the 
high efficiency of large scale Cloud data centers. 

is 

1.  Dynamic  Provisioning: 

In 

traditional 

setting, 
datacenters  and  private  infrastructure  used  to  be 
maintained  to  fulfill  worst  case  demand.  Thus,  IT 
companies end up deploying far more infrastructure 
than  needed.  There  are  various  reasons  for  such 
over-provisioning: a) it is very difficult to predict the 
demand  at  a  time;  this  is  particularly  true  for  Web 
applications  and  b)  to  guarantee  availability  of 
services  and  to  maintain  certain  level  of  service 
quality to end users. One example of a Web service 
facing these problems is a Website for the Australian 
Open  Tennis  Championship  [21].  The  Australian 
Open Website each year receives a significant spike 
in traffic during the tournament period. The increase 
in  traffic  can  amount  to  over  100  times  its  typical 
volume (22 million visits in a couple of weeks) [21]. 
To  handle  such  peak  load  during  short  period  in  a 
year, running hundreds of server throughout the year 
is not really energy efficient. Thus, the infrastructure 
provisioned with a conservative approach results in 
unutilized resources. Such scenarios can be readily 
managed  by  Cloud 
infrastructure.  The  virtual 
machines  in  a  Cloud  infrastructure  can  be  live 
migrated  to  another  host  in  case  user  application 
requires  more  resources.  Cloud  providers  monitor 
and predict the demand and thus allocate resources 
according to demand. Those applications that require 
less number of resources can be consolidated on the 
same server. Thus, datacenters always maintain the 
active  servers  according  to  current  demand,  which 
results 
the 
conservative approach of over-provisioning.   

low  energy  consumption 

than 

in 

 

2.  Multi-tenancy:  Using  multi-tenancy  approach, 
Cloud  computing  infrastructure  reduces  overall 
energy usage and associated carbon emissions. The 
SaaS  providers  serve  multiple  companies  on  same 
infrastructure  and  software.  This  approach 
is 
obviously more energy efficient than multiple copies 
of  software  installed  on  different  infrastructure. 
Furthermore,  businesses  have  highly  variable 
demand patterns in general, and hence multi-tenancy 
on the same server allows the flattening of the overall 
peak demand which can minimize the need for extra 
infrastructure.  The  smaller  fluctuation  in  demand 
results  in  better  prediction  and  results  in  greater 
energy savings.   

3.  Server  Utilization: 

In 

general, 

run  with  very 

on-premise 
infrastructure 
low  utilization, 
sometimes  it  goes  down  up  to  5  to  10  percent  of 
average utilization. Using virtualization technologies, 
multiple applications can be hosted and executed on 
the same server in isolation, thus lead to utilization 
levels up to 70%. Thus, it dramatically reduces the 
number  of  active  servers.  Even 
though  high 
utilization  of  servers  results 
in  more  power 
consumption, server running at higher utilization can 
process more workload with similar power usage. 

4.  Datacenter  Efficiency:  As  already  discussed,  the 
power efficiency of datacenters has major impact on 
the total energy usage of Cloud computing. By using 
the  most  energy  efficient 
technologies,  Cloud 
providers can significantly improve the PUE of their 
datacenters.  Today ‟ s  state-of-the-art  datacenter 
designs  for  large  Cloud  service  providers  can 
achieve  PUE  levels  as  low  as  1.1  to  1.2,  which  is 
about  40%  more  power  efficiency 
the 
traditional datacenters. The server design in the form 
of modular containers, water or air based cooling, or 
advanced power management through power supply 
optimization,  are  all  approaches 
that  have 
significantly 
improved  PUE  in  datacenters.  In 
addition,  Cloud  computing  allows  services  to  be 
moved  between  multiple  datacenter  which  are 
running with better PUE values. This is achieved by 
using  high  speed  network,  virtualized  services  and 
measurement,  and  monitoring  and  accounting  of 
datacenter.   

than 

5.  Towards  Energy  Efficiency  of  Cloud  computing: 

State-of-the-Art   

5.1. Applications 

SaaS  model  has  changed  the  way  applications  and 
software are distributed and used. More and more companies 
are switching to SaaS Clouds to minimize their IT cost. Thus, 
it  has  become  very  important  to  address  the  energy 
efficiency at application level itself. However, this layer has 
received  very  little  attraction  since  many  applications  are 
already on use and most of the new applications are mostly 

162 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

of 

highlighted 

servers  was 

over-provisioning 
by 
Ranganathan et al. [41]. They present a peak power budget 
management solution to avoid excessive over-provisioning 
considering  DVS  and  memory/disk  scaling.  There  are 
several other research work which focus on minimizing the 
over provisioning using consolidation of virtualized server 
[27]. Majority of these works use monitoring and estimation 
of resource utilization by applications based on the arrival 
rate  of  requests.  However,  due  to  multiple  levels  of 
abstractions, it is really hard to maintain deployment data of 
each  virtual  machine  within  a  Cloud  datacenter.  Thus, 
various  indirect  load  estimation  techniques  are  used  for 
consolidation of VMs. 

upgraded  version  of  or  developed  using  previously 
implemented tools. Some of the efforts in this direction are 
for MPI applications [22], which are designed to run directly 
on  physical  machines.  Thus,  their  performance  on  virtual 
machine is still undefined. 

Various power efficient techniques [24][25] for software 
designs are proposed in the literature but these are mostly for 
embedded devices. In the development of commercial and 
enterprise  applications  which  are  designed 
for  PC 
environment, generally energy efficiency is neglected. Mayo 
et al. [23] presented in their study that even simple tasks such 
as  listening  to  music  can  consume  significantly  different 
amounts of energy on a variety of heterogeneous devices. As 
these tasks have the same purpose on each device, the results 
show  that  the  implementation  of  the  task  and  the  system 
upon which it is performed can have a dramatic impact on 
efficiency.  Therefore,  to  achieve  energy  efficiency  at 
application  level,  SaaS  providers  should  pay  attention  in 
deploying software on right kind of infrastructure which can 
execute the software most efficiently. This necessitates the 
research and analysis of trade-off between performance and 
energy  consumption  due  to  execution  of  software  on 
multiple  platforms  and  hardware.  In  addition,  the  energy 
consumption at the compiler level and code level should be 
considered  by  software  developers  in  the  design  of  their 
future 
various 
energy-efficient techniques proposed in the literature. 

implementations 

application 

using 

5.2. Cloud Software Stack: Virtualization and 

Provisioning 

In the Cloud stack, most works in the literature address the 
challenges at the IaaS provider level where research focus is 
on  scheduling  and  resource  management  to  reduce  the 
amount of active  resources executing the workload of user 
applications.  The  consolidation  of  VMs,  VM  migration, 
scheduling,  demand  projection,  heat  management  and 
temperature-aware allocation, and load balancing are used as 
basic  techniques  for  minimizing  power  consumption.  As 
discussed  in  previous  section,  virtualization  plays  an 
important role in these techniques due to its several features 
such  as  consolidation,  live  migration,  and  performance 
isolation.  Consolidation  helps  in  managing  the  trade-off 
between  performance,  resource  utilization,  and  energy 
consumption  [26].  Similarly,  VM  migration  [48]  allows 
flexible  and  dynamic 
resource  management  while 
facilitating  fault  management  and  lower  maintenance  cost. 
Additionally, the advancement in virtualization technology 
has  led  to  significant  reduction  in  VM  overhead  which 
improves 
the  energy  efficiency  of  Cloud 
infrastructure. 

further 

Abdelsalam  et  al.  [31]  proposed  a  power  efficient 
technique to improve the management of Cloud computing 
environments. They formulated the management problem in 
the form of an optimization model aiming at minimization of 
the total energy consumption of the Cloud, taking SLAs into 
account.  The  current 
issue  of  under  utilization  and 
 

Although  above  consolidation  methods  can  reduce  the 
overall number of resources used to serve user applications, 
the  migration  and  relocation  of  VMs  for  matching 
application demand can impact the QoS service requirements 
of the user. Since Cloud providers need to satisfy a certain 
level  of  service,  some  work  focused  on  minimizing  the 
energy  consumption  while  reducing  the  number  of  SLA 
violations. One of the first works that dealt with performance 
and energy trade-off was by Chase et al. [27] who introduced 
MUSE,  an  economy-based  system  of  resource  allocation. 
They  proposed  a  bidding  system  to  deliver  the  required 
performance level and switching off unused servers. Kephart 
et al. [29] addressed the coordination of multiple autonomic 
managers  for  power/performance  tradeoffs  using  a  utility 
function approach in a non-virtualized environment. Song et 
al.  [30]  proposed  an  adaptive  and  dynamic  scheme  for 
efficient  sharing  of  a  server  by  adjusting  resources 
(specifically, CPU and memory) between virtual machines. 
At the operating system level, Nathuji et al. [28] proposed a 
power management system called Virtual Power integrating 
the  power  management  and  virtualization  technologies. 
Virtual Power allows the isolated and independent operation 
of virtual  machine to reduce  the energy consumption. The 
soft states are intercepted by Xen hypervisor and are mapped 
to  changes  in  the  underlying  hardware  such  as  CPU 
frequency 
the  virtual  power 
management rules. 

scaling  according 

In  addition,  there  are  works  on  improving  the  energy 
efficiency of storage systems. Kaushik et al. [32] presented 
an energy conserving self-adaptive Commodity Green Cloud 
storage called Lightning. The Lightning file system divides 
the  Storage  servers  into  Cold  and  Hot  logical  zones  using 
data  classification.  These  servers  are  then  switched  to 
inactive states for energy saving. 

Verma  et  al  [33]  proposed  an  optimization  for  storage 
virtualization called Sample-Replicate-Consoidate Mapping 
(SRCMAP)  which  enables  the  energy  proportionality  for 
dynamic  I/O  workloads  by  consolidating  the  cumulative 
workload on a subset of physical volumes proportional to the 
I/O  workload  intensity.  Gurumurthi  et  al.  [39]  proposed 
intra-disk  parallelism  on  high  capacity  drives  to  improve 
disk  bandwidth  without  increasing  power  consumption. 
Soror  et  al.  [34]  addressed  the  problem  of  optimizing  the 
systems  by 
performance  of  database  management 

to 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

163 

controlling  the  configurations  of  the  virtual  machines  in 
which they run. 

the 

thermal 

investigating 

Since power is dissipated in Cloud datacenter due to heat 
generated  by  the  servers,  several  work  also  have  been 
proposed for dynamic scheduling of VMs and applications 
which  take  into  account  the  thermal  states  or  the  heat 
dissipation  in  a  data  centre.  The  consideration  of  thermal 
factor in scheduling also improves the reliability of underline 
infrastructure. Tang et al. [36] formulated the problem using 
a mathematical model for maximizing the cooling efficiency 
of a data center. Heath et al. [40] proposed emulation tools 
for 
implications  of  power 
management.  Ramos  et  al.  [37]  proposed  a  software 
prediction infrastructure called C-Oracle that makes online 
predictions  for  data  center  thermal  management  based  on 
load redistribution and DVS. Moore et al. [35] proposed a 
method  for  automatic  reconfiguration  of  thermal  load 
management system taking into account thermal behavior for 
improving cooling efficiency and power consumption. They 
also  propose  thermal  management  solutions  focusing  on 
scheduling  workloads 
temperature-aware 
workload  placement.  Bash  et  al.  [36]  propose  a  workload 
placement policy for a datacenter that allocate resources in 
the areas which are easier to cool resulting in cooling power 
savings. Raghavendra et al. [38] propose a framework which 
coordinates and unifies five individual power management 
solutions (consisting of HW/SW mechanisms). 

considering 

proposed  based  on  liquid  cooling,  nano  fluid-cooling 
systems,  and  in-server,  in-rack,  and  in-row  cooling  by 
companies such as SprayCool. Other than that, the outside 
temperature/climate  can  have  direct  impact  on  the  energy 
requirement  of  cooling  system.  Some  systems  have  been 
constructed where external cool air is used to remove heat 
from the datacenter [42]. 

Another  level at  which datacenter‟s power efficiency is 
addressed  is  on  the  deployment  of  new  power  efficient 
servers and processors. Low  energy processors can reduce 
the power usage of IT systems in a great degree. Many new 
energy  efficient  server  models  are  available  currently  in 
market from vendors such as AMD, Intel, and others; each of 
them offering good performance/watt system. These server 
architecture enable slowing down CPU clock speeds (clock 
gating), or powering off parts of the chips (power gating), if 
they  are  idle.  Further  enhancement  in  energy  saving  and 
increasing  computing  per  watt  can  be  achieved  by  using 
multi-core processors. For instance  Sun‟s  multicore chips, 
each  32-thread  Niagara  chip,  UltraSPARC  1,  consumes 
about 60 watts, while the two Niagara chips have 64 threads 
and run at about 80 watts. However, the exploitation of such 
power  efficiency  of  multi-core  system  requires  software 
which  can 
run  on  multi-CPU  environment.  Here, 
virtualization technologies play an important role. Similarly, 
consolidation of storage system helps to further reduce the 
energy  requirements  of  IT  Systems.  For  example,  Storage 
Area Networks (SAN) allow building of an efficient storage 
network  that  consolidates  all  storage.  The  use  of  energy 
efficient  disks  such  as  tiered  storage  (Solid-State,  SATA, 
SAS) allows better energy efficiency. 

The  power  supply  unit  is  another  infrastructure  which 
needs  to  be  designed  in  an  energy  efficient  manner.  Their 
task is to feed the server resources with power by converting 
the  high-voltage  alternating  current  (AC)  from  the  power 
grid to a low-voltage direct current (DC) which most of the 
electric  circuits  (e.g.  computers)  require.  These  circuits 
inside Power Supply Unit (PSU) inevitably lose some energy 
in the form of heat,  which is dissipated by additional fans 
inside PSU. The energy efficiency of a PSU mainly depends 
on  its  load,  number  of  circuits  and  other  conditions  (e.g. 
temperature).  Hence,  a  PSU  which  is  labeled  to  be  80% 
efficient is not necessarily that efficient for all power loads. 
For example, low power loads tend to be the  most energy 
inefficient  ones.  Thus,  a  PSU  can  be just  60%  efficient  at   
20% of power load. Some studies have found that PSUs are 
one  of  the  most  inefficient  components  in  today‟s  data 
centers as many servers are still shipped with low quality 60 
to 70 percent efficient power supplies. One possible solution 
offered is to replace all PSUs by ENERGY STAR certified 
ones.  This  certificate  is  given  to  PSUs  which  guarantee  a 
minimum 80% efficiency at any power load. 

5.4. Monitoring/Metering 

It is said that you cannot improve what you do not measure. 
It  is  essential  to  construct  power  models  that  allow  the 

5.3. Datacenter level: Cooling, Hardware, Network, and 

Storage 

The rising energy costs, cost savings and a desire to get 
more out of existing investments are making today‟s Cloud 
providers  to  adopt  best  practices  to  make  datacenters 
operation green. To build energy efficient datacenter, several 
best  practices  has  been  proposed  to  improve  efficiency  of 
each device from electrical systems to processor level. 

First level is the smart construction of the datacenter and 
choosing of its location. There are two major factors in that 
one  is  energy  supply  and  other  is  energy  efficiency  of 
equipments. Hence, the datacenters are being constructed in 
such a way that electricity can be generated using renewable 
sources  such  as  sun  and  wind.  Currently  the  datacenter 
location  is  decided  based  on  their  geographical  features; 
climate,  fibre-optic  connectivity  and  access  to  a  plentiful 
supply of affordable energy.  Since  main concern of Cloud 
providers is business, energy source is also seen mostly in 
terms of cost not carbon emissions. 

Another area of concern within a datacenter is its cooling 
system  that  contributes  to  almost  1/3  of  total  energy 
consumption.  Some  research  studies  [17][35]  have  shown 
that  uneven  temperature  within  datacenter  can  also  lead 
significant decline in reliability of IT systems. In datacenter 
cooling,  two  types  of  approaches  are  used:  air  and  water 
based  cooling  systems.  In  both  approaches,  it  is  necessary 
that they directly cool the hot equipment rather than entire 
room area. Thus newer energy efficient cooling systems are 
 

164 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

system to know the energy consumed by a particular device, 
and how it can be reduced. To measure the unified efficiency 
of  a  datacenter  and  improve  its'  performance  per-watt,  the 
Green Grid has proposed two specific metrics known as the 
Power  Usage  Effectiveness 
(PUE)  and  Datacenter 
Infrastructure Efficiency (DciE) [19]. 

PUE = Total Facility Power/IT Equipment Power 

DciE = 1/PUE = IT Equipment Power/Total Facility Power x 

100% 

Here,  the  Total  Facility  Power  is  defined  as  the  power 
measured at the utility meter that is dedicated solely to the 
datacenter power. The IT Equipment Power is defined as the 
power consumed in the management, processing, and storage 
or routing of data within the datacenter. 

PUE  and  DCIE  are  most  common  metrics  designed  to 
compare  the  efficiency  of  datacenters.  There  are  many 
systems  in  the  marketplace  for  such  measurements.  For 
instance SunSM Eco 

Services measures at a higher level rather than attempting 
to  measure  each  individual  device‟s  power  consumption. 
For  measuring  and  modeling  the  power  usage  of  storage 
system,  Researchers  from  IBM  [44]  have  proposed  a 
scalable,  enterprise  storage  modelling  framework  called 
STAMP. It side steps the need for detailed traces by using 
interval  performance  statistics  and  a  power  table  for  each 
disk  model.  STAMP  takes  into  account  controller  caching 
and  algorithms,  including  protection  schemes,  and  adjusts 
the workload accordingly. To measure the power consumed 
by a server (e.g. PowerEdge R610) the Intelligent Platform 
Management  Interface  (IPMI)  [43]  is  proposed.  This 
framework  provides  a  uniform  way 
the 
power-monitoring sensors available on recent servers. This 
interface being independent of the operating system can be 
accessed despite of operating system failures and without the 
need of the servers to be powered on (i.e. connection to the 
power grid is enough). Further, intelligent power distribution 
units (PDUs), traditional power meters (e.g. Watts Up Pro 
power meter) and ACPI enabled power supplies can be used 
to measure the power consumption of the whole server. 

to  access 

5.5. Network Infrastructure 

As  discussed  previously,  at  network  level,  the  energy 
efficiency is achieved either at the node level (i.e. network 
interface card) or at the infrastructure level (i.e. switches and 
routers).  The  energy  efficiency  issues  in  networking  is 
usually referred to as “green networking”, which relates to 
embedding  energy-awareness  in  the  design,  in  the  devices 
and in the protocols of networks. There are four classes of 
solutions offered in literature, namely resource consolidation, 
virtualization,  selective  connectedness,  and  proportional 
computing. Resource consolidation helps in regrouping the 
under-utilized  devices  to  reduce  the  global  consumption. 
Similar to consolidation, selective connectedness of devices 
[44][45] consists of distributed mechanisms which allow the 
single  pieces  of  equipment  to  go  idle  for  some  time,  as 
 

transparently  as  possible  from  the  rest  of  the  networked 
devices. The difference between resource consolidation and 
selective connectedness is that the consolidation applies to 
resources that are  shared  within the  network infrastructure 
while  selective  connectedness  allows  turning  off  unused 
resources  at  the  edge  of  the  network.  Virtualization  as 
discussed before allows more than one service to operate on 
the  same  piece  of  hardware,  thus  improving  the  hardware 
utilization. Proportional computing [45] can be applied to a 
system  as  a  whole,  to  network  protocols,  as  well  as  to 
individual  devices  and  components.  Dynamic  Voltage 
Scaling  and  Adaptive  Link  Rate  are  typical  examples  of 
proportional  computing.  Dynamic  Voltage  Scaling  [45] 
reduces the energy state of the CPU as a function of a system 
load, while Adaptive Link Rate applies a similar concept to 
network  interfaces,  reducing  their  capacity,  and  thus  their 
consumption, as a function of the link load. The survey by 
Bianzino et al. [46] gives more details about the work in the 
area of Green networking. 

6. Green Cloud Architecture 

From the above study of current efforts in making Cloud 
computing  energy  efficient,  it  shows  that  even  though 
researchers  have  made  various  components  of  Cloud 
efficient in terms of power and performance, still they lack a 
unified  picture.  Most  of  efforts  for  sustainability  of  Cloud 
computing have missed the network contribution. If the file 
sizes  are  quite  large,  network  will  become  a  major 
contributor to energy consumption; thus it will be greener to 
run application locally than in  Clouds.  Furthermore,  many 
work  focused  on  just  particular  component  of  Cloud 
computing while neglecting effect of other, which may not 
result  in  overall  energy  efficiency.  For  example,  VM 
consolidation may reduce number of active servers but it will 
put excessive load on few servers where heat distribution can 
become  a  major  issue.  Some  other  works  just  focus  on 
redistribution  of  workload  to  support  energy  efficient 
cooling  without  considering  the  effect  of  virtualization.  In 
addition, Cloud providers, being profit oriented, are looking 
for solutions which can reduce the power consumption and 
thus,  carbon  emission  without  hurting 
their  market. 
Therefore,  we  provide  a  unified  solution  to  enable  Green 
Cloud  computing.  We  propose  a  Green  Cloud  framework, 
which  takes  into  account  these  goals  of  provider  while 
curbing the energy consumption of Clouds. The high level 
view of the green Cloud architecture is given in Figure 5. The 
goal of this architecture is to make Cloud green from both 
user and provider‟s perspective. 

In the Green Cloud architecture, users submit their Cloud 
service  requests  through  a  new  middleware  Green  Broker 
that manages the selection of the greenest Cloud provider to 
serve  the  user‟s  request.  A  user  service  request  can  be  of 
three  types  i.e.,  software,  platform  or  infrastructure.  The 
Cloud  providers  can  register  their  services  in  the  form  of 
„green  offers‟  to  a  public  directory  which  is  accessed  by 

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

165 

Green  Broker.  The  green  offers  consist  of  green  services, 
pricing and time when it should be accessed for least carbon 
emission.  Green  Broker  gets  the  current  status  of  energy 
parameters  for  using  various  Cloud  services  from  Carbon 
Emission  Directory.  The  Carbon  Emission  Directory 
maintains all the data related to energy efficiency of Cloud 
service. This data may include PUE and cooling efficiency of 
Cloud datacenter which is providing the service, the network 
cost  and  carbon  emission  rate  of  electricity,  Green  Broker 
calculates  the  carbon  emission  of  all  the  Cloud  providers 
who are offering the requested Cloud service. Then, it selects 
the set of services that will result in least carbon emission 
and buy these services on behalf users. 

The Green Cloud framework is designed such that it keeps 
track  of  overall  energy  usage  of  serving  a  user  request.  It 
relies on two main components, Carbon Emission Directory 
and  Green  Cloud  offers,  which  keep  track  of  energy 
efficiency of each Cloud provider and also give incentive to 
Cloud providers to make their service “Green”. From  user 
side, the Green Broker plays a crucial role in monitoring and 
selecting  the  Cloud  services  based  on  the  user  QoS 
requirements,  and  ensuring  minimum  carbon  emission  for 
serving a user. In general, a user can use Cloud to access any 
of these three types of services (SaaS, PaaS, and IaaS), and 
therefore  process  of  serving  them  should  also  be  energy 
efficient. In other words, from the Cloud provider side, each 
Cloud layer needs to be “Green” conscious. 

SaaS Level: Since SaaS providers mainly offer 
software installed on their own datacenters or 
resources from IaaS providers, the SaaS providers 
need to model and measure energy efficiency of their 
software design, implementation, and deployment. 
For serving users, the SaaS provider chooses the 
datacenters which are not only energy efficient but 
also near to users. The minimum number of replicas 
of user‟s confidential data should be maintained 
using energy-efficient storage.   
PaaS  level:  PaaS  providers  offer  in  general  the 
platform services for application  development. The 
platform facilitates the development of applications 
which ensures  system  wide energy efficiency. This 
can be done by inclusion of various energy profiling 
tools such as JouleSort [5]. It is a software energy 
efficiency  benchmark  that  measures  the  energy 
required  to  perform  an  external  sort.  In  addition, 
platforms itself can be designed to have various code 
level  optimizations  which  can  cooperate  with 
underlying complier in energy efficient execution of 
applications.  Other  than  application  development, 
Cloud platforms also allow the deployment of user 
applications  on  Hybrid  Cloud.  In  this  case,  to 
achieve  maximum  energy  efficiency,  the  platforms 

- 

- 

 

- 

using 

virtualization 

profile the application and decide which portion of 
application or data should be processed in house and 
in Cloud.   
IaaS level: Providers in this layer plays most crucial 
role in the success of whole Green Architecture since 
IaaS level not only offer independent infrastructure 
services  but  also  support  other  services  offered  by 
Clouds.  They  use  latest  technologies  for  IT  and 
cooling  systems  to  have  most  energy  efficient 
infrastructure.  By 
and 
consolidation,  the  energy  consumption  is  further 
reduced by switching-off unutilized server. Various 
energy meters and sensors are installed to calculate 
the current energy efficiency of each IaaS providers 
and  their  sites.  This  information  is  advertised 
regularly  by  Cloud  providers  in  Carbon  Emission 
Directory.  Various  green  scheduling  and  resource 
provisioning  policies  will  ensure  minimum  energy 
usage.  In  addition,  the  Cloud  provider  designs 
various  green  offers  and  pricing  schemes  for 
providing  incentive  to  users  to  use  their  services 
during  off-peak  or  maximum  energy-efficiency 
hours. 

7. Case Study: IaaS Provider 

In  this  section,  we  describe  a  case  study  example  to 
illustrate the working of the proposed Green Architecture in 
order to highlight the importance of considering the unifying 
picture to reduce the energy and carbon emissions by Cloud 
infrastructure.  The  case  study  focuses  on  IaaS  service 
providers.  Our  experimental  platform  consists  of  multiple 
Cloud  providers  who  offer  computational  resources  to 
execute user‟s HPC applications. A user request consists of 
application,  its  estimated  length  in  time  and  number  of 
resources required. These applications are submitted to the 
Green  broker  who  acts  as  an  interface  to  the  Cloud 
infrastructure and schedules applications on behalf of users. 
The  Green  Broker  interprets  and  analyzes  the  service 
requirements of a submitted application and decides where to 
execute it. As discussed, Green Broker‟s main objective is to 
schedule  applications  such  that  the  CO2  emissions  are 
reduced  and  the  profit  is  increased,  while  the  Quality  of 
Service (QoS) requirements of the applications are met. As 
Cloud  data  centers  are  located  in  different  geographical 
regions, they have different CO2 emission rates and energy 
costs depending on regional constraints. Each datacenter is 
responsible  for  updating 
to  Carbon 
Emission  Directory  for  facilitating  the  energy-efficient 
scheduling. The list of energy related parameters is given in 
Table 3. 

information 

this 

166 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

Figure 5.    Green Cloud Architecture 

Table 3.    Carbon Emission Related Parameter of a Datacenter 

 

 

 
In  order  to  validate  our  framework  and  to  prove  that  it 
achieves better efficiency  in terms of carbon emission,  we 
have  studied  five  policies  (Green  and  profit-oriented) 
employed for scheduling by Green Broker. 

a.  Greedy Minimum Carbon Emission (GMCE): In this 
policy,  user  applications  are  assigned  to  Cloud 
providers  in  greedy  manner  based  on  their  carbon 
emission.   

b.  Minimum  Carbon  Emission  -  Minimum  Carbon 
Emission  (MCE-MCE):  This  is  a  double  greedy 
policy where applications are assigned to the Cloud 

 

providers  with  minimum  Carbon  emission  due  to 
their datacenter location and Carbon emission due to 
application execution. 

c.  Greedy Maximum Profit (GMP): In this policy, user 
applications  are  assigned  in  greedy  manner  to  a 
provider who execute the application fastest and get 
maximum profit. .   

d.  Maximum Profit - Maximum Profit (MP-MP): This is 
double  greedy  policy  considering  profit  made  by 
Cloud  providers  and  application  finishes  by  its 
deadline.   

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

167 

e.  Minimising Carbon Emission and Maximising Profit 
(MCE-MP):  In  this  policy,  the  broker  tries  to 
schedule  the  applications  to  those  providers  which 
results in minimization of total carbon emission and 
maximization of profit.   

Above  GMCE,  MCE-MCE  and  MCE-MP  are  “Green” 
policies while MP-MP and GMP are profit-oriented policies. 
A more extensive detail on modeling of energy efficiency of 
a Cloud datacenter, experimental data and results is available 
in  previous  work  [47].  Here,  we  present  some  important 
results to illustrate the validity of our presented framework. 
Figure 6 shows the course of experiments conducted with 
varying user‟s urgency for executing his application and job 
arrival rate. The metrics of total carbon emission and total 
profit are used since the resource provider needs to know the 
collective loss in carbon emission and gain in profit across all 
datacenters. From these results three main inferences can be 
made. 

-  Green policies reduce the carbon emission by almost 

20%  in  comparison  to  profit  based  policies.  This 
observation  emphasizes  the  inclusion  of  overall 
carbon  efficiency  of  all  the  Cloud  providers  in 
scheduling decisions.   

-  With the increase in  user‟s  urgency to execute the 
application,  the  gain  in  carbon  emission  reduces 
almost linearly. This clearly shows how important is 
the  role  of  user  in  making  Cloud  computing  in 
general  “Green”.  If  users  are  more  patient  and 
schedule  the  applications  when  the  datacenters  are 
running at higher energy efficiency, more energy and 
carbon gain can be made. Thus, in our framework, 
we introduce the need of Green Cloud Offers from 
providers.   
The green policies also have minimal effect on the 
provider‟s profit. This clearly shows that by using 
energy  efficient  solutions  such  as  Green  Cloud 
Framework  both  Cloud  providers  and  users  can 
benefit.   

- 

(a) Carbon Emission VS Urgency                                                                                (b) Carbon Emission VS Arrival Rate 

 

 

(c) Profit VS Urgency                                                                                              (d) Profit VS Arrival Rate 

Figure 6.    Carbon Emission and Profit of Provider Using Green Cloud Framework 

 

168 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

8. Conclusions and Future Directions   

Cloud  computing  business  potential  and  contribution  to 
already aggravating carbon emission from ICT, has lead to a 
series of discussion whether Cloud computing is really green. 
It  is  forecasted  that  the  environmental  footprint  from  data 
centers will triple between 2002 and 2020, which is currently 
7.8 billion tons of CO2 per year. There are reports on Green 
IT analysis of Clouds and datacenters that show that Cloud 
computing is “Green”, while others show that it will lead to 
alarming increase in Carbon emission. Thus, in this chapter, 
we first analyzed the benefits offered by Cloud computing by 
studying  its  fundamental  definitions  and  benefits,  the 
services  it  offers  to  end  users,  and  its  deployment  model. 
Then,  we  discussed 
that 
contribute to carbon emission and the features of Clouds that 
make it “Green”. We also discussed several research efforts 
and  technologies  that  increase  the  energy  efficiency  of 
various  aspects  of  Clouds.  For  this  study,  we  identified 
several  unexplored  areas  that  can  help  in  maximizing  the 
energy  efficiency  of  Clouds  from  a  holistic  perspective. 
After  analyzing  the  shortcoming  of  previous  solutions,  we 
proposed  a  Green  Cloud  Framework  and  presented  some 
results  for  its  validation.  Even  though  our  Green  Cloud 
to  make  Cloud 
framework  embeds  various  features 
computing  much  more  Green, 
there  are  still  many 
technological solutions are required to make it a reality: 

the  components  of  Clouds 

levels 

First  efforts  are  required  in  designing  software  at 
various 
(OS,  compiler,  algorithm  and 
application)  that  facilitates  system  wide  energy 
efficiency.  Although  SaaS  providers  may  still  use 
already implemented software, they need to analyze 
the  runtime  behavior  of  applications.  The  gathered 
empirical  data  can  be  used  in  energy  efficient 
scheduling and resource provisioning. The compiler 
and operating systems need to be designed in such a 
way  that  resources  can  be  allocated  to  application 
based on the required level of performance, and thus 
performance versus energy consumption tradeoff can 
be managed.   
To  enable  the  green  Cloud  datacenters,  the  Cloud 
providers need to understand and  measure existing 
datacenter  power  and  cooling  designs,  power 
consumptions  of 
their  cooling 
requirements, and equipment resource utilization to 
achieve maximum efficiency. In addition, modeling 
tools are required to measure the energy usage of all 
the components and services of Cloud, from user PC 
to datacenter where Cloud services are hosted. 
For designing the holistic solutions in the scheduling 
and resource provisioning of applications within the 
datacenter, all the factors such as cooling, network, 
memory,  and  CPU  should  be  considered.  For 
instance,  consolidation  of  VMs  even 
though 
effective technique to minimize overall power usage 
of  datacenter,  also  raises  the  issue  related  to 
necessary  redundancy  and  placement  geo-diversity 

servers  and 

- 

- 

- 

 

- 

required to be maintained to fulfill SLAs with users. 
It is obvious that last thing Cloud provider will want 
is  to  lose  their  reputation  by  their  bad  service  or 
violation of promised service requirements. 
Last but not the least, the responsibility also goes to 
both  providers  and  customers  to  make  sure  that 
emerging  technologies  do  not  bring  irreversible 
changes  which  can  bring  threat  to  the  health  of 
human society. The way end users interact with the 
application also has a very real cost and impact. For 
example,  purging  of  unsolicited  emails  can 
eliminates  energy  wasted  in  storage  and  network. 
Similarly, if Cloud providers want to provide a truly 
green and renewable Cloud, they must deploy their 
datacenters  near  renewable  energy  sources  and 
maximize  the  Green  energy  usage  in  their  already 
established  datacenters.  Before 
adding  new 
technologies  such  as  virtualization,  proper  analysis 
of overhead should be done real benefit in terms of 
energy efficiency.   

In  conclusion,  by  simply  improving  the  efficiency  of 
equipment, Cloud computing cannot be claimed to be Green. 
What is important is to make its usage more carbon efficient 
both from user and provider‟s perspective. Cloud Providers 
need  to  reduce  the  electricity  demand  of  Clouds  and  take 
major  steps  in  using  renewable  energy  sources  rather  than 
just looking for cost minimization. 

 

REFERENCES 
[1]  Gleeson,  E.  2009.  Computing  industry  set  for  a  shocking 
change. 
from 
http://www.moneyweek.com/investment-advice/computing-i
ndustry-set-for-a-shocking-change-43226.aspx   

Retrieved 

January 

2010 

10, 

[2]  Buyya,  R.,  Yeo,  C.S.  and  Venugopal,  S.  2008. 
Market-oriented Cloud computing: Vision, hype, and reality 
for delivering it services as computing utilities. Proceedings 
of 
the  10th  IEEE  International  Conference  on  High 
Performance Computing and Communications, Los Alamitos, 
CA, USA.   

[3]  New Datacenter Locations. 2008. http://royal.pingdom.com/

2008/04/11/map-of-all-google-data-center-locations/   

[4]  Bianchini,  R.,  and  Rajamony,  R.  2004,  Power  and  energy 

management for server systems, Computer, 37 (11) 68-74.   

[5]  Rivoire, S., Shah, M. A., Ranganathan, P., and Kozyrakis, C. 
2007.  Joulesort:  a  balanced  energy-efficiency  benchmark, 
Proceedings  of  the  2007  ACM  SIGMOD  International 
Conference on Management of Data, NY, USA.   

[6]  Greenpeace 

International. 
http://www.greenpeace.org/ 
international/en/publications/reports/make-it-green-Cloudco
mputing/   

2010.  Make 

IT  Green 

[7]  Accenture  Microsoft  Report.  2010.  Cloud  computing  and 
Sustainability: The Environmental Benefits of Moving to the 
Cloud, http://www.wspenvironmental.com/media/docs/news

 

  Environment and Ecology Research 2(4): 153-170, 2014 

 

169 

room/Cloud_computing_and_Sustainability_-_Whitepaper_-
_Nov_2010.pdf.   

[24]  Saxe, E. 2008. Power Efficient Software. Communication of 

the ACM. 53(2) 44-48.   

[8]  Mell, P. and Grance, T. 2009. The NIST Definition of Cloud 
computing, National Institute of Standards and Technology.   
[9]  Google App Engine. 2010. http://code.google.com/appengin

e/.   

[10]  Vecchiola,  C.,  Chu,  X.  and  Buyya,  R.  2009.  Aneka:  A 
Software Platform for .NET-based Cloud Computing. In High 
Performance & Large Scale computing, Advances in Parallel 
Computing, ed. W. Gentzsch, L. Grandinetti and G. Joubert, 
IOS Press.   

[11]  Microsoft Azure. 2011. www.microsoft.com/windowsazure/   
[12]  Charrington, S. 2010, Characteristics of Platform as a Service, 
Cloud Pulse blog, http://Cloudpulseblog.com/2010/02/the-es
sential-characteristics-of-paas.   

[13]  Cherkasova,  L.  and  Gardner,  R.  2005,  Measuring  CPU 
overhead  for  I/O  processing  in  the  Xen  virtual  machine 
monitor. Proceeding of  2005  Annual  Technical  Conference 
on USENIX, Anaheim, CA, USA.   

[14]  Sarokin,  D.  2007.  Question:  Energy  use  of  Internet, 

http://uclue.com/?xq=724.   

[15]  Baliga J., Ayre R., Hinton K., and Tucker R. S. 2010. Green 
Cloud  computing:  Balancing  energy  in  processing,  storage 
and transport. Proceedings of the IEEE, 99(1) 149-167.   

[16]  Chabarek, J., Sommers, J., Barford, P., Estan, C., Tsiang, D., 
and Wright, S. 2008. Power Awareness in Network Design 
and Routing. Proceedings of 27th IEEE INFOCOM, Pheonix, 
AZ, USA.   

[17]  Ranganathan  P,  2010,  Recipe  for  efficiency:  principles  of 
ACM, 

Communication. 

computing. 

power-aware 
53(4):60–67.   

[25]  Großschädl,  Avanzi  R.M.,  Savas  E.,  and  Tillich  S.  2005. 
Energy-efficient  software  implementation  of  long  integer 
modular  arithmetic,  Proceedings  of  7th  Workshop  on 
Cryptographic Hardware and Embedded Systems, Edinburg, 
Scotland.   

[26]  Srikantaiah, S., Kansal, A., and Zhao, F. 2008. Energy aware 
consolidation 
for  Cloud  computing.  Proceedings  of 
HotPower  ’08  Workshop  on  Power  Aware  computing  and 
Systems, San Diego, CA, USA.   

[27]  Chase, J.S., Anderson, D.C., Thakar, P.N., Vahdat, A.M., and 
Doyle, R.P. 2001. Managing energy and server resources in 
hosting  centers.  Proceedings  of  18th  ACM  Symposium  on 
Operating Systems Principles (SOSP ’01), Banff, Canada.   

[28]  Nathuji, R. and Schwan, K. 2007. VirtualPower: coordinated 
power  management 
in  virtualized  enterprise  systems. 
Proceedings of 21st ACM SIGOPS Symposium on Operating 
Systems Principles, Stevenson, WA, USA.   

[29]  Kephart, J. O., Chan, H., Das, R., Levine, D. W., Tesauro, G., 
Rawson,  F.,  and  Lefurgy,  C.  2007.  Coordinating  multiple 
autonomic managers to achieve specified power-performance 
tradeoffs.  Proceedings  of  4th  International  Conference  on 
Autonomic Computing, Florida, USA.   

[30]  Song, Y., Sun, Y., Wang, H., and Song, X. 2007. An adaptive 
resource flowing scheme amongst VMs in a VM-based utility 
computing. Proceedings of IEEE International Conference on 
Computer and Information Technology, Fukushima, Japan.   
[31]  Abdelsalam, H., Maly, K., Mukkamala, R., Zubair, M., and 
Kaminsky,  D.  2009.  Towards  energy  efficient  change 
management in a Cloud computing environment, Proceedings 
of 
on  Autonomous 
Infrastructure, Management and Security, The Netherlands.   

International  Conference 

3rd 

[18]  Greenberg, S., Mills, E., Tschudi, B., Rumsey, P., and Myatt, 
B., 2008, Best Practices for Data Centers: Lessons Learned 
from Benchmarking 22 Data Centers. ACEEE Summer Study 
on  Energy  Efficiency  in  Buildings.  Retrieved  September  4, 
2008, fromhttp://eetd.lbl.gov/emills/PUBS/PDF/ACEEE-dat
acenters.pdf   

[19]  Rawson,  A.,  Pfleuger,  J.,  and  Cader,  T.,  2008.  Green  Grid 
Data  Center  Power  Efficiency  Metrics.  Consortium  Green 
Grid.   

[20]  Smith,  J.  and  Nair,  R.  2003.  Virtual  Machines:  Versatile 
Platforms  for  Systems  and  Processes.  Morgan  Kaufmann: 
Los Altos, CA.   

[21]  IBM. 2008. ”Take the tennis to 1.9 billion viewersworldwide? 
Done.,” 04/05/08, 2008; http://www- 07.ibm.com/innovation
/au/ausopen/pdf/CaseStudy 01.pdf   

[32]  Kaushik, R. T., Cherkasova, L., Campbell, R., and Nahrstedt, 
K.,  2010.  Lightning:  self-adaptive,  energy-conserving, 
multi-zoned,  commodity  green  Cloud  storage  system.  In 
Proceedings of  the 19th  ACM  International Symposium  on 
High Performance Distributed computing (HPDC '10). ACM, 
New York, NY, USA.   

[33]  Verma, A., Koller, R., Useche, L., and Rangaswami, R., 2010. 
SRCMap:  energy  proportional  storage  using  dynamic 
consolidation.  2010,  Proceedings  of  the  8th  USENIX 
conference on File and storage technologies (FAST'10), San 
Jose, California   

[34]  Soror,  A.  A.,  Minhas,  U.  F.,  Aboulnaga,  A.,  Salem,  K., 
Kokosielis,  P.,  and  Kamath,  S.  2008.  Automatic  virtual 
machine configuration for database  workloads. Proceedings 
of ACM SIGMOD International Conference on Management 
of data, Vancouver, Canada   

[22]  Freeh, V. W., Pan, F., Kappiah, N., Lowenthal, D. K., and 
Springer,  R.  2005.  Exploring  the  energy-time  trade-off  in 
MPI programs on a power-scalable cluster, Proceedings of the 
19th IEEE International Parallel and Distributed Processing 
Symposium, CA, USA.   

[35]  Moore,  J.  D.,  Chase,  J.  S.,  and  Ranganathan,  P.  2006. 
Weatherman:  Automated,  online  and  predictive  thermal 
mapping and management for datacenters, Proceedings of the 
3rd  International  Conference  on  Autonomic  computing, 
Dublin, Ireland.   

[23]  Mayo, R. N. and Ranganathan P., 2005. Energy consumption 
in  mobile 
need 
requirements-aware  energy  scale-down.  Proceedings  of  3rd 
International Workshop on Power-Aware Computer Systems, 
San Diego, CA, USA.   

devices:  Why 

systems 

future 

[36]  Bash,  C.  and  Forman,  G.  2007.  Cool  job  allocation: 
Measuring 
jobs  at 
cooling-efficient  locations  in  the  datacenter,  Proceeding  of 
2007 Annual Technical Conference on USENIX, Santa Clara, 
CA, USA.   

savings  of  placing 

the  power 

 

170 

  A Strategic Model for Adopting Energy Efficient Cloud Computing Infrastructure for Sustainable Environment   

 

 

[37]  Ramos,  L.  and  Bianchini,  R.,  2008,  C-oracle:  Predictive 
thermal  management  for  data  centers,  Proceedings  of  14th 
International  Symposium  on  High-  Performance  Computer 
Architecture, Salt Lake City, UT, USA.   

[44]  Allalouf, M., Arbitman, Y., Factor, M., Kat, R. I., Meth, K., 
and Naor, D. 2009. Storage modelling for power estimation. 
In  Proceedings  of  2009  Israeli  Experimental  Systems 
Conference (SYSTOR '09), Isreal.   

[45]  Allman, M., Christensen, K., Nordman, B., and Paxson, V. 
2007. Enabling an Energy-Efficient Future Internet Through 
Selectively Connected End Systems, Proceedings of the Sixth 
ACM Workshop on Hot Topics in Networks (HotNets-VI), 
Atlanta, Georgia, USA.   

[46]  Bianzino, P., Chaudet, C., Rossi, D., and Rougier, J. (2011). 
A  Survey  of  Green  Networking  Research, 
IEEE 
Communications  Surveys  and  Tutorials,  IEEE,  USA  (in 
press.)   

[47]  Garg,  S.  K.,  Yeo,  C.  S.,  Anandasivam,  A.,  and  Buyya,  R. 
of  HPC 
2011.  Environment-conscious 
applications  on  distributed  Cloud-oriented  datacenters, 
Journal  of  Parallel  and  Distributed  computing  (JPDC), 
71(6):732-749.   

scheduling 

[48]  Beloglazov, A, Buyya, R, Lee, YC, and Zomaya, A. 2011. A 
Taxonomy and Survey of Energy-Efficient Data Centers and 
Cloud  computing  Systems,  Advances  in  Computers,  M. 
Zelkowitz  (ed),  ISBN  13:  978-0-12-012141-0,  Elsevier, 
Amsterdam, The Netherlands.   

[49]  Allenotor, D., Thulasiram, R. K. 2008. Grid resources pricing: 
A  novel  financial  option  based  quality  of  service-profit 
quasi-static  equilibrium  model,  Proceedings  of  the  8th 
ACM/IEEE  International  Conference  on  Grid  Computing, 
Tsukuba, Japan.

[38]  Raghavendra, R., Ranganathan, P., Talwar, V., Wang, Z., and 
Zhu Z. 2008. No “power” struggles: coordinated multi-level 
power  management  for  the  datacenter,  SIGOPS  Operating 
System Review, 42(2) 48–59.   

[39]  Gurumurthi,  S.,  Stan,  M.  R.,  and  Sankar,  S.,  2009,  Using 
intra-disk  parallelism 
to  build  energy-efficient  storage 
systems,  IEEE  Micro  Special  Issue  on  Top  Picks  from  the 
Computer Architecture Conferences of 2008.   

[40]  Heath, T., Centeno, A. P., George, P., Ramos, L., Jaluria, Y., 
and  Bianchini,  R.  2006.  Mercury  and  Freon:  temperature 
emulation and management for server systems. Proceedings 
of Twelfth International Conference on Architectural Support 
for  Programming  Languages  and  Operating  Systems,  San 
Jose, CA, USA.   

[41]  Ranganathan,  P.,  Leech,  P.,  Irwin,  D.,  and  Chase,  J.  2006. 
Ensemble level power management for dense blade servers, 
SIGARCH Computer Architecture News, 34(2)66–77.   

[42]  Woods, A. 2010. Cooling the data center. Communications of 

the ACM, 53(4):36-42.   

[43]  Giri,  Ravi  A.  2010.  Increasing  Datacenter  efficiency  with 
server power measurements. http://download.intel.com/it/pdf
/Server_Power_Measurement_final.pdf   

 

 

