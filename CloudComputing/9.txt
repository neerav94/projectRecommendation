Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

Multi objective parameters for real time scheduling in 

cloud computing 

Simi Gupta1, Kamal Kumar Sharma2, Surjeet Dalal3 

1Student, M. Tech, ESSEAR, Ambala 

2Professor, Dept. of ECE, E-Max group of Institutions, Ambala 

3Assistant Professor, Dept. of CSE, E-Max group of Institutions, Ambala 

Abstract—Cloud  computing  has  been  portrayed  as  synonym  for  distributed  computing.  It  is  a  type  of  computing 
which relies on sharing computing resources on pay per usage basis. Therefore, minimizing cost of the infrastructure is 
of  utmost  importance.  But  minimizing  the  total  cost  of  the  cloud  is  not  only  the  solution  to  generate  revenue  but 
multiple parameter like response time and efficiency also plays a great role. In this paper we present a model which 
takes  care  of  cost-effectiveness,  response  time  and  efficiency.  Simulation  results  also  show  the  effectiveness  of  the 
proposed scheme. 
Keywords— cloud, scheduling, cost

I. INTRODUCTION 

sense  of  Application  Service  Provisioning  that  run  Client 
server software on a remote location. 

them  more  revenue  and 

In computer science, the Cloud Computing describes a type 
of outsourcing of computer services which are similar to the 
way  in  which  the  supply  of  electricity  is  out  sourced.  The 
users can simply use it then they do not need to worry from 
where  the  electricity  is  coming  from,  how  it  is  made  or 
transported  from.  Every  month,  they  pay  for  what  they 
consumed.  The idea  behind  cloud  computing  is  similar  that 
the  user  can  simply  use  storage  computing  power  or 
specially  crafted  development  environments  without having 
to  worry  how  these  work  internally.  Cloud  computing  is  a 
system architecture model for internet based computing. It is 
the  development  and  use  of  computer  technology  on  the 
internet.  Data  centers  and  cloud  computing  services 
providers hope that the extensive adoption of the cloud will 
bring 
they  are  dynamically 
promoting  the  technology.  The  Cloud  ranging  from  the 
definition  of  cloud  computing  talk  about  energy  efficiency 
one  of  the  main  area  which  needs  to  be  focus.  Cloud 
computing  which  is  a  kind  of  distributed  system  consisting 
of  a  collection  of  interconnected  Data  centers  which 
constitutes  a  numbers  of  virtual  machines  obtained  by 
virtualization processes that are dynamically provisioned and 
accessible as one or more unified computing resources based 
on  service  level  agreements.  A  cloud  Data  center  usually 
deploys  many  servers,  compactly  packed  to  make  the  most 
of the space utilization. 
Cloud  computing  is  a  type  of  computing  that  relies  on 
sharing computing resources rather than having local servers 
or  personal  devices  to  handle  applications.  The  ‗cloud‘  in 
cloud  computing  can  be  defined  as  the  set  of  hardware, 
network,  storage  services  and  interface  that  combine  to 
deliver  aspects  of  computing  as  a  service.  Cloud  service 
include  the  delivery  of  software  ,infrastructure  &  storage 
over  the  internet  based  on  a  user  demand.  In  computer 
science  Cloud  computing  is  a  synonym  for  distributed 
computing  over  a  network  and  means  the  ability  to  run  a 
program  on  many  connected  computers  at  the  same  time. 
The  popularity  of  the  term  Cloud  computing  can  be 
attributed to its use in marketing to sell hosted services in the 

II. RELATED WORK 

to 

the  author 

Francis  et  al.  [1]  outline  previous  contributions  to  the 
discussion  of  efficiency  of  cloud  computing,  provide  a 
working  definition  of  cloud  computing  and  discuss  its 
importance, which will grow as the technology matures and 
becomes  well  known.  According 
the 
assessment  of  the  efficiency  of  cloud  computing  cannot  be 
based  only  on  data  centers  due  to  the  importance  of  the 
intermediate  communication  networks  that  support  the 
overall  activity  of  providing  cloud  computing  services  and 
the  devices  used  to  access  cloud  services.  The  other 
components  should  be  taken  into  account  when  measuring 
the  efficiency  of  cloud  computing.  There  is  the  need  to 
improve  the  efficiency  of  communication networks  and  the 
Internet in  order  to  meet  the  new  levels  of  demand.  In  this 
paper  they  analyzed  the  optimization  of  the  network 
infrastructure  should  be  paramount  if  the  improved  energy 
efficiency  of  data  centers  will  result  in  overall  benefits. 
Keville et al. [2] examine the use of ARM-based clusters for 
low-power,  high  performance  computing.  This  work 
examines  two  likely  use-modes:  (i)  a  standard  dedicated 
cluster; and (ii) a cluster of pre-configured virtual machines 
in the cloud. A 40-node department-level cluster based on an 
ARM Cortex-A9 is compared against a similar cluster based 
on an Intel Core 2 Duo, in contrast to a recent similar study 
on  just  a  4-node  cluster.  For  the  NAS  benchmarks  on  32- 
node  clusters,  ARM  was  found  to  have  a  power  efficiency 
ranging from 1.3 to 6.2 times greater than that of Intel. This 
times  greater 
is  despite 
five 
performance.  The  particular  efficiency 
ratio  depends 
primarily on the size of the working set relative to L2 cache. 
Zhang et al. [3] propose a software and lightweight approach 
to  accurately  estimate  the  power  usage  of  virtual  machines 
and  cloud  servers. 
It  explores  hypervisor-observable 
performance  metrics  to  build  the  power  usage  model.  To 
configure  cloud  resources,  it  considers  both  the  system 
power  usage  and  the  SLA  requirements,  and  leverage 
learning techniques to achieve autonomic resource allocation 
and  optimal  power  efficiency.  In  this  paper  they  analyzed 

Intel‘s  approximately 

   © 2014 IJRAEM All Rights Reserved                                                                                   20 

Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

Multi objective parameters for real time scheduling in 

cloud computing 

Simi Gupta1, Kamal Kumar Sharma2, Surjeet Dalal3 

1Student, M. Tech, ESSEAR, Ambala 

2Professor, Dept. of ECE, E-Max group of Institutions, Ambala 

3Assistant Professor, Dept. of CSE, E-Max group of Institutions, Ambala 

Abstract—Cloud  computing  has  been  portrayed  as  synonym  for  distributed  computing.  It  is  a  type  of  computing 
which relies on sharing computing resources on pay per usage basis. Therefore, minimizing cost of the infrastructure is 
of  utmost  importance.  But  minimizing  the  total  cost  of  the  cloud  is  not  only  the  solution  to  generate  revenue  but 
multiple parameter like response time and efficiency also plays a great role. In this paper we present a model which 
takes  care  of  cost-effectiveness,  response  time  and  efficiency.  Simulation  results  also  show  the  effectiveness  of  the 
proposed scheme. 
Keywords— cloud, scheduling, cost

I. INTRODUCTION 

sense  of  Application  Service  Provisioning  that  run  Client 
server software on a remote location. 

them  more  revenue  and 

In computer science, the Cloud Computing describes a type 
of outsourcing of computer services which are similar to the 
way  in  which  the  supply  of  electricity  is  out  sourced.  The 
users can simply use it then they do not need to worry from 
where  the  electricity  is  coming  from,  how  it  is  made  or 
transported  from.  Every  month,  they  pay  for  what  they 
consumed.  The idea  behind  cloud  computing  is  similar  that 
the  user  can  simply  use  storage  computing  power  or 
specially  crafted  development  environments  without having 
to  worry  how  these  work  internally.  Cloud  computing  is  a 
system architecture model for internet based computing. It is 
the  development  and  use  of  computer  technology  on  the 
internet.  Data  centers  and  cloud  computing  services 
providers hope that the extensive adoption of the cloud will 
bring 
they  are  dynamically 
promoting  the  technology.  The  Cloud  ranging  from  the 
definition  of  cloud  computing  talk  about  energy  efficiency 
one  of  the  main  area  which  needs  to  be  focus.  Cloud 
computing  which  is  a  kind  of  distributed  system  consisting 
of  a  collection  of  interconnected  Data  centers  which 
constitutes  a  numbers  of  virtual  machines  obtained  by 
virtualization processes that are dynamically provisioned and 
accessible as one or more unified computing resources based 
on  service  level  agreements.  A  cloud  Data  center  usually 
deploys  many  servers,  compactly  packed  to  make  the  most 
of the space utilization. 
Cloud  computing  is  a  type  of  computing  that  relies  on 
sharing computing resources rather than having local servers 
or  personal  devices  to  handle  applications.  The  ‗cloud‘  in 
cloud  computing  can  be  defined  as  the  set  of  hardware, 
network,  storage  services  and  interface  that  combine  to 
deliver  aspects  of  computing  as  a  service.  Cloud  service 
include  the  delivery  of  software  ,infrastructure  &  storage 
over  the  internet  based  on  a  user  demand.  In  computer 
science  Cloud  computing  is  a  synonym  for  distributed 
computing  over  a  network  and  means  the  ability  to  run  a 
program  on  many  connected  computers  at  the  same  time. 
The  popularity  of  the  term  Cloud  computing  can  be 
attributed to its use in marketing to sell hosted services in the 

II. RELATED WORK 

to 

the  author 

Francis  et  al.  [1]  outline  previous  contributions  to  the 
discussion  of  efficiency  of  cloud  computing,  provide  a 
working  definition  of  cloud  computing  and  discuss  its 
importance, which will grow as the technology matures and 
becomes  well  known.  According 
the 
assessment  of  the  efficiency  of  cloud  computing  cannot  be 
based  only  on  data  centers  due  to  the  importance  of  the 
intermediate  communication  networks  that  support  the 
overall  activity  of  providing  cloud  computing  services  and 
the  devices  used  to  access  cloud  services.  The  other 
components  should  be  taken  into  account  when  measuring 
the  efficiency  of  cloud  computing.  There  is  the  need  to 
improve  the  efficiency  of  communication networks  and  the 
Internet in  order  to  meet  the  new  levels  of  demand.  In  this 
paper  they  analyzed  the  optimization  of  the  network 
infrastructure  should  be  paramount  if  the  improved  energy 
efficiency  of  data  centers  will  result  in  overall  benefits. 
Keville et al. [2] examine the use of ARM-based clusters for 
low-power,  high  performance  computing.  This  work 
examines  two  likely  use-modes:  (i)  a  standard  dedicated 
cluster; and (ii) a cluster of pre-configured virtual machines 
in the cloud. A 40-node department-level cluster based on an 
ARM Cortex-A9 is compared against a similar cluster based 
on an Intel Core 2 Duo, in contrast to a recent similar study 
on  just  a  4-node  cluster.  For  the  NAS  benchmarks  on  32- 
node  clusters,  ARM  was  found  to  have  a  power  efficiency 
ranging from 1.3 to 6.2 times greater than that of Intel. This 
times  greater 
is  despite 
five 
performance.  The  particular  efficiency 
ratio  depends 
primarily on the size of the working set relative to L2 cache. 
Zhang et al. [3] propose a software and lightweight approach 
to  accurately  estimate  the  power  usage  of  virtual  machines 
and  cloud  servers. 
It  explores  hypervisor-observable 
performance  metrics  to  build  the  power  usage  model.  To 
configure  cloud  resources,  it  considers  both  the  system 
power  usage  and  the  SLA  requirements,  and  leverage 
learning techniques to achieve autonomic resource allocation 
and  optimal  power  efficiency.  In  this  paper  they  analyzed 

Intel‘s  approximately 

   © 2014 IJRAEM All Rights Reserved                                                                                   20 

Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

energy-efficient  data 

that  it  implements  a  prototype  of  the  proposed  power 
management system and test it on a cloud test bed. Graubner 
et  al.  [4]  a novel  approach  to  virtual  machine  consolidation 
for  saving  energy  is  presented.  In  this  paper  they  analyzed 
that  it  is  based  on  efficient  storage  migration  and  live 
migration  of  virtual  machines  to  take  advantage  of  the 
lacking  energy  proportionality  of  commodity  hardware. 
Dharwar  et  al.  [5]  outlines  the  state-of-the-art  in  power-
management  technology  on  server  hardware  and  describes 
how these raw features can be abstracted into a set of energy 
policies.  In  this  paper  they  analyzed  to  explain  how  these 
policies  or  energy-profiles  can  be  used  to  run  cloud 
datacenter  energy  efficiently.  Kejiang  et  al.  [7]  present  a 
virtual  machine  based 
center 
architecture for cloud computing. It investigates the potential 
performance  overheads  caused  by  server  consolidation  and 
live  migration  of  virtual  machine  technology.  In  this  paper 
they  analyzed  the  experimental  results  show  that  both  the 
two  technologies  can  effectively  implement  energy-saving 
goals  with 
little  performance  overheads.  Efficient 
consolidation  and  migration  strategies  can  improve  the 
energy  efficiency.  Yamini  et  al. 
task 
consolidation particularly in clouds has become an important 
approach  to  streamline  resource  usage  and  in  turn  improve 
energy efficiency. Based on the fact that resource utilization 
directly relates to energy consumption, it has modeled their 
relationship  and  developed 
task 
consolidation heuristics. The cost functions incorporated into 
these 
energy-saving 
possibilities  and  their  capability  has  been  verified  by  my 
evaluation  study.  In  this  paper  they  analyzed  the  results  in 
this  study  should  not  have  only  a  direct  impact  on  the 
reduction  of  electricity  bills  of  cloud 
infrastructure 
providers,  but  also  imply  possible  savings(with  better 
resource  provisioning)  in  other  operational  costs  (e.g.,  rent 
for floor space). 

two  energy-conscious 

[8]  propose 

heuristics 

effectively 

capture 

III. SYSTEM MODEL 

In  the  Figure  1  users  bases  generated  the  requests  for  the 
scheduler  to  get  the  desired  resources  over  internet.  This 
request is further forwarded to broker and following steps are 
followed: 
1.  Virtual  Resources  are  pretreated  before  going 

to 

scheduling. 

2.  All the tasks are put into buffer. 
3.  All  the  N  tasks  are  divided  into  M  classes  and  after 
calculation  a  set  is  being  created  since  larger  tasks  are 
put in one block and smaller tasks in other 

4.  Choose  a task in  each  queue head; there are M tasks in 

5. 

total. 
 M  tasks  are  scheduled  to  clouds  clusters  and  local 
clusters  at  the  same  time,  the  tasks  of  large  amount  of 
calculation  are  scheduled  to  resources  queue  whose 
calculation ability are strong., the tasks of small amount 
of  calculation  are  scheduled  to  resources  queue  whose 
calculation  ability  are  weak,  the  special  tasks  are 
scheduled to special resources queue. 
the  basis  of  cost,  response 

time,  efficiency 
information available  for each virtual machine instance 
resource is allocated in the corresponding queue.  

6.  On 

 

 

Figure 1: Schematic view 

 

IV. SIMULATION RESULTS 

      We  have  implemented  a  custom  simulator to  model  the 
proposed  system.  In  our  study  we  consider  a  maximum  of 
5000 task centers belonging to different CSPs. For simplicity 
we  assume  that  one  CSP  has  only  one  task  center  which 
participates  in  the  federation.  The  simulator  considers  6 
different  geographical  locations  and  randomly  assigns  task 
centers to different locations, such that, the simulator keeps 
the number of resources available at different task centers as 
constant. 
In  Figure  1  we  can  evaluate  that  the  latency  of  different 
locations  have  different  impact  on  the  performance  of 
workload  further  if  we  move  at  the  Probability  distributive 
function  (PDF)  at  Figure  2  we  can  see  that  the  values  at 
which the  different  strategies  are  working and  the  output  is 
coming.  
 

Figure 1: Latency at different Locations (ms) 

 

 

   © 2014 IJRAEM All Rights Reserved                                                                                   21 

Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

Multi objective parameters for real time scheduling in 

cloud computing 

Simi Gupta1, Kamal Kumar Sharma2, Surjeet Dalal3 

1Student, M. Tech, ESSEAR, Ambala 

2Professor, Dept. of ECE, E-Max group of Institutions, Ambala 

3Assistant Professor, Dept. of CSE, E-Max group of Institutions, Ambala 

Abstract—Cloud  computing  has  been  portrayed  as  synonym  for  distributed  computing.  It  is  a  type  of  computing 
which relies on sharing computing resources on pay per usage basis. Therefore, minimizing cost of the infrastructure is 
of  utmost  importance.  But  minimizing  the  total  cost  of  the  cloud  is  not  only  the  solution  to  generate  revenue  but 
multiple parameter like response time and efficiency also plays a great role. In this paper we present a model which 
takes  care  of  cost-effectiveness,  response  time  and  efficiency.  Simulation  results  also  show  the  effectiveness  of  the 
proposed scheme. 
Keywords— cloud, scheduling, cost

I. INTRODUCTION 

sense  of  Application  Service  Provisioning  that  run  Client 
server software on a remote location. 

them  more  revenue  and 

In computer science, the Cloud Computing describes a type 
of outsourcing of computer services which are similar to the 
way  in  which  the  supply  of  electricity  is  out  sourced.  The 
users can simply use it then they do not need to worry from 
where  the  electricity  is  coming  from,  how  it  is  made  or 
transported  from.  Every  month,  they  pay  for  what  they 
consumed.  The idea  behind  cloud  computing  is  similar  that 
the  user  can  simply  use  storage  computing  power  or 
specially  crafted  development  environments  without having 
to  worry  how  these  work  internally.  Cloud  computing  is  a 
system architecture model for internet based computing. It is 
the  development  and  use  of  computer  technology  on  the 
internet.  Data  centers  and  cloud  computing  services 
providers hope that the extensive adoption of the cloud will 
bring 
they  are  dynamically 
promoting  the  technology.  The  Cloud  ranging  from  the 
definition  of  cloud  computing  talk  about  energy  efficiency 
one  of  the  main  area  which  needs  to  be  focus.  Cloud 
computing  which  is  a  kind  of  distributed  system  consisting 
of  a  collection  of  interconnected  Data  centers  which 
constitutes  a  numbers  of  virtual  machines  obtained  by 
virtualization processes that are dynamically provisioned and 
accessible as one or more unified computing resources based 
on  service  level  agreements.  A  cloud  Data  center  usually 
deploys  many  servers,  compactly  packed  to  make  the  most 
of the space utilization. 
Cloud  computing  is  a  type  of  computing  that  relies  on 
sharing computing resources rather than having local servers 
or  personal  devices  to  handle  applications.  The  ‗cloud‘  in 
cloud  computing  can  be  defined  as  the  set  of  hardware, 
network,  storage  services  and  interface  that  combine  to 
deliver  aspects  of  computing  as  a  service.  Cloud  service 
include  the  delivery  of  software  ,infrastructure  &  storage 
over  the  internet  based  on  a  user  demand.  In  computer 
science  Cloud  computing  is  a  synonym  for  distributed 
computing  over  a  network  and  means  the  ability  to  run  a 
program  on  many  connected  computers  at  the  same  time. 
The  popularity  of  the  term  Cloud  computing  can  be 
attributed to its use in marketing to sell hosted services in the 

II. RELATED WORK 

to 

the  author 

Francis  et  al.  [1]  outline  previous  contributions  to  the 
discussion  of  efficiency  of  cloud  computing,  provide  a 
working  definition  of  cloud  computing  and  discuss  its 
importance, which will grow as the technology matures and 
becomes  well  known.  According 
the 
assessment  of  the  efficiency  of  cloud  computing  cannot  be 
based  only  on  data  centers  due  to  the  importance  of  the 
intermediate  communication  networks  that  support  the 
overall  activity  of  providing  cloud  computing  services  and 
the  devices  used  to  access  cloud  services.  The  other 
components  should  be  taken  into  account  when  measuring 
the  efficiency  of  cloud  computing.  There  is  the  need  to 
improve  the  efficiency  of  communication networks  and  the 
Internet in  order  to  meet  the  new  levels  of  demand.  In  this 
paper  they  analyzed  the  optimization  of  the  network 
infrastructure  should  be  paramount  if  the  improved  energy 
efficiency  of  data  centers  will  result  in  overall  benefits. 
Keville et al. [2] examine the use of ARM-based clusters for 
low-power,  high  performance  computing.  This  work 
examines  two  likely  use-modes:  (i)  a  standard  dedicated 
cluster; and (ii) a cluster of pre-configured virtual machines 
in the cloud. A 40-node department-level cluster based on an 
ARM Cortex-A9 is compared against a similar cluster based 
on an Intel Core 2 Duo, in contrast to a recent similar study 
on  just  a  4-node  cluster.  For  the  NAS  benchmarks  on  32- 
node  clusters,  ARM  was  found  to  have  a  power  efficiency 
ranging from 1.3 to 6.2 times greater than that of Intel. This 
times  greater 
is  despite 
five 
performance.  The  particular  efficiency 
ratio  depends 
primarily on the size of the working set relative to L2 cache. 
Zhang et al. [3] propose a software and lightweight approach 
to  accurately  estimate  the  power  usage  of  virtual  machines 
and  cloud  servers. 
It  explores  hypervisor-observable 
performance  metrics  to  build  the  power  usage  model.  To 
configure  cloud  resources,  it  considers  both  the  system 
power  usage  and  the  SLA  requirements,  and  leverage 
learning techniques to achieve autonomic resource allocation 
and  optimal  power  efficiency.  In  this  paper  they  analyzed 

Intel‘s  approximately 

   © 2014 IJRAEM All Rights Reserved                                                                                   20 

Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

energy-efficient  data 

that  it  implements  a  prototype  of  the  proposed  power 
management system and test it on a cloud test bed. Graubner 
et  al.  [4]  a novel  approach  to  virtual  machine  consolidation 
for  saving  energy  is  presented.  In  this  paper  they  analyzed 
that  it  is  based  on  efficient  storage  migration  and  live 
migration  of  virtual  machines  to  take  advantage  of  the 
lacking  energy  proportionality  of  commodity  hardware. 
Dharwar  et  al.  [5]  outlines  the  state-of-the-art  in  power-
management  technology  on  server  hardware  and  describes 
how these raw features can be abstracted into a set of energy 
policies.  In  this  paper  they  analyzed  to  explain  how  these 
policies  or  energy-profiles  can  be  used  to  run  cloud 
datacenter  energy  efficiently.  Kejiang  et  al.  [7]  present  a 
virtual  machine  based 
center 
architecture for cloud computing. It investigates the potential 
performance  overheads  caused  by  server  consolidation  and 
live  migration  of  virtual  machine  technology.  In  this  paper 
they  analyzed  the  experimental  results  show  that  both  the 
two  technologies  can  effectively  implement  energy-saving 
goals  with 
little  performance  overheads.  Efficient 
consolidation  and  migration  strategies  can  improve  the 
energy  efficiency.  Yamini  et  al. 
task 
consolidation particularly in clouds has become an important 
approach  to  streamline  resource  usage  and  in  turn  improve 
energy efficiency. Based on the fact that resource utilization 
directly relates to energy consumption, it has modeled their 
relationship  and  developed 
task 
consolidation heuristics. The cost functions incorporated into 
these 
energy-saving 
possibilities  and  their  capability  has  been  verified  by  my 
evaluation  study.  In  this  paper  they  analyzed  the  results  in 
this  study  should  not  have  only  a  direct  impact  on  the 
reduction  of  electricity  bills  of  cloud 
infrastructure 
providers,  but  also  imply  possible  savings(with  better 
resource  provisioning)  in  other  operational  costs  (e.g.,  rent 
for floor space). 

two  energy-conscious 

[8]  propose 

heuristics 

effectively 

capture 

III. SYSTEM MODEL 

In  the  Figure  1  users  bases  generated  the  requests  for  the 
scheduler  to  get  the  desired  resources  over  internet.  This 
request is further forwarded to broker and following steps are 
followed: 
1.  Virtual  Resources  are  pretreated  before  going 

to 

scheduling. 

2.  All the tasks are put into buffer. 
3.  All  the  N  tasks  are  divided  into  M  classes  and  after 
calculation  a  set  is  being  created  since  larger  tasks  are 
put in one block and smaller tasks in other 

4.  Choose  a task in  each  queue head; there are M tasks in 

5. 

total. 
 M  tasks  are  scheduled  to  clouds  clusters  and  local 
clusters  at  the  same  time,  the  tasks  of  large  amount  of 
calculation  are  scheduled  to  resources  queue  whose 
calculation ability are strong., the tasks of small amount 
of  calculation  are  scheduled  to  resources  queue  whose 
calculation  ability  are  weak,  the  special  tasks  are 
scheduled to special resources queue. 
the  basis  of  cost,  response 

time,  efficiency 
information available  for each virtual machine instance 
resource is allocated in the corresponding queue.  

6.  On 

 

 

Figure 1: Schematic view 

 

IV. SIMULATION RESULTS 

      We  have  implemented  a  custom  simulator to  model  the 
proposed  system.  In  our  study  we  consider  a  maximum  of 
5000 task centers belonging to different CSPs. For simplicity 
we  assume  that  one  CSP  has  only  one  task  center  which 
participates  in  the  federation.  The  simulator  considers  6 
different  geographical  locations  and  randomly  assigns  task 
centers to different locations, such that, the simulator keeps 
the number of resources available at different task centers as 
constant. 
In  Figure  1  we  can  evaluate  that  the  latency  of  different 
locations  have  different  impact  on  the  performance  of 
workload  further  if  we  move  at  the  Probability  distributive 
function  (PDF)  at  Figure  2  we  can  see  that  the  values  at 
which the  different  strategies  are  working and  the  output  is 
coming.  
 

Figure 1: Latency at different Locations (ms) 

 

 

   © 2014 IJRAEM All Rights Reserved                                                                                   21 

Simi Gupta al. International Journal of Research Aspects of Engineering and Management  

ISSN: 2348-6627, Vol. 1, Issue 2, June 2014, pp. 20-22 

Supercomputing  (SC),  Pittsburgh,  PA,  2004,  pp.  47–
58. 

[4]  Deepthi  Dharwar,  Srivatsa  S.  Bhat,  Vaidyanathan 
Srinivasan,  Dipankar  Sarma,  Pradipta  Kumar 
Banerjee,  ―Approaches  towards  energy-efficiency  in 
the  cloud  for  emerging  markets‖in  Proceedings  of 
twenty-first  ACM  SIGOPS  symposium  on  Operating 
systems principles. ACM, 2007, p. 278. 

[5]  Francis Owusu, Colin Pattinson, ―The current state of 
understanding  of  the  energy  efficiency  of  cloud 
computing‖  on  11th  International  Conference  on 
Trust,  Security  and  Privacy 
in  Computing  and 
Communications, IEEE, 2012, pp. 1948 –1953. 

[6]  Kurt  L.  Keville,  Rohan  Garg,  David  J.  Yates,  Kapil 
Arya,  Gene  Cooperman,  ―Towards  Fault-Tolerant 
Energy-Efficient High Performance Computing in the 
Cloud‖, 
International  Conference 
on  Cluster 
Computing, 2012 IEEE, pp.  622-626. 

[7]  Kejiang  Ye,  Xiaohong  Jiang,  Dawei  Huang,  Jianhai 
Chen, Bei Wang ―Live Migration of Multiple Virtual 
Machines  with  Resource  Reservation 
in  Cloud 
Computing Environments‖ IEEE, vol. 4, pp. 422–431, 
2011. 

[8]  Kejiang  Ye,  Dawei  Huang,  Xiaohong  Jiang,  Huajun 
Chen,  Shuang  Wu,  ―Virtual  Machine  Based  Energy-
Efficient  Data  Center  Architecture 
for  Cloud 
Computing:  A  performance  Perspective‖  in  2010 
IEEE/ACM 
International  Conference  on  Green 
Computing and Communications & 2010 IEEE/ACM 
International  Conference  on  Cyber,  Physical  and 
Social Computing, vol. 6161, pp. 172–182. 

[9]  Liang  Zhou,  Baoyu  Zheng,  Jingwu  Cui,  and  Sulan 
Tang,  ―Toward  Green  Service  in  Cloud:  From  the 
Perspective  of  Scheduling‖ 
the 
International  Conference  on  Computing,  Networking 
and Communications, Big Sky, MT, 2009, pp. 1–14 

in  Proc.  of 

Figure 2: Probability distributive Function of Response Time 
 

 

 
Figure 3: Cumulative Distributive Function of Response 

Time 

In Figure 3 we can observe that our strategy process all the 
queries under 8500 ms which is more significant to deal with 
500 queries/second. 

V. CONCLUSION AND FUTURE WORK 

this  work  we  have  evaluated 

that  workload  pre 
In 
assumption  plays  a  significant  role  in  the  management  of 
requests  from  users  end.  Further  the  processing  time  and 
hypervisor monitoring needs to be done in order to get more 
detailed  and  effective  pre-assumption  of  workload  of  a 
virtual machine. 

REFERENCES 

[1]  Andreas  Berl,  Erol  Gelenbe,  Marco  di  Girolamo, 
Giovanni  Giuliani,  Hermann  de  Meer,  Minh  Quan 
Dang  and  Kostas  Pentikousis  ,‖  Energy-Efficient 
Cloud Computing‖ in Advance Access publication on 
August  19,  2009,  Published  by  Oxford  University 
Press on behalf of The British Computer Society. 

[2]  Anton  Beloglazov,  Rajkumar  Buyya,  Young  Choon 
Lee,  and  Albert  Zomaya  ―  A  Taxonomy  and  Survey 
of  Energy-Efficient  Data  Centers  and  Cloud 
Computing  Systems‖  in  Proc.  of  the  ACM/IEEE 
Conf.  on  Supercomputing  (SC),  Seattle,  WA,  2005, 
pp. 1–9. 

[3]  Anton  Beloglazov,  Jemal  Abawajy,  Rajkumar  Buyya 
,‖  Energy-aware  resource  allocation  heuristics  for 
efficient  management  of  data  centers  for  Cloud 
the  ACM/IEEE  Conf.  on 
computing‖  Proc.  of 

   © 2014 IJRAEM All Rights Reserved                                                                                   22 

