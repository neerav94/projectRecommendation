GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)LinearmodelGEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples AvailableGEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

Malware family

Top 5 features

FakeInstaller

DroidKungFu

GoldDream

GingerMaster

Feature s
sendSMS
SEND SMS
android.hardware.telephony
sendTextMessage
READ PHONE STATE

SIG STR
system/bin/su
BATTERY CHANGED ACTION
READ PHONE STATE
getSubscriberId

sendSMS
lebar.gicp.net
DELETE PACKAGES
android.provider.Telephony.SMS RECEIVED
getSubscriberId

USER PRESENT
getSubscriberId
READ PHONE STATE
system/bin/su
HttpPost

Feature set
S7 Suspicious API Call
S2 Requested permissions
S1 Hardware components
S5 Restricted API calls
S2 Requested permissions
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls
S8 Network addresses
S2 Requested permission
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S7 Suspicious API calls
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls

Weight ws
1.12
0.84
0.57
0.52
0.50
2.02
1.30
1.26
0.54
0.49
1.07
0.93
0.58
0.56
0.53
0.67
0.64
0.55
0.44
0.38

Table 3. Top features for the malware families FakeInstaller, DroidKungFu, Geinimi and GingerMaster.

Feature sets

Malware families
I

K

J

L M N

O

P

Q

R

S

T

S1 Hardware components
S2 Requested permissions (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

B

C

E

F

G

H
(cid:88)

A
(cid:88)

(cid:88)

(cid:88)

D
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Table 4. Contribution of the feature sets to the detection of malware families.

10

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

Malware family

Top 5 features

FakeInstaller

DroidKungFu

GoldDream

GingerMaster

Feature s
sendSMS
SEND SMS
android.hardware.telephony
sendTextMessage
READ PHONE STATE

SIG STR
system/bin/su
BATTERY CHANGED ACTION
READ PHONE STATE
getSubscriberId

sendSMS
lebar.gicp.net
DELETE PACKAGES
android.provider.Telephony.SMS RECEIVED
getSubscriberId

USER PRESENT
getSubscriberId
READ PHONE STATE
system/bin/su
HttpPost

Feature set
S7 Suspicious API Call
S2 Requested permissions
S1 Hardware components
S5 Restricted API calls
S2 Requested permissions
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls
S8 Network addresses
S2 Requested permission
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S7 Suspicious API calls
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls

Weight ws
1.12
0.84
0.57
0.52
0.50
2.02
1.30
1.26
0.54
0.49
1.07
0.93
0.58
0.56
0.53
0.67
0.64
0.55
0.44
0.38

Table 3. Top features for the malware families FakeInstaller, DroidKungFu, Geinimi and GingerMaster.

Feature sets

Malware families
I

K

J

L M N

O

P

Q

R

S

T

S1 Hardware components
S2 Requested permissions (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

B

C

E

F

G

H
(cid:88)

A
(cid:88)

(cid:88)

(cid:88)

D
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Table 4. Contribution of the feature sets to the detection of malware families.

10

To analyze the run-time of DREBIN we implement a
standalone Android application that receives a learned de-
tection model and is able to perform the detection process
directly on the smartphone. The size of the downloaded
model is only about 280 kbytes. Using this application we
measure the run-time of DREBIN on different devices us-
ing 100 randomly selected popular applications from the
Google Play Store. For this experiment, we choose de-
vices which cover various widespread hardware conﬁgura-
tions including four smartphone (Nexus 4, Galaxy S3, Xpe-
ria Mini Pro and Nexus 3), a tablet (Nexus 7) and a regular
desktop computer (PC).

Figure 6. Run-time performance of Drebin.

The results are presented in Figure 6. On average,
DREBIN is able to analyze a given application in 10 seconds
on the ﬁve smartphones. Even on older models, such as the
Xperia Mini Pro, the method is able to analyze the applica-
tion in less than 20 seconds on average. Overall, no analysis
takes longer than 1 minute on all devices. On the desktop
computer (2.26 GHz Core 2 Duo with 4GB RAM) DREBIN
achieves a remarkable analysis performance of 750 ms per
application, which enables scanning 100,000 applications
in less than a day.

A detailed run-time analysis for the desktop computer
and the Galaxy S3 smartphone is presented in Figure 7,
where the run-time per application is plotted against the
size of the analyzed code. Surprisingly, on both devices
DREBIN attains a sublinear run-time, that is, its perfor-
mance increases with O(√m) in the number of analyzed
bytes m. Apparently, the number of features does not in-
crease linearly with the code and thus larger applications do
not necessarily contain more features to analyze.

From this evaluation, we conclude that DREBIN does not
only reliably detect malicious applications but is further-
more capable to perform this task in a time which clearly
meets practical requirements.

11

Figure 7. Detailed run-time analysis of Drebin.

4 Limitations

The previous evaluation demonstrates the efﬁcacy of our
method in detecting recent malware on the Android plat-
form. However, DREBIN cannot generally prohibit infec-
tions with malicious applications, as it builds on concepts
of static analysis and lacks the capabilities of a run-time
analysis. Some strains of malware make use of obfusca-
tion or load code dynamically, which hinders any static in-
spection. To alleviate the absence of a dynamic analysis,
DREBIN thus extracts API calls related to obfuscation and
loading of code, such as DexClassLoader.loadClass()
and Cipher.getInstance(). These features enable us to
at least spot the execution of hidden code—even if we can-
not further analyze it. In combinations with other features,
DREBIN is able to identify malware despite the use of some
obfuscation techniques.

To avoid crafting detection patterns manually, we make
use machine learning for generating detection models.
While learning techniques provide a powerful tool for au-
tomatically inferring models,
they require a representa-
tive basis of data for training. That is,
the quality of
the detection model of DREBIN critically depends on the
availability of representative malicious and benign applica-
tions. While it is straightforward to collect benign appli-
cations, gathering recent malware samples requires some
technical effort. Fortunately, methods for ofﬂine analy-
sis, such as DroidRanger [31], AppsPlayground [24] and
RiskRanker [18], might help here to automatically acquire
malware and provide the basis for updating and maintaining
a representative dataset for DREBIN over time.

5 Related Work

The analysis and detection of Android malware has been
a vivid area of research in the last years. Several concepts

PCN4S3XMPN3N7Devices10-1100101102Run-time (sec)10-210-1100101Size of dexcode (MB)10-210-1100101102Run-time (sec)O(n0.45)O(n0.49)Estimate (S3)Estimate (PC)MeasurementsGEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

Malware family

Top 5 features

FakeInstaller

DroidKungFu

GoldDream

GingerMaster

Feature s
sendSMS
SEND SMS
android.hardware.telephony
sendTextMessage
READ PHONE STATE

SIG STR
system/bin/su
BATTERY CHANGED ACTION
READ PHONE STATE
getSubscriberId

sendSMS
lebar.gicp.net
DELETE PACKAGES
android.provider.Telephony.SMS RECEIVED
getSubscriberId

USER PRESENT
getSubscriberId
READ PHONE STATE
system/bin/su
HttpPost

Feature set
S7 Suspicious API Call
S2 Requested permissions
S1 Hardware components
S5 Restricted API calls
S2 Requested permissions
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls
S8 Network addresses
S2 Requested permission
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S7 Suspicious API calls
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls

Weight ws
1.12
0.84
0.57
0.52
0.50
2.02
1.30
1.26
0.54
0.49
1.07
0.93
0.58
0.56
0.53
0.67
0.64
0.55
0.44
0.38

Table 3. Top features for the malware families FakeInstaller, DroidKungFu, Geinimi and GingerMaster.

Feature sets

Malware families
I

K

J

L M N

O

P

Q

R

S

T

S1 Hardware components
S2 Requested permissions (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

B

C

E

F

G

H
(cid:88)

A
(cid:88)

(cid:88)

(cid:88)

D
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Table 4. Contribution of the feature sets to the detection of malware families.

10

To analyze the run-time of DREBIN we implement a
standalone Android application that receives a learned de-
tection model and is able to perform the detection process
directly on the smartphone. The size of the downloaded
model is only about 280 kbytes. Using this application we
measure the run-time of DREBIN on different devices us-
ing 100 randomly selected popular applications from the
Google Play Store. For this experiment, we choose de-
vices which cover various widespread hardware conﬁgura-
tions including four smartphone (Nexus 4, Galaxy S3, Xpe-
ria Mini Pro and Nexus 3), a tablet (Nexus 7) and a regular
desktop computer (PC).

Figure 6. Run-time performance of Drebin.

The results are presented in Figure 6. On average,
DREBIN is able to analyze a given application in 10 seconds
on the ﬁve smartphones. Even on older models, such as the
Xperia Mini Pro, the method is able to analyze the applica-
tion in less than 20 seconds on average. Overall, no analysis
takes longer than 1 minute on all devices. On the desktop
computer (2.26 GHz Core 2 Duo with 4GB RAM) DREBIN
achieves a remarkable analysis performance of 750 ms per
application, which enables scanning 100,000 applications
in less than a day.

A detailed run-time analysis for the desktop computer
and the Galaxy S3 smartphone is presented in Figure 7,
where the run-time per application is plotted against the
size of the analyzed code. Surprisingly, on both devices
DREBIN attains a sublinear run-time, that is, its perfor-
mance increases with O(√m) in the number of analyzed
bytes m. Apparently, the number of features does not in-
crease linearly with the code and thus larger applications do
not necessarily contain more features to analyze.

From this evaluation, we conclude that DREBIN does not
only reliably detect malicious applications but is further-
more capable to perform this task in a time which clearly
meets practical requirements.

11

Figure 7. Detailed run-time analysis of Drebin.

4 Limitations

The previous evaluation demonstrates the efﬁcacy of our
method in detecting recent malware on the Android plat-
form. However, DREBIN cannot generally prohibit infec-
tions with malicious applications, as it builds on concepts
of static analysis and lacks the capabilities of a run-time
analysis. Some strains of malware make use of obfusca-
tion or load code dynamically, which hinders any static in-
spection. To alleviate the absence of a dynamic analysis,
DREBIN thus extracts API calls related to obfuscation and
loading of code, such as DexClassLoader.loadClass()
and Cipher.getInstance(). These features enable us to
at least spot the execution of hidden code—even if we can-
not further analyze it. In combinations with other features,
DREBIN is able to identify malware despite the use of some
obfuscation techniques.

To avoid crafting detection patterns manually, we make
use machine learning for generating detection models.
While learning techniques provide a powerful tool for au-
tomatically inferring models,
they require a representa-
tive basis of data for training. That is,
the quality of
the detection model of DREBIN critically depends on the
availability of representative malicious and benign applica-
tions. While it is straightforward to collect benign appli-
cations, gathering recent malware samples requires some
technical effort. Fortunately, methods for ofﬂine analy-
sis, such as DroidRanger [31], AppsPlayground [24] and
RiskRanker [18], might help here to automatically acquire
malware and provide the basis for updating and maintaining
a representative dataset for DREBIN over time.

5 Related Work

The analysis and detection of Android malware has been
a vivid area of research in the last years. Several concepts

PCN4S3XMPN3N7Devices10-1100101102Run-time (sec)10-210-1100101Size of dexcode (MB)10-210-1100101102Run-time (sec)O(n0.45)O(n0.49)Estimate (S3)Estimate (PC)Measurementsand techniques have been proposed to counter the growing
amount and sophistication of this malware. An overview of
the current malware landscape is provided in the studies of
Felt et al. [14] and Zhou & Jiang [30].

clone without disrupting the functionality of the real device.
The duplication of functionality, however, is involved and
with millions of smartphones in practice operating Para-
noidAndroid at large scale is technically not feasible.

Detection using static analysis. The ﬁrst approaches for
detecting Android malware have been inspired by concepts
from static program analysis. Several methods have been
proposed that statically inspect applications and disassem-
ble their code [e.g., 10, 11, 13, 18]. For example, the
method Kirin [11] checks the permission of applications for
indications of malicious activity. Similarly, Stowaway [13]
analyzes API calls to detect overprivileged applications and
RiskRanker [18] statically identiﬁes applications with dif-
ferent security risks. Common open-source tools for static
analysis are Smali [15] and Androguard [8], which enable
dissecting the content of applications with little effort.

Our method DREBIN builds on similar concepts for static
analysis. However, it differs in two central aspects from pre-
vious work: First, we abstain from crafting detection pat-
terns manually and instead apply machine learning to an-
alyze information extracted from static analysis. Second,
the analysis of DREBIN is optimized for effectivity and ef-
ﬁciency, which enables us to inspect application directly on
the smartphone.

Detection using dynamic analysis. A second branch of
research has studied the detection of Android malware at
run-time. Most notably, are the analysis system Taint-
Droid [9] and DroidScope [29] that enable dynamically
monitoring applications in a protected environment, where
the ﬁrst focuses on taint analysis and the later enables intro-
spection at different layers of the platform. While both sys-
tems provide detailed information about the behavior of ap-
plications, they are technically too involved to be deployed
on smartphones and detect malicious software directly.

As a consequence, dynamic analysis is mainly applied
for ofﬂine detection of malware, such as scanning large col-
lections of Android applications. For example, the meth-
ods DroidRanger [31] and AppsPlayground [24] have been
successfully applied to identify applications with malicious
behavior in different Android markets. A similar detec-
tion system called Bouncer is currently operated by Google.
These dynamic analysis systems are suitable for ﬁltering
malicious applications from markets. Due to the openness
of the Android platform, however, applications may also be
retrieved from other sources, such as web pages, which are
not covered by these approaches.

ParanoidAndroid [23] is one of the few detection sys-
tems that employs dynamic analysis and can spot malicious
activity on the smartphone. To this end, a virtual clone of
the smartphone is run in parallel on a dedicated server and
synchronized with the activities of the device. This setting
allows for monitoring the behavior of applications on the

Detection using machine learning. The difﬁculty of
manually crafting and updating detection patterns for An-
droid malware has motivated the application of machine
learning techniques.
Several methods have been pro-
posed that analyze applications automatically using learn-
ing methods [e.g., 2, 22, 26]. As an example, the method
of Peng et al. [22] applies probabilistic learning methods
to the permissions of applications for detecting malware.
Similarly, the methods Crowdroid [4], DroidMat [28] and
DroidAPIMiner[1] analyze the usage of system and API
calls using machine learning techniques.

All of these approaches mainly focus on an accurate de-
tection of malware. Additional aspects, such as the efﬁ-
ciency and the explainability of the detection, are not con-
sidered. We address these aspects in this work and propose
a method that provides an effective, efﬁcient and explain-
able detection of malicious applications.

6 Conclusion

Android malware is a new yet fast growing threat.
Classic defenses, such as anti-virus scanners, increasingly
fail to cope with the amount and diversity of malware in
application markets. While recent approaches, such as
DroidRanger [31] and AppPlayground [24], support ﬁl-
tering such applications off these markets, they induce a
run-time overhead that is prohibitive for directly protect-
ing smartphones. As a remedy, we introduce DREBIN,
a lightweight method for detection of Android malware.
DREBIN combines concepts from static analysis and ma-
chine learning, which enables it to better keep pace with
malware development. Our evaluation demonstrates the po-
tential of this approach, where DREBIN outperforms related
approaches and identiﬁes malicious applications with few
false alarms.

In practice, DREBIN provides two advantages for the se-
curity of the Android platform: First, it enables efﬁciently
scanning large amounts of applications, such as from third-
party markets. With an average run-time of 750 ms per ap-
plication on a regular computer, it requires less than a day to
analyze 100,000 unknown applications. Second, DREBIN
can be applied directly on smartphones, where the analysis
can be triggered when new applications are downloaded to
the device. Thereby, DREBIN can protect users that install
applications from untrusted sources, such as websites and
third-party markets.

Although DREBIN effectively identiﬁes malicious soft-
ware in our evaluation, it exhibits the inherent limitations

12

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

Malware family

Top 5 features

FakeInstaller

DroidKungFu

GoldDream

GingerMaster

Feature s
sendSMS
SEND SMS
android.hardware.telephony
sendTextMessage
READ PHONE STATE

SIG STR
system/bin/su
BATTERY CHANGED ACTION
READ PHONE STATE
getSubscriberId

sendSMS
lebar.gicp.net
DELETE PACKAGES
android.provider.Telephony.SMS RECEIVED
getSubscriberId

USER PRESENT
getSubscriberId
READ PHONE STATE
system/bin/su
HttpPost

Feature set
S7 Suspicious API Call
S2 Requested permissions
S1 Hardware components
S5 Restricted API calls
S2 Requested permissions
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls
S8 Network addresses
S2 Requested permission
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S7 Suspicious API calls
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls

Weight ws
1.12
0.84
0.57
0.52
0.50
2.02
1.30
1.26
0.54
0.49
1.07
0.93
0.58
0.56
0.53
0.67
0.64
0.55
0.44
0.38

Table 3. Top features for the malware families FakeInstaller, DroidKungFu, Geinimi and GingerMaster.

Feature sets

Malware families
I

K

J

L M N

O

P

Q

R

S

T

S1 Hardware components
S2 Requested permissions (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

B

C

E

F

G

H
(cid:88)

A
(cid:88)

(cid:88)

(cid:88)

D
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Table 4. Contribution of the feature sets to the detection of malware families.

10

To analyze the run-time of DREBIN we implement a
standalone Android application that receives a learned de-
tection model and is able to perform the detection process
directly on the smartphone. The size of the downloaded
model is only about 280 kbytes. Using this application we
measure the run-time of DREBIN on different devices us-
ing 100 randomly selected popular applications from the
Google Play Store. For this experiment, we choose de-
vices which cover various widespread hardware conﬁgura-
tions including four smartphone (Nexus 4, Galaxy S3, Xpe-
ria Mini Pro and Nexus 3), a tablet (Nexus 7) and a regular
desktop computer (PC).

Figure 6. Run-time performance of Drebin.

The results are presented in Figure 6. On average,
DREBIN is able to analyze a given application in 10 seconds
on the ﬁve smartphones. Even on older models, such as the
Xperia Mini Pro, the method is able to analyze the applica-
tion in less than 20 seconds on average. Overall, no analysis
takes longer than 1 minute on all devices. On the desktop
computer (2.26 GHz Core 2 Duo with 4GB RAM) DREBIN
achieves a remarkable analysis performance of 750 ms per
application, which enables scanning 100,000 applications
in less than a day.

A detailed run-time analysis for the desktop computer
and the Galaxy S3 smartphone is presented in Figure 7,
where the run-time per application is plotted against the
size of the analyzed code. Surprisingly, on both devices
DREBIN attains a sublinear run-time, that is, its perfor-
mance increases with O(√m) in the number of analyzed
bytes m. Apparently, the number of features does not in-
crease linearly with the code and thus larger applications do
not necessarily contain more features to analyze.

From this evaluation, we conclude that DREBIN does not
only reliably detect malicious applications but is further-
more capable to perform this task in a time which clearly
meets practical requirements.

11

Figure 7. Detailed run-time analysis of Drebin.

4 Limitations

The previous evaluation demonstrates the efﬁcacy of our
method in detecting recent malware on the Android plat-
form. However, DREBIN cannot generally prohibit infec-
tions with malicious applications, as it builds on concepts
of static analysis and lacks the capabilities of a run-time
analysis. Some strains of malware make use of obfusca-
tion or load code dynamically, which hinders any static in-
spection. To alleviate the absence of a dynamic analysis,
DREBIN thus extracts API calls related to obfuscation and
loading of code, such as DexClassLoader.loadClass()
and Cipher.getInstance(). These features enable us to
at least spot the execution of hidden code—even if we can-
not further analyze it. In combinations with other features,
DREBIN is able to identify malware despite the use of some
obfuscation techniques.

To avoid crafting detection patterns manually, we make
use machine learning for generating detection models.
While learning techniques provide a powerful tool for au-
tomatically inferring models,
they require a representa-
tive basis of data for training. That is,
the quality of
the detection model of DREBIN critically depends on the
availability of representative malicious and benign applica-
tions. While it is straightforward to collect benign appli-
cations, gathering recent malware samples requires some
technical effort. Fortunately, methods for ofﬂine analy-
sis, such as DroidRanger [31], AppsPlayground [24] and
RiskRanker [18], might help here to automatically acquire
malware and provide the basis for updating and maintaining
a representative dataset for DREBIN over time.

5 Related Work

The analysis and detection of Android malware has been
a vivid area of research in the last years. Several concepts

PCN4S3XMPN3N7Devices10-1100101102Run-time (sec)10-210-1100101Size of dexcode (MB)10-210-1100101102Run-time (sec)O(n0.45)O(n0.49)Estimate (S3)Estimate (PC)Measurementsand techniques have been proposed to counter the growing
amount and sophistication of this malware. An overview of
the current malware landscape is provided in the studies of
Felt et al. [14] and Zhou & Jiang [30].

clone without disrupting the functionality of the real device.
The duplication of functionality, however, is involved and
with millions of smartphones in practice operating Para-
noidAndroid at large scale is technically not feasible.

Detection using static analysis. The ﬁrst approaches for
detecting Android malware have been inspired by concepts
from static program analysis. Several methods have been
proposed that statically inspect applications and disassem-
ble their code [e.g., 10, 11, 13, 18]. For example, the
method Kirin [11] checks the permission of applications for
indications of malicious activity. Similarly, Stowaway [13]
analyzes API calls to detect overprivileged applications and
RiskRanker [18] statically identiﬁes applications with dif-
ferent security risks. Common open-source tools for static
analysis are Smali [15] and Androguard [8], which enable
dissecting the content of applications with little effort.

Our method DREBIN builds on similar concepts for static
analysis. However, it differs in two central aspects from pre-
vious work: First, we abstain from crafting detection pat-
terns manually and instead apply machine learning to an-
alyze information extracted from static analysis. Second,
the analysis of DREBIN is optimized for effectivity and ef-
ﬁciency, which enables us to inspect application directly on
the smartphone.

Detection using dynamic analysis. A second branch of
research has studied the detection of Android malware at
run-time. Most notably, are the analysis system Taint-
Droid [9] and DroidScope [29] that enable dynamically
monitoring applications in a protected environment, where
the ﬁrst focuses on taint analysis and the later enables intro-
spection at different layers of the platform. While both sys-
tems provide detailed information about the behavior of ap-
plications, they are technically too involved to be deployed
on smartphones and detect malicious software directly.

As a consequence, dynamic analysis is mainly applied
for ofﬂine detection of malware, such as scanning large col-
lections of Android applications. For example, the meth-
ods DroidRanger [31] and AppsPlayground [24] have been
successfully applied to identify applications with malicious
behavior in different Android markets. A similar detec-
tion system called Bouncer is currently operated by Google.
These dynamic analysis systems are suitable for ﬁltering
malicious applications from markets. Due to the openness
of the Android platform, however, applications may also be
retrieved from other sources, such as web pages, which are
not covered by these approaches.

ParanoidAndroid [23] is one of the few detection sys-
tems that employs dynamic analysis and can spot malicious
activity on the smartphone. To this end, a virtual clone of
the smartphone is run in parallel on a dedicated server and
synchronized with the activities of the device. This setting
allows for monitoring the behavior of applications on the

Detection using machine learning. The difﬁculty of
manually crafting and updating detection patterns for An-
droid malware has motivated the application of machine
learning techniques.
Several methods have been pro-
posed that analyze applications automatically using learn-
ing methods [e.g., 2, 22, 26]. As an example, the method
of Peng et al. [22] applies probabilistic learning methods
to the permissions of applications for detecting malware.
Similarly, the methods Crowdroid [4], DroidMat [28] and
DroidAPIMiner[1] analyze the usage of system and API
calls using machine learning techniques.

All of these approaches mainly focus on an accurate de-
tection of malware. Additional aspects, such as the efﬁ-
ciency and the explainability of the detection, are not con-
sidered. We address these aspects in this work and propose
a method that provides an effective, efﬁcient and explain-
able detection of malicious applications.

6 Conclusion

Android malware is a new yet fast growing threat.
Classic defenses, such as anti-virus scanners, increasingly
fail to cope with the amount and diversity of malware in
application markets. While recent approaches, such as
DroidRanger [31] and AppPlayground [24], support ﬁl-
tering such applications off these markets, they induce a
run-time overhead that is prohibitive for directly protect-
ing smartphones. As a remedy, we introduce DREBIN,
a lightweight method for detection of Android malware.
DREBIN combines concepts from static analysis and ma-
chine learning, which enables it to better keep pace with
malware development. Our evaluation demonstrates the po-
tential of this approach, where DREBIN outperforms related
approaches and identiﬁes malicious applications with few
false alarms.

In practice, DREBIN provides two advantages for the se-
curity of the Android platform: First, it enables efﬁciently
scanning large amounts of applications, such as from third-
party markets. With an average run-time of 750 ms per ap-
plication on a regular computer, it requires less than a day to
analyze 100,000 unknown applications. Second, DREBIN
can be applied directly on smartphones, where the analysis
can be triggered when new applications are downloaded to
the device. Thereby, DREBIN can protect users that install
applications from untrusted sources, such as websites and
third-party markets.

Although DREBIN effectively identiﬁes malicious soft-
ware in our evaluation, it exhibits the inherent limitations

12

of static analysis. While it is able to detect indications of
obfuscation or dynamic execution, the retrieved code is not
accessible by the method. A similar setting has been suc-
cessfully tackled for the analysis of JavaScript code [see 7]
and dynamically triggering the static analysis of DREBIN
whenever new code is loaded seems like a promising direc-
tion of future work.

References

[1] Y. Aafer, W. Du, and H. Yin. DroidAPIMiner: Min-
ing API-level features for robust malware detection in
android. In Proc. of International Conference on Se-
curity and Privacy in Communication Networks (Se-
cureComm), 2013.

[2] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and
A. Somayaji. A methodology for empirical analysis
of permission-based security models and its applica-
tion to android. In Proc. of ACM Conference on Com-
puter and Communications Security (CCS), pages 73–
84, 2010.

[3] B. Bloom.

Space/time trade-offs in hash coding
with allowable errors. Communication of the ACM,
13(7):422–426, 1970.

[4] I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani.
Crowdroid: behavior-based malware detection system
for android.
In Proc. of ACM Worksgop on Secu-
rity and Privacy in Smartphones and Mobile Devices
(SPSM), pages 15–26, 2011.

[5] T. Cormen, C. Leiserson, and R. Rivest. Introduction

to Algorithms. MIT Press, 1989.

[6] N. Cristianini and J. Shawe-Taylor. An Introduction
to Support Vector Machines. Cambridge University
Press, Cambridge, UK, 2000.

[7] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert.
Zozzle: Fast and precise in-browser JavaScript mal-
ware detection. In Proc. of USENIX Security Sympo-
sium, 2011.

[8] A. Desnos and G. Gueguen. Android: From reversing
In Presentation at Black Hat Abu

to decompilation.
Dhabi, 2011.

[10] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri.
A study of Android application security. In Proc. of
USENIX Security Symposium, 2011.

[11] W. Enck, M. Ongtang, and P. D. McDaniel. On
lightweight mobile phone application certiﬁcation. In
Proc. of ACM Conference on Computer and Commu-
nications Security (CCS), pages 235–245, 2009.

[12] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang,
and C.-J. Lin. LIBLINEAR: A library for large linear
classiﬁcation. Journal of Machine Learning Research
(JMLR), 9:1871–1874, 2008.

[13] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.
Android permissions demystiﬁed.
In Proc. of ACM
Conference on Computer and Communications Secu-
rity (CCS), pages 627–638, 2011.

[14] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wag-
ner. A survey of mobile malware in the wild.
In
Proc. of ACM Worksgop on Security and Privacy in
Smartphones and Mobile Devices (SPSM), pages 3–
14, 2011.

[15] J. Freke. An assembler/disassembler for android’s dex
format. Google Code, http://code.google.
com/p/smali/, visited February, 2013.

[16] Mobile threat report 2012 q3. F-Secure Response

Labs, 2012.

[17] 2012.

http://www.naked-security.com/

malware/Android.Gappusin/.

[18] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang.
Riskranker: scalable and accurate zero-day android
malware detection. In Proc. of International Confer-
ence on Mobile Systems, Applications, and Services
(MOBISYS), pages 281–294, 2012.

[19] X. Jiang.

Security alert: Gingermaster, 2011.

http://www.csc.ncsu.edu/faculty/
jiang/GingerMaster/.

[20] X. Jiang.

Security alert: Golddream, 2011.

http://www.csc.ncsu.edu/faculty/
jiang/GoldDream/.

[21] X.

Jiang.

Security alert: New droidkungfu
http://www.csc.ncsu.edu/

variant, 2011.
faculty/jiang/DroidKungFu3/.

[9] W. Enck, P. Gilbert, B. gon Chun, L. P. Cox,
J. Jung, P. McDaniel, and A. Sheth. Taintdroid: An
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In Proc. of USENIX Sym-
posium on Operating Systems Design and Implemen-
tation (OSDI), pages 393–407, 2010.

[22] H. Peng, C. S. Gates, B. P. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy. Us-
ing probabilistic generative models for ranking risks
of android apps.
In Proc. of ACM Conference on
Computer and Communications Security (CCS), pages
241–252, 2012.

13

GEORG-AUGUST-UNIVERSIT ¨AT G ¨OTTINGEN
INSTITUTE OF COMPUTER SCIENCE

Technical Report IFI-TB-2013-02

DREBIN: Efﬁcient and Explainable Detection of

Android Malware in Your Pocket

Daniel Arp, Michael Spreitzenbarth, Malte H¨ubner,

Hugo Gascon, and Konrad Rieck

TECHNICAL REPORTS OF THE

INSTITUTE OF COMPUTER SCIENCE

ISSN 1611-1044

AUGUST 2013

Georg-August-Universit¨at G¨ottingen
Institute of Computer Science

Goldschmidtstr. 7
37077 G¨ottingen
Germany

Phone: +49 (551) 39 - 172000
Fax: +49 (551) 39 - 14403
E-Mail: ofﬁce@cs.uni-goettingen.de
WWW: www.iﬁ.informatik.uni-goettingen.de

DREBIN: Effective and Explainable Detection

of Android Malware in Your Pocket

Daniel Arp

University of G¨ottingen

G¨ottingen, Germany

Michael Spreitzenbarth

Siemens AG

M¨unchen, Germany

Malte H¨ubner

University of G¨ottingen

G¨ottingen, Germany

Hugo Gascon

University of G¨ottingen

G¨ottingen, Germany

Konrad Rieck

University of G¨ottingen

G¨ottingen, Germany

Abstract

Malicious applications pose a threat to the security of
the Android platform. The growing amount and diversity
of these applications render conventional defenses largely
ineffective and thus Android smartphones often remain un-
protected from novel malware. In this paper, we propose
DREBIN, a lightweight method for detection of Android
malware that enables identifying malicious applications di-
rectly on the smartphone. As the limited resources impede
monitoring applications at run-time, DREBIN performs a
broad static analysis, gathering as many features of an ap-
plication as possible. These features are embedded in a
joint vector space, such that typical patterns indicative for
malware can be automatically identiﬁed and used for ex-
plaining the decisions of our method. In an evaluation with
123,453 applications and 5,560 malware samples DREBIN
outperforms several related approaches and detects 94%
of the malware with few false alarms, where the explana-
tions provided for each detection reveal relevant properties
of the detected malware. On ﬁve popular smartphones, the
method requires 10 seconds for an analysis on average, ren-
dering it suitable for checking downloaded applications di-
rectly on the device.

1

Introduction

Android is one of the most popular platforms for smart-
phones today. With several hundred thousands of appli-
cations in different markets, it provides a wealth of func-
tionality to its users. Unfortunately, smartphones running
Android are increasingly targeted by attackers and infected
with malicious software.
In contrast to other platforms,
Android allows for installing applications from unveriﬁed
sources, such as third-party markets, which makes bundling

and distributing applications with malware easy for attack-
ers. According to a recent study [16] over 55,000 malicious
applications and 119 new malware families have been dis-
covered in 2012 alone. It is evident that there is a need for
stopping the proliferation of malware on Android markets
and smartphones.

The Android platform provides several security mea-
sures that harden the installation of malware, most notably
the Android permission system. To perform certain tasks
on the device, such as sending a SMS message, each ap-
plication has to explicitly request permission from the user
during the installation. However, many users tend to blindly
grant permissions to unknown applications and thereby un-
dermine the purpose of the permission system. As a con-
sequence, malicious applications are hardly constrained by
the Android permission system in practice.

A large body of research has thus studied methods for
analyzing and detecting Android malware prior to their in-
stallation. These methods can be roughly categorized into
approaches using static and dynamic analysis. For exam-
ple, TaintDroid [9], DroidRanger [31] and DroidScope [29]
are methods that can monitor the behavior of applications at
run-time. Although very effective in identifying malicious
activity, run-time monitoring suffers from a signiﬁcant over-
head and can not be directly applied on mobile devices. By
contrast, static analysis methods, such as Kirin [11], Stow-
away [13], RiskRanker [18] or regular anti-virus scanners,
usually induce only a short run-time burst. While these
approaches are efﬁcient and scalable, they mainly build
on manually crafted detection patterns which are often not
available for new malware instances. Moreover, most of
these methods do not provide explanations for their deci-
sions and are thus opaque to the practitioner.

In this paper, we propose DREBIN, a lightweight method
for detection of Android malware that infers detection pat-
terns automatically and enables identifying malware di-

1

Figure 1. Schematic depiction of the analysis steps performed by Drebin.

rectly on the smartphone. DREBIN performs a broad static
analysis, gathering as many features from an application’s
code and manifest as possible. These features are organized
in sets of strings (such as permissions, intents, API calls and
network addresses) and embedded in a joint vector space.
As an example, an application sending premium SMS mes-
sages is cast to a speciﬁc region in the vector space associ-
ated with the corresponding permissions, intents and API
calls. This geometric representation enables DREBIN to
identify combinations and patterns of features indicative for
malware automatically using machine learning techniques.
For each detected application the respective patterns can be
extracted, mapped to meaningful descriptions and then pro-
vided to the user as explanation for the detection. Aside
from detection, DREBIN can thus also provide insights into
identiﬁed malware samples.

Experiments with 123,453 applications from different
markets and 5,560 recent malware samples demonstrate the
efﬁcacy of our method: DREBIN outperforms related ap-
proaches [11, 22, 26] as well 9 out of 10 popular anti-virus
scanners. The method detects 94% of the malware samples
with a false-positive rate of 1%, corresponding to one false
alarm in 100 installed applications. On average the analysis
of an application requires less than a second on a regular
computer and 10 seconds on popular smartphone models.
To the best of our knowledge, DREBIN is the ﬁrst method
which provides effective and explainable detection of An-
droid malware directly on smartphone devices.

In summary, we make the following contributions to the

detection of Android malware in this paper:

• Effective detection. We introduce a method combining
static analysis and machine learning that is capable of
identifying Android malware with high accuracy and
few false alarms, independent of manually crafted de-
tection patterns.

• Explainable results. The proposed method provides
an explainable detection. Patterns of features indica-
tive for a detected malware instance can be traced back
from the vector space and provide insights into the de-
tection process.

• Lightweight analysis. For efﬁciency we apply linear-

2

time analysis and learning techniques that enable de-
tecting malware directly on the smartphone as well as
analyzing large sets of applications in reasonable time.

We need to note here that DREBIN builds on concepts of
static analysis and thus cannot rule out the presence of ob-
fuscated or dynamically loaded malware on mobile devices.
We speciﬁcally discuss this limitation of our approach in
Section 4. Due to the broad analysis of features however,
our method raises the bar for attackers to infect smartphones
with malicious applications and strengthens the security of
the Android platform, as demonstrated in our evaluation.

The rest of this paper is organized as follows: DREBIN
and its detection methodology are introduced in Section 2.
Experiments and a comparison with related approaches are
presented in Section 3. Limitations and related work are
discussed in Section 4 and Section 5, respectively. Section 6
concludes.

2 Methodology

To detect malicious software on a smartphone, DREBIN
requires a comprehensive yet lightweight representation of
applications that enables determining typical indications of
malicious activity. To this end, the method employs a
broad static analysis that extracts feature sets from different
sources and analyzes these in an expressive vector space.
This process is illustrated in Figure 1 and outlined in the
following:

1. Static analysis. In the ﬁrst step, DREBIN statically in-
spects a given Android application and extracts differ-
ent feature sets from the application’s manifest and dex
code (Section 2.1).

2. Embedding in vector space. The extracted feature sets
are then mapped to a joint vector space, where patterns
and combinations of the features can be analyzed geo-
metrically (Section 2.2).

3. Learning-based detection. The embedding of appli-
cations enables us to identify malware using efﬁcient
learning techniques, such as linear Support Vector Ma-
chines (Section 2.3).

Android app(apk)Used permissionsSuspicious API callsFeature sets...Network addresses(a) Broad static analysis(b) Embedding in vector space(c) Learning-based detectionMalicious (+)(d) ExplanationUsed permissionsSuspicious API callsFeature sets...Network addressesBenign (–)Linearmodel4. Explanation. In the last step, features contributing to
the detection of a malicious application are extracted
and presented to the user for explaining the detection
process (Section 2.4).

In the following sections, we discuss these four steps in
more detail and provide necessary technical background of
the analysis.

2.1 Static Analysis of Applications

As the ﬁrst step, DREBIN performs a lightweight static
analysis of a given Android application. Although appar-
ently straightforward, the static extraction of features needs
to run in a constrained environment and complete in a
timely manner. If the analysis takes too long, the user might
skip the ongoing process and refuse the overall method. Ac-
cordingly, it becomes essential to select features which can
be extracted efﬁciently.

We thus focus on the manifest and the disassembled dex
code of the application, which both can be obtained by a
linear sweep over the application’s content. To allow for a
generic and extensible analysis, we represent all extracted
features as sets of strings, such as permissions, API calls
and network addresses. In particular, we extract the follow-
ing 8 sets of strings.
Feature sets from the manifest Every application devel-
oped for Android must include a manifest ﬁle called An-
droidManifest.xml which provides data supporting the in-
stallation and later execution of the application. The infor-
mation stored in this ﬁle can be efﬁciently retrieved on the
device using the Android Asset Packaging Tool that enables
us to extract the following sets:

S1 Hardware components: This ﬁrst feature set contains
requested hardware components. If an application re-
quests access to the camera, touchscreen or the GPS
module of the smartphone, these features need to be
declared in the manifest ﬁle. Requesting access to spe-
ciﬁc hardware has clearly security implications, as the
use of certain combinations of hardware often reﬂect
harmful behavior. An application which has access to
GPS and network modules is, for instance, able to col-
lect location data and exﬁltrate it to an attacker.

S2 Requested permissions: One of the most important se-
curity mechanisms introduced in Android is the per-
mission system. Permissions are actively granted by
the user at installation time and allow an application to
access security-relevant resources. As shown by previ-
ous work, malicious software tends to request certain
permissions more often than innocuous applications.
For example, a great percentage of current malware
sends premium SMS messages and thus requests the

SEND SMS permission. We thus gather all permissions
listed in the manifest in a feature set.

S3 App components: There exist four different types of
components in an application, each deﬁning different
interfaces to the system: activities, services, content
providers and broadcast receivers. Every application
can declare several components of each type in the
manifest. The names of these components are also
collected in a feature set, as the names may help to
identify well-known components of malware. For ex-
ample, several variants of the malware family Droid-
KungFu share the name of particular services [see 21].

S4 Filtered intents: Inter-process and intra-process com-
munication on Android is mainly performed through
intents: passive data structures exchanged as asyn-
chronous messages and allowing information about
events to be shared between different components and
applications. We collect all intents listed in the mani-
fest as another feature set, as malware often listens to
speciﬁc intents. A typical example of an intent mes-
sage involved in malware is BOOT COMPLETED, which
is used to trigger malicious activity directly after re-
booting the smartphone.

Feature sets from disassembled code Android applica-
tions are developed in Java and compiled into optimized
bytecode for the Dalvik virtual machine. This bytecode can
be efﬁciently disassembled and provides DREBIN with in-
formation about API calls and data used in an application.
To achieve a low run-time, we implement a lightweight dis-
assembler based on the dex libraries of the Android plat-
form that can output all API calls and strings contained in
an application. We use this information to construct the fol-
lowing feature sets.

S5 Restricted API calls: The Android permission system
restricts access to a series of critical API calls. Our
method searches for the occurrence of these calls in
the disassembled code in order to gain a deeper under-
standing of the functionality of an application. A par-
ticular case, revealing malicious behavior, is the use of
restricted API calls for which the required permissions
have not been requested. This may indicate that the
malware is using root exploits in order to surpass the
limitations imposed by the Android platform.

S6 Used permissions: The complete set of calls extracted
in S5 is used as the ground for determining the sub-
set of permissions that are both requested and actually
used. For this purpose, we implement the method in-
troduced by Felt et al. [13] to match API calls and per-
missions. In contrast to S5, this feature set provides
a more general view on the behavior of an application

3

as multiple API calls can be protected by a single per-
mission (e.g., sendMultipartTextMessage() and
sendTextMessage() both require that the SEND SMS
permission is granted to an application).

S7 Suspicious API calls: Certain API calls allow access to
sensitive data or resources of the smartphone and are
frequently found in malware samples. As these calls
can specially lead to malicious behavior, they are ex-
tracted and gathered in a separated feature set. In par-
ticular, we collect the following types of API calls:

(a) API calls for accessing sensitive data, such as

getDeviceId(), and getSubscriberId()

(b) API calls for communication over

the net-
work, for example execHttpRequest() and
setWifiEnabled().

(c) API calls for sending and receiving SMS mes-

sages, such as sendTextMessage()

(d) API calls for execution of external commands

like Runtime.exec()

(e) API calls frequently used for obfuscation, such

as Cipher.getInstance()

S8 Network addresses: Malware regularly establishes net-
work connections to retrieve commands or exﬁltrate
data collected from the device. Therefore, all IP ad-
dresses, hostnames and URLs found in the disassem-
bled code are included in the last set of features. Some
of these addresses might be involved in botnets and
thus present in several malware samples, which can
help to improve the learning of detection patterns.

We ensure that elements of different sets do not collide by
adding a unique preﬁx to all strings in each feature set. In
our evaluation the set S contains roughly 545,000 different
features (see Section 3).

Using the set S, we deﬁne an |S|-dimensional vector
space, where each dimension is either 0 or 1. An appli-
cation x is mapped to this space by constructing a vector
ϕ(x), such that for each feature s extracted from x the re-
spective dimension is set to 1 and all other dimensions are 0.
Formally, this map ϕ can be deﬁned for a set of applications
X as follows

ϕ : X → {0, 1}

|S|, ϕ(x) (cid:55)→

(cid:0)I(x, s)(cid:1)

s∈S

(cid:40)

where the indicator function I(x, s) is simply deﬁned as

I(x, s) =

1
0

if the application x contains feature s
otherwise.

Applications sharing similar features lie close to each other
in this representation, whereas applications with mainly dif-
ferent features are separated by large distances. Moreover,
directions in this space can be used to describe combina-
tions of features and ultimately enable us to learn explain-
able detection models.

Let us, as an example, consider a malicious application
that sends premium SMS messages and thus needs to re-
quest certain permissions and hardware components. A cor-
responding vector ϕ(x) for this application looks like this

···
android.hardware.wifi
android.hardware.telephony
···
SEND SMS
DELETE PACKAGES

(cid:27)
(cid:27)

S1

S2





···0

1

···1

0
···

2.2 Embedding in Vector Space

ϕ(x) (cid:55)→

Malicious activity is usually reﬂected in speciﬁc patterns
and combinations of the extracted features. For example, a
malware sending premiums SMS messages might contain
the permission SEND SMS in set S2, and the hardware com-
ponent android.hardware.telephony in set S1.
Ide-
ally, we would like to formulate Boolean expressions that
capture these dependencies between features and return true
if a malware is detected. However, inferring Boolean ex-
pressions from real-world data is a hard problem and difﬁ-
cult to solve efﬁciently.

As a remedy, we aim at capturing the dependencies be-
tween features using concepts from machine learning. As
most learning methods operate on numerical vectors, we
ﬁrst need to map the extracted feature sets to a vector space.
To this end, we deﬁne a joint set S that comprises all ob-
servable strings contained in the 8 feature sets

S := S1 ∪ S2 ∪ ··· ∪ S8.

···
At a ﬁrst glance, the map ϕ seems inappropriate for the
lightweight analysis of applications, as it embeds data into
a high-dimensional vector space. Fortunately, the num-
ber of features extracted from an application is linear in
its size. That is, an application x containing m bytes of
code and data contains at most m feature strings. As a
consequence, only m dimensions are non-zero in the vec-
tor ϕ(x)—irrespective of the dimension of the vector space.
It thus sufﬁces to only store the features extracted from an
application for sparsely representing the vector ϕ(x), for
example, using hash tables [5] or Bloom ﬁlters [3].

2.3 Learning-based Detection

In the third step, we apply machine learning techniques
for automatically learning a separation between malicious

4

and benign applications. The application of machine learn-
ing spares us from manually constructing detection rules for
the extracted features.

While several learning methods can be applied to learn
a separation between two classes, only few methods are ca-
pable of producing an efﬁcient and explainable detection
model. We consider linear Support Vector Machines [SVM;
6, 12] for this task. Given vectors of two classes as training
data, a linear SVM determines a hyperplane that separates
both classes with maximal margin. In our setting, one of
these classes is associated with malware, whereas the other
class corresponds to benign applications. An unknown ap-
plication is classiﬁed by mapping it to the vector space and
checking if it falls on the malicious (+) or benign (−) side
of the hyperplane.

Figure 2. A separating hyperplane with maxi-
mum margin (SVM).

Formally, the detection model of a linear SVM simply
corresponds to a vector w specifying the direction of the
hyperplane, where the corresponding detection function f
is given by

f (x) = (cid:104)ϕ(x), w(cid:105) =

I(x, s) · ws

(cid:88)

s∈S

and returns the orientation of ϕ(x) with respect to the hy-
perplane. That is, f (x) > t indicates malicious activity,
while f (x) ≤ t corresponds to benign applications for a
given threshold t.
To compute the function f efﬁciently, we again exploit
the sparse representation of the map ϕ. Given an application
x, we know that only features extracted from x have non-
zero entries in ϕ(x). All other dimensions are zero and do
not contribute to the computation of f (x). Hence, we can
simplify the detection function f as follows

(cid:88)

s∈S

f (x) =

(cid:88)

s∈x

I(x, s) · ws =

ws.

Instead of an involved learning model, we ﬁnally arrive at
simple sum that can be efﬁciently computed by just adding
the weight ws for each feature s in an application x. This
formulation enables us to apply a learned detection model
on a smartphone and also allows us to explain results ob-
tained by the SVM.

5

Ofﬂine learning.
In our implementation we do not learn
a detection model on the smartphone. Instead, we train the
Support Vector Machine ofﬂine on a dedicated system and
only transfer the learned model w to the smartphone for de-
tecting malicious applications.

2.4 Explanation

In practice, a detection system must not only indicate
malicious activity, but also provide explanations for its de-
tection results.
It is a common shortcoming of learning-
based approaches that they are black-box methods [27]. In
the case of DREBIN, we address this problem and extend
our learning-based detection, such that it can identify fea-
tures of an application that contribute to a detection. More-
over, an explainable detection may also help researchers to
inspect patterns in malware and gain a deeper understanding
of its functionality.

By virtue of the simple detection function of the linear
SVM, we are able to determine the contribution of each sin-
gle feature s to the function f (x). During the computation
of f (x), we just need to store the largest k weights ws shift-
ing the application to the malicious side of the hyperplane.
Since each weight ws is assigned to a certain feature s, it is
then possible to explain why an application has been clas-
siﬁed as malicious or not. This approach can be efﬁciently
realized by maintaining the k largest weights ws in a heap
during the computation of the function f (x) [5].

After extracting the top k features by their weights,
DREBIN automatically constructs sentences which describe
the functionality underlying these features. To achieve
this goal we design sentence templates for each feature set
which can be completed using the respective feature. Ta-
ble 1 list these templates. For features frequently observed
in malware, such as the permission SEND SMS, we provide
individual descriptions.

Explanation
App uses %s feature %s.

Feature set
S1 Hardware features
S2 Requested permissions App requests permission to access %s.
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

App contains suspicious component %s.
Action is triggered by %s.
App calls function %s to access %s.
App uses permissions %s to access %s.
App uses suspicious API call %s.
Communication with host %s.

Table 1. Templates for explanation.

For most of the feature sets, the construction of sentences
from the templates in Table 1 is straightforward. For exam-
ple, for the hardware features we make use of their nam-
ing scheme to construct meaningful sentences. If an appli-
cation for instance uses the android.hardware.camera

hyperplane withmaximum marginmalicious applicationsbenign applicationsφ(x)}w〈φ(x),w〉feature, DREBIN presents the sentence ”App uses hardware
feature camera.” to the user.

Similarly, we provide explanations for requested and
used permissions. The explanation for a permissions can
be derived from the Android documentation which provides
proper descriptions—at least for all system permissions. We
slightly modify these descriptions in order to present mean-
ingful explanations to the user. However, due to the fact
that application developers are able to deﬁne custom per-
missions we also provide a generic sentence which is pre-
sented to the user if no proper description exists. We follow
the same approach for the restricted API calls that build on
the use of certain permissions. For all other feature sets the
templates are directly ﬁlled with either the feature’s name
or a corresponding place holder.

An example of an explanation generated by DREBIN is
shown in Figure 3. The presented sample belongs to the
GoldDream family. DREBIN correctly identiﬁes that the
malware communicates with an external server and sends
SMS messages. The application requests 16 permissions
during the installation process. Many users ignore such long
lists of permissions and thereby fall victim to this type of
malware. In contrast to the conventional permission-based
approach DREBIN draws the user’s attention directly to rel-
evant aspects indicating malicious activity. Furthermore,
DREBIN presents a score to the user which tells him how
conﬁdent the decision is. As a result, the user is able to
decide whether the presented functionality matches his ex-
pectation or not.

In addition to the beneﬁt for the user, the generated ex-
planations can also help researchers to discover relevant pat-
terns in common malware families. We discuss this aspect
in more detail in the following section.

3 Evaluation

After presenting DREBIN in detail, we now proceed to
an empirical evaluation of its efﬁcacy. In particular, we con-
duct the following three experiments:

1. Detection performance. First, we evaluate the detec-
tion performance of DREBIN on a dataset of 5,560 mal-
ware samples and 123,453 benign applications. We
compare its performance against related approaches
and anti-virus scanners (Section 3.2).

2. Explainability. In the second experiment, we analyze
the explanations provided by DREBIN in detail for dif-
ferent malware families and verify whether they relate
to actual characteristics of the malware (Section 3.3).

3. Run-time performance. Finally, we evaluate the run-
time performance of DREBIN. For this experiment

6

Figure 3. Example of an explanation.

we conduct different measurements using ﬁve com-
mon smartphone models as well as a regular desktop
computer (Section 3.4).

3.1 Data sets

For all experiments, we consider a dataset of real An-
droid applications and real malware. In particular, we have
acquired an initial dataset of 131,611 applications compris-
ing benign as well as malicious software. The samples have
been collected in the period from August 2010 to October
2012.
In detail, the dataset contains 96,150 applications
from the GooglePlay Store, 19,545 applications from dif-
ferent alternative Chinese Markets, 2,810 applications from
alternative Russian Markets and 13,106 samples from other
sources, such as Android websites, malware forums and se-
curity blogs. Additionally, the dataset includes all samples
from the Malgenome project [30].

To determine malicious and benign applications, we send
each sample to the VirusTotal service and inspect the out-
put of ten common anti-virus scanners (AntiVir, AVG, Bit-
Defender, ClamAV, ESET, F-Secure, Kaspersky, McAfee,
Panda, Sophos). We ﬂag all applications as malicious that
are detected by at least two of the scanners. This procedure
ensures that our data is correctly split into benign and mali-
cious samples even if one of the ten scanners falsely labels
a benign application as malicious.

Finally, we remove samples labeled as adware from our
dataset, as this type of software is in a twilight zone between

(a) Detection performance as ROC curve.

(b) Detection per malware family.

(c) Top malware families in our dataset.

Figure 4. Detection performance of Drebin and related approaches.

malware and benign functionality. The ﬁnal dataset con-
tains 123,453 benign applications and 5,560 malware sam-
ples. To the best of our knowledge, this is one of the largest
malware datasets that has been used to evaluate a malware
detection method on Android.

An overview of the top 20 malware families in our
dataset is provided in Table 4(c) including several families
that are currently actively distributed in application markets.
Note that only the top 20 families are shown and our dataset
contains 1,048 further malicious samples.

3.2 Detection Performance

In our ﬁrst experiment, we evaluate the detection perfor-
mance of DREBIN and related static detection approaches.
For this experiment, we randomly split the dataset into a
known partition (66%) and an unknown partition (33%).
The detection model and respective parameters of DREBIN
are determined on the known partition, whereas the un-
known partition is only used for measuring the ﬁnal detec-
tion performance. We repeat this procedure 10 times and
average results. The partitioning ensures that reported re-
sults only refer to malicious applications unknown during
the learning phase of DREBIN. For the related approaches,
such as Kirin [11] and RCP [26] this experimental proce-
dure differs slightly, since not all methods require a separate
training step.

Comparison with related approaches. We ﬁrst com-
pare the performance of DREBIN against related static ap-
proaches for detection of Android malware. In particular,
we consider the methods Kirin [11], RCP [26] and the ap-
proach by Peng et al. [22], where we implement the latter
using an SVM instead of a Naive Bayes classiﬁer. The re-
sults of this experiments are shown in Figure 4(a) as ROC
curve, that is, the detection of malware (true-positive rate)

is plotted against the number of false alarms (false-positive
rate) for different thresholds of the detection methods.

DREBIN signiﬁcantly outperforms the other approaches
and detects 94% of the malware samples at a false-positive
rate of 1%, corresponding to one false alarm when installing
100 applications. The other approaches provide a detection
rate between 10%–50% at this false-positive rate. As Kirin
and RCP both consider only a subset of the requested per-
missions, they have obvious limitations in detecting mali-
cious applications. Even the method by Peng et al. which
considers all permissions is unable to detect malware with
sufﬁcient accuracy in this experiment. The superior perfor-
mance of DREBIN results from the different feature sets that
are used to model malicious activity. These sets include the
requested permissions but also contain other relevant char-
acteristics of applications, such as suspicious API calls, ﬁl-
tered intents and network addresses.

Comparison with AV scanners. Although DREBIN
shows a much better performance compared to related ap-
proaches, in the end it has to compete with common anti-
virus products in practice. Consequently, we also compare
it against ten anti-virus scanners on our dataset. The detec-
tion performance of each scanner is again taken from the
VirusTotal service. We run two experiments where we ﬁrst
consider all malware samples of our dataset and then only
those samples provided by the Malgenome project [30]. We
choose a false-positive rate of 1% for DREBIN which we
think is sufﬁciently low for practical operation.

The results of the experiments are shown in Table 2. The
detection rate of the anti-virus scanners varies considerably.
While the best scanners detect over 90% of the malware,
some scanners discover less than 10% of the malicious sam-
ples, likely due to not being specialized in detecting An-
droid malware. On the full dataset DREBIN provides the
second best performance with a detection of 93.9% and out-

7

0.000.020.040.060.080.10False-positive rate0.00.20.40.60.81.0True-positive rateDREBINPeng et al.RCPKIRINABCDEFGHIJKLMNOPQRSTMalware families020406080100Detection rateAverage detection rate (FP=0.01)Detection rate (FP=0.01)IdFamily#IdFamily#AFakeInstaller925KAdrd91BDroidKungFu667LDroidDream81CPlankton625MLinuxLotoor70DOpfake613NGoldDream69EGingerMaster339OMobileTx69FBaseBridge330PFakeRun61GIconosys152QSendPay59HKmin147RGappusin58IFakeDoc132SImlog43JGeinimi92TSMSreg41Table1:Top20malwarefamiliesinourdatasetandthenumberoftheiroccurrences(#).ThefamilynamesarederivedfromthelabelsoftheKasperskyAVscanner.3.1DatasetsForallexperiments,weconsideradatasetofrealAn-droidapplicationsandrealmalware.Inparticular,wehaveacquiredaninitialdatasetof131,398applicationscomprisingbenignaswellasmalicioussoftware.ThesampleshavebeencollectedintheperiodfromAugust2010toOctober2012fromseveralsourcesincludingtheGooglePlayStore,Asianthird-partymarketsandmal-wareforums.ThedatasetalsoincludesallsamplesfromtheMalgenomeproject[?].Todeterminemaliciousandbenignapplications,wesendeachsampletotheVirusTotalserviceandinspecttheoutputoftencommonanti-virusscanners(AntiVir,AVG,BitDefender,ClamAV,ESET,F-Secure,Kasper-sky,McAfee,Panda,Sophos).Weﬂagallapplicationsasmaliciousthatareatleastdetectedbyoneofthescan-ners.Thisprocedureensuresthatourdataiscorrectlysplitintobenignandmalicioussamples—leavingasideasmallfractionofapplicationsthatmightbemissedbyalltenscanners.Finally,weremovesampleslabeledasadwarefromourdataset,asthistypeofsoftwareisinatwilightzonebetweenmalwareandbenignfunctionality.Theﬁnaldatasetcontains122,629benignapplicationand6,526malwaresamples.Tothebestofourknowledge,thisisoneofthelargestmalwaredatasetsthathasbeenusedtoevaluateamalwaredetectionmethodonAndroid.Anoverviewofthetop20malwarefamiliesinourdatasetisprovidedinTable1includingseveralfamiliesthatarecurrentlyactivelydistributedinapplicationmar-kets.Notethatonlythetop20familiesareshownandourdatasetcontain1,227furthermalicioussamples.3.2DetectionPerformanceInourﬁrstexperiment,weevaluatethedetectionperfor-manceofDREBINandrelatedstaticapproaches.Experimentalprocedure.Werandomlysplitthedatasetintoaknownpartition(66%)andanunknownpartition(33%).Thedetectionmodelandrespectivepa-rametersofthesupportvectormachinearedeterminedontheknownpartition,whereastheunknownpartitionisonlyusedformeasuringtheﬁnaldetectionperformance.Werepeatthisprocedure10timesandaverageresults.ThepartitioningensuresthatreportedresultsonlyrefertomaliciousapplicationsunknownduringthelearningphaseofDREBIN.Fortherelatedapproaches,suchasKirin[?]andRPC[?]theexperimentalprocedurediffersslightly,sincenotallmethodsrequireaseparatetrainingstep.ComparisonwithrelatedapproachesWeﬁrstcom-paretheperformanceofDREBINagainstrelatedstaticapproachesfordetectionofAndroidmalware.Inpartic-ular,weconsiderthemethodsKirin[?],RPC[?]andtheapproachbyPengetal.[?],whereweimplementthelatterusingsupportvectormachinesinsteadofaba-sicNaiveBayesclassier.TheresultsofthisexperimentsareshowninFigure3asROCcurve,thatis,thedetec-tionofmalware(true-positiverate)isplottedagainstthenumberoffalsealarms(false-positiverate)fordifferentthresholdsofthedetectionmethods.Figure3:DetectionperformanceofDREBINandthere-lateddetectionapproaches.DREBINsigniﬁcantlyoutperformstheotherap-proachesanddetects93%ofthemalwaresamplesatafalse-positiverateof1%,correspondingtoonefalsealarmwheninstalling100applications.Theotherap-proachesattainonlyadetectionratebetween10%–50%atthisfalse-positiverate.AsKirinandRPCbothcon-sideronlyasubsetoftherequestedpermissions,theyhaveobviouslimitationsindetectingmaliciousapplica-tions.EventhemethodbyPengetal.whichconsidersall6Full dataset
Malgenome

AV1

AV10
DREBIN
93.90% 96.41% 93.71% 84.66% 84.54% 78.38% 64.16% 48.50% 48.34% 9.84% 3.99%
95.90% 98.63% 98.90% 98.28% 98.07% 98.66% 96.49% 94.67% 84.23% 23.68% 1.12%

AV2

AV3

AV4

AV5

AV6

AV7

AV8

AV9

Table 2. Detection rates of Drebin and anti-virus scanners.

performs 9 of the commercial products. This observation is
remarkable since, due to our test setting, at least two scan-
ners should be able to detect each malware sample. There-
fore, each sample has to be known for a certain amount time
and most anti-virus scanners should be equipped with a cor-
responding signature. However, the automatically gener-
ated detection model of DREBIN proves to be more effective
than the manually crafted signatures of many scanners. On
the Malgenome dataset the anti-virus scanners achieve bet-
ter detection rates, since these samples are well-known for a
longer period of time. Hence, almost all anti-virus scanners
provide proper signatures for this dataset.

The false-positive rates of the anti-virus scanners range
from 0% to 0.3% on our dataset of benign applications and
thus are slightly below DREBIN’s performance. Despite the
vast number of available Android applications, the average
user only installs some dozens of applications on his de-
vice. For example, according to Nielsen1, a market research
company, the average number of installed applications per
smartphone in the U.S. has been 32 in 2011 and 41 in 2012.
Consequently, we consider a false-positive rate of 1% ac-
ceptable for operating DREBIN in practice.
Detection of malware families. Another important as-
pect that should be considered when testing the detection
performance of a method is the balance of malware fami-
lies in the dataset [25]. If the number of samples of certain
malware families is much larger than of other families the
detection result mainly depends on these families. To ad-
dress this problem one can use the same number of samples
for each family. However, this leads to a distribution that
signiﬁcantly differs from reality.
Instead we evaluate the
detection performance for each of the 20 largest malware
families separately. The family names and the number of
samples for each family can be found in Table 4(c) and the
detection performance of DREBIN for each family is illus-
trated in Figure 4(b).

DREBIN is able to reliably detect all families with an av-
erage accuracy of 93% at a false-positive rate of 1%. In par-
ticular, all families show a detection rate of more than 90%,
where three of them can be identiﬁed perfectly (H, O, P).
There is only one malware family which cannot be reliably
detected by DREBIN. This family is Gappusin (R) and we
will examine its low performance in the next section.
It
should be pointed out that there seems to be no dependency

between the size of a malware family and its detection rate
as long as the number of samples is sufﬁciently high and
allows the SVM to generalize its features.

Detection of unknown malware families. DREBIN uses
known malware for learning its detection model. It is thus
important to assess how many samples of a family need to
be known to reliable detect this family. To study this issue,
we conduct two additional experiments where we limit the
number of samples for a particular family in the training set.
In the ﬁrst experiment we provide no samples of the family,
corresponding to a totally unknown malware strain. In the
second experiment, we put 10 randomly chosen samples of
the family back into the training set, thus simulating the
starting spread of a new family.

The results of the two experiments are shown in Figure 5,
where the detection rate is shown for 0 and 10 available
samples in the training set for each family. If no samples
are available for learning, it is difﬁcult for DREBIN to de-
tect a family, as no discriminative patterns can be discov-
ered by the SVM. However, only very few samples are nec-
essary to generalize the behavior of most malware families.
With only 10 samples in the training set, the average detec-
tion performance increases by more than 25 percent. Three
families can even be detected perfectly in this setting. The
reason for this is that members of a certain families are often
just repackaged applications with slight modiﬁcations. Due
to the generalization which is done by the SVM it is there-
fore possible to detect variations of a family even though
only a very small set of samples is known.

Figure 5. Detection of unknown families.

1Nielsen Report: “State of the Appnation – A Year of Change and

Growth in U.S. Smartphones”

In summary, DREBIN provides an effective detection
of Android malware and outperforms related detection ap-

8

ABCDEFGHIJKLMNOPQRSTMalware Families020406080100Detection Rate0 Samples Available10 Samples Availableproaches as well as several anti-virus scanners. While
DREBIN can not spot unknown malware from the very start,
only few samples of each family are required for achieving
a reliable detection.

3.3 Explanations

Apart from its detection performance a strength of
DREBIN lies in its ability to the explain obtained results.
This allows us to check whether the extracted features
which contribute to the detection ﬁt to common malware
characteristics. In this section we ﬁrst take a look at four
popular malware families and analyze how features with
high weights allow conclusions to be drawn about their be-
havior. We then inspect false positives and false negatives
of DREBIN in detail.
Explanation for malware families. To study the expla-
nations provided by DREBIN we consider four well-known
malware families, namely FakeInstaller, GoldDream [20],
GingerMaster [19] and DroidKungFu [21]. For each sample
of these families we determine the features with the high-
est contribution to the classiﬁcation decision and average
the results over all members of a family. The resulting top
ﬁve features for each malware family are shown in Table 3.
For clarity we presents the exact features rather then the ex-
plaining sentences introduced in Section 2.4.

• FakeInstaller is currently the most widespread mal-
ware. The members of this family hide their mali-
cious code inside repackaged versions of popular ap-
plications. During the installation process the mal-
ware send expensive SMS messages to premium ser-
vices owned by the malware authors.
Even on
the ﬁrst sight, three of the extracted features indi-
cate that the malware uses SMS functionality, where
android.hardware.telephony is implicitly added
to the manifest ﬁle as soon as an application requests
permissions to use SMS functionality.

• DroidKungFu tries to exploit several vulnerabilities in
earlier Android versions to gain root access and steal
sensitive data from the device. Its intention to gain root
access is reﬂected by the feature system/bin/su.
The invocation of getSubscriberId() indicates
that the malware tries to access sensitive data. The
two intents BATTERY CHANGED ACTION and SIG STR
are ﬁltered by a broadcast receiver component which is
part of many DroidKungFu samples. Both intents are
used to trigger malicious functionality when the appli-
cation is running in the background.

• GoldDream is a Trojan which monitors an infected
device, collects sensitive data and records informa-
The feature
tion from received SMS messages.

Telephony.SMS RECEIVED directly hints us to the
reading of SMS messages. After the malware has col-
lected sufﬁcient data, it sends the data to an external
server, whose hostname is second ranked in the fea-
ture list. Furthermore, the malware is able to install
and delete packages as well as to send SMS messages,
which is also reﬂected in the extracted features.

• GingerMaster is also a Trojan application which is of-
ten bundled with benign applications and tries to gain
root access, steals sensitive data and sends it to a re-
mote server. Similar to the DroidKungFu family the
malware starts its malicious service as soon as it re-
ceives a BOOT COMPLETED or USER PRESENT intent.
Again a signiﬁcant part of this behavior can be recon-
structed just by looking at the top features.

To study the contribution of the different feature sets to
the detection of malware in general, we extract the top 5
features for all of the malware families in our dataset. The
results are presented in Table 4. Although the requested
permissions occur in the top features of all families, it is
evident that this feature set alone is not sufﬁcient to ensure
a reliable detection. In particular, each feature set occurs at
least once in the table which clearly indicates that all sets
are necessary for the detection of Android malware.
False and missing detections. We ﬁnally examine benign
applications which are wrongly classiﬁed as malware by
DREBIN. Similar to malicious applications, most of these
samples use SMS functionality and access sensitive data,
which is reﬂected in high weights of the corresponding fea-
tures. Moreover, these samples often show only very little
benign behavior and thus trigger false alarms. Fortunately,
the ability of DREBIN to output explainable results can help
the user to decide whether a suspicious looking functional-
ity is indeed malicious or needed for the intented purpose
of the application.

A similar situation occurs when DREBIN classiﬁes sam-
ples of the Gappusin family [17] as benign. Although it
is in many cases possible to extract features which match
the description of the Gappusin family—amongst others the
hostname of the external server—there are too few mali-
cious features to identify the samples as malware. Gap-
pussin mainly acts as a downloader for further malicious
applications and thus does not exhibit common malicious
functionality, such as theft of sensitive data.

3.4 Run-time Performance

While the computing power of mobile devices is rapidly
increasing, it is still limited compared to regular desktop
computers. Consequently, a detection method that is sup-
posed to run directly on these devices has to carry out its
task very efﬁciently.

9

Malware family

Top 5 features

FakeInstaller

DroidKungFu

GoldDream

GingerMaster

Feature s
sendSMS
SEND SMS
android.hardware.telephony
sendTextMessage
READ PHONE STATE

SIG STR
system/bin/su
BATTERY CHANGED ACTION
READ PHONE STATE
getSubscriberId

sendSMS
lebar.gicp.net
DELETE PACKAGES
android.provider.Telephony.SMS RECEIVED
getSubscriberId

USER PRESENT
getSubscriberId
READ PHONE STATE
system/bin/su
HttpPost

Feature set
S7 Suspicious API Call
S2 Requested permissions
S1 Hardware components
S5 Restricted API calls
S2 Requested permissions
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls
S8 Network addresses
S2 Requested permission
S4 Filtered intents
S7 Suspicious API calls
S4 Filtered intents
S7 Suspicious API calls
S2 Requested permissions
S7 Suspicious API calls
S7 Suspicious API calls

Weight ws
1.12
0.84
0.57
0.52
0.50
2.02
1.30
1.26
0.54
0.49
1.07
0.93
0.58
0.56
0.53
0.67
0.64
0.55
0.44
0.38

Table 3. Top features for the malware families FakeInstaller, DroidKungFu, Geinimi and GingerMaster.

Feature sets

Malware families
I

K

J

L M N

O

P

Q

R

S

T

S1 Hardware components
S2 Requested permissions (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
S3 App components
S4 Filtered intents
S5 Restricted API calls
S6 Used permissions
S7 Suspicious API calls
S8 Network addresses

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

B

C

E

F

G

H
(cid:88)

A
(cid:88)

(cid:88)

(cid:88)

D
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Table 4. Contribution of the feature sets to the detection of malware families.

10

To analyze the run-time of DREBIN we implement a
standalone Android application that receives a learned de-
tection model and is able to perform the detection process
directly on the smartphone. The size of the downloaded
model is only about 280 kbytes. Using this application we
measure the run-time of DREBIN on different devices us-
ing 100 randomly selected popular applications from the
Google Play Store. For this experiment, we choose de-
vices which cover various widespread hardware conﬁgura-
tions including four smartphone (Nexus 4, Galaxy S3, Xpe-
ria Mini Pro and Nexus 3), a tablet (Nexus 7) and a regular
desktop computer (PC).

Figure 6. Run-time performance of Drebin.

The results are presented in Figure 6. On average,
DREBIN is able to analyze a given application in 10 seconds
on the ﬁve smartphones. Even on older models, such as the
Xperia Mini Pro, the method is able to analyze the applica-
tion in less than 20 seconds on average. Overall, no analysis
takes longer than 1 minute on all devices. On the desktop
computer (2.26 GHz Core 2 Duo with 4GB RAM) DREBIN
achieves a remarkable analysis performance of 750 ms per
application, which enables scanning 100,000 applications
in less than a day.

A detailed run-time analysis for the desktop computer
and the Galaxy S3 smartphone is presented in Figure 7,
where the run-time per application is plotted against the
size of the analyzed code. Surprisingly, on both devices
DREBIN attains a sublinear run-time, that is, its perfor-
mance increases with O(√m) in the number of analyzed
bytes m. Apparently, the number of features does not in-
crease linearly with the code and thus larger applications do
not necessarily contain more features to analyze.

From this evaluation, we conclude that DREBIN does not
only reliably detect malicious applications but is further-
more capable to perform this task in a time which clearly
meets practical requirements.

11

Figure 7. Detailed run-time analysis of Drebin.

4 Limitations

The previous evaluation demonstrates the efﬁcacy of our
method in detecting recent malware on the Android plat-
form. However, DREBIN cannot generally prohibit infec-
tions with malicious applications, as it builds on concepts
of static analysis and lacks the capabilities of a run-time
analysis. Some strains of malware make use of obfusca-
tion or load code dynamically, which hinders any static in-
spection. To alleviate the absence of a dynamic analysis,
DREBIN thus extracts API calls related to obfuscation and
loading of code, such as DexClassLoader.loadClass()
and Cipher.getInstance(). These features enable us to
at least spot the execution of hidden code—even if we can-
not further analyze it. In combinations with other features,
DREBIN is able to identify malware despite the use of some
obfuscation techniques.

To avoid crafting detection patterns manually, we make
use machine learning for generating detection models.
While learning techniques provide a powerful tool for au-
tomatically inferring models,
they require a representa-
tive basis of data for training. That is,
the quality of
the detection model of DREBIN critically depends on the
availability of representative malicious and benign applica-
tions. While it is straightforward to collect benign appli-
cations, gathering recent malware samples requires some
technical effort. Fortunately, methods for ofﬂine analy-
sis, such as DroidRanger [31], AppsPlayground [24] and
RiskRanker [18], might help here to automatically acquire
malware and provide the basis for updating and maintaining
a representative dataset for DREBIN over time.

5 Related Work

The analysis and detection of Android malware has been
a vivid area of research in the last years. Several concepts

PCN4S3XMPN3N7Devices10-1100101102Run-time (sec)10-210-1100101Size of dexcode (MB)10-210-1100101102Run-time (sec)O(n0.45)O(n0.49)Estimate (S3)Estimate (PC)Measurementsand techniques have been proposed to counter the growing
amount and sophistication of this malware. An overview of
the current malware landscape is provided in the studies of
Felt et al. [14] and Zhou & Jiang [30].

clone without disrupting the functionality of the real device.
The duplication of functionality, however, is involved and
with millions of smartphones in practice operating Para-
noidAndroid at large scale is technically not feasible.

Detection using static analysis. The ﬁrst approaches for
detecting Android malware have been inspired by concepts
from static program analysis. Several methods have been
proposed that statically inspect applications and disassem-
ble their code [e.g., 10, 11, 13, 18]. For example, the
method Kirin [11] checks the permission of applications for
indications of malicious activity. Similarly, Stowaway [13]
analyzes API calls to detect overprivileged applications and
RiskRanker [18] statically identiﬁes applications with dif-
ferent security risks. Common open-source tools for static
analysis are Smali [15] and Androguard [8], which enable
dissecting the content of applications with little effort.

Our method DREBIN builds on similar concepts for static
analysis. However, it differs in two central aspects from pre-
vious work: First, we abstain from crafting detection pat-
terns manually and instead apply machine learning to an-
alyze information extracted from static analysis. Second,
the analysis of DREBIN is optimized for effectivity and ef-
ﬁciency, which enables us to inspect application directly on
the smartphone.

Detection using dynamic analysis. A second branch of
research has studied the detection of Android malware at
run-time. Most notably, are the analysis system Taint-
Droid [9] and DroidScope [29] that enable dynamically
monitoring applications in a protected environment, where
the ﬁrst focuses on taint analysis and the later enables intro-
spection at different layers of the platform. While both sys-
tems provide detailed information about the behavior of ap-
plications, they are technically too involved to be deployed
on smartphones and detect malicious software directly.

As a consequence, dynamic analysis is mainly applied
for ofﬂine detection of malware, such as scanning large col-
lections of Android applications. For example, the meth-
ods DroidRanger [31] and AppsPlayground [24] have been
successfully applied to identify applications with malicious
behavior in different Android markets. A similar detec-
tion system called Bouncer is currently operated by Google.
These dynamic analysis systems are suitable for ﬁltering
malicious applications from markets. Due to the openness
of the Android platform, however, applications may also be
retrieved from other sources, such as web pages, which are
not covered by these approaches.

ParanoidAndroid [23] is one of the few detection sys-
tems that employs dynamic analysis and can spot malicious
activity on the smartphone. To this end, a virtual clone of
the smartphone is run in parallel on a dedicated server and
synchronized with the activities of the device. This setting
allows for monitoring the behavior of applications on the

Detection using machine learning. The difﬁculty of
manually crafting and updating detection patterns for An-
droid malware has motivated the application of machine
learning techniques.
Several methods have been pro-
posed that analyze applications automatically using learn-
ing methods [e.g., 2, 22, 26]. As an example, the method
of Peng et al. [22] applies probabilistic learning methods
to the permissions of applications for detecting malware.
Similarly, the methods Crowdroid [4], DroidMat [28] and
DroidAPIMiner[1] analyze the usage of system and API
calls using machine learning techniques.

All of these approaches mainly focus on an accurate de-
tection of malware. Additional aspects, such as the efﬁ-
ciency and the explainability of the detection, are not con-
sidered. We address these aspects in this work and propose
a method that provides an effective, efﬁcient and explain-
able detection of malicious applications.

6 Conclusion

Android malware is a new yet fast growing threat.
Classic defenses, such as anti-virus scanners, increasingly
fail to cope with the amount and diversity of malware in
application markets. While recent approaches, such as
DroidRanger [31] and AppPlayground [24], support ﬁl-
tering such applications off these markets, they induce a
run-time overhead that is prohibitive for directly protect-
ing smartphones. As a remedy, we introduce DREBIN,
a lightweight method for detection of Android malware.
DREBIN combines concepts from static analysis and ma-
chine learning, which enables it to better keep pace with
malware development. Our evaluation demonstrates the po-
tential of this approach, where DREBIN outperforms related
approaches and identiﬁes malicious applications with few
false alarms.

In practice, DREBIN provides two advantages for the se-
curity of the Android platform: First, it enables efﬁciently
scanning large amounts of applications, such as from third-
party markets. With an average run-time of 750 ms per ap-
plication on a regular computer, it requires less than a day to
analyze 100,000 unknown applications. Second, DREBIN
can be applied directly on smartphones, where the analysis
can be triggered when new applications are downloaded to
the device. Thereby, DREBIN can protect users that install
applications from untrusted sources, such as websites and
third-party markets.

Although DREBIN effectively identiﬁes malicious soft-
ware in our evaluation, it exhibits the inherent limitations

12

of static analysis. While it is able to detect indications of
obfuscation or dynamic execution, the retrieved code is not
accessible by the method. A similar setting has been suc-
cessfully tackled for the analysis of JavaScript code [see 7]
and dynamically triggering the static analysis of DREBIN
whenever new code is loaded seems like a promising direc-
tion of future work.

References

[1] Y. Aafer, W. Du, and H. Yin. DroidAPIMiner: Min-
ing API-level features for robust malware detection in
android. In Proc. of International Conference on Se-
curity and Privacy in Communication Networks (Se-
cureComm), 2013.

[2] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and
A. Somayaji. A methodology for empirical analysis
of permission-based security models and its applica-
tion to android. In Proc. of ACM Conference on Com-
puter and Communications Security (CCS), pages 73–
84, 2010.

[3] B. Bloom.

Space/time trade-offs in hash coding
with allowable errors. Communication of the ACM,
13(7):422–426, 1970.

[4] I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani.
Crowdroid: behavior-based malware detection system
for android.
In Proc. of ACM Worksgop on Secu-
rity and Privacy in Smartphones and Mobile Devices
(SPSM), pages 15–26, 2011.

[5] T. Cormen, C. Leiserson, and R. Rivest. Introduction

to Algorithms. MIT Press, 1989.

[6] N. Cristianini and J. Shawe-Taylor. An Introduction
to Support Vector Machines. Cambridge University
Press, Cambridge, UK, 2000.

[7] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert.
Zozzle: Fast and precise in-browser JavaScript mal-
ware detection. In Proc. of USENIX Security Sympo-
sium, 2011.

[8] A. Desnos and G. Gueguen. Android: From reversing
In Presentation at Black Hat Abu

to decompilation.
Dhabi, 2011.

[10] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri.
A study of Android application security. In Proc. of
USENIX Security Symposium, 2011.

[11] W. Enck, M. Ongtang, and P. D. McDaniel. On
lightweight mobile phone application certiﬁcation. In
Proc. of ACM Conference on Computer and Commu-
nications Security (CCS), pages 235–245, 2009.

[12] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang,
and C.-J. Lin. LIBLINEAR: A library for large linear
classiﬁcation. Journal of Machine Learning Research
(JMLR), 9:1871–1874, 2008.

[13] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.
Android permissions demystiﬁed.
In Proc. of ACM
Conference on Computer and Communications Secu-
rity (CCS), pages 627–638, 2011.

[14] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wag-
ner. A survey of mobile malware in the wild.
In
Proc. of ACM Worksgop on Security and Privacy in
Smartphones and Mobile Devices (SPSM), pages 3–
14, 2011.

[15] J. Freke. An assembler/disassembler for android’s dex
format. Google Code, http://code.google.
com/p/smali/, visited February, 2013.

[16] Mobile threat report 2012 q3. F-Secure Response

Labs, 2012.

[17] 2012.

http://www.naked-security.com/

malware/Android.Gappusin/.

[18] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang.
Riskranker: scalable and accurate zero-day android
malware detection. In Proc. of International Confer-
ence on Mobile Systems, Applications, and Services
(MOBISYS), pages 281–294, 2012.

[19] X. Jiang.

Security alert: Gingermaster, 2011.

http://www.csc.ncsu.edu/faculty/
jiang/GingerMaster/.

[20] X. Jiang.

Security alert: Golddream, 2011.

http://www.csc.ncsu.edu/faculty/
jiang/GoldDream/.

[21] X.

Jiang.

Security alert: New droidkungfu
http://www.csc.ncsu.edu/

variant, 2011.
faculty/jiang/DroidKungFu3/.

[9] W. Enck, P. Gilbert, B. gon Chun, L. P. Cox,
J. Jung, P. McDaniel, and A. Sheth. Taintdroid: An
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In Proc. of USENIX Sym-
posium on Operating Systems Design and Implemen-
tation (OSDI), pages 393–407, 2010.

[22] H. Peng, C. S. Gates, B. P. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy. Us-
ing probabilistic generative models for ranking risks
of android apps.
In Proc. of ACM Conference on
Computer and Communications Security (CCS), pages
241–252, 2012.

13

[23] G. Portokalidis, P. Homburg, K. Anagnostakis, and
H. Bos. Paranoid android: Versatile protection for
smartphones. In Proc. of Annual Computer Security
Applications Conference (ACSAC), 2010.

[24] V. Rastogi, Y. Chen, and W. Enck. Appsplayground:
Automatic security analysis of smartphone applica-
tions. In Proc. ACM Conference on Data and Appli-
cation Security and Privacy (CODASPY), 2013.

[25] C. Rossow, C. Dietrich, C. Gier, C. Kreibich, V. Pax-
son, N. Pohlmann, H. Bos, and M. van Steen. Prudent
practices for designing malware experiments: Status
quo and outlook. In Proc. of IEEE Symposium on Se-
curity and Privacy, 2012.

[26] B. P. Sarma, N. Li, C. Gates, R. Potharaju, C. Nita-
Rotaru, and I. Molloy. Android permissions: a per-
spective combining risks and beneﬁts.
In Proc. of
ACM symposium on Access Control Models and Tech-
nologies (SACMAT), pages 13–22, 2012.

[27] R. Sommer and V. Paxson. Outside the closed world:
On using machine learning for network intrusion de-
tection. In Proc. of IEEE Symposium on Security and
Privacy, pages 305–316, 2010.

[28] D.-J. Wu, C.-H. Mao, T.-E. Wei, H.-M. Lee, and K.-P.
Wu. Droidmat: Android malware detection through
manifest and API calls tracing.
In Proc. of Asia
Joint Conference on Information Security (Asia JCIS),
pages 62–69, 2012.

[29] L.-K. Yan and H. Yin. Droidscope: Seamlessly recon-
structing os and dalvik semantic views for dynamic
android malware analysis. In Proc. of USENIX Secu-
rity Symposium, 2012.

[30] Y. Zhou and X. Jiang. Dissecting android malware:
Characterization and evolution. In Proc. of IEEE Sym-
posium on Security and Privacy, pages 95–109, 2012.

[31] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you,
get off of my market: Detecting malicious apps in
ofﬁcial and alternative android markets.
In Proc. of
Network and Distributed System Security Symposium
(NDSS), 2012.

14

