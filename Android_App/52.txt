Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

We explore the distribution of defects across
source code ﬁles by extracting the number of de-
fect ﬁxing changes made to each source code ﬁle.
We assume that each defect ﬁxing change corre-
sponds to a defect in the source code ﬁle. We ﬁnd
defect ﬁxing changes by mining the commit log
messages for a set of keywords [31, 32]. The key-
words (i.e., “bug(s),” “ﬁx(es,ed,ing),” “issue(s),”
“defect(s)” and “patch(s)”) were developed based
on manual analysis of commit log messages. We
ﬁnd the total number of defects in a source code ﬁle
by counting the number of times the ﬁle is changed
by the set of defect ﬁxing changes.

We were unable to use the issues reported in
the issue tracking system because these tend not to
include information regarding how the defect was
ﬁxed (e.g., the location of the defect). We were also
unable to trace defect ﬁxing changes to speciﬁc is-
sues in the issue tracking system because mobile
app developers tend not to reference speciﬁc issues
in their commit messages. Hence, heuristics based
on the commit message need to be used to identify
defect ﬁxing changes despite the lack of a connec-
tion between the source code repository and issue
tracking system.

Once we have extracted the number of defects in
each source code ﬁle, we then calculate the num-
ber of defects in the top 20% most defect-prone
ﬁles by sorting the list of ﬁles by the number of
defects in descending order and summing the num-
ber of defects in the ﬁrst 20% of the list. Figure 3
presents the percentage of defects in the top 20%
most defect-prone ﬁles.

We ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest across mobile
apps, followed by large desktop/server applications
and ﬁnally unix utilities.

In our ﬁrst research question, we found that mo-
bile apps are typically small. Combined with the
distribution of defects, mobile app developers can
ﬁnd the majority of defects in a very small number
of ﬁles, typically only 10s of ﬁles.

From Figure 3, we ﬁnd that a higher percent-
age of defects are concentrated in the top 20%
most defect-prone ﬁles in mobile apps, compared
to desktop/server applications. At least 80% of
the defects are concentrated in the top 20% most
defect-prone ﬁles in nine of our mobile apps and
at least 70% of the defects are concentrated in the
top 20% most defect-prone ﬁles in thirteen of our
mobile apps.

Figure 3: Percentage of All Defects in the Top 20%
Most Defect-Prone Files.

Finding the rationale for the relatively quick de-
fect ﬁx times in mobile apps requires more analysis
on other systems.

We ﬁnd that mobile app developers typi-
cally ﬁx defects faster than desktop/server de-
velopers, regardless of the size of the project.
Defects in mobile apps tend to be concentrated
in fewer source code ﬁles.

5 Discussion
We identiﬁed several potential areas for future
research in mobile apps during our current and pre-
vious case studies [7]. We believe that the potential
impact of such research may be signiﬁcant given
the ubiquity of mobile devices and growing im-
portance of mobile apps. We present two such ar-
eas based on observations made during our manual
analysis of the source code and development his-
tory of mobile apps.

5.1 Platform Usage

We observed that many mobile apps depend
highly on their underlying platform (i.e., the An-
droid platform). In our previous work, we deﬁned
the “platform dependency ratio” as the ratio of plat-
form API calls to all calls [7]. A low platform
dependency ratio indicates that developers do not
rely signiﬁcantly on the platform APIs. For exam-

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

We explore the distribution of defects across
source code ﬁles by extracting the number of de-
fect ﬁxing changes made to each source code ﬁle.
We assume that each defect ﬁxing change corre-
sponds to a defect in the source code ﬁle. We ﬁnd
defect ﬁxing changes by mining the commit log
messages for a set of keywords [31, 32]. The key-
words (i.e., “bug(s),” “ﬁx(es,ed,ing),” “issue(s),”
“defect(s)” and “patch(s)”) were developed based
on manual analysis of commit log messages. We
ﬁnd the total number of defects in a source code ﬁle
by counting the number of times the ﬁle is changed
by the set of defect ﬁxing changes.

We were unable to use the issues reported in
the issue tracking system because these tend not to
include information regarding how the defect was
ﬁxed (e.g., the location of the defect). We were also
unable to trace defect ﬁxing changes to speciﬁc is-
sues in the issue tracking system because mobile
app developers tend not to reference speciﬁc issues
in their commit messages. Hence, heuristics based
on the commit message need to be used to identify
defect ﬁxing changes despite the lack of a connec-
tion between the source code repository and issue
tracking system.

Once we have extracted the number of defects in
each source code ﬁle, we then calculate the num-
ber of defects in the top 20% most defect-prone
ﬁles by sorting the list of ﬁles by the number of
defects in descending order and summing the num-
ber of defects in the ﬁrst 20% of the list. Figure 3
presents the percentage of defects in the top 20%
most defect-prone ﬁles.

We ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest across mobile
apps, followed by large desktop/server applications
and ﬁnally unix utilities.

In our ﬁrst research question, we found that mo-
bile apps are typically small. Combined with the
distribution of defects, mobile app developers can
ﬁnd the majority of defects in a very small number
of ﬁles, typically only 10s of ﬁles.

From Figure 3, we ﬁnd that a higher percent-
age of defects are concentrated in the top 20%
most defect-prone ﬁles in mobile apps, compared
to desktop/server applications. At least 80% of
the defects are concentrated in the top 20% most
defect-prone ﬁles in nine of our mobile apps and
at least 70% of the defects are concentrated in the
top 20% most defect-prone ﬁles in thirteen of our
mobile apps.

Figure 3: Percentage of All Defects in the Top 20%
Most Defect-Prone Files.

Finding the rationale for the relatively quick de-
fect ﬁx times in mobile apps requires more analysis
on other systems.

We ﬁnd that mobile app developers typi-
cally ﬁx defects faster than desktop/server de-
velopers, regardless of the size of the project.
Defects in mobile apps tend to be concentrated
in fewer source code ﬁles.

5 Discussion
We identiﬁed several potential areas for future
research in mobile apps during our current and pre-
vious case studies [7]. We believe that the potential
impact of such research may be signiﬁcant given
the ubiquity of mobile devices and growing im-
portance of mobile apps. We present two such ar-
eas based on observations made during our manual
analysis of the source code and development his-
tory of mobile apps.

5.1 Platform Usage

We observed that many mobile apps depend
highly on their underlying platform (i.e., the An-
droid platform). In our previous work, we deﬁned
the “platform dependency ratio” as the ratio of plat-
form API calls to all calls [7]. A low platform
dependency ratio indicates that developers do not
rely signiﬁcantly on the platform APIs. For exam-

ple, their app may be simple or self-contained, or
the platform may be too difﬁcult to use. Such mo-
bile apps may be easily ported to other platforms.
Conversely, a high platform dependency ratio in-
dicates that mobile app developers heavily exploit
platform APIs. However, this leads to platform
“lock-in”, which may complicate porting to other
platforms and potentially introduces instability due
to the rapid evolution of mobile platforms. While
these issues are relevant to all software that is built
on an underlying platform or framework, it is par-
ticularly acute in mobile apps. This is because the
Android platform averages one major release every
year. Hence, researchers should look at the impact
of platform dependence on quality and how back-
ward compatibility issues could affect quality.

5.2 Development Processes

We observed that many mobile apps have a very
high frequency of releases. For example, K9Mail
typically has two internal releases every week and
one release to Google Play every month. Quick re-
lease cycles may be required to remain competitive
within the marketplace.

Currently, there is evidence that some mobile
apps do not follow a formal development or main-
tenance process. These apps are developed in an
ad hoc manner to get to the market as quickly as
possible. For example, as we discussed in Subsec-
tion 3.1, three mobile apps were excluded from our
case study because they did not have a public issue
tracking system. These apps had been downloaded
hundreds of thousands of times, and yet they did
not have a system where users could report defects.
In addition, the source code repositories of eleven
mobile apps in our case study do not contain any
test cases. Such ad hoc development and mainte-
nance processes may adversely affect the quality
or maintainability of mobile apps.

Researchers should also investigate the relation-
ship between these two factors (frequent releases
and lack of testing) and the quality of code. Khomh
et al. have studied the Mozilla Firefox project and
found that a shorter release cycle 1) allows defects
to be ﬁxed faster and 2) does not introduce signif-
icantly more defects [33]. However, several open
questions remain. Does such a high frequency of
releases mitigate the lack of testing? If there are
frequent releases for the mobile app, then does

quality matter as much? Is the project in a con-
stant beta testing state? Does the platform provide
sufﬁcient support for building high quality apps
quickly? Is the frequent release only inﬂuenced by
the demand factor in the app store? Are the devel-
opers of mobile apps more skilled or do they have
more resources at hand? Or, are mobile apps them-
selves less complex to develop?

6 Threats to Validity
This section outlines the threats to the validity of

our case study.

6.1 Construct Validity

Wget was ﬁrst released in January 1996 and As-
pell was ﬁrst released in September 1998, however,
the development history of this time is not avail-
able. Therefore, the ﬁrst three years of the publicly
available source code repository and issue tracker
do not correspond to the ﬁrst three years of devel-
opment.

The number of downloads is not an ideal mea-
sure of success (unlike user retention or engage-
ment), however, it is the best measure currently
available [4]. Therefore, it is possible that we have
mistakenly included mobile apps with small user
bases or excluded mobile apps with large user bases
from our analysis.

The number of unique developers was found
by counting the number of unique local parts
(i.e.,
the characters before the @ symbol) for
each developer who made at least one commit
to a source code ﬁle in the repository.
Simi-
larly, the number of unique reporters was found
by counting the number of unique local parts for
each reporter who submitted at least one defect
report. While we did perform a manual veri-
ﬁcation of this analysis,
it is possible that we
misidentiﬁed two local parts as either unique or
distinct. For example, john doe@gmail.com and
admin@my project.com were counted as two dis-
tinct developers/reporters, although they may be
a single developer/reporter with multiple (distinct)
email address. Conversely, j doe@gmail.com and
j doe@yahoo.com were counted as one distinct de-
veloper/reporter, although they may be two distinct
developers/reporters (e.g., John and James).

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

We explore the distribution of defects across
source code ﬁles by extracting the number of de-
fect ﬁxing changes made to each source code ﬁle.
We assume that each defect ﬁxing change corre-
sponds to a defect in the source code ﬁle. We ﬁnd
defect ﬁxing changes by mining the commit log
messages for a set of keywords [31, 32]. The key-
words (i.e., “bug(s),” “ﬁx(es,ed,ing),” “issue(s),”
“defect(s)” and “patch(s)”) were developed based
on manual analysis of commit log messages. We
ﬁnd the total number of defects in a source code ﬁle
by counting the number of times the ﬁle is changed
by the set of defect ﬁxing changes.

We were unable to use the issues reported in
the issue tracking system because these tend not to
include information regarding how the defect was
ﬁxed (e.g., the location of the defect). We were also
unable to trace defect ﬁxing changes to speciﬁc is-
sues in the issue tracking system because mobile
app developers tend not to reference speciﬁc issues
in their commit messages. Hence, heuristics based
on the commit message need to be used to identify
defect ﬁxing changes despite the lack of a connec-
tion between the source code repository and issue
tracking system.

Once we have extracted the number of defects in
each source code ﬁle, we then calculate the num-
ber of defects in the top 20% most defect-prone
ﬁles by sorting the list of ﬁles by the number of
defects in descending order and summing the num-
ber of defects in the ﬁrst 20% of the list. Figure 3
presents the percentage of defects in the top 20%
most defect-prone ﬁles.

We ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest across mobile
apps, followed by large desktop/server applications
and ﬁnally unix utilities.

In our ﬁrst research question, we found that mo-
bile apps are typically small. Combined with the
distribution of defects, mobile app developers can
ﬁnd the majority of defects in a very small number
of ﬁles, typically only 10s of ﬁles.

From Figure 3, we ﬁnd that a higher percent-
age of defects are concentrated in the top 20%
most defect-prone ﬁles in mobile apps, compared
to desktop/server applications. At least 80% of
the defects are concentrated in the top 20% most
defect-prone ﬁles in nine of our mobile apps and
at least 70% of the defects are concentrated in the
top 20% most defect-prone ﬁles in thirteen of our
mobile apps.

Figure 3: Percentage of All Defects in the Top 20%
Most Defect-Prone Files.

Finding the rationale for the relatively quick de-
fect ﬁx times in mobile apps requires more analysis
on other systems.

We ﬁnd that mobile app developers typi-
cally ﬁx defects faster than desktop/server de-
velopers, regardless of the size of the project.
Defects in mobile apps tend to be concentrated
in fewer source code ﬁles.

5 Discussion
We identiﬁed several potential areas for future
research in mobile apps during our current and pre-
vious case studies [7]. We believe that the potential
impact of such research may be signiﬁcant given
the ubiquity of mobile devices and growing im-
portance of mobile apps. We present two such ar-
eas based on observations made during our manual
analysis of the source code and development his-
tory of mobile apps.

5.1 Platform Usage

We observed that many mobile apps depend
highly on their underlying platform (i.e., the An-
droid platform). In our previous work, we deﬁned
the “platform dependency ratio” as the ratio of plat-
form API calls to all calls [7]. A low platform
dependency ratio indicates that developers do not
rely signiﬁcantly on the platform APIs. For exam-

ple, their app may be simple or self-contained, or
the platform may be too difﬁcult to use. Such mo-
bile apps may be easily ported to other platforms.
Conversely, a high platform dependency ratio in-
dicates that mobile app developers heavily exploit
platform APIs. However, this leads to platform
“lock-in”, which may complicate porting to other
platforms and potentially introduces instability due
to the rapid evolution of mobile platforms. While
these issues are relevant to all software that is built
on an underlying platform or framework, it is par-
ticularly acute in mobile apps. This is because the
Android platform averages one major release every
year. Hence, researchers should look at the impact
of platform dependence on quality and how back-
ward compatibility issues could affect quality.

5.2 Development Processes

We observed that many mobile apps have a very
high frequency of releases. For example, K9Mail
typically has two internal releases every week and
one release to Google Play every month. Quick re-
lease cycles may be required to remain competitive
within the marketplace.

Currently, there is evidence that some mobile
apps do not follow a formal development or main-
tenance process. These apps are developed in an
ad hoc manner to get to the market as quickly as
possible. For example, as we discussed in Subsec-
tion 3.1, three mobile apps were excluded from our
case study because they did not have a public issue
tracking system. These apps had been downloaded
hundreds of thousands of times, and yet they did
not have a system where users could report defects.
In addition, the source code repositories of eleven
mobile apps in our case study do not contain any
test cases. Such ad hoc development and mainte-
nance processes may adversely affect the quality
or maintainability of mobile apps.

Researchers should also investigate the relation-
ship between these two factors (frequent releases
and lack of testing) and the quality of code. Khomh
et al. have studied the Mozilla Firefox project and
found that a shorter release cycle 1) allows defects
to be ﬁxed faster and 2) does not introduce signif-
icantly more defects [33]. However, several open
questions remain. Does such a high frequency of
releases mitigate the lack of testing? If there are
frequent releases for the mobile app, then does

quality matter as much? Is the project in a con-
stant beta testing state? Does the platform provide
sufﬁcient support for building high quality apps
quickly? Is the frequent release only inﬂuenced by
the demand factor in the app store? Are the devel-
opers of mobile apps more skilled or do they have
more resources at hand? Or, are mobile apps them-
selves less complex to develop?

6 Threats to Validity
This section outlines the threats to the validity of

our case study.

6.1 Construct Validity

Wget was ﬁrst released in January 1996 and As-
pell was ﬁrst released in September 1998, however,
the development history of this time is not avail-
able. Therefore, the ﬁrst three years of the publicly
available source code repository and issue tracker
do not correspond to the ﬁrst three years of devel-
opment.

The number of downloads is not an ideal mea-
sure of success (unlike user retention or engage-
ment), however, it is the best measure currently
available [4]. Therefore, it is possible that we have
mistakenly included mobile apps with small user
bases or excluded mobile apps with large user bases
from our analysis.

The number of unique developers was found
by counting the number of unique local parts
(i.e.,
the characters before the @ symbol) for
each developer who made at least one commit
to a source code ﬁle in the repository.
Simi-
larly, the number of unique reporters was found
by counting the number of unique local parts for
each reporter who submitted at least one defect
report. While we did perform a manual veri-
ﬁcation of this analysis,
it is possible that we
misidentiﬁed two local parts as either unique or
distinct. For example, john doe@gmail.com and
admin@my project.com were counted as two dis-
tinct developers/reporters, although they may be
a single developer/reporter with multiple (distinct)
email address. Conversely, j doe@gmail.com and
j doe@yahoo.com were counted as one distinct de-
veloper/reporter, although they may be two distinct
developers/reporters (e.g., John and James).

The number of defects in each source code ﬁle
was measured by identifying the ﬁles that were
changed in a defect ﬁxing change. Although this
technique has been found to be effective [31, 32],
it is not without ﬂaws. We identiﬁed defect ﬁxing
changes by mining the commit logs for a set of key-
words. Therefore, we are unable to identify defect
ﬁxing changes (and therefore defects) if we failed
to search for a speciﬁc keyword, if the committer
misspelled the keyword or if the committer failed
to include any commit message. We are also unable
to determine which source code ﬁles have defects
when defect ﬁxing modiﬁcations and non-defect
ﬁxing modiﬁcations are made in the same commit.
However, such problems are common when mining
software repositories [34].

6.2 Internal Validity

The time to ﬁx a defect was calculated by count-
ing the number of days between the date an issue
was opened and the date it was closed. It is pos-
sible that the defect was ﬁxed quickly, but the is-
sue tracking system was not immediately updated
to reﬂect the ﬁx. In addition, this analysis does not
consider defects that were not reported within the
issue tracking system.

The number of unique developers is based on the
list of people who commit to the source code repos-
itory and the number of unique reporters is based
on the list of people who submit issues to the issue
tracking system. This does not capture people who
submit code or issues using other mediums (e.g.,
email or forums).

6.3 External Validity

The studied mobile apps and desktop/server ap-
plications represent a small subset of the total num-
ber of mobile apps and desktop/server applications
available. We have limited our study to open-
source mobile apps and desktop/server applica-
tions. In addition, we have only studied the mo-
bile apps of a single mobile platform (i.e., the An-
droid Platform). Further, some mobile apps (acting
merely as a client) rely on data or services from
backend servers, however our results are limited to
the apps themselves. Therefore, it is unclear how
our results will generalize to 1) closed source mo-
bile apps and desktop/server applications and 2)
other mobile platforms.

6.4 Conclusion Validity

Our results may have been affected by confound-
ing factors. One such confounding factor is that the
defect reporting mechanisms of Android apps af-
fects the defect ﬁxing process [35]. This may have
affected the time to ﬁx defects and the number of
defects reported in each mobile app. For example,
the authors found that Google Code’s bug tracker,
which is used by most open-source Android apps,
offers less support for management (i.e., triaging)
than other widely-used issue tracking systems (e.g,
Bugzilla or Jira). This may increase the time it
takes to ﬁx defects in mobile apps.

The conclusions of empirical software engineer-
ing research may be mistaken as “obvious.” How-
ever, the goal of empirical research is to scientif-
ically validate whether the “obvious” conclusions
are true. We would like to point out that there
have been no empirical studies to prove/disprove
the claims in this study. Mobile app developers
cannot make decisions based on “gut-feeling” in-
stincts. Data-driven empirical studies such as this
will provide the necessary scientiﬁc foundation for
developers to make informed decisions regarding
their software.

7 Conclusions
This paper presented an exploratory study to
compare mobile apps and desktop/server applica-
tions, as a ﬁrst step toward understanding how the
software engineering concepts developed by study-
ing desktop/server will apply to mobile apps. We
studied ﬁfteen open-source Android apps and ﬁve
desktop/server applications (two large, commonly
studied systems and three smaller unix utilities).

We ﬁnd that, in some respects, mobile apps are
similar to unix utilities and differ from large desk-
top and server applications. Mobile apps and unix
utilities are smaller than traditionally studied desk-
top and server applications (e.g., Apache HTTP
server and Eclipse). This is true in terms of the
size of the code base and the development team.
Further, we ﬁnd that the number of core develop-
ers (i.e., those responsible for at least 80% of the
commits), is very small in both mobile apps and
unix utilities, typically only one or two. We also
ﬁnd that few users report defects and few defects
are reported in both mobile apps and unix utilities.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

We explore the distribution of defects across
source code ﬁles by extracting the number of de-
fect ﬁxing changes made to each source code ﬁle.
We assume that each defect ﬁxing change corre-
sponds to a defect in the source code ﬁle. We ﬁnd
defect ﬁxing changes by mining the commit log
messages for a set of keywords [31, 32]. The key-
words (i.e., “bug(s),” “ﬁx(es,ed,ing),” “issue(s),”
“defect(s)” and “patch(s)”) were developed based
on manual analysis of commit log messages. We
ﬁnd the total number of defects in a source code ﬁle
by counting the number of times the ﬁle is changed
by the set of defect ﬁxing changes.

We were unable to use the issues reported in
the issue tracking system because these tend not to
include information regarding how the defect was
ﬁxed (e.g., the location of the defect). We were also
unable to trace defect ﬁxing changes to speciﬁc is-
sues in the issue tracking system because mobile
app developers tend not to reference speciﬁc issues
in their commit messages. Hence, heuristics based
on the commit message need to be used to identify
defect ﬁxing changes despite the lack of a connec-
tion between the source code repository and issue
tracking system.

Once we have extracted the number of defects in
each source code ﬁle, we then calculate the num-
ber of defects in the top 20% most defect-prone
ﬁles by sorting the list of ﬁles by the number of
defects in descending order and summing the num-
ber of defects in the ﬁrst 20% of the list. Figure 3
presents the percentage of defects in the top 20%
most defect-prone ﬁles.

We ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest across mobile
apps, followed by large desktop/server applications
and ﬁnally unix utilities.

In our ﬁrst research question, we found that mo-
bile apps are typically small. Combined with the
distribution of defects, mobile app developers can
ﬁnd the majority of defects in a very small number
of ﬁles, typically only 10s of ﬁles.

From Figure 3, we ﬁnd that a higher percent-
age of defects are concentrated in the top 20%
most defect-prone ﬁles in mobile apps, compared
to desktop/server applications. At least 80% of
the defects are concentrated in the top 20% most
defect-prone ﬁles in nine of our mobile apps and
at least 70% of the defects are concentrated in the
top 20% most defect-prone ﬁles in thirteen of our
mobile apps.

Figure 3: Percentage of All Defects in the Top 20%
Most Defect-Prone Files.

Finding the rationale for the relatively quick de-
fect ﬁx times in mobile apps requires more analysis
on other systems.

We ﬁnd that mobile app developers typi-
cally ﬁx defects faster than desktop/server de-
velopers, regardless of the size of the project.
Defects in mobile apps tend to be concentrated
in fewer source code ﬁles.

5 Discussion
We identiﬁed several potential areas for future
research in mobile apps during our current and pre-
vious case studies [7]. We believe that the potential
impact of such research may be signiﬁcant given
the ubiquity of mobile devices and growing im-
portance of mobile apps. We present two such ar-
eas based on observations made during our manual
analysis of the source code and development his-
tory of mobile apps.

5.1 Platform Usage

We observed that many mobile apps depend
highly on their underlying platform (i.e., the An-
droid platform). In our previous work, we deﬁned
the “platform dependency ratio” as the ratio of plat-
form API calls to all calls [7]. A low platform
dependency ratio indicates that developers do not
rely signiﬁcantly on the platform APIs. For exam-

ple, their app may be simple or self-contained, or
the platform may be too difﬁcult to use. Such mo-
bile apps may be easily ported to other platforms.
Conversely, a high platform dependency ratio in-
dicates that mobile app developers heavily exploit
platform APIs. However, this leads to platform
“lock-in”, which may complicate porting to other
platforms and potentially introduces instability due
to the rapid evolution of mobile platforms. While
these issues are relevant to all software that is built
on an underlying platform or framework, it is par-
ticularly acute in mobile apps. This is because the
Android platform averages one major release every
year. Hence, researchers should look at the impact
of platform dependence on quality and how back-
ward compatibility issues could affect quality.

5.2 Development Processes

We observed that many mobile apps have a very
high frequency of releases. For example, K9Mail
typically has two internal releases every week and
one release to Google Play every month. Quick re-
lease cycles may be required to remain competitive
within the marketplace.

Currently, there is evidence that some mobile
apps do not follow a formal development or main-
tenance process. These apps are developed in an
ad hoc manner to get to the market as quickly as
possible. For example, as we discussed in Subsec-
tion 3.1, three mobile apps were excluded from our
case study because they did not have a public issue
tracking system. These apps had been downloaded
hundreds of thousands of times, and yet they did
not have a system where users could report defects.
In addition, the source code repositories of eleven
mobile apps in our case study do not contain any
test cases. Such ad hoc development and mainte-
nance processes may adversely affect the quality
or maintainability of mobile apps.

Researchers should also investigate the relation-
ship between these two factors (frequent releases
and lack of testing) and the quality of code. Khomh
et al. have studied the Mozilla Firefox project and
found that a shorter release cycle 1) allows defects
to be ﬁxed faster and 2) does not introduce signif-
icantly more defects [33]. However, several open
questions remain. Does such a high frequency of
releases mitigate the lack of testing? If there are
frequent releases for the mobile app, then does

quality matter as much? Is the project in a con-
stant beta testing state? Does the platform provide
sufﬁcient support for building high quality apps
quickly? Is the frequent release only inﬂuenced by
the demand factor in the app store? Are the devel-
opers of mobile apps more skilled or do they have
more resources at hand? Or, are mobile apps them-
selves less complex to develop?

6 Threats to Validity
This section outlines the threats to the validity of

our case study.

6.1 Construct Validity

Wget was ﬁrst released in January 1996 and As-
pell was ﬁrst released in September 1998, however,
the development history of this time is not avail-
able. Therefore, the ﬁrst three years of the publicly
available source code repository and issue tracker
do not correspond to the ﬁrst three years of devel-
opment.

The number of downloads is not an ideal mea-
sure of success (unlike user retention or engage-
ment), however, it is the best measure currently
available [4]. Therefore, it is possible that we have
mistakenly included mobile apps with small user
bases or excluded mobile apps with large user bases
from our analysis.

The number of unique developers was found
by counting the number of unique local parts
(i.e.,
the characters before the @ symbol) for
each developer who made at least one commit
to a source code ﬁle in the repository.
Simi-
larly, the number of unique reporters was found
by counting the number of unique local parts for
each reporter who submitted at least one defect
report. While we did perform a manual veri-
ﬁcation of this analysis,
it is possible that we
misidentiﬁed two local parts as either unique or
distinct. For example, john doe@gmail.com and
admin@my project.com were counted as two dis-
tinct developers/reporters, although they may be
a single developer/reporter with multiple (distinct)
email address. Conversely, j doe@gmail.com and
j doe@yahoo.com were counted as one distinct de-
veloper/reporter, although they may be two distinct
developers/reporters (e.g., John and James).

The number of defects in each source code ﬁle
was measured by identifying the ﬁles that were
changed in a defect ﬁxing change. Although this
technique has been found to be effective [31, 32],
it is not without ﬂaws. We identiﬁed defect ﬁxing
changes by mining the commit logs for a set of key-
words. Therefore, we are unable to identify defect
ﬁxing changes (and therefore defects) if we failed
to search for a speciﬁc keyword, if the committer
misspelled the keyword or if the committer failed
to include any commit message. We are also unable
to determine which source code ﬁles have defects
when defect ﬁxing modiﬁcations and non-defect
ﬁxing modiﬁcations are made in the same commit.
However, such problems are common when mining
software repositories [34].

6.2 Internal Validity

The time to ﬁx a defect was calculated by count-
ing the number of days between the date an issue
was opened and the date it was closed. It is pos-
sible that the defect was ﬁxed quickly, but the is-
sue tracking system was not immediately updated
to reﬂect the ﬁx. In addition, this analysis does not
consider defects that were not reported within the
issue tracking system.

The number of unique developers is based on the
list of people who commit to the source code repos-
itory and the number of unique reporters is based
on the list of people who submit issues to the issue
tracking system. This does not capture people who
submit code or issues using other mediums (e.g.,
email or forums).

6.3 External Validity

The studied mobile apps and desktop/server ap-
plications represent a small subset of the total num-
ber of mobile apps and desktop/server applications
available. We have limited our study to open-
source mobile apps and desktop/server applica-
tions. In addition, we have only studied the mo-
bile apps of a single mobile platform (i.e., the An-
droid Platform). Further, some mobile apps (acting
merely as a client) rely on data or services from
backend servers, however our results are limited to
the apps themselves. Therefore, it is unclear how
our results will generalize to 1) closed source mo-
bile apps and desktop/server applications and 2)
other mobile platforms.

6.4 Conclusion Validity

Our results may have been affected by confound-
ing factors. One such confounding factor is that the
defect reporting mechanisms of Android apps af-
fects the defect ﬁxing process [35]. This may have
affected the time to ﬁx defects and the number of
defects reported in each mobile app. For example,
the authors found that Google Code’s bug tracker,
which is used by most open-source Android apps,
offers less support for management (i.e., triaging)
than other widely-used issue tracking systems (e.g,
Bugzilla or Jira). This may increase the time it
takes to ﬁx defects in mobile apps.

The conclusions of empirical software engineer-
ing research may be mistaken as “obvious.” How-
ever, the goal of empirical research is to scientif-
ically validate whether the “obvious” conclusions
are true. We would like to point out that there
have been no empirical studies to prove/disprove
the claims in this study. Mobile app developers
cannot make decisions based on “gut-feeling” in-
stincts. Data-driven empirical studies such as this
will provide the necessary scientiﬁc foundation for
developers to make informed decisions regarding
their software.

7 Conclusions
This paper presented an exploratory study to
compare mobile apps and desktop/server applica-
tions, as a ﬁrst step toward understanding how the
software engineering concepts developed by study-
ing desktop/server will apply to mobile apps. We
studied ﬁfteen open-source Android apps and ﬁve
desktop/server applications (two large, commonly
studied systems and three smaller unix utilities).

We ﬁnd that, in some respects, mobile apps are
similar to unix utilities and differ from large desk-
top and server applications. Mobile apps and unix
utilities are smaller than traditionally studied desk-
top and server applications (e.g., Apache HTTP
server and Eclipse). This is true in terms of the
size of the code base and the development team.
Further, we ﬁnd that the number of core develop-
ers (i.e., those responsible for at least 80% of the
commits), is very small in both mobile apps and
unix utilities, typically only one or two. We also
ﬁnd that few users report defects and few defects
are reported in both mobile apps and unix utilities.

We also ﬁnd that,

in other respects, mobile
apps differ from both unix utilities and large
desktop/server applications. We ﬁnd that mobile
app developers place a great deal of emphasis
on rapidly responding to quality issues and most
projects ﬁx over a third of reported defects within
one week and two thirds of reported defects within
one month. This is greater for the Eclipse UI com-
ponent and the aspell, joe and wget utilities, which
typically ﬁx only 20% of reported defects in one
week and 40% of reported defects in one month.
However, developers of the Apache HTTP server
project ﬁx 46% of all reported defects in one week
and 96% of all reported defects in one month. We
also ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest in mobile
apps, followed by large desktop and server appli-
cations and ﬁnally unix utilities. Most mobile apps
have more than 80% of the defects in 20% of the
most defect-prone ﬁles. This compares to two third
and half for large desktop and server applications
and unix utilities respectively.

In conclusion, our ﬁndings suggest that mobile
apps may be facing unique challenges. In order to
support the 50,000 developers creating mobile apps
[13], researchers should begin to study mobile apps
alongside traditionally studied desktop and server
applications.

References
[1] L. Columbus, “Roundup of mobile apps
2013.
and
www.forbes.com
[Online]. Available:
/sites/louiscolumbus/2013/06/09/roundup-of-
mobile-apps-app-store-forecasts-2013/

forecasts,”

Jun

app

store

[2] C. Sharma, “Sizing up the global apps

market,” www.chetansharma.com/
mobileappseconomy.htm, Chetan Sharma
Consulting, Mar 2013.

[3] “Google play,” play.google.com.

[4] M. Harman, Y. Jia, and Y. Z. Test, “App Store
Mining and Analysis: MSR for App Stores,”
in Proceedings of the International Working
Conference on Mining Software Repositories,
Jun 2012.

[5] R. Minelli and M. Lanza, “Software ana-
lytics for mobile applications - insights &
lessons learned,” Mar 2013, pp. 144–153.

[6] I. J. M. Ruiz, M. Nagappan, B. Adams, and
A. E. Hassan, “Understanding reuse in the an-
droid market,” in Proceedings of the Interna-
tional Conference on Program Comprehen-
sion, Jun 2012, pp. 113–122.

[7] M. D. Syer, B. Adams, A. E. Hassan, and
Y. Zou, “Exploring the development of micro-
apps: A case study on the blackberry and an-
droid platforms,” in Proceedings of the Inter-
national Working Conference on Source Code
Analysis and Manipulation, Sep 2011.

[8] F. P. Brooks, The mythical man-month – Es-
Addison-

says on Software-Engineering.
Wesley, 1975.

[9] S. Chidamber and C. Kemerer, “A metrics
suite for object oriented design,” Transactions
on Software Engineering, vol. 20, no. 6, pp.
476 –493, Jun 1994.

[10] N. Nagappan and T. Ball, “Use of relative
code churn measures to predict system defect
density,” in Proceedings of the International
Conference on Software Engineering, 2005,
pp. 284–292.

[11] C. Bird, N. Nagappan, B. Murphy, H. Gall,
and P. Devanbu, “Don’t touch my code!: ex-
amining the effects of ownership on software
quality,” in Proceedings of the Symposium
and the European Conference on Foundations
of Software Engineering, 2011, pp. 4–14.

[12] B. Robinson and P. Francis, “Improving in-
dustrial adoption of software engineering re-
search: a comparison of open and closed
source software,” in Proceedings of the Inter-
national Symposium on Empirical Software
Engineering and Measurement, Sep 2010, pp.
21:1–21:10.

[13] N. O’Neill, “10 surprising app platform
facts,” http://allfacebook.com/app-platform-
facts b18514, All Facebook, Sep 2010.

[14] A. Cravens, “A demographic and business
model analysis of today’s app developer,”
http://pro.gigaom.com/archives/research-
brieﬁngs/, GigaOM, Sep 2012.

[15] “Mobile software engineering,” mobilese-

workshop.org, Apr 2013.

Revisiting Prior Empirical Findings For Mobile Apps:

An Empirical Case Study on the 15 Most Popular

Open-Source Android Apps

Mark D. Syer, Meiyappan Nagappan, Ahmed E. Hassan

Software Analysis and Intelligence Lab
School of Computing, Queens University
{mdsyer, mei, ahmed}@cs.queensu.ca

Lab on Maintenance, Construction and Intelligence of Software

G´enie Informatique et G´enie Logiciel, ´Ecole Polytechnique de Montr´eal

Bram Adams

bram.adams@polymtl.ca

Abstract
Our increasing reliance on mobile devices has
led to the explosive development of millions of mo-
bile apps across multiple platforms that are used
by millions of people around the world every day.
However, most software engineering research is
performed on large desktop or server-side software
applications (e.g., Eclipse and Apache). Unlike the
software applications that we typically study, mo-
bile apps are 1) designed to run on devices with
limited, but diverse, resources (e.g., limited screen
space and touch interfaces with diverse gestures)
and 2) distributed through centralized “app stores,”
where there is a low barrier to entry and heavy com-
petition. Hence, mobile apps may differ from tradi-
tionally studied desktop or server side applications,
the extent that existing software development “best
practices” may not apply to mobile apps. There-
fore, we perform an exploratory study, comparing
mobile apps to commonly studied large applica-
tions and smaller applications along two dimen-
sions:
the size of the code base and the time to
ﬁx defects. Finally, we discuss the impact of our
ﬁndings by identifying a set of unique software en-
gineering challenges posed by mobile apps.

Copyright c(cid:13) 2013 Mark D. Syer. Permission to copy is
hereby granted provided the original copyright notice is repro-
duced in copies made.

1

Introduction

App stores (e.g., Google Play and Apple App
Store) have changed the software development
world by providing a platform for the rapid growth
of mobile apps (i.e., software applications for
smartphones and tablets). Since 2007, mobile apps
have exploded into a multi-billion dollar market
[1, 2] and become hugely popular among con-
sumers and developers. Mobile app downloads
have risen from 7 billion in 2009 to 15 billion in
2010 [2] and are projected to reach 74 billion in
2016 [1]. Simultaneously, the number of mobile
apps has also increased: Google Play now hosts
over 1 million mobile apps [3].

Despite the ubiquity of mobile devices and the
popularity of mobile apps, few software engi-
neering researchers have studied them [4, 5, 6,
7]. During the thirty-ﬁve years following Fred
Brooks’ seminal text, The Mythical Man Month
[8], the software engineering community has pro-
posed and evaluated several ideas of how high qual-
ity, successful software is developed and main-
tained. These “software engineering concepts” aim
to tie aspects of software artifacts (e.g., size and
complexity) [9], their development (e.g., number
of changes) [10] and their developers (e.g., devel-
oper experience) [11] to deﬁnitions of quality (e.g.,
post-release defects). However, such software en-
gineering concepts have primarily been evaluated
against large-scale projects [12].

Understanding how established software engi-
neering concepts apply to mobile apps is an im-
portant research question. Mobile apps distinguish
themselves from desktop and server applications
by their limited functionality,
low memory and
CPU footprint, limited screen sizes, touch inter-
faces and access to diverse hardware (e.g., GPS and
accelerometers). Hence, mobile apps are expected
to become a major challenge for software devel-
opers and maintainers in the near future because
the underlying hardware and software is constantly
and rapidly evolving. In addition, centralized “app
stores” (e.g., Google Play) provide consumers with
easy access to tens of thousands of apps, and devel-
opers with access to millions of consumers. This
ecosystem has become characterized by low bar-
riers to entry for prospective developers, but with
heavy competition.

As a ﬁrst step towards understanding how estab-
lished software engineering concepts apply to mo-
bile apps, we perform an exploratory study to com-
pare mobile apps and desktop/server applications.
We study ﬁfteen open-source Android apps and ﬁve
desktop/ server applications (two large, commonly
studied applications and three smaller unix utili-
ties). Our study addresses the following two re-
search questions:

• RQ1: How does the size of the code base com-
pare? – mobile apps and unix utilities tend
to have smaller code bases than larger desk-
top and server applications. The development
of mobile apps and unix utilities tends to be
driven by one or two core developers. Further,
mobile apps tend to depend heavily on an un-
derlying platform.

• RQ2: How does the defect ﬁx time compare?
– mobile app developers typically ﬁx defects
faster than desktop/server developers, regard-
less of the size of the project. Defects in
mobile apps tend to be concentrated in fewer
source code ﬁles.

The paper is organized as follows: Section 2 mo-
tivates our case study and presents related work.
Section 3 describes the setup of our case study and
Section 4 describes the results. In Section 5, we
present potential directions for future research of
mobile apps. Section 6 outlines the threats to the
validity of our case study. Finally, Section 7 con-
cludes the paper.

2 Motivation and Related

Work

Mobile app downloads have seen explosive
growth in the past few years, which is expected
to continue well into the future [1]. Despite this
growth, few researchers have studied mobile apps
from a software engineering perspective. Software
engineering concepts like “high churn leads to poor
quality” [10] and “high cohesion and low coupling
leads to high quality” [9], have primarily been eval-
uated against large-scale projects such as Apache
and Eclipse [12]. Determining how these concepts
apply to mobile apps may reduce the effort in de-
veloping and maintaining high quality mobile apps.
Our existing software engineering knowledge
may not apply to mobile apps due to differences
between the mobile app and desktop/server ecosys-
tems. Two potentially inﬂuential differences are
1) the hardware limitations and diversity of mobile
devices and 2) the distribution channel provided by
app stores.

2.1 Hardware Limitations and

Diversity

The hardware limitations of mobile devices has
led to mobile apps with small memory and CPU
footprints that are intended for mobile devices with
small screen sizes. These hardware limitations may
limit the scope of mobile apps. Indeed, even the
latest generation of mobile devices fails to meet
the minimum system requirements for best-selling
games (e.g., World of Warcraft) and applications
(e.g, Adobe Photoshop CS5). Further, the shift in
usage from desktop and server systems to mobile
devices (mobile devices are intended to be used
“on-the-go”) may also limit the scope of mobile
apps.

While the capabilities of mobile devices have
been rapidly increasing (e.g., many new devices
boast dual-core processors) some of these limita-
tions are permanent. This is particularly true of the
screen size and resolution, which may limit the in-
formation and functionality displayed at one time.
the diversity of hardware (e.g., ac-
celerometers and touch interfaces with gesture
recognition) may complicate development as de-
velopers experiment with these features.

Further,

Therefore, the diversity and limitations of mo-
bile device hardware may limit the scope of mobile
apps. Although all software faces hardware limita-
tions, the limitations of mobile devices are gener-
ally much greater than those of desktop or server
systems.

2.2 Distribution Channel

Major mobile platforms (e.g., the Android plat-
form) provide centralized app stores for users to
download mobile apps. Centralized app stores are
easily browsed and directly available from a user’s
device. Therefore, the effort to install mobile apps
is minimal. Further, the cost of listing a mobile app
in an app store is very low (occasionally there is no
cost) while the potential to reach millions of con-
sumers is high.

The low cost to enter the mobile market and
the potential to generate revenue has attracted a
large number of developers [1, 2]. In 2010, more
than 50,000 developers were creating mobile apps
for the Android or iOS platforms [13]. Further,
development tools have been released to the gen-
eral public so that anyone can develop a mobile
app, even without prior development experience.
Nearly half of mobile app developers have less than
two years of experience [14]. The large and con-
stantly expanding development community leads to
high competition between developers. For exam-
ple, Google Play contains hundreds of competing
weather, media and instant messaging apps.

The high competition between developers may
affect the quality of mobile apps for fear of losing
users to competing apps. Therefore, the emphasis
on defect ﬁxing may be high and hence the defect
ﬁx times may be low.

2.3 Related Work

Software engineering researchers are now be-
ginning to explore the challenges and issues sur-
rounding mobile apps and platforms [15]. Re-
searchers are also studying mobile apps from other
perspectives,
including app ecosystems [4, 16],
cross platform development [17, 18] and security
[19, 20, 21]. However, there are only a few studies
of mobile apps from a software engineering per-
spective.

Mojica et al. studied code reuse in 4,323 Android
apps and found that, on average, 61% in the classes
in a mobile app are reused by other apps in the same
domain [6] (e.g., social networking). The authors
also found that 23% of the 534,057 classes in their
case study inherit from a class in the Android plat-
form. In this paper, we are interested in how such
measures compare across mobile apps and desktop
and server applications.

Maji et al. studied defect reports in the Android
and Symbian platforms to understand where de-
fects occur in these platforms and how defects are
ﬁxed [22]. The authors determine that development
tools, web browsers and multimedia modules are
the most defect-prone and that most defects require
minor code changes. The authors also determine
that despite the high cyclomatic complexity of the
Android and Symbian platforms, defect densities
are surprisingly low. In this paper, we study An-
droid apps, not the platform itself.

Minelli and Lanza have developed SAMOA, a
new tool that can gather and visualize basic source
code metrics (e.g., size and complexity) from mo-
bile apps [5]. SAMOA is intended to help devel-
opers better understand the development and evo-
lution of their app, whereas the purpose of our
work is to empirically establish typical properties
of mobile apps and to contrast these properties
with traditionally-studied desktop and server appli-
cations. Further, we extract and analyze metrics
from both the source code and issue tracking sys-
tems of both mobile apps and desktop and server
applications.

In our previous work, we performed a study of
three pairs of functionally equivalent mobile apps
from two popular mobile platforms (i.e., the An-
droid and BlackBerry platforms), as a ﬁrst step to-
wards understanding the development and mainte-
nance process of mobile apps [7]. We found that
BlackBerry apps are much larger and rely more on
third party libraries. However, they are less sus-
ceptible to platform changes since they rely less on
the underlying platform. On the other hand, An-
droid apps tend to concentrate code into fewer large
ﬁles and rely heavily on the Android platform. On
both platforms, we found code churn to be high.
However, we are unaware of how these ﬁndings on
mobile apps compare to desktop or server applica-
tions.

3 Case Study Setup
3.1 Mobile App Selection

In this paper, we studied mobile apps written for
the Android platform. The Android platform is the
largest (by user base) and fastest growing mobile
platform.
In addition, the Android platform has
more free mobile apps than any other major mobile
platform [23].

Mobile apps for Android devices are primarily
hosted in Google Play [3]. Google Play classiﬁes
mobile apps into two groups (i.e., free and paid)
and records details such as cost and the number of
times each app has been installed. We used Google
Play to list the top 2,000 free apps and the top 2,000
paid apps (2,000 is the maximum number of apps
that Google Play ranks). However, we limit our
study to free Android mobile apps, because 1) the
majority (63%) of Android apps are free [23], 2)
free apps are downloaded signiﬁcantly more than
paid mobile apps [24] and 3) the source code repos-
itories and issue tracking systems are not available
for paid apps.

Google Play uses the term “free” to describe
Android apps that are may be downloaded at no
cost. Free apps are not necessarily open source.
One reason is that many of these apps are de-
veloped internally by organizations as mobile in-
terfaces to their online services (e.g., Facebook,
Google Maps and Twitter). Another reason is that
many paid apps have versions that are available for
free. This is because a common revenue model is
to use a multi-tiered structure (e.g., a free app with
ads and a paid app without ads, or a demo version
with a limited feature set and a paid app). How-
ever, we are unable to study these apps because
they are only available as bytecode ﬁles (i.e., we
do not have access to their source code repositories
or issue tracking systems). Therefore, we must de-
termine which apps in the top 2,000 free app list
are open source.

We selected apps for our case study by cross-
referencing the list of the top 2,000 free apps in
Google Play, with the list of apps in the FDroid
repository. The FDroid repository is an alterna-
tive app store that exclusively lists free and open-
source (FOSS) Android apps that are also listed in
Google Play [25]. It contains links to the home-
page, source code repository and issue tracking
system (if available). Since it does not contain any

Table 1: Selected Mobile Apps

Name
Description
3
Music Player
Apps Organizer
Utility
Barcode Scanner Utility
ConnectBot
Cool Reader
Frozen Bubble
K-9 Mail
KeePassDroid
Quick Settings

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10 Reddit is fun
Scrambled Net
M11
Sipdroid
M12
M13
Solitaire
M14 Tricorder
M15 Wordpress

SSH Client
E-Book Reader
Game
Email Client
Password Vault
Utility
Social Networking
Game
VOIP client
Game
Game
CMS Client

information regarding the user base (e.g., the num-
ber of downloads), we must retrieve this informa-
tion from Google Play.

Mobile apps in the resulting list of ﬁltered apps
are 1) popular amongst users (allowing us to study
“successful” apps) and 2) open source (allowing us
to access source code repositories and issue track-
ing systems). This list contains twenty mobile
apps. However, ﬁve were excluded from our case
study:
three were excluded because they did not
have an issue tracking system, one used a differ-
ent source control system (other than SVN/GIT)
and one was a mobile port of a desktop applica-
tion. We excluded the latter app because the same
development team produced the mobile and desk-
top versions within the same source code reposi-
tory, meaning that the app was developed largely
following a desktop mind set, with minor changes
towards the mobile end. This is not typical for a
mobile app. Therefore, our case study includes ﬁf-
teen mobile apps.

Table 1 contains the list of mobile apps that were
included in our case study. We have assigned an
ID to each mobile app for brevity. Table 1 con-
tains mobile apps from a number of different do-
mains, including utilities, networking, multimedia
and games.

Table 2: Selected Desktop and Server Applications

Description
ID Name
D1 Apache HTTP Server
HTTP Server
D2 Eclipse UI Component User Interface
Spell Checker
D3
Text Editor
D4
D5 wget
File Retriever

aspell
joe

First Commit Last Commit
07/03/1996
05/23/2001
01/01/2000
04/19/2001
02/12/1999

07/02/2011
09/12/2011
01/01/2004
04/19/2005
01/11/2003

3.2 Desktop/Server Application

Selection

In this paper, we use two types of desktop/server

applications.

First, we study two large, commonly studied
desktop/server applications. In particular, we study
the User Interface (UI) component of the Eclipse
platform and the Apache HTTP server projects.
These applications are two of the most commonly
studied desktop/server applications in software en-
gineering literature [12], used by many researchers
to derive general ﬁndings about the software en-
gineering process. We do not claim that these
projects are the baseline against which all software
engineering research should be measured. How-
ever, we wish to determine the similarities and dif-
ferences between these two projects and our mo-
bile apps as a ﬁrst step towards understanding how
the software engineering concepts developed from
studying desktop/server applications apply to mo-
bile apps.

Second, we also study three smaller unix util-
In particular, we study the aspell, joe and
ities.
wget unix utilities. These applications are rarely
studied by software engineering researchers, how-
ever, they may be more similar to mobile apps than
the larger, more commonly studied desktop/server
applications. Similar to mobile apps, these applica-
tions have small feature sets and are readily avail-
able to large user bases (typically pre-installed on
all unix-like operating systems and hence available
to millions of users). To enhance the similarity be-
tween these applications and mobile apps, we con-
sider only the ﬁrst four years of development (i.e.,
four years from the date of the initial commit to
the source code repository). Therefore, the mod-

iﬁed aspell, joe and wget data sets represent rela-
tively young projects with small feature sets that
are available to a large user base (these characteris-
tics are very similar to the mobile apps in our case
study).

Table 2 contains the list of desktop/server appli-
cations that were included in our case study. We
have assigned an ID to each desktop/server appli-
cation for brevity. For each of the selected desk-
top/server applications, Table 2 contains 1) a brief
description and 2) the date of the ﬁrst and last com-
mits included within our analysis.

3.3 Research Questions

As a ﬁrst step toward determining how exist-
ing software engineering knowledge may be ap-
plied to mobile apps, we perform an exploratory
study comparing mobile apps and desktop/server
applications. We study ﬁfteen open-source An-
droid apps, two large desktop/server applications
(Apache HTTP server and Eclipse UI component)
and three smaller unix utilities (aspell,
joe and
wget) to address the following two research ques-
tions:

• RQ1: How does the size of the code base com-
pare between mobile apps and desktop/server
applications?

• RQ2: How does the defect ﬁx time compare
between mobile apps and desktop/server ap-
plications?

The purpose of our research questions is to em-
pirically establish properties of mobile apps and to
contrast these properties with traditionally-studied
software.

4 Case Study Results
RQ1: How does the size of the
code base compare?
Motivation

Many problems typically addressed by software
engineering researchers and faced by developers
are caused by large code bases and development
teams. For example, the difﬁculty of code naviga-
tion increases as the code base grows. In addition,
the size of the code base (e.g., lines of code) has
been shown to be highly correlated to the complex-
ity of a software application [26, 27]. The difﬁculty
of understanding, evolving and maintaining a soft-
ware application is strongly tied to the complexity
of the application. Therefore, we measure the size
of the code base and of mobile apps and compare it
to desktop/server applications.

Approach

We explore the size of the code base by extract-
ing the total number of lines of code and number
of source code ﬁles. We used the Understand tools
by Scitools [28] to extract these metrics. Under-
stand is a toolset of static source code analysis tools
for measuring and analyzing software projects. Ta-
ble 3 presents the total number of source code ﬁles
and lines of code (LOC) in the code base of each
mobile app and desktop/server application. These
measurements were made on the latest version of
the projects, either 1) August 8, 2011 for the mo-
bile apps or 2) the date of the last commit for the
desktop/server applications in Table 2.

Results
Size of the Code Base

From Table 3, we ﬁnd that the size of our mobile
apps ranges between 2,332 and 47,927 LOC with a
median value of 14,014. This is the same order of
magnitude as aspell, joe and wget. This value is ap-
proximately 9 times smaller than the Apache HTTP
server project and 20 times smaller than the Eclipse
UI component (note that the Eclipse UI component
is only one component of the Eclipse project).

From Table 3, we ﬁnd that many games tend to
be small. For example, M6, M11, M13 and M14
are less than 6,000 LOC. These apps offer simple

Table 3: Size of the Code Base

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Files LOC
69
131
237
229
39
15
157
306
63
43
6
250
14
32
64
386
2,360
129
91
61

20,050
12,282
22,785
32,692
14,014
2,846
47,927
23,808
5,288
10,524
2,332
24,259
4,196
5,470
17,287
123,293
276,980
12,311
27,419
17,376

board games, puzzles and card games. Conversely,
the largest mobile app, M7, is a full-ﬂedged email
client designed to replace the default email client
that ships with an Android device. M7 has an
extensive feature set, including support for IMAP,
POP3 and Exchange, multiple identities, customiz-
able viewing preferences and alternate themes.

Since mobile apps tend to have small code bases,
we further explore two factors that may inﬂuence
the size of the code base: 1) the size of the devel-
opment team and 2) platform usage.

Size of the Development Team

One factor that may inﬂuence the size of the code
base is the number of developers. If few developers
contribute to a project, then the size of the project
is constrained by the developers combined effort.

We explored the size of the development team by
extracting the number of developers and the num-
ber of source code commits that each developer
makes to a project. We extracted the commit logs
from the source code repository and isolated the
committer ﬁeld for each source code commit (i.e.,

a commit that included at least one source code
ﬁle (e.g., “.java,” or “.c” ﬁles)). To measure the
number of unique developers, we extract the lo-
cal part of each email address (i.e., the characters
before the @ symbol), and count the number of
unique local parts across all source code commits.
We then count the number of source code com-
mits made by each developer. We perform manual
checks to verify that the extracted list of develop-
ers contains only unique entries and we merge any
john doe@gmail.com and
uncaught cases (e.g.,
doe.john@google.com).
Similar to Mockus et al.
[29], we then calculate the minimum number of
developers who, when combined, are responsible
for at least 80% of the commits. These “core” de-
velopers are responsible for the majority of the de-
velopment and maintenance effort. Although this
deﬁnition of core developer and may miss devel-
opers that contribute substantially through other
means, it is commonly used in practice [29]. Ta-
ble 4 presents the number of developers and core
developers for each mobile app and desktop/server
application and the average number of lines of code
per developer and core developer.

From Table 4, we ﬁnd that the number of core
developers participating in the development and
maintenance of a mobile app is approximately the
same as the number of developers participating
in aspell, joe and wget, but much smaller than
the number of core developers participating in the
Apache HTTP server and Eclipse UI component.
We also ﬁnd that, despite the large variability in
the number of mobile app developers, from 1 to 22
developers, the number of core developers is one in
three quarters of the mobile apps. Therefore, the
development of mobile apps tends to be driven by
a single developer.

The size of the development team was further ex-
plored by comparing the size of the code base and
the size of the development team. Figure 1 shows
the number of developers plotted against the num-
ber of lines of code in the code base. Figure 1 also
shows a trend line generated by ﬁtting a straight
line to the data from our mobile apps.

From Figure 1, we ﬁnd that the number of de-
velopers increases as the number of lines of code
increases. However, this trend line is not a perfect
ﬁt to the data, indicating that the relationship be-
tween the size of the code base and development
team varies between projects. This is supported
by Table 4, where we ﬁnd that the average number

Figure 1: Size of the code base and development
team.

of lines of code per developer varies signiﬁcantly,
from 501 to 12,282. Interestingly, the median num-
ber of lines of code per developer across the mobile
apps (10,524) and the Apache HTTP server and
Eclipse UI component (9,977) are very similar.

There are many reasons why mobile apps have
varying numbers of developers. Some developers
request that the user community contribute towards
the project. For example, the core developer of
M10 informed users that he was unable to continue
maintaining the project and asked the user commu-
nity to contribute. Conversely, some developers act
as gate keepers to their source code repository and
are responsible for each commit. For example, the
developer of M2 asked that translations be submit-
ted via email, whereas translators were given com-
mit privileges in M11 (many of whom would later
contribute defect ﬁxes).

Platform Usage

Another factor that may inﬂuence the size of
the code base is the reuse of existing functional-
ity through libraries. The Android and Java APIs
(Android apps are written in Java) provide basic
and commonly required functionalities, thereby re-
ducing the size of the code base and the amount of
functionality that the development team must im-
plement themselves.

Table 4: Size of the Development Team

#Core Devs LOC/

ID

M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

#Devs LOC/
#Devs
5,013
12,282
2,071
2,724
1,168
2,846
2,995
5,952
5,288
501
2,332
1,103
2,098
2,735
8,644
1,284
3,901
4,104
4,570
2,896

4
1
11
12
12
1
16
4
1
21
1
22
2
2
2
96
71
3
6
6

1
1
2
1
2
1
4
1
1
1
1
5
1
1
1
27
18
1
2
1

Table 5: Java and Android Depen-
dencies

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15

Java Android
20% 39%
13% 16%
19% 13%
21% 14%
33% 11%
19% 20%
14% 17%
38% 7%
8%
42%
64% 17%
10% 30%
13% 11%
4%
12%
7%
25%
68% 18%

#Core Devs
20,050
12,282
11,393
32,692
7,007
2,846
11,982
23,808
5,288
10,524
2,332
4,852
4,196
5,470
17,287
4,566
15,388
12,311
13,710
17,376

We explore the extent of platform usage by ex-
tracting the number of references (e.g., calls to the
Android library). We used the Understand tool to
extract, for each source code ﬁle in the subject mo-
bile apps, a list of classes on which the ﬁle depends.
These dependencies were classiﬁed into one of the
following categories based on the class name:
• Android - dependency on a class

that
the Android platform (e.g.,

is part of
android.app.Activity).

• Java

-
part

dependency
of

the

is
java.io.IOException).

on
Java

class

that
a
platform (e.g.,

We then determined platform usage (i.e., the ra-
tio of the number of platform dependencies to the
total number of dependencies). Table 5 presents the
Platform and Java dependencies as a percentage of
the total dependencies.

From Table 5, we ﬁnd that Java and Android de-
pendence is relatively high in most mobile apps.
Further, the median value of the Java and Android
dependencies combined is 39% and exceeds 80%
in M10 and M15.

From Table 5, we also ﬁnd that Android de-
pendence is particularly high (42%) in M9 (Quick
Settings). The app is designed to interface with
the Android platform and give users control over
device settings (e.g., screen brightness).
In con-
trast, platform dependence is low (7% and 11% re-
spectively) in M8 (KeePassDroid) and M5 (Cool
Reader). KeePassDroid is a port of the KeePass
Password safe and Cool Reader is a cross-platform
e-reader.

Uncovering the rationale for the relatively small
code bases in mobile apps requires more analysis
on other systems and consumer usage trends (are
consumer demands satisﬁed by mobile apps with
limited functionality?).

We ﬁnd that mobile apps and unix utilities
tend to have smaller code bases than larger
desktop/server applications. The development
of mobile apps and unix utilities tends to be
driven by a one or two core developers. Fur-
ther, mobile apps tend to rely heavily on an
underlying platform.

RQ2: How does the defect ﬁx
time compare?
Motivation

Software quality is a major draw for users, and
with access to thousands of mobile apps through
app stores, users demand the highest quality. If a
user installs a low quality app from the app store,
he or she can typically ﬁnd and install a replace-
ment from the app store within minutes. Competi-
tion may force developers to place a greater empha-
sis on ﬁxing defects, or risk losing users to compet-
ing apps. Thus, the emphasis on defect ﬁxing, and
hence defect ﬁx times, may differ between mobile
apps and desktop/server applications. Therefore,
we must compare the defect ﬁx times of mobile
apps and desktop/server applications.

Approach

We explored the time it takes to ﬁx defects by ex-
tracting the list of issues that have been resolved as
“closed” with a “ﬁxed” status from the issue track-
ing system. We did not include issues that were
classiﬁed as “not a bug,” “duplicates” or “not repro-
ducible”, because these issues did not involve any
time to ﬁx. The resulting issues describe unique
defects that have been ﬁxed. We then calculate
the number of days between the date the issue was
opened and the date it was closed. For issues with
multiple close dates (i.e., issues that have been re-
opened) we take the last close date. We then calcu-
late the percentage of defects that have been ﬁxed
within one week, one month and one year of being
reported. Figure 2 presents these measures for each
mobile app and desktop/server application and Ta-
ble 6 presents the median value of these measures
across all 1) mobile apps, 2) large desktop/server
applications and 3) unix utilities.

Table 6: Median Percentage of Defects Fixed in
One Week/Month/Year

Week Month Year
36
100
Mobile Apps
Apache HTTP & 33
92
Eclipse
Unix Utilities

68
69

80

21

36

Figure 2: Percentage of Defects Fixed in One
Week, One Month and One Year.

Results
Defect Fix Times

From Figure 2, we ﬁnd that developers of four
mobile apps ﬁx 50% of reported defects in one
week and developers of eleven mobile apps ﬁx 33%
of reported defects in one week. This is greater
than the aspell, joe and wget utilities, which ﬁx
24%, 21% and 17% of the reported defects in one
week respectively. This is also greater than the
Eclipse UI component, where 19% of the reported
defects are ﬁxed in one week. However, it is less
than the Apache HTTP server, where 46% of the
reported defects are ﬁxed in one week. The num-
ber of defects ﬁxed within one week in M6 is zero
because only a single defect was reported in total
(it was ﬁxed in 26 days).

From Table 6, we ﬁnd that the defect ﬁx times
in mobile apps are more similar to large desk-
top/server applications than to unix utilities. For
example, the median percentage of defects ﬁxed
within one week is 36% in mobile apps and 33%
in large desktop/ server applications compared to
only 21% in unix utilities.

From Table 6 and Figure 2, we also ﬁnd that 20%
of defects in unix utilities take longer than one year
to ﬁx, whereas 100% of defects in mobile apps are
ﬁxed within one year.

From Figure 2, the percentage of reported de-
fects ﬁxed in one year in D4 is 61%, compared to
80% in D3 and 80% in D5. However, the develop-
ers of D4 close groups of defects at the same time.

For example, between May 5, 2003 and February 1,
2006, the developers did not close any issues, how-
ever, on February 2, 2006, ten issues were closed
(on average, these ten issues were open for three
years). Therefore, it is possible that developers ﬁx
defects within a short time span, but fail to update
the issue tracking system until a later date.

As the defect ﬁx times for mobile apps tend to be
less than the defect ﬁx times of large desktop/server
applications, we further explore two factors that
may inﬂuence the time it takes to ﬁx defects. First,
we explore the number of defects reported in the
issue tracking system. Second, we explore the dis-
tribution of defects across source code ﬁles.

Number of Defects Reported

One factor that may inﬂuence the time it takes to
ﬁx defects is the number of defects reported in the
issue tracking system. If few defects are reported,
then fewer defects need to be ﬁxed and developers
can focus more of their attention on these defects.
We explore the number of defects reported by
counting the number of issues in the issue track-
ing system that have been marked as defects. Sim-
ilar to our analysis of defect ﬁx times, we did not
include issues that were classiﬁed as “not a bug,”
“duplicates” or “not reproducible.” However, un-
like our analysis of defect ﬁx times, we do not limit
our analysis to issues that have been closed. This
is because we are including defects that have been
reported, but have yet to be ﬁxed.

We also explore the number of reporters who
have reported at least one defect in the issue track-
ing system. This analysis is similar to our identiﬁ-
cation of unique developers, except that we use the
list of people who have reported issues, instead of
the list of people who have committed source code.
Table 7 presents the number of defects reported
and the number of users reporting defects in each
mobile app and desktop/server application. We ﬁnd
that few defects are reported and few users report
defects in both mobile apps and unix utilities com-
pared to large desktop/server applications.

Android users primarily download apps through
Google Play, where they can also rate apps and pro-
vide comments. However, user ratings and com-
ments do not provide the same structure as is-
sue tracking systems. The developers of M7 have
speciﬁcally asked users to report defects in their is-
sue tracking system.

Table 7: Number of Defects Reported and Unique
Defect Reporters

ID
M1
M2
M3
M4
M5
M6
M7
M8
M9
M10
M11
M12
M13
M14
M15
D1
D2
D3
D4
D5

Reporters Reported Defects
4
13
267
315
8
6
1,293
178
99
18
6
591
77
33
15
3,425
1,206
35
26
25

21
15
342
425
20
7
2,518
192
120
62
7
803
100
38
98
5,104
6,287
268
64
55

From Table 7, we ﬁnd that the greatest number
of defects are reported in M7 (email client), M12
(VOIP client), M4 (SSH client) and M3 (barcode
scanner), whereas, few defects are reported in mo-
bile apps related to entertainment, M1 and M5 (me-
dia players), M6, M11 and M14 (games) and M10
(social networking).

Distribution of Defects

Another factor that may inﬂuence the time it
takes to ﬁx defects is the distribution of defects
across source code ﬁles. If defects tend to be con-
centrated in a few ﬁles and developers are aware of
these ﬁles, then they may be able to locate these
defects with less effort. Ostrand et al. found that,
in large software systems, most defects are found
within a small subset of the source code ﬁles [30].
The authors found that 80% of the defects are found
within 20% of the source code ﬁles (this is often re-
ferred to as the 80-20 rule). Hence, developers can
prioritize their code reviews and test cases to fo-
cus on these ﬁles and reduce the effort required to
locate most defects.

We explore the distribution of defects across
source code ﬁles by extracting the number of de-
fect ﬁxing changes made to each source code ﬁle.
We assume that each defect ﬁxing change corre-
sponds to a defect in the source code ﬁle. We ﬁnd
defect ﬁxing changes by mining the commit log
messages for a set of keywords [31, 32]. The key-
words (i.e., “bug(s),” “ﬁx(es,ed,ing),” “issue(s),”
“defect(s)” and “patch(s)”) were developed based
on manual analysis of commit log messages. We
ﬁnd the total number of defects in a source code ﬁle
by counting the number of times the ﬁle is changed
by the set of defect ﬁxing changes.

We were unable to use the issues reported in
the issue tracking system because these tend not to
include information regarding how the defect was
ﬁxed (e.g., the location of the defect). We were also
unable to trace defect ﬁxing changes to speciﬁc is-
sues in the issue tracking system because mobile
app developers tend not to reference speciﬁc issues
in their commit messages. Hence, heuristics based
on the commit message need to be used to identify
defect ﬁxing changes despite the lack of a connec-
tion between the source code repository and issue
tracking system.

Once we have extracted the number of defects in
each source code ﬁle, we then calculate the num-
ber of defects in the top 20% most defect-prone
ﬁles by sorting the list of ﬁles by the number of
defects in descending order and summing the num-
ber of defects in the ﬁrst 20% of the list. Figure 3
presents the percentage of defects in the top 20%
most defect-prone ﬁles.

We ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest across mobile
apps, followed by large desktop/server applications
and ﬁnally unix utilities.

In our ﬁrst research question, we found that mo-
bile apps are typically small. Combined with the
distribution of defects, mobile app developers can
ﬁnd the majority of defects in a very small number
of ﬁles, typically only 10s of ﬁles.

From Figure 3, we ﬁnd that a higher percent-
age of defects are concentrated in the top 20%
most defect-prone ﬁles in mobile apps, compared
to desktop/server applications. At least 80% of
the defects are concentrated in the top 20% most
defect-prone ﬁles in nine of our mobile apps and
at least 70% of the defects are concentrated in the
top 20% most defect-prone ﬁles in thirteen of our
mobile apps.

Figure 3: Percentage of All Defects in the Top 20%
Most Defect-Prone Files.

Finding the rationale for the relatively quick de-
fect ﬁx times in mobile apps requires more analysis
on other systems.

We ﬁnd that mobile app developers typi-
cally ﬁx defects faster than desktop/server de-
velopers, regardless of the size of the project.
Defects in mobile apps tend to be concentrated
in fewer source code ﬁles.

5 Discussion
We identiﬁed several potential areas for future
research in mobile apps during our current and pre-
vious case studies [7]. We believe that the potential
impact of such research may be signiﬁcant given
the ubiquity of mobile devices and growing im-
portance of mobile apps. We present two such ar-
eas based on observations made during our manual
analysis of the source code and development his-
tory of mobile apps.

5.1 Platform Usage

We observed that many mobile apps depend
highly on their underlying platform (i.e., the An-
droid platform). In our previous work, we deﬁned
the “platform dependency ratio” as the ratio of plat-
form API calls to all calls [7]. A low platform
dependency ratio indicates that developers do not
rely signiﬁcantly on the platform APIs. For exam-

ple, their app may be simple or self-contained, or
the platform may be too difﬁcult to use. Such mo-
bile apps may be easily ported to other platforms.
Conversely, a high platform dependency ratio in-
dicates that mobile app developers heavily exploit
platform APIs. However, this leads to platform
“lock-in”, which may complicate porting to other
platforms and potentially introduces instability due
to the rapid evolution of mobile platforms. While
these issues are relevant to all software that is built
on an underlying platform or framework, it is par-
ticularly acute in mobile apps. This is because the
Android platform averages one major release every
year. Hence, researchers should look at the impact
of platform dependence on quality and how back-
ward compatibility issues could affect quality.

5.2 Development Processes

We observed that many mobile apps have a very
high frequency of releases. For example, K9Mail
typically has two internal releases every week and
one release to Google Play every month. Quick re-
lease cycles may be required to remain competitive
within the marketplace.

Currently, there is evidence that some mobile
apps do not follow a formal development or main-
tenance process. These apps are developed in an
ad hoc manner to get to the market as quickly as
possible. For example, as we discussed in Subsec-
tion 3.1, three mobile apps were excluded from our
case study because they did not have a public issue
tracking system. These apps had been downloaded
hundreds of thousands of times, and yet they did
not have a system where users could report defects.
In addition, the source code repositories of eleven
mobile apps in our case study do not contain any
test cases. Such ad hoc development and mainte-
nance processes may adversely affect the quality
or maintainability of mobile apps.

Researchers should also investigate the relation-
ship between these two factors (frequent releases
and lack of testing) and the quality of code. Khomh
et al. have studied the Mozilla Firefox project and
found that a shorter release cycle 1) allows defects
to be ﬁxed faster and 2) does not introduce signif-
icantly more defects [33]. However, several open
questions remain. Does such a high frequency of
releases mitigate the lack of testing? If there are
frequent releases for the mobile app, then does

quality matter as much? Is the project in a con-
stant beta testing state? Does the platform provide
sufﬁcient support for building high quality apps
quickly? Is the frequent release only inﬂuenced by
the demand factor in the app store? Are the devel-
opers of mobile apps more skilled or do they have
more resources at hand? Or, are mobile apps them-
selves less complex to develop?

6 Threats to Validity
This section outlines the threats to the validity of

our case study.

6.1 Construct Validity

Wget was ﬁrst released in January 1996 and As-
pell was ﬁrst released in September 1998, however,
the development history of this time is not avail-
able. Therefore, the ﬁrst three years of the publicly
available source code repository and issue tracker
do not correspond to the ﬁrst three years of devel-
opment.

The number of downloads is not an ideal mea-
sure of success (unlike user retention or engage-
ment), however, it is the best measure currently
available [4]. Therefore, it is possible that we have
mistakenly included mobile apps with small user
bases or excluded mobile apps with large user bases
from our analysis.

The number of unique developers was found
by counting the number of unique local parts
(i.e.,
the characters before the @ symbol) for
each developer who made at least one commit
to a source code ﬁle in the repository.
Simi-
larly, the number of unique reporters was found
by counting the number of unique local parts for
each reporter who submitted at least one defect
report. While we did perform a manual veri-
ﬁcation of this analysis,
it is possible that we
misidentiﬁed two local parts as either unique or
distinct. For example, john doe@gmail.com and
admin@my project.com were counted as two dis-
tinct developers/reporters, although they may be
a single developer/reporter with multiple (distinct)
email address. Conversely, j doe@gmail.com and
j doe@yahoo.com were counted as one distinct de-
veloper/reporter, although they may be two distinct
developers/reporters (e.g., John and James).

The number of defects in each source code ﬁle
was measured by identifying the ﬁles that were
changed in a defect ﬁxing change. Although this
technique has been found to be effective [31, 32],
it is not without ﬂaws. We identiﬁed defect ﬁxing
changes by mining the commit logs for a set of key-
words. Therefore, we are unable to identify defect
ﬁxing changes (and therefore defects) if we failed
to search for a speciﬁc keyword, if the committer
misspelled the keyword or if the committer failed
to include any commit message. We are also unable
to determine which source code ﬁles have defects
when defect ﬁxing modiﬁcations and non-defect
ﬁxing modiﬁcations are made in the same commit.
However, such problems are common when mining
software repositories [34].

6.2 Internal Validity

The time to ﬁx a defect was calculated by count-
ing the number of days between the date an issue
was opened and the date it was closed. It is pos-
sible that the defect was ﬁxed quickly, but the is-
sue tracking system was not immediately updated
to reﬂect the ﬁx. In addition, this analysis does not
consider defects that were not reported within the
issue tracking system.

The number of unique developers is based on the
list of people who commit to the source code repos-
itory and the number of unique reporters is based
on the list of people who submit issues to the issue
tracking system. This does not capture people who
submit code or issues using other mediums (e.g.,
email or forums).

6.3 External Validity

The studied mobile apps and desktop/server ap-
plications represent a small subset of the total num-
ber of mobile apps and desktop/server applications
available. We have limited our study to open-
source mobile apps and desktop/server applica-
tions. In addition, we have only studied the mo-
bile apps of a single mobile platform (i.e., the An-
droid Platform). Further, some mobile apps (acting
merely as a client) rely on data or services from
backend servers, however our results are limited to
the apps themselves. Therefore, it is unclear how
our results will generalize to 1) closed source mo-
bile apps and desktop/server applications and 2)
other mobile platforms.

6.4 Conclusion Validity

Our results may have been affected by confound-
ing factors. One such confounding factor is that the
defect reporting mechanisms of Android apps af-
fects the defect ﬁxing process [35]. This may have
affected the time to ﬁx defects and the number of
defects reported in each mobile app. For example,
the authors found that Google Code’s bug tracker,
which is used by most open-source Android apps,
offers less support for management (i.e., triaging)
than other widely-used issue tracking systems (e.g,
Bugzilla or Jira). This may increase the time it
takes to ﬁx defects in mobile apps.

The conclusions of empirical software engineer-
ing research may be mistaken as “obvious.” How-
ever, the goal of empirical research is to scientif-
ically validate whether the “obvious” conclusions
are true. We would like to point out that there
have been no empirical studies to prove/disprove
the claims in this study. Mobile app developers
cannot make decisions based on “gut-feeling” in-
stincts. Data-driven empirical studies such as this
will provide the necessary scientiﬁc foundation for
developers to make informed decisions regarding
their software.

7 Conclusions
This paper presented an exploratory study to
compare mobile apps and desktop/server applica-
tions, as a ﬁrst step toward understanding how the
software engineering concepts developed by study-
ing desktop/server will apply to mobile apps. We
studied ﬁfteen open-source Android apps and ﬁve
desktop/server applications (two large, commonly
studied systems and three smaller unix utilities).

We ﬁnd that, in some respects, mobile apps are
similar to unix utilities and differ from large desk-
top and server applications. Mobile apps and unix
utilities are smaller than traditionally studied desk-
top and server applications (e.g., Apache HTTP
server and Eclipse). This is true in terms of the
size of the code base and the development team.
Further, we ﬁnd that the number of core develop-
ers (i.e., those responsible for at least 80% of the
commits), is very small in both mobile apps and
unix utilities, typically only one or two. We also
ﬁnd that few users report defects and few defects
are reported in both mobile apps and unix utilities.

We also ﬁnd that,

in other respects, mobile
apps differ from both unix utilities and large
desktop/server applications. We ﬁnd that mobile
app developers place a great deal of emphasis
on rapidly responding to quality issues and most
projects ﬁx over a third of reported defects within
one week and two thirds of reported defects within
one month. This is greater for the Eclipse UI com-
ponent and the aspell, joe and wget utilities, which
typically ﬁx only 20% of reported defects in one
week and 40% of reported defects in one month.
However, developers of the Apache HTTP server
project ﬁx 46% of all reported defects in one week
and 96% of all reported defects in one month. We
also ﬁnd that the concentrations of defects in the
most defect-prone ﬁles is the highest in mobile
apps, followed by large desktop and server appli-
cations and ﬁnally unix utilities. Most mobile apps
have more than 80% of the defects in 20% of the
most defect-prone ﬁles. This compares to two third
and half for large desktop and server applications
and unix utilities respectively.

In conclusion, our ﬁndings suggest that mobile
apps may be facing unique challenges. In order to
support the 50,000 developers creating mobile apps
[13], researchers should begin to study mobile apps
alongside traditionally studied desktop and server
applications.

References
[1] L. Columbus, “Roundup of mobile apps
2013.
and
www.forbes.com
[Online]. Available:
/sites/louiscolumbus/2013/06/09/roundup-of-
mobile-apps-app-store-forecasts-2013/

forecasts,”

Jun

app

store

[2] C. Sharma, “Sizing up the global apps

market,” www.chetansharma.com/
mobileappseconomy.htm, Chetan Sharma
Consulting, Mar 2013.

[3] “Google play,” play.google.com.

[4] M. Harman, Y. Jia, and Y. Z. Test, “App Store
Mining and Analysis: MSR for App Stores,”
in Proceedings of the International Working
Conference on Mining Software Repositories,
Jun 2012.

[5] R. Minelli and M. Lanza, “Software ana-
lytics for mobile applications - insights &
lessons learned,” Mar 2013, pp. 144–153.

[6] I. J. M. Ruiz, M. Nagappan, B. Adams, and
A. E. Hassan, “Understanding reuse in the an-
droid market,” in Proceedings of the Interna-
tional Conference on Program Comprehen-
sion, Jun 2012, pp. 113–122.

[7] M. D. Syer, B. Adams, A. E. Hassan, and
Y. Zou, “Exploring the development of micro-
apps: A case study on the blackberry and an-
droid platforms,” in Proceedings of the Inter-
national Working Conference on Source Code
Analysis and Manipulation, Sep 2011.

[8] F. P. Brooks, The mythical man-month – Es-
Addison-

says on Software-Engineering.
Wesley, 1975.

[9] S. Chidamber and C. Kemerer, “A metrics
suite for object oriented design,” Transactions
on Software Engineering, vol. 20, no. 6, pp.
476 –493, Jun 1994.

[10] N. Nagappan and T. Ball, “Use of relative
code churn measures to predict system defect
density,” in Proceedings of the International
Conference on Software Engineering, 2005,
pp. 284–292.

[11] C. Bird, N. Nagappan, B. Murphy, H. Gall,
and P. Devanbu, “Don’t touch my code!: ex-
amining the effects of ownership on software
quality,” in Proceedings of the Symposium
and the European Conference on Foundations
of Software Engineering, 2011, pp. 4–14.

[12] B. Robinson and P. Francis, “Improving in-
dustrial adoption of software engineering re-
search: a comparison of open and closed
source software,” in Proceedings of the Inter-
national Symposium on Empirical Software
Engineering and Measurement, Sep 2010, pp.
21:1–21:10.

[13] N. O’Neill, “10 surprising app platform
facts,” http://allfacebook.com/app-platform-
facts b18514, All Facebook, Sep 2010.

[14] A. Cravens, “A demographic and business
model analysis of today’s app developer,”
http://pro.gigaom.com/archives/research-
brieﬁngs/, GigaOM, Sep 2012.

[15] “Mobile software engineering,” mobilese-

workshop.org, Apr 2013.

[16] H.-W. Kim, H. L. Lee, and J. E. Son, “An ex-
ploratory study on the determinants of smart-
phone app purchase,” in Proceedings of the
International DSI and the APDSI Joint Meet-
ing, Jul 2011.

[17] Y. Wu, J. Luo, and L. Luo, “Porting mobile
web application engine to the android plat-
form,” in Proceedings of the International
Conference on Computer and Information
Technology, Jul 2010, pp. 2157–2161.

[18] C. Xin, “Cross-platform mobile phone game
development environment,” in Proceedings
of the International Conference on Industrial
and Information Systems, Apr 2009, pp. 182–
184.

[19] W. Enck, M. Ongtang, and P. McDaniel, “Un-
derstanding android security,” Security and
Privacy, vol. 7, no. 1, pp. 50–57, Jan 2009.

[20] A. Shabtai, Y. Fledel, U. Kanonov, Y. Elovici,
S. Dolev, and C. Glezer, “Google android: A
comprehensive security assessment,” Security
and Privacy, vol. 8, no. 2, pp. 35–44, Mar
2010.

[21] M. C. Grace, Y. Zhou, Q. Zhang, S. Zou, and
X. Jiang, “Riskranker: scalable and accurate
zero-day android malware detection,” in Pro-
ceedings of the International Conference on
Mobile Systems, Applications, and Services,
Jun 2012, pp. 281–294.

[22] A. K. Maji, K. Hao, S. Sultana, and S. Bagchi,
“Characterizing failures in mobile oses: A
case study with android and symbian,” in Pro-
ceedings of the International Conference on
Software Reliability Engineering, Nov 2010,
pp. 249–258.

[23] “Comparisons and Contrasts: Windows
Phone 7 Marketplace and Google Android
Market,”
www.distimo.com/publications,
Distimo, Jan 2011.

[24] “In-depth

view

on
in the google

umes
www.distimo.com/publications,
May 2011.

download
vol-
android market,”
Distimo,

[25] “F-droid,” https://f-droid.org/.

[26] R. Lind and K. Vairavan, “An experimen-
tal
investigation of software metrics and
their relationship to software development ef-
fort,” Transactions on Software Engineering,
vol. 15, no. 5, pp. 649–653, May 1989.

[27] I. Herraiz, J. M. Gonzalez-Barahona, and
G. Robles, “Towards a theoretical model for
software growth,” in Proceedings of the Work-
shop on Mining Software Repositories, 2007,
pp. 21–28.

[28] “Understand Your Code,” scitools.com.

[29] A. Mockus, R. T. Fielding, and J. Herbsleb,
“A case study of open source software devel-
the apache server,” in Proceedings
opment:
of the International Conference on Software
Engineering, Jun 2000, pp. 263–272.

[30] T. Ostrand, E. Weyuker, and R. Bell, “Predict-
ing the location and number of faults in large
software systems,” Transactions on Software
Engineering, vol. 31, no. 4, pp. 340–355, apr
2005.

[31] A. E. Hassan, “Automated classiﬁcation of
change messages in open source projects,”
in Proceedings of the Symposium on Applied
Computing, Mar 2008, pp. 837–841.

[32] A. Mockus and L. G. Votta, “Identifying
reasons for software changes using historic
databases,” in Proceedings of the Interna-
tional Conference on Software Maintenance,
Oct 2000, pp. 120–130.

[33] F. Khomh, T. Dhaliwal, Y. Zou,

and
B. Adams, “Do faster releases improve soft-
ware quality?
an empirical case study of
mozilla ﬁrefox,” in Proceedings of the Inter-
national Working Conference on Mining Soft-
ware Repositories, Jun 2012.

[34] A. E. Hassan, “The road ahead for Mining
Software Repositories,” in Frontiers of Soft-
ware Maintenance, Oct 2008, pp. 48–57.

[35] P. Bhattacharya, L. Ulanova, I. Neamtiu, and
S. C. Koduru, “An empirical analysis of bug
reports and bug ﬁxing in open source an-
droid apps,” in Proceedings of the European
Conference on Software Maintenance and
Reengineering, Mar 2013, pp. 133–143.

