International Journal of Multimed ia Technology  (IJMT) 

Table of the Gods: Development of a Multi-Touch 

App for Museum  
Geneviève Lucet*1, Víctor Godoy2 

Institute of Aesthetic Research, Nat ional Autonomous of Mexico , Me xico City, Me xico  

*1genevieve.lucet@gmail.co m; 2godoy.vic@gma il.co m 

 
 

Abstract-  We  descri be  the  development  of  an  application  
accomplished  in  a  museum  context  to  explain  the  varied 
representations, traits, an d connections between some of the  
deities  from  the  Mesoamerican  pantheon.  In  order  to 
attract  a  youn ger  au dience,  a  multi -user  interface  was  
implemented,  with  an intuitive interaction sys tem  base d on  
graphic information an d tou ch-screen technology.  

We  explain  the installed  app,  its  conceptual  design  and its 
implementation  with  the  Unity  engine.  The  development  has 
two main parts: the programming of the objects as intelligent 
agents  with  random  and  anti-collision  movement;  and  the 
multi-touch  screen  programming,  meaning  the  detection  and 
interpretation  of  different kinds  of  touches  and  gestures  and 
the changes they produce in objects behavior. 

Keywords-  Interface;  Multitouch;  Museum  Application; 

Behavior 

I. 

INT RODUCTION 

For  a   long  time ,  museu ms  we re  regarded  as  places 
where  pieces  or  co llect ions  valued  through  artistic  criteria  
were  e xh ibited  to  the  public.  Th is  idea  has  changed  in  the 
second  half  of  the  20th  century,  in  the  hopes  that  they 
become useful tools in the achievement of educational tasks 
towards  a  wide  but  predominantly  young  public  [1]. 
Another  goal  is  to  improve  the  population’s  knowledge  by 
motivating  self-study  and  solving  it  interest  about  a  wide 
range of  topics. 

Museums  dedicated  to  the  Hispanic  cultures  have  also 
evolved,  as  evidenced  by  "The  National  Museum  of 
Anthropology in Me xico" which  was designed with a c lear 
educational  purpose.  The  founding  of  “The  Museum  of 
Tlatelolco”  by 
(National  Autonomous 
University  of  Me xico)  and  INAH  (National  Institute  of 
Anthropology  and  History)  in  2011,  atte mpted  to  integrate 
the  mu ltidiscip linary  knowledge  of  history,  anthropology, 
arts,  science,  and  technology  to  show  that  the  areas  of 
science and humanities are integrated and combined in order 
to enrich and e xpand our approach to the past. 

the  UNAM 

concepts, so the comple xity of their defin ition and the links 
established  between 
the 
sophistication of the Mesoamerican way of thinking. For the 
Museum,  we   simp lified  the  informat ion  to  include  only  a  
subset of deities and only some of their attributes. 

them  can  be  measured  by 

In  order  to  e xpress  this  intricate  way  of  thinking  in  an 
appealing  way,  we  looked  for  a   solution  that  has  the 
following characteristics: 

  Visual:  co mmunicat ion  through  images  is  preferred  by 

young people. 

  Dynamic : to catch the users’ attention and curiosity. 

 

 

Intuitive:  with  an  accessible  interface  requiring  little  
time to get used to. 

Interactive: the user becomes pro-active, thus increasing 
the cognitive process [2]. 

  Multi-user:  to  pro mote  the  dynamic  part icipation  of  a  

group of people. 

 

These  requirements  are  co mmon  in  many  e xhib itions, 
and  various  technological  solutions  are  often  used  for 
enhanced  educational  effects;  these  include  multimedia, 
systems built specifically and VR technologies [3]. 

II.  CONCEPT DESIGN 

In  order  to  better  e xp lain  Mesoame rican  deities,  we  
opted  for  dynamic  imagery,  representing  them  in  mot ion, 
combined  with  a 
that  allows  several 
simu ltaneous  users  to select  icons,  drag  them,  and  display 
informat ion.  The  installation  was  designed  as  a  horizontal 
board around which several people can interact at the same 
time (Fig. 1). 

tactile  system 

It  is  within  this  context  that  we  developed  a  system  to 
introduce  some  deities  fro m  the  Mesoamerican  pantheon. 
It's a co mplicated issue, there is a  mu ltitude of de ities with 
varying  degrees  of  importance  and  they  are  subject  to 
changes,  such  as  their  names  and  representation  according 
to  the  historical  period  and  the  local  culture.  Research  on 
this 
for 
understanding 
roles  of 
prehispanic  deities.  We   now  know  that  they  represent 

subject  has  provided 
the  meaning, 

re levance  and 

important 

insights 

Fig. 1 The “Table of the Gods” installed in the Museum of Tlatelolco 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

1 

International Journal of Multimed ia Technology  (IJMT) 

Table of the Gods: Development of a Multi-Touch 

App for Museum  
Geneviève Lucet*1, Víctor Godoy2 

Institute of Aesthetic Research, Nat ional Autonomous of Mexico , Me xico City, Me xico  

*1genevieve.lucet@gmail.co m; 2godoy.vic@gma il.co m 

 
 

Abstract-  We  descri be  the  development  of  an  application  
accomplished  in  a  museum  context  to  explain  the  varied 
representations, traits, an d connections between some of the  
deities  from  the  Mesoamerican  pantheon.  In  order  to 
attract  a  youn ger  au dience,  a  multi -user  interface  was  
implemented,  with  an intuitive interaction sys tem  base d on  
graphic information an d tou ch-screen technology.  

We  explain  the installed  app,  its  conceptual  design  and its 
implementation  with  the  Unity  engine.  The  development  has 
two main parts: the programming of the objects as intelligent 
agents  with  random  and  anti-collision  movement;  and  the 
multi-touch  screen  programming,  meaning  the  detection  and 
interpretation  of  different kinds  of  touches  and  gestures  and 
the changes they produce in objects behavior. 

Keywords-  Interface;  Multitouch;  Museum  Application; 

Behavior 

I. 

INT RODUCTION 

For  a   long  time ,  museu ms  we re  regarded  as  places 
where  pieces  or  co llect ions  valued  through  artistic  criteria  
were  e xh ibited  to  the  public.  Th is  idea  has  changed  in  the 
second  half  of  the  20th  century,  in  the  hopes  that  they 
become useful tools in the achievement of educational tasks 
towards  a  wide  but  predominantly  young  public  [1]. 
Another  goal  is  to  improve  the  population’s  knowledge  by 
motivating  self-study  and  solving  it  interest  about  a  wide 
range of  topics. 

Museums  dedicated  to  the  Hispanic  cultures  have  also 
evolved,  as  evidenced  by  "The  National  Museum  of 
Anthropology in Me xico" which  was designed with a c lear 
educational  purpose.  The  founding  of  “The  Museum  of 
Tlatelolco”  by 
(National  Autonomous 
University  of  Me xico)  and  INAH  (National  Institute  of 
Anthropology  and  History)  in  2011,  atte mpted  to  integrate 
the  mu ltidiscip linary  knowledge  of  history,  anthropology, 
arts,  science,  and  technology  to  show  that  the  areas  of 
science and humanities are integrated and combined in order 
to enrich and e xpand our approach to the past. 

the  UNAM 

concepts, so the comple xity of their defin ition and the links 
established  between 
the 
sophistication of the Mesoamerican way of thinking. For the 
Museum,  we   simp lified  the  informat ion  to  include  only  a  
subset of deities and only some of their attributes. 

them  can  be  measured  by 

In  order  to  e xpress  this  intricate  way  of  thinking  in  an 
appealing  way,  we  looked  for  a   solution  that  has  the 
following characteristics: 

  Visual:  co mmunicat ion  through  images  is  preferred  by 

young people. 

  Dynamic : to catch the users’ attention and curiosity. 

 

 

Intuitive:  with  an  accessible  interface  requiring  little  
time to get used to. 

Interactive: the user becomes pro-active, thus increasing 
the cognitive process [2]. 

  Multi-user:  to  pro mote  the  dynamic  part icipation  of  a  

group of people. 

 

These  requirements  are  co mmon  in  many  e xhib itions, 
and  various  technological  solutions  are  often  used  for 
enhanced  educational  effects;  these  include  multimedia, 
systems built specifically and VR technologies [3]. 

II.  CONCEPT DESIGN 

In  order  to  better  e xp lain  Mesoame rican  deities,  we  
opted  for  dynamic  imagery,  representing  them  in  mot ion, 
combined  with  a 
that  allows  several 
simu ltaneous  users  to select  icons,  drag  them,  and  display 
informat ion.  The  installation  was  designed  as  a  horizontal 
board around which several people can interact at the same 
time (Fig. 1). 

tactile  system 

It  is  within  this  context  that  we  developed  a  system  to 
introduce  some  deities  fro m  the  Mesoamerican  pantheon. 
It's a co mplicated issue, there is a  mu ltitude of de ities with 
varying  degrees  of  importance  and  they  are  subject  to 
changes,  such  as  their  names  and  representation  according 
to  the  historical  period  and  the  local  culture.  Research  on 
this 
for 
understanding 
roles  of 
prehispanic  deities.  We   now  know  that  they  represent 

subject  has  provided 
the  meaning, 

re levance  and 

important 

insights 

Fig. 1 The “Table of the Gods” installed in the Museum of Tlatelolco 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

1 

International Journal of Multimed ia Technology  (IJMT) 

The  informat ion  about  the  deities  was  structured  in  a 
simp le  way:  nine   ma jor  de ities  man ifest  in   motion  on  a  
background,  where  ten  suns,  eight  stars  and  three  comets 
randomly  appear,  soaring  through  and  generating  the 
contextual environ ment (Fig. 2).  

many users can manipulate the display simultaneously with 
varied  and  independent  events.  These systems  also  record 
the  pressure,  speed  and  direction  each  point  is  sending, 
opening  a  variety  of  options  that  provide  full  interactivity 
through natural user gestures. 

This 

feature 

represents  an 

in 
application progra mming methods because the interpretation 
of mu ltiple  variables in  pressure, gestures, and simu ltaneous 
events have to be taken into account. 

important  change 

Fig. 2 Screenshot of the application 

When the user touches, drags, or rotate one of the deit ies; 
its name is displayed, as well as a series of options in color 
circ les  around  the  deity.  When  touched,  these  options 
replace  the  central  image  with  an  a lternate  one  and, 
depending on the god, may d isplay a different representation; 
or  show  its characteristic  attributes  or  connections to  other 
deities;  other  options  linked  to  each  god  image  allow  to 
change the language or to return to the original image.  

There  are  several  unresolved  issues  in  mu lti-touch 
systems.  The  first  is  tied   to  traditional  Operating  Systems  
which  are  designed  to  work  with  a  single  point  of 
interaction, so applications have been developed in order to 
capture  the  movement,  interpret  it,  and  communicate  this 
informat ion  to  the  program,  there  a re  still,  however, 
limitat ions in their potential as  each  manufacturer develops 
its  own  solution.  The  second  issue  resides  in  the  lack  of 
standardization 
language  of  gesture-based 
communicat ion, although the iPad’s and iPhone’s popularity 
has promoted a more  unified form of use.  

the 

in 

IV. SOLUT ION 

The  development  must 

to: 
application-screen  communication  protocols; 
intelligent 
agent integration; object response to input and gesture; and 
mu lti-tactile  recognition and interpretation. 

solutions 

integrate 

III. BACKGROUND 

A.  Multi-Touch Communication Protocols 

The “Fie ry Pool: The Maya and the Mythic Sea”  sets a 
precedent to this work. Developed for the Peabody Museum 
in Essex in 2010 to e xhib it the Mayan wo rld  view regarding 
water and its related deities and ancestors. This setup uses a 
projector and peripheral  infra red sensors [4],  it's a technical 
solution  that  requires  a  great  deal  of  calibrat ion,  wh ich 
complicates  ma intenance,  so  we  opted  for  the  more  stable 
choice of a touchscreen device. 

Touchscreen  technology  development  started  back  in  
1972 and IBM  was the first company to market  it, based on 
infra red  technology,  it   contained  16  receptors  with in  the 
screen.  In  1984,  the  first  mult i-touch  screen  was  fu rther 
developed.  Bill  Bu xton  published  research  on  human -
computer interaction in 1986 [5][6] would  mark th is section 
of computer graphics developments for the following years. 
Research by the Mitsubishi Research Labs in 2001  revealed 
advances  in  comple x  gestures  interpretation,  which  were 
followed  by  the  works  of  Jefferson  Han  in  2005  and  the 
creation of Perceptive  Pixe l  Co [7]. At the same time , John 
Elias  and  Wayne  Westerman  developed  mu lti-touch 
surfaces  and  the  patents  were   bought  by  Apple  Inc.,  who 
integrated  all  of  thes e  advances  in  the  iPhone,  in  2007. 
Thirty-five  years  had  passed  since  the  beginning  of  the 
research  about  computer-human  interface,  it  had  been 
necessary to overcome the diffe rent screen defic iencies, find 
stable  and  affordable  technological  solutions,  a  few  years 
later, mu lt itouch screen would be completely installed in  our 
lifestyle. 

Multi-touch  systems  recognize  numerous  points  of 
contact  and  interpret  them  as  an  interface,  meaning  that 

We  opted  for  a  50’  plas ma  screen,  on  top  of  which  a 
PqLabs  32  touches  Multi-tactile   screen  was  mounted,  so 
numerous  users  can  interact  at  the  same  time  and  use 
various  fingers  to  add  up  to  32  po ints  of  contact.  The 
PqLabs screen is a transceiver kind fra me consisting of two 
LEDs that e mit  an in frared  beam and two photodiodes that 
receive  it,  being  able   to  detect  an  area  where  the  bea m  is 
interrupted by an object. 

When the signal is interrupted by an obstacle, no  matter 
the  color,  te xture,  shape  or  brightness  of  the  object,  the 
emitters recognize the (x,y) position on the screen and send 
the  informat ion  via   USB  using  TUIO  o r  WM_TOUCH 
protocols,  transmitt ing  the  interpretations  of  pressure  and 
gestures  from  the  tactile  surface  to  the  application.  The 
TUIO  p rotocol  [8]  (Tab le-top  Tangible   User  Interface) 
recognizes  an  infinite  a mount  of  points  of  contact  on  the 
screen  and  transmits  them  to  an  application  in  Open GL 
(Unix, Windows, and OSX)  meanwhile WM_TOUCH only 
works with directX and just allows eight points of contact. 

B.  The Virtual Space 

The  application  develop ment  and  its  integration  to  the 
interaction system was made possible by utilizing the Unity 
3.0 engine, this progra m is be ing used more  and more  in the 
production  of  interactive  materia l  made  for  museums  and 
the  internet,  since  it  offers  developmental  tools  in  mult i-
platform  environments,  as  well  as  ma king  possible  the 
programming  of  object-oriented 
language  scripts  and 
enables  the  development  of  e xternal  e xtensions  so  as  to 
meet  specific  needs,  which  has  opened  the  possibility  of  

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

2 

International Journal of Multimed ia Technology  (IJMT) 

Table of the Gods: Development of a Multi-Touch 

App for Museum  
Geneviève Lucet*1, Víctor Godoy2 

Institute of Aesthetic Research, Nat ional Autonomous of Mexico , Me xico City, Me xico  

*1genevieve.lucet@gmail.co m; 2godoy.vic@gma il.co m 

 
 

Abstract-  We  descri be  the  development  of  an  application  
accomplished  in  a  museum  context  to  explain  the  varied 
representations, traits, an d connections between some of the  
deities  from  the  Mesoamerican  pantheon.  In  order  to 
attract  a  youn ger  au dience,  a  multi -user  interface  was  
implemented,  with  an intuitive interaction sys tem  base d on  
graphic information an d tou ch-screen technology.  

We  explain  the installed  app,  its  conceptual  design  and its 
implementation  with  the  Unity  engine.  The  development  has 
two main parts: the programming of the objects as intelligent 
agents  with  random  and  anti-collision  movement;  and  the 
multi-touch  screen  programming,  meaning  the  detection  and 
interpretation  of  different kinds  of  touches  and  gestures  and 
the changes they produce in objects behavior. 

Keywords-  Interface;  Multitouch;  Museum  Application; 

Behavior 

I. 

INT RODUCTION 

For  a   long  time ,  museu ms  we re  regarded  as  places 
where  pieces  or  co llect ions  valued  through  artistic  criteria  
were  e xh ibited  to  the  public.  Th is  idea  has  changed  in  the 
second  half  of  the  20th  century,  in  the  hopes  that  they 
become useful tools in the achievement of educational tasks 
towards  a  wide  but  predominantly  young  public  [1]. 
Another  goal  is  to  improve  the  population’s  knowledge  by 
motivating  self-study  and  solving  it  interest  about  a  wide 
range of  topics. 

Museums  dedicated  to  the  Hispanic  cultures  have  also 
evolved,  as  evidenced  by  "The  National  Museum  of 
Anthropology in Me xico" which  was designed with a c lear 
educational  purpose.  The  founding  of  “The  Museum  of 
Tlatelolco”  by 
(National  Autonomous 
University  of  Me xico)  and  INAH  (National  Institute  of 
Anthropology  and  History)  in  2011,  atte mpted  to  integrate 
the  mu ltidiscip linary  knowledge  of  history,  anthropology, 
arts,  science,  and  technology  to  show  that  the  areas  of 
science and humanities are integrated and combined in order 
to enrich and e xpand our approach to the past. 

the  UNAM 

concepts, so the comple xity of their defin ition and the links 
established  between 
the 
sophistication of the Mesoamerican way of thinking. For the 
Museum,  we   simp lified  the  informat ion  to  include  only  a  
subset of deities and only some of their attributes. 

them  can  be  measured  by 

In  order  to  e xpress  this  intricate  way  of  thinking  in  an 
appealing  way,  we  looked  for  a   solution  that  has  the 
following characteristics: 

  Visual:  co mmunicat ion  through  images  is  preferred  by 

young people. 

  Dynamic : to catch the users’ attention and curiosity. 

 

 

Intuitive:  with  an  accessible  interface  requiring  little  
time to get used to. 

Interactive: the user becomes pro-active, thus increasing 
the cognitive process [2]. 

  Multi-user:  to  pro mote  the  dynamic  part icipation  of  a  

group of people. 

 

These  requirements  are  co mmon  in  many  e xhib itions, 
and  various  technological  solutions  are  often  used  for 
enhanced  educational  effects;  these  include  multimedia, 
systems built specifically and VR technologies [3]. 

II.  CONCEPT DESIGN 

In  order  to  better  e xp lain  Mesoame rican  deities,  we  
opted  for  dynamic  imagery,  representing  them  in  mot ion, 
combined  with  a 
that  allows  several 
simu ltaneous  users  to select  icons,  drag  them,  and  display 
informat ion.  The  installation  was  designed  as  a  horizontal 
board around which several people can interact at the same 
time (Fig. 1). 

tactile  system 

It  is  within  this  context  that  we  developed  a  system  to 
introduce  some  deities  fro m  the  Mesoamerican  pantheon. 
It's a co mplicated issue, there is a  mu ltitude of de ities with 
varying  degrees  of  importance  and  they  are  subject  to 
changes,  such  as  their  names  and  representation  according 
to  the  historical  period  and  the  local  culture.  Research  on 
this 
for 
understanding 
roles  of 
prehispanic  deities.  We   now  know  that  they  represent 

subject  has  provided 
the  meaning, 

re levance  and 

important 

insights 

Fig. 1 The “Table of the Gods” installed in the Museum of Tlatelolco 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

1 

International Journal of Multimed ia Technology  (IJMT) 

The  informat ion  about  the  deities  was  structured  in  a 
simp le  way:  nine   ma jor  de ities  man ifest  in   motion  on  a  
background,  where  ten  suns,  eight  stars  and  three  comets 
randomly  appear,  soaring  through  and  generating  the 
contextual environ ment (Fig. 2).  

many users can manipulate the display simultaneously with 
varied  and  independent  events.  These systems  also  record 
the  pressure,  speed  and  direction  each  point  is  sending, 
opening  a  variety  of  options  that  provide  full  interactivity 
through natural user gestures. 

This 

feature 

represents  an 

in 
application progra mming methods because the interpretation 
of mu ltiple  variables in  pressure, gestures, and simu ltaneous 
events have to be taken into account. 

important  change 

Fig. 2 Screenshot of the application 

When the user touches, drags, or rotate one of the deit ies; 
its name is displayed, as well as a series of options in color 
circ les  around  the  deity.  When  touched,  these  options 
replace  the  central  image  with  an  a lternate  one  and, 
depending on the god, may d isplay a different representation; 
or  show  its characteristic  attributes  or  connections to  other 
deities;  other  options  linked  to  each  god  image  allow  to 
change the language or to return to the original image.  

There  are  several  unresolved  issues  in  mu lti-touch 
systems.  The  first  is  tied   to  traditional  Operating  Systems  
which  are  designed  to  work  with  a  single  point  of 
interaction, so applications have been developed in order to 
capture  the  movement,  interpret  it,  and  communicate  this 
informat ion  to  the  program,  there  a re  still,  however, 
limitat ions in their potential as  each  manufacturer develops 
its  own  solution.  The  second  issue  resides  in  the  lack  of 
standardization 
language  of  gesture-based 
communicat ion, although the iPad’s and iPhone’s popularity 
has promoted a more  unified form of use.  

the 

in 

IV. SOLUT ION 

The  development  must 

to: 
application-screen  communication  protocols; 
intelligent 
agent integration; object response to input and gesture; and 
mu lti-tactile  recognition and interpretation. 

solutions 

integrate 

III. BACKGROUND 

A.  Multi-Touch Communication Protocols 

The “Fie ry Pool: The Maya and the Mythic Sea”  sets a 
precedent to this work. Developed for the Peabody Museum 
in Essex in 2010 to e xhib it the Mayan wo rld  view regarding 
water and its related deities and ancestors. This setup uses a 
projector and peripheral  infra red sensors [4],  it's a technical 
solution  that  requires  a  great  deal  of  calibrat ion,  wh ich 
complicates  ma intenance,  so  we  opted  for  the  more  stable 
choice of a touchscreen device. 

Touchscreen  technology  development  started  back  in  
1972 and IBM  was the first company to market  it, based on 
infra red  technology,  it   contained  16  receptors  with in  the 
screen.  In  1984,  the  first  mult i-touch  screen  was  fu rther 
developed.  Bill  Bu xton  published  research  on  human -
computer interaction in 1986 [5][6] would  mark th is section 
of computer graphics developments for the following years. 
Research by the Mitsubishi Research Labs in 2001  revealed 
advances  in  comple x  gestures  interpretation,  which  were 
followed  by  the  works  of  Jefferson  Han  in  2005  and  the 
creation of Perceptive  Pixe l  Co [7]. At the same time , John 
Elias  and  Wayne  Westerman  developed  mu lti-touch 
surfaces  and  the  patents  were   bought  by  Apple  Inc.,  who 
integrated  all  of  thes e  advances  in  the  iPhone,  in  2007. 
Thirty-five  years  had  passed  since  the  beginning  of  the 
research  about  computer-human  interface,  it  had  been 
necessary to overcome the diffe rent screen defic iencies, find 
stable  and  affordable  technological  solutions,  a  few  years 
later, mu lt itouch screen would be completely installed in  our 
lifestyle. 

Multi-touch  systems  recognize  numerous  points  of 
contact  and  interpret  them  as  an  interface,  meaning  that 

We  opted  for  a  50’  plas ma  screen,  on  top  of  which  a 
PqLabs  32  touches  Multi-tactile   screen  was  mounted,  so 
numerous  users  can  interact  at  the  same  time  and  use 
various  fingers  to  add  up  to  32  po ints  of  contact.  The 
PqLabs screen is a transceiver kind fra me consisting of two 
LEDs that e mit  an in frared  beam and two photodiodes that 
receive  it,  being  able   to  detect  an  area  where  the  bea m  is 
interrupted by an object. 

When the signal is interrupted by an obstacle, no  matter 
the  color,  te xture,  shape  or  brightness  of  the  object,  the 
emitters recognize the (x,y) position on the screen and send 
the  informat ion  via   USB  using  TUIO  o r  WM_TOUCH 
protocols,  transmitt ing  the  interpretations  of  pressure  and 
gestures  from  the  tactile  surface  to  the  application.  The 
TUIO  p rotocol  [8]  (Tab le-top  Tangible   User  Interface) 
recognizes  an  infinite  a mount  of  points  of  contact  on  the 
screen  and  transmits  them  to  an  application  in  Open GL 
(Unix, Windows, and OSX)  meanwhile WM_TOUCH only 
works with directX and just allows eight points of contact. 

B.  The Virtual Space 

The  application  develop ment  and  its  integration  to  the 
interaction system was made possible by utilizing the Unity 
3.0 engine, this progra m is be ing used more  and more  in the 
production  of  interactive  materia l  made  for  museums  and 
the  internet,  since  it  offers  developmental  tools  in  mult i-
platform  environments,  as  well  as  ma king  possible  the 
programming  of  object-oriented 
language  scripts  and 
enables  the  development  of  e xternal  e xtensions  so  as  to 
meet  specific  needs,  which  has  opened  the  possibility  of  

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

2 

International Journal of Multimed ia Technology  (IJMT) 

ma king  numerous  plugins,  several  being  open  source.  Its 
ma rket  acceptance  is  also  a  guarantee  of  continuity  and 
updates for a few years. 

This tool manages to integrate the graphic  materia l in an  
organized  manner.  We  associated  behaviors  to  different 
objects and included interactive ele ments programed in  C#. 
One group includes all the  main co mponents of the project: 
deities, stars, suns, comets, buttons, counters, virtual screen 
delimitations, 
animated 
background.  Another  group  includes  the  elements  that 
comple ment the environment and the system: ca me ra, lights, 
and a mu lti-touch input manager. 

info rmation 

aspects, 

and 

Virtual Space Definition: each object moves in a random 
pattern  within  a  determined  space  wider  than  the screen  in 
order to let the object  fo llo ws its course as it  disappears and 
reenters  the  board  again  at  another  location.  As  the  object 
detects this space’s limits,  it  rotates and changes its course 
in  the  opposite  direction.  Simu lated  clouds  appear  in  the 
background;  this  animation  is  calculated  in  rea l  t ime   with 
“billboard” particles, te xturized with color. 

C.  Objects 

Given  their  independent  behavior  and  change  in  state, 
objects  fall  into  three  ma jor  categories:  Deity-objects,  Sun 
and Star-objects, and Co met-objects. 

1)  Properties and Traits: 

All  the  ele ments  found  in  the  virtual  space  have  an 
associated image to the m. In  addition, De ity-objects possess 
a  name,  buttons  linked  to  secondary  level  informat ion  and 
language  selection,  and  values  set  to  simu late  real-world-
physics-dependable behavior. 

 

 

Fig. 3 Object behaviour 

Sun-objects  and  Star-objects  move  in  a   separate  layer, 
therefore  avoiding  collision  with  the  De ity-objects.  What 
distinguishes these two groups is a variation in speed. 

Co met-objects possess a simpler definition; they appear 
on  the  board  sporadically  and  follow  a  linea l  path  as  they 
travel across. They’re located on a layer separated from the 
other  two  and  their  course  is  not  modified  when  they 
encounter  another  object.  They  have  set  and  random 
move ment  properties,  and  are  limited  by  the  virtual  space 
boundaries. Their move ment  speed is the highest among the 
objects  and  their  rando m  movement   is  the  min imu m 
required to obtain harmonic traversing.  

2)  Independent Behavior: 

D.  Interactivity 

To progra m the object behavior and move ment, we  used 
Unitysteer [9,10], an open source solution developed by the 
Arges Systems, a consulting company in the development of 
games  using  Unity.  It  allo ws  exe rting  control  over  generic 
objects’ behavior required to be provided with  independent 
move ment,  and  it  consists  of  a  set  of  libra ries  based  on 
OpenSteer and OpenSteerDotNet.  

Except for the Co mets, each of the objects that make up 

the application has the following properties (Fig. 3): 

  Vehic le-like  behavior,  wh ich  allows  establishing  initia l 

move ment and defined speed. 

  Random  move ment,  which enables the object to have a  
soft,  organic  behavior  and  to  simu late  how  it  would  
behave in real world physics. 

  Sonar or radar,  which sets up each element’s place ment 
within   the  board,  as  we ll  as  detecting  other  objects  or 
obstacles in proximity, in order to evade them, avoid ing 
their  piling  up  in  just  one  spot.  Each  object  takes  into 
account the position as well as the direction of the other 
objects,  calculates  the  trajectory  and  modifies  its  own 
route accordingly. 

  Movement  zone,  which  creates  an  allo wed  move ment 

quadrant for each of the objects. 

its 

translated 

information.  Gestures  are 

Touching an object stops its independent movement and 
displays 
into 
diffe rent  instructions  according  to  the  amount  of  points  of 
contact  on  the  board,  as  well  as  their  location  and  the 
distance  between 
the 
application  can  determine  the  amount  of  users  and  how 
many points are used by each one. 

them.  With 

information, 

this 

touches  are 

For  each  user,  a  single   touch  is  translated  as  a  cursor, 
while  mult iple 
interpreted  as  different 
independent  cursors.  The  user  can  drag  an  object  with  a 
touch;  this  combines  rotation  and translation  following  the 
orientation of the finger’s  move ment. Two  fingers are used 
to  rotate  an  object  and  the  fingers’  turning  direction 
determine  the  object’s  rotational  direction  in  regard  to  the 
object’s rotational center (Fig . 4). 

We  used  uniTUIO  for  the  mu lti-touch  gesture-based 
communicat ion between the screen and Unity. Un iTUIO  is 
free  software,  developed  in  2009  by  Sandor  Rozs a  and 
Stephan  Schlupek.  It  is  a  group  of  C#  libra ries  used  to 
interpret  the  inputs sent  through  the  touch  screen  and  into 
Unity.  Un ity  was  origina lly  conceived  to  deal  with  single-
user events, which not only affects the amount of users that 
can  interact  simu ltaneously,  but  also  gesture  possibilities 
and object dynamics. Un iTUIO was specifica lly  designed to 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

3 

International Journal of Multimed ia Technology  (IJMT) 

Table of the Gods: Development of a Multi-Touch 

App for Museum  
Geneviève Lucet*1, Víctor Godoy2 

Institute of Aesthetic Research, Nat ional Autonomous of Mexico , Me xico City, Me xico  

*1genevieve.lucet@gmail.co m; 2godoy.vic@gma il.co m 

 
 

Abstract-  We  descri be  the  development  of  an  application  
accomplished  in  a  museum  context  to  explain  the  varied 
representations, traits, an d connections between some of the  
deities  from  the  Mesoamerican  pantheon.  In  order  to 
attract  a  youn ger  au dience,  a  multi -user  interface  was  
implemented,  with  an intuitive interaction sys tem  base d on  
graphic information an d tou ch-screen technology.  

We  explain  the installed  app,  its  conceptual  design  and its 
implementation  with  the  Unity  engine.  The  development  has 
two main parts: the programming of the objects as intelligent 
agents  with  random  and  anti-collision  movement;  and  the 
multi-touch  screen  programming,  meaning  the  detection  and 
interpretation  of  different kinds  of  touches  and  gestures  and 
the changes they produce in objects behavior. 

Keywords-  Interface;  Multitouch;  Museum  Application; 

Behavior 

I. 

INT RODUCTION 

For  a   long  time ,  museu ms  we re  regarded  as  places 
where  pieces  or  co llect ions  valued  through  artistic  criteria  
were  e xh ibited  to  the  public.  Th is  idea  has  changed  in  the 
second  half  of  the  20th  century,  in  the  hopes  that  they 
become useful tools in the achievement of educational tasks 
towards  a  wide  but  predominantly  young  public  [1]. 
Another  goal  is  to  improve  the  population’s  knowledge  by 
motivating  self-study  and  solving  it  interest  about  a  wide 
range of  topics. 

Museums  dedicated  to  the  Hispanic  cultures  have  also 
evolved,  as  evidenced  by  "The  National  Museum  of 
Anthropology in Me xico" which  was designed with a c lear 
educational  purpose.  The  founding  of  “The  Museum  of 
Tlatelolco”  by 
(National  Autonomous 
University  of  Me xico)  and  INAH  (National  Institute  of 
Anthropology  and  History)  in  2011,  atte mpted  to  integrate 
the  mu ltidiscip linary  knowledge  of  history,  anthropology, 
arts,  science,  and  technology  to  show  that  the  areas  of 
science and humanities are integrated and combined in order 
to enrich and e xpand our approach to the past. 

the  UNAM 

concepts, so the comple xity of their defin ition and the links 
established  between 
the 
sophistication of the Mesoamerican way of thinking. For the 
Museum,  we   simp lified  the  informat ion  to  include  only  a  
subset of deities and only some of their attributes. 

them  can  be  measured  by 

In  order  to  e xpress  this  intricate  way  of  thinking  in  an 
appealing  way,  we  looked  for  a   solution  that  has  the 
following characteristics: 

  Visual:  co mmunicat ion  through  images  is  preferred  by 

young people. 

  Dynamic : to catch the users’ attention and curiosity. 

 

 

Intuitive:  with  an  accessible  interface  requiring  little  
time to get used to. 

Interactive: the user becomes pro-active, thus increasing 
the cognitive process [2]. 

  Multi-user:  to  pro mote  the  dynamic  part icipation  of  a  

group of people. 

 

These  requirements  are  co mmon  in  many  e xhib itions, 
and  various  technological  solutions  are  often  used  for 
enhanced  educational  effects;  these  include  multimedia, 
systems built specifically and VR technologies [3]. 

II.  CONCEPT DESIGN 

In  order  to  better  e xp lain  Mesoame rican  deities,  we  
opted  for  dynamic  imagery,  representing  them  in  mot ion, 
combined  with  a 
that  allows  several 
simu ltaneous  users  to select  icons,  drag  them,  and  display 
informat ion.  The  installation  was  designed  as  a  horizontal 
board around which several people can interact at the same 
time (Fig. 1). 

tactile  system 

It  is  within  this  context  that  we  developed  a  system  to 
introduce  some  deities  fro m  the  Mesoamerican  pantheon. 
It's a co mplicated issue, there is a  mu ltitude of de ities with 
varying  degrees  of  importance  and  they  are  subject  to 
changes,  such  as  their  names  and  representation  according 
to  the  historical  period  and  the  local  culture.  Research  on 
this 
for 
understanding 
roles  of 
prehispanic  deities.  We   now  know  that  they  represent 

subject  has  provided 
the  meaning, 

re levance  and 

important 

insights 

Fig. 1 The “Table of the Gods” installed in the Museum of Tlatelolco 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

1 

International Journal of Multimed ia Technology  (IJMT) 

The  informat ion  about  the  deities  was  structured  in  a 
simp le  way:  nine   ma jor  de ities  man ifest  in   motion  on  a  
background,  where  ten  suns,  eight  stars  and  three  comets 
randomly  appear,  soaring  through  and  generating  the 
contextual environ ment (Fig. 2).  

many users can manipulate the display simultaneously with 
varied  and  independent  events.  These systems  also  record 
the  pressure,  speed  and  direction  each  point  is  sending, 
opening  a  variety  of  options  that  provide  full  interactivity 
through natural user gestures. 

This 

feature 

represents  an 

in 
application progra mming methods because the interpretation 
of mu ltiple  variables in  pressure, gestures, and simu ltaneous 
events have to be taken into account. 

important  change 

Fig. 2 Screenshot of the application 

When the user touches, drags, or rotate one of the deit ies; 
its name is displayed, as well as a series of options in color 
circ les  around  the  deity.  When  touched,  these  options 
replace  the  central  image  with  an  a lternate  one  and, 
depending on the god, may d isplay a different representation; 
or  show  its characteristic  attributes  or  connections to  other 
deities;  other  options  linked  to  each  god  image  allow  to 
change the language or to return to the original image.  

There  are  several  unresolved  issues  in  mu lti-touch 
systems.  The  first  is  tied   to  traditional  Operating  Systems  
which  are  designed  to  work  with  a  single  point  of 
interaction, so applications have been developed in order to 
capture  the  movement,  interpret  it,  and  communicate  this 
informat ion  to  the  program,  there  a re  still,  however, 
limitat ions in their potential as  each  manufacturer develops 
its  own  solution.  The  second  issue  resides  in  the  lack  of 
standardization 
language  of  gesture-based 
communicat ion, although the iPad’s and iPhone’s popularity 
has promoted a more  unified form of use.  

the 

in 

IV. SOLUT ION 

The  development  must 

to: 
application-screen  communication  protocols; 
intelligent 
agent integration; object response to input and gesture; and 
mu lti-tactile  recognition and interpretation. 

solutions 

integrate 

III. BACKGROUND 

A.  Multi-Touch Communication Protocols 

The “Fie ry Pool: The Maya and the Mythic Sea”  sets a 
precedent to this work. Developed for the Peabody Museum 
in Essex in 2010 to e xhib it the Mayan wo rld  view regarding 
water and its related deities and ancestors. This setup uses a 
projector and peripheral  infra red sensors [4],  it's a technical 
solution  that  requires  a  great  deal  of  calibrat ion,  wh ich 
complicates  ma intenance,  so  we  opted  for  the  more  stable 
choice of a touchscreen device. 

Touchscreen  technology  development  started  back  in  
1972 and IBM  was the first company to market  it, based on 
infra red  technology,  it   contained  16  receptors  with in  the 
screen.  In  1984,  the  first  mult i-touch  screen  was  fu rther 
developed.  Bill  Bu xton  published  research  on  human -
computer interaction in 1986 [5][6] would  mark th is section 
of computer graphics developments for the following years. 
Research by the Mitsubishi Research Labs in 2001  revealed 
advances  in  comple x  gestures  interpretation,  which  were 
followed  by  the  works  of  Jefferson  Han  in  2005  and  the 
creation of Perceptive  Pixe l  Co [7]. At the same time , John 
Elias  and  Wayne  Westerman  developed  mu lti-touch 
surfaces  and  the  patents  were   bought  by  Apple  Inc.,  who 
integrated  all  of  thes e  advances  in  the  iPhone,  in  2007. 
Thirty-five  years  had  passed  since  the  beginning  of  the 
research  about  computer-human  interface,  it  had  been 
necessary to overcome the diffe rent screen defic iencies, find 
stable  and  affordable  technological  solutions,  a  few  years 
later, mu lt itouch screen would be completely installed in  our 
lifestyle. 

Multi-touch  systems  recognize  numerous  points  of 
contact  and  interpret  them  as  an  interface,  meaning  that 

We  opted  for  a  50’  plas ma  screen,  on  top  of  which  a 
PqLabs  32  touches  Multi-tactile   screen  was  mounted,  so 
numerous  users  can  interact  at  the  same  time  and  use 
various  fingers  to  add  up  to  32  po ints  of  contact.  The 
PqLabs screen is a transceiver kind fra me consisting of two 
LEDs that e mit  an in frared  beam and two photodiodes that 
receive  it,  being  able   to  detect  an  area  where  the  bea m  is 
interrupted by an object. 

When the signal is interrupted by an obstacle, no  matter 
the  color,  te xture,  shape  or  brightness  of  the  object,  the 
emitters recognize the (x,y) position on the screen and send 
the  informat ion  via   USB  using  TUIO  o r  WM_TOUCH 
protocols,  transmitt ing  the  interpretations  of  pressure  and 
gestures  from  the  tactile  surface  to  the  application.  The 
TUIO  p rotocol  [8]  (Tab le-top  Tangible   User  Interface) 
recognizes  an  infinite  a mount  of  points  of  contact  on  the 
screen  and  transmits  them  to  an  application  in  Open GL 
(Unix, Windows, and OSX)  meanwhile WM_TOUCH only 
works with directX and just allows eight points of contact. 

B.  The Virtual Space 

The  application  develop ment  and  its  integration  to  the 
interaction system was made possible by utilizing the Unity 
3.0 engine, this progra m is be ing used more  and more  in the 
production  of  interactive  materia l  made  for  museums  and 
the  internet,  since  it  offers  developmental  tools  in  mult i-
platform  environments,  as  well  as  ma king  possible  the 
programming  of  object-oriented 
language  scripts  and 
enables  the  development  of  e xternal  e xtensions  so  as  to 
meet  specific  needs,  which  has  opened  the  possibility  of  

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

2 

International Journal of Multimed ia Technology  (IJMT) 

ma king  numerous  plugins,  several  being  open  source.  Its 
ma rket  acceptance  is  also  a  guarantee  of  continuity  and 
updates for a few years. 

This tool manages to integrate the graphic  materia l in an  
organized  manner.  We  associated  behaviors  to  different 
objects and included interactive ele ments programed in  C#. 
One group includes all the  main co mponents of the project: 
deities, stars, suns, comets, buttons, counters, virtual screen 
delimitations, 
animated 
background.  Another  group  includes  the  elements  that 
comple ment the environment and the system: ca me ra, lights, 
and a mu lti-touch input manager. 

info rmation 

aspects, 

and 

Virtual Space Definition: each object moves in a random 
pattern  within  a  determined  space  wider  than  the screen  in 
order to let the object  fo llo ws its course as it  disappears and 
reenters  the  board  again  at  another  location.  As  the  object 
detects this space’s limits,  it  rotates and changes its course 
in  the  opposite  direction.  Simu lated  clouds  appear  in  the 
background;  this  animation  is  calculated  in  rea l  t ime   with 
“billboard” particles, te xturized with color. 

C.  Objects 

Given  their  independent  behavior  and  change  in  state, 
objects  fall  into  three  ma jor  categories:  Deity-objects,  Sun 
and Star-objects, and Co met-objects. 

1)  Properties and Traits: 

All  the  ele ments  found  in  the  virtual  space  have  an 
associated image to the m. In  addition, De ity-objects possess 
a  name,  buttons  linked  to  secondary  level  informat ion  and 
language  selection,  and  values  set  to  simu late  real-world-
physics-dependable behavior. 

 

 

Fig. 3 Object behaviour 

Sun-objects  and  Star-objects  move  in  a   separate  layer, 
therefore  avoiding  collision  with  the  De ity-objects.  What 
distinguishes these two groups is a variation in speed. 

Co met-objects possess a simpler definition; they appear 
on  the  board  sporadically  and  follow  a  linea l  path  as  they 
travel across. They’re located on a layer separated from the 
other  two  and  their  course  is  not  modified  when  they 
encounter  another  object.  They  have  set  and  random 
move ment  properties,  and  are  limited  by  the  virtual  space 
boundaries. Their move ment  speed is the highest among the 
objects  and  their  rando m  movement   is  the  min imu m 
required to obtain harmonic traversing.  

2)  Independent Behavior: 

D.  Interactivity 

To progra m the object behavior and move ment, we  used 
Unitysteer [9,10], an open source solution developed by the 
Arges Systems, a consulting company in the development of 
games  using  Unity.  It  allo ws  exe rting  control  over  generic 
objects’ behavior required to be provided with  independent 
move ment,  and  it  consists  of  a  set  of  libra ries  based  on 
OpenSteer and OpenSteerDotNet.  

Except for the Co mets, each of the objects that make up 

the application has the following properties (Fig. 3): 

  Vehic le-like  behavior,  wh ich  allows  establishing  initia l 

move ment and defined speed. 

  Random  move ment,  which enables the object to have a  
soft,  organic  behavior  and  to  simu late  how  it  would  
behave in real world physics. 

  Sonar or radar,  which sets up each element’s place ment 
within   the  board,  as  we ll  as  detecting  other  objects  or 
obstacles in proximity, in order to evade them, avoid ing 
their  piling  up  in  just  one  spot.  Each  object  takes  into 
account the position as well as the direction of the other 
objects,  calculates  the  trajectory  and  modifies  its  own 
route accordingly. 

  Movement  zone,  which  creates  an  allo wed  move ment 

quadrant for each of the objects. 

its 

translated 

information.  Gestures  are 

Touching an object stops its independent movement and 
displays 
into 
diffe rent  instructions  according  to  the  amount  of  points  of 
contact  on  the  board,  as  well  as  their  location  and  the 
distance  between 
the 
application  can  determine  the  amount  of  users  and  how 
many points are used by each one. 

them.  With 

information, 

this 

touches  are 

For  each  user,  a  single   touch  is  translated  as  a  cursor, 
while  mult iple 
interpreted  as  different 
independent  cursors.  The  user  can  drag  an  object  with  a 
touch;  this  combines  rotation  and translation  following  the 
orientation of the finger’s  move ment. Two  fingers are used 
to  rotate  an  object  and  the  fingers’  turning  direction 
determine  the  object’s  rotational  direction  in  regard  to  the 
object’s rotational center (Fig . 4). 

We  used  uniTUIO  for  the  mu lti-touch  gesture-based 
communicat ion between the screen and Unity. Un iTUIO  is 
free  software,  developed  in  2009  by  Sandor  Rozs a  and 
Stephan  Schlupek.  It  is  a  group  of  C#  libra ries  used  to 
interpret  the  inputs sent  through  the  touch  screen  and  into 
Unity.  Un ity  was  origina lly  conceived  to  deal  with  single-
user events, which not only affects the amount of users that 
can  interact  simu ltaneously,  but  also  gesture  possibilities 
and object dynamics. Un iTUIO was specifica lly  designed to 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

3 

International Journal of Multimed ia Technology  (IJMT) 

input 

events: 

resolve these problems, integrating mu lti-touch events to the 
object selection that Unity a lready possesses. It incorporates 
doTouchUP, 
new 
doTouchOutside, 
and 
manyTouch,  being  able  to  work  with  various  simu ltaneous 
events,  and  ma king  possible  for  an  object  to  interact  with 
several touches in an accurate way. 

doTouchDown, 

doubleTouch 

singleTouch, 

Fig. 4 Touch gesture 

 

Given the interaction and object  dynamics specifications 
this  application  has,  we  established  direct  communication 
with uniTUIO developers, so as to add physic properties to 
the objects and improve their response to input. The objects’ 
move ment  speed,  acceleration,  frict ion,  force   absorption, 
and direction of drag properties was modified and adjusted. 
Likewise,  two-finger  object  man ipulation,  mult iple -pointer 
(cursor) object selection and dynamic move ment response to 
diffe rent applied inputs was included. 

The  parameters  are:  mass ,  drag  value,  drag  angle,  drag 
distance, absorption and collision reduction and recoil. The 
mass value serves as a weight simulator enabling the object 
to  behave  as  heavy  or  light.  The  drag  value  establishes 
friction resistance and deceleration of objects in mot ion. The 
drag  angle  defines  the  friction  resistance  to  rotation.  The 
objects  have,  in  addition  and  so  as  to  avoid  rigid ity  when 
man ipulated,  absorption  and  recoil  characteristics  and  their 
move ment resemb les that of an elastic band. Several va lues 
were  defined to control the distance between the object drag 
and the point of contact, as well as the amount of co llision 
reduction. When an object is grasped with a quic k mot ion, it 
possesses  an  init ial  accele ration  factor  and  when  it  is 
winnowed  an 
reduce 
progressively its speed. In order for the objects to stay inside 
the virtual space, they have collision features that detect the 
screen’s  boundaries,  and  recoil  properties  so  they  can 
bounce off. 

is  generated 

inverse 

force 

to 

E.  Information Switching 

Only  deity-objects  image  can  switch  to  another  image, 
touching one  makes  a  set  of  6-7  co lored  buttons  to  appear 
around it, associated information is obtained when selecting 
a  button(Fig.  5).  One  button  selects  language  (Eng lish  – 
Spanish),  another  hides  all  other  options  and  displays  the 
image of the deity again  while  reverting to the independent 
move ment  properties.  A  hidden  time r  returns  the  object  to 
independent move ment after three minutes of inactivity.  

 

Fig. 5 Information switching 

F.  Independent Movement Changes 

Selecting  a  De ity-object  interrupts  its  move ments  and 
ma kes it  obedient to the motions and directions given by the 
user. When selected, Sun-objects and Star-objects lose their 
independent  move ment  and  re ma in  static  until  released. 
Co met-objects cannot be interacted with. 

V.  CONCLUSIONS 

The  board  installed  at  “the  Museum  of  Tlatelo lco” 
accomplished its exh ibit ion goal; users can watch the icons 
freely  mov ing and this attracts their attention, and since the 
mu lti-touch technologies are becoming increasingly p opular, 
when  users  approach,  they  immed iately  begin  to  interact 
intuitively with the application.   

However,  this  simp lic ity  conceals  a   great  deal  of  care  
and  comple xity   in   the  development  of  this  application,  as 
well  as  attention  to  details  in  the  object  b ehavior  and 
responses to user’s input interface. 

The  object’s  behavior  organization  and  progra mming 
need  a  lot  of  care,  because  it  is  necessary  to  define  the 
events  that  classify  individual  behaviors  assigned  to  each 
object: object and option selection, independent movements, 
solid  object  dynamics,  borders,  obstacles,  options  display, 
informat ion  switches,  language  selection,  and  t imers.  It  is 
important  to  establish  priority  events  and  tag  sets,  where 
every event and change can be stored in. 

The  integration  of  a   mult i-touch-screen  goes  beyond 
being  able  to  manage  mu ltip le  simu ltaneous  events;  it 
resides in the interaction imple menting possibilities between 
objects  and  users’  gestures.  Not  taking  advantage  of  this 
feature  would  mean  losing  one  of  the  most  imp ortant 
aspects  of  this  interface.  The  application  design  and 
development costs compensate the greater impact of its use. 

REFERENCES 

Orozco,  G.,  Interactive  museums  as  educational  mediators, 
Electronic  Journal  Kinetic,  vol.  26,  Feb-June  2005,  pp. 
38-50. 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

4 

International Journal of Multimed ia Technology  (IJMT) 

Table of the Gods: Development of a Multi-Touch 

App for Museum  
Geneviève Lucet*1, Víctor Godoy2 

Institute of Aesthetic Research, Nat ional Autonomous of Mexico , Me xico City, Me xico  

*1genevieve.lucet@gmail.co m; 2godoy.vic@gma il.co m 

 
 

Abstract-  We  descri be  the  development  of  an  application  
accomplished  in  a  museum  context  to  explain  the  varied 
representations, traits, an d connections between some of the  
deities  from  the  Mesoamerican  pantheon.  In  order  to 
attract  a  youn ger  au dience,  a  multi -user  interface  was  
implemented,  with  an intuitive interaction sys tem  base d on  
graphic information an d tou ch-screen technology.  

We  explain  the installed  app,  its  conceptual  design  and its 
implementation  with  the  Unity  engine.  The  development  has 
two main parts: the programming of the objects as intelligent 
agents  with  random  and  anti-collision  movement;  and  the 
multi-touch  screen  programming,  meaning  the  detection  and 
interpretation  of  different kinds  of  touches  and  gestures  and 
the changes they produce in objects behavior. 

Keywords-  Interface;  Multitouch;  Museum  Application; 

Behavior 

I. 

INT RODUCTION 

For  a   long  time ,  museu ms  we re  regarded  as  places 
where  pieces  or  co llect ions  valued  through  artistic  criteria  
were  e xh ibited  to  the  public.  Th is  idea  has  changed  in  the 
second  half  of  the  20th  century,  in  the  hopes  that  they 
become useful tools in the achievement of educational tasks 
towards  a  wide  but  predominantly  young  public  [1]. 
Another  goal  is  to  improve  the  population’s  knowledge  by 
motivating  self-study  and  solving  it  interest  about  a  wide 
range of  topics. 

Museums  dedicated  to  the  Hispanic  cultures  have  also 
evolved,  as  evidenced  by  "The  National  Museum  of 
Anthropology in Me xico" which  was designed with a c lear 
educational  purpose.  The  founding  of  “The  Museum  of 
Tlatelolco”  by 
(National  Autonomous 
University  of  Me xico)  and  INAH  (National  Institute  of 
Anthropology  and  History)  in  2011,  atte mpted  to  integrate 
the  mu ltidiscip linary  knowledge  of  history,  anthropology, 
arts,  science,  and  technology  to  show  that  the  areas  of 
science and humanities are integrated and combined in order 
to enrich and e xpand our approach to the past. 

the  UNAM 

concepts, so the comple xity of their defin ition and the links 
established  between 
the 
sophistication of the Mesoamerican way of thinking. For the 
Museum,  we   simp lified  the  informat ion  to  include  only  a  
subset of deities and only some of their attributes. 

them  can  be  measured  by 

In  order  to  e xpress  this  intricate  way  of  thinking  in  an 
appealing  way,  we  looked  for  a   solution  that  has  the 
following characteristics: 

  Visual:  co mmunicat ion  through  images  is  preferred  by 

young people. 

  Dynamic : to catch the users’ attention and curiosity. 

 

 

Intuitive:  with  an  accessible  interface  requiring  little  
time to get used to. 

Interactive: the user becomes pro-active, thus increasing 
the cognitive process [2]. 

  Multi-user:  to  pro mote  the  dynamic  part icipation  of  a  

group of people. 

 

These  requirements  are  co mmon  in  many  e xhib itions, 
and  various  technological  solutions  are  often  used  for 
enhanced  educational  effects;  these  include  multimedia, 
systems built specifically and VR technologies [3]. 

II.  CONCEPT DESIGN 

In  order  to  better  e xp lain  Mesoame rican  deities,  we  
opted  for  dynamic  imagery,  representing  them  in  mot ion, 
combined  with  a 
that  allows  several 
simu ltaneous  users  to select  icons,  drag  them,  and  display 
informat ion.  The  installation  was  designed  as  a  horizontal 
board around which several people can interact at the same 
time (Fig. 1). 

tactile  system 

It  is  within  this  context  that  we  developed  a  system  to 
introduce  some  deities  fro m  the  Mesoamerican  pantheon. 
It's a co mplicated issue, there is a  mu ltitude of de ities with 
varying  degrees  of  importance  and  they  are  subject  to 
changes,  such  as  their  names  and  representation  according 
to  the  historical  period  and  the  local  culture.  Research  on 
this 
for 
understanding 
roles  of 
prehispanic  deities.  We   now  know  that  they  represent 

subject  has  provided 
the  meaning, 

re levance  and 

important 

insights 

Fig. 1 The “Table of the Gods” installed in the Museum of Tlatelolco 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

1 

International Journal of Multimed ia Technology  (IJMT) 

The  informat ion  about  the  deities  was  structured  in  a 
simp le  way:  nine   ma jor  de ities  man ifest  in   motion  on  a  
background,  where  ten  suns,  eight  stars  and  three  comets 
randomly  appear,  soaring  through  and  generating  the 
contextual environ ment (Fig. 2).  

many users can manipulate the display simultaneously with 
varied  and  independent  events.  These systems  also  record 
the  pressure,  speed  and  direction  each  point  is  sending, 
opening  a  variety  of  options  that  provide  full  interactivity 
through natural user gestures. 

This 

feature 

represents  an 

in 
application progra mming methods because the interpretation 
of mu ltiple  variables in  pressure, gestures, and simu ltaneous 
events have to be taken into account. 

important  change 

Fig. 2 Screenshot of the application 

When the user touches, drags, or rotate one of the deit ies; 
its name is displayed, as well as a series of options in color 
circ les  around  the  deity.  When  touched,  these  options 
replace  the  central  image  with  an  a lternate  one  and, 
depending on the god, may d isplay a different representation; 
or  show  its characteristic  attributes  or  connections to  other 
deities;  other  options  linked  to  each  god  image  allow  to 
change the language or to return to the original image.  

There  are  several  unresolved  issues  in  mu lti-touch 
systems.  The  first  is  tied   to  traditional  Operating  Systems  
which  are  designed  to  work  with  a  single  point  of 
interaction, so applications have been developed in order to 
capture  the  movement,  interpret  it,  and  communicate  this 
informat ion  to  the  program,  there  a re  still,  however, 
limitat ions in their potential as  each  manufacturer develops 
its  own  solution.  The  second  issue  resides  in  the  lack  of 
standardization 
language  of  gesture-based 
communicat ion, although the iPad’s and iPhone’s popularity 
has promoted a more  unified form of use.  

the 

in 

IV. SOLUT ION 

The  development  must 

to: 
application-screen  communication  protocols; 
intelligent 
agent integration; object response to input and gesture; and 
mu lti-tactile  recognition and interpretation. 

solutions 

integrate 

III. BACKGROUND 

A.  Multi-Touch Communication Protocols 

The “Fie ry Pool: The Maya and the Mythic Sea”  sets a 
precedent to this work. Developed for the Peabody Museum 
in Essex in 2010 to e xhib it the Mayan wo rld  view regarding 
water and its related deities and ancestors. This setup uses a 
projector and peripheral  infra red sensors [4],  it's a technical 
solution  that  requires  a  great  deal  of  calibrat ion,  wh ich 
complicates  ma intenance,  so  we  opted  for  the  more  stable 
choice of a touchscreen device. 

Touchscreen  technology  development  started  back  in  
1972 and IBM  was the first company to market  it, based on 
infra red  technology,  it   contained  16  receptors  with in  the 
screen.  In  1984,  the  first  mult i-touch  screen  was  fu rther 
developed.  Bill  Bu xton  published  research  on  human -
computer interaction in 1986 [5][6] would  mark th is section 
of computer graphics developments for the following years. 
Research by the Mitsubishi Research Labs in 2001  revealed 
advances  in  comple x  gestures  interpretation,  which  were 
followed  by  the  works  of  Jefferson  Han  in  2005  and  the 
creation of Perceptive  Pixe l  Co [7]. At the same time , John 
Elias  and  Wayne  Westerman  developed  mu lti-touch 
surfaces  and  the  patents  were   bought  by  Apple  Inc.,  who 
integrated  all  of  thes e  advances  in  the  iPhone,  in  2007. 
Thirty-five  years  had  passed  since  the  beginning  of  the 
research  about  computer-human  interface,  it  had  been 
necessary to overcome the diffe rent screen defic iencies, find 
stable  and  affordable  technological  solutions,  a  few  years 
later, mu lt itouch screen would be completely installed in  our 
lifestyle. 

Multi-touch  systems  recognize  numerous  points  of 
contact  and  interpret  them  as  an  interface,  meaning  that 

We  opted  for  a  50’  plas ma  screen,  on  top  of  which  a 
PqLabs  32  touches  Multi-tactile   screen  was  mounted,  so 
numerous  users  can  interact  at  the  same  time  and  use 
various  fingers  to  add  up  to  32  po ints  of  contact.  The 
PqLabs screen is a transceiver kind fra me consisting of two 
LEDs that e mit  an in frared  beam and two photodiodes that 
receive  it,  being  able   to  detect  an  area  where  the  bea m  is 
interrupted by an object. 

When the signal is interrupted by an obstacle, no  matter 
the  color,  te xture,  shape  or  brightness  of  the  object,  the 
emitters recognize the (x,y) position on the screen and send 
the  informat ion  via   USB  using  TUIO  o r  WM_TOUCH 
protocols,  transmitt ing  the  interpretations  of  pressure  and 
gestures  from  the  tactile  surface  to  the  application.  The 
TUIO  p rotocol  [8]  (Tab le-top  Tangible   User  Interface) 
recognizes  an  infinite  a mount  of  points  of  contact  on  the 
screen  and  transmits  them  to  an  application  in  Open GL 
(Unix, Windows, and OSX)  meanwhile WM_TOUCH only 
works with directX and just allows eight points of contact. 

B.  The Virtual Space 

The  application  develop ment  and  its  integration  to  the 
interaction system was made possible by utilizing the Unity 
3.0 engine, this progra m is be ing used more  and more  in the 
production  of  interactive  materia l  made  for  museums  and 
the  internet,  since  it  offers  developmental  tools  in  mult i-
platform  environments,  as  well  as  ma king  possible  the 
programming  of  object-oriented 
language  scripts  and 
enables  the  development  of  e xternal  e xtensions  so  as  to 
meet  specific  needs,  which  has  opened  the  possibility  of  

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

2 

International Journal of Multimed ia Technology  (IJMT) 

ma king  numerous  plugins,  several  being  open  source.  Its 
ma rket  acceptance  is  also  a  guarantee  of  continuity  and 
updates for a few years. 

This tool manages to integrate the graphic  materia l in an  
organized  manner.  We  associated  behaviors  to  different 
objects and included interactive ele ments programed in  C#. 
One group includes all the  main co mponents of the project: 
deities, stars, suns, comets, buttons, counters, virtual screen 
delimitations, 
animated 
background.  Another  group  includes  the  elements  that 
comple ment the environment and the system: ca me ra, lights, 
and a mu lti-touch input manager. 

info rmation 

aspects, 

and 

Virtual Space Definition: each object moves in a random 
pattern  within  a  determined  space  wider  than  the screen  in 
order to let the object  fo llo ws its course as it  disappears and 
reenters  the  board  again  at  another  location.  As  the  object 
detects this space’s limits,  it  rotates and changes its course 
in  the  opposite  direction.  Simu lated  clouds  appear  in  the 
background;  this  animation  is  calculated  in  rea l  t ime   with 
“billboard” particles, te xturized with color. 

C.  Objects 

Given  their  independent  behavior  and  change  in  state, 
objects  fall  into  three  ma jor  categories:  Deity-objects,  Sun 
and Star-objects, and Co met-objects. 

1)  Properties and Traits: 

All  the  ele ments  found  in  the  virtual  space  have  an 
associated image to the m. In  addition, De ity-objects possess 
a  name,  buttons  linked  to  secondary  level  informat ion  and 
language  selection,  and  values  set  to  simu late  real-world-
physics-dependable behavior. 

 

 

Fig. 3 Object behaviour 

Sun-objects  and  Star-objects  move  in  a   separate  layer, 
therefore  avoiding  collision  with  the  De ity-objects.  What 
distinguishes these two groups is a variation in speed. 

Co met-objects possess a simpler definition; they appear 
on  the  board  sporadically  and  follow  a  linea l  path  as  they 
travel across. They’re located on a layer separated from the 
other  two  and  their  course  is  not  modified  when  they 
encounter  another  object.  They  have  set  and  random 
move ment  properties,  and  are  limited  by  the  virtual  space 
boundaries. Their move ment  speed is the highest among the 
objects  and  their  rando m  movement   is  the  min imu m 
required to obtain harmonic traversing.  

2)  Independent Behavior: 

D.  Interactivity 

To progra m the object behavior and move ment, we  used 
Unitysteer [9,10], an open source solution developed by the 
Arges Systems, a consulting company in the development of 
games  using  Unity.  It  allo ws  exe rting  control  over  generic 
objects’ behavior required to be provided with  independent 
move ment,  and  it  consists  of  a  set  of  libra ries  based  on 
OpenSteer and OpenSteerDotNet.  

Except for the Co mets, each of the objects that make up 

the application has the following properties (Fig. 3): 

  Vehic le-like  behavior,  wh ich  allows  establishing  initia l 

move ment and defined speed. 

  Random  move ment,  which enables the object to have a  
soft,  organic  behavior  and  to  simu late  how  it  would  
behave in real world physics. 

  Sonar or radar,  which sets up each element’s place ment 
within   the  board,  as  we ll  as  detecting  other  objects  or 
obstacles in proximity, in order to evade them, avoid ing 
their  piling  up  in  just  one  spot.  Each  object  takes  into 
account the position as well as the direction of the other 
objects,  calculates  the  trajectory  and  modifies  its  own 
route accordingly. 

  Movement  zone,  which  creates  an  allo wed  move ment 

quadrant for each of the objects. 

its 

translated 

information.  Gestures  are 

Touching an object stops its independent movement and 
displays 
into 
diffe rent  instructions  according  to  the  amount  of  points  of 
contact  on  the  board,  as  well  as  their  location  and  the 
distance  between 
the 
application  can  determine  the  amount  of  users  and  how 
many points are used by each one. 

them.  With 

information, 

this 

touches  are 

For  each  user,  a  single   touch  is  translated  as  a  cursor, 
while  mult iple 
interpreted  as  different 
independent  cursors.  The  user  can  drag  an  object  with  a 
touch;  this  combines  rotation  and translation  following  the 
orientation of the finger’s  move ment. Two  fingers are used 
to  rotate  an  object  and  the  fingers’  turning  direction 
determine  the  object’s  rotational  direction  in  regard  to  the 
object’s rotational center (Fig . 4). 

We  used  uniTUIO  for  the  mu lti-touch  gesture-based 
communicat ion between the screen and Unity. Un iTUIO  is 
free  software,  developed  in  2009  by  Sandor  Rozs a  and 
Stephan  Schlupek.  It  is  a  group  of  C#  libra ries  used  to 
interpret  the  inputs sent  through  the  touch  screen  and  into 
Unity.  Un ity  was  origina lly  conceived  to  deal  with  single-
user events, which not only affects the amount of users that 
can  interact  simu ltaneously,  but  also  gesture  possibilities 
and object dynamics. Un iTUIO was specifica lly  designed to 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

3 

International Journal of Multimed ia Technology  (IJMT) 

input 

events: 

resolve these problems, integrating mu lti-touch events to the 
object selection that Unity a lready possesses. It incorporates 
doTouchUP, 
new 
doTouchOutside, 
and 
manyTouch,  being  able  to  work  with  various  simu ltaneous 
events,  and  ma king  possible  for  an  object  to  interact  with 
several touches in an accurate way. 

doTouchDown, 

doubleTouch 

singleTouch, 

Fig. 4 Touch gesture 

 

Given the interaction and object  dynamics specifications 
this  application  has,  we  established  direct  communication 
with uniTUIO developers, so as to add physic properties to 
the objects and improve their response to input. The objects’ 
move ment  speed,  acceleration,  frict ion,  force   absorption, 
and direction of drag properties was modified and adjusted. 
Likewise,  two-finger  object  man ipulation,  mult iple -pointer 
(cursor) object selection and dynamic move ment response to 
diffe rent applied inputs was included. 

The  parameters  are:  mass ,  drag  value,  drag  angle,  drag 
distance, absorption and collision reduction and recoil. The 
mass value serves as a weight simulator enabling the object 
to  behave  as  heavy  or  light.  The  drag  value  establishes 
friction resistance and deceleration of objects in mot ion. The 
drag  angle  defines  the  friction  resistance  to  rotation.  The 
objects  have,  in  addition  and  so  as  to  avoid  rigid ity  when 
man ipulated,  absorption  and  recoil  characteristics  and  their 
move ment resemb les that of an elastic band. Several va lues 
were  defined to control the distance between the object drag 
and the point of contact, as well as the amount of co llision 
reduction. When an object is grasped with a quic k mot ion, it 
possesses  an  init ial  accele ration  factor  and  when  it  is 
winnowed  an 
reduce 
progressively its speed. In order for the objects to stay inside 
the virtual space, they have collision features that detect the 
screen’s  boundaries,  and  recoil  properties  so  they  can 
bounce off. 

is  generated 

inverse 

force 

to 

E.  Information Switching 

Only  deity-objects  image  can  switch  to  another  image, 
touching one  makes  a  set  of  6-7  co lored  buttons  to  appear 
around it, associated information is obtained when selecting 
a  button(Fig.  5).  One  button  selects  language  (Eng lish  – 
Spanish),  another  hides  all  other  options  and  displays  the 
image of the deity again  while  reverting to the independent 
move ment  properties.  A  hidden  time r  returns  the  object  to 
independent move ment after three minutes of inactivity.  

 

Fig. 5 Information switching 

F.  Independent Movement Changes 

Selecting  a  De ity-object  interrupts  its  move ments  and 
ma kes it  obedient to the motions and directions given by the 
user. When selected, Sun-objects and Star-objects lose their 
independent  move ment  and  re ma in  static  until  released. 
Co met-objects cannot be interacted with. 

V.  CONCLUSIONS 

The  board  installed  at  “the  Museum  of  Tlatelo lco” 
accomplished its exh ibit ion goal; users can watch the icons 
freely  mov ing and this attracts their attention, and since the 
mu lti-touch technologies are becoming increasingly p opular, 
when  users  approach,  they  immed iately  begin  to  interact 
intuitively with the application.   

However,  this  simp lic ity  conceals  a   great  deal  of  care  
and  comple xity   in   the  development  of  this  application,  as 
well  as  attention  to  details  in  the  object  b ehavior  and 
responses to user’s input interface. 

The  object’s  behavior  organization  and  progra mming 
need  a  lot  of  care,  because  it  is  necessary  to  define  the 
events  that  classify  individual  behaviors  assigned  to  each 
object: object and option selection, independent movements, 
solid  object  dynamics,  borders,  obstacles,  options  display, 
informat ion  switches,  language  selection,  and  t imers.  It  is 
important  to  establish  priority  events  and  tag  sets,  where 
every event and change can be stored in. 

The  integration  of  a   mult i-touch-screen  goes  beyond 
being  able  to  manage  mu ltip le  simu ltaneous  events;  it 
resides in the interaction imple menting possibilities between 
objects  and  users’  gestures.  Not  taking  advantage  of  this 
feature  would  mean  losing  one  of  the  most  imp ortant 
aspects  of  this  interface.  The  application  design  and 
development costs compensate the greater impact of its use. 

REFERENCES 

Orozco,  G.,  Interactive  museums  as  educational  mediators, 
Electronic  Journal  Kinetic,  vol.  26,  Feb-June  2005,  pp. 
38-50. 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

4 

International Journal of Multimed ia Technology  (IJMT) 

Paris, S., Perspectives on Object–Centered Learning in M useums, 
Lawrence  Elbaum  Associates,  M ahwah,  N.J.,  2002, 
pp.408. 

Caulton,  T.,  Hands-on  Exhibitions:  M anaging 

Interactive 
M useums  and  Science  Centres,  Routledge,  Nueva 
York,1998, pp.168. 

LM G,  Creatures  of  the  Fiery  Pool,  Peabody  Essex  M useum, 

http://rlmg.com/project/creatures-of-the-fiery-pool-4, 
consulted on M arch 10th, 2013. 

Buxton,  W.  &  Myers,  B.,  A  study  in  two-handed  input.  In 
Proceeding of CHI´86 Conference on Human Factors in 
Computing  System  Boston  M assachusetts.  1986,  pp. 
321–326. 

Baecker,  R.  &  Buxton,  W.,  Readings 

in  human-computer 
interaction:  A  multidisciplinary  approach,  M organ 
Kaufman Publishers, Inc., Los Altos, CA, 1987, pp. 950. 

M iette,  T.,  L es   t ech n o lo g i es   t acti l es   -  Hi s t o ri q u e  -  L ’o ri gi n e  d es  
t em ps ,  h tt p: // ww w -i g m .u ni v -m l v .fr/ ~d r/ XP OS E 2 0 0 8 / L es  
t ech n ol o gi es  t acti l es/ hi st o _ o ri gi n e.h t ml , Xp o s és  S y st èm es  
et  R és eau x , co n s u lt ed  o n  M arch  1 0 th , 2 0 1 3 . 

Kaltenbrunner,  M .,  Bovermann,  T.,  Bencina,  R.  &  Costanza,  E., 
for  Table-Top  Tangible  User 
TUIO  A  Protocol 
Interfaces,http://opensoundcontrol.org/files/tuio_gw2005
.pdf , 2005. 

Reynolds,  C.  W.,  Flocks,  herds  and  schools:  a  distributed 
behavioral  model,  Proceedings  of  the  14th  annual 
conference  on  Computer  graphics  and 
interactive 
techniques, ACM , 1987, pp. 25–34, New York, USA. 

Reynolds, C. W., Steering Behaviors For Autonomous Characters, 
Game  Developers  Conference,  1999,  pp.  763–782,  San 
Jose, California, U SA. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

IJMT Vo lu me 3, Issue 4 Dec. 2013 PP. 1-5 www.v kingpub.com @ A merican V-King Sc ientific  Publishing 

5 

